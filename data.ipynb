{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import BERTScorer\n",
    "\n",
    "model_type = \"facebook/bart-large\"\n",
    "model_lang = \"en\"\n",
    "# load scorer\n",
    "bert_scorer = BERTScorer(model_type=model_type, lang=model_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/hdu5/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset csv (/home/hdu5/.cache/huggingface/datasets/csv/default-4327c2f5a178f0c7/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['pid', 'document', 'summary'],\n",
      "        num_rows: 484\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "raw_datasets = load_dataset('csv', data_files={'train': 'AutoReview_summarized.csv'\n",
    "                                            #    'validation': 'dataset/all_data_val/all_data_val.csv',\n",
    "                                            })\n",
    "print(raw_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "DF = pd.DataFrame(columns=['pid', 'document', 'summary', 'classification'])\n",
    "cnt_dict = {'pid':[], 'cnt':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get each sentence from the original summary\n",
    "for item in raw_datasets['train'] : \n",
    "    # print(item['summary'])\n",
    "    # res = item['summary'].split('.')\n",
    "    res = nlp(item['summary'])\n",
    "    cnt = 0 # number of positive examples\n",
    "    for sent in res.sents :\n",
    "        # print(sent)\n",
    "        str_summary = str(sent)\n",
    "        str_pid = item['pid']\n",
    "        str_doc = item['document']\n",
    "        str_classification = '1' # those are positive test cases\n",
    "        # print(pd.Series([str_pid, str_doc, str_summary], index=DF.columns))\n",
    "        cnt = cnt + 1\n",
    "        DF = DF.append(pd.Series([str_pid, str_doc, str_summary, str_classification], index=DF.columns), ignore_index=True)\n",
    "        # break\n",
    "    cnt_dict['pid'].append(str_pid)\n",
    "    cnt_dict['cnt'].append(cnt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_negative(index, positive_examples_lst) :\n",
    "    while True :\n",
    "        random_index = random.randint(0, len(cnt_dict['pid'])-1)\n",
    "        if random_index != index :\n",
    "            break\n",
    "    \n",
    "    random_pid = cnt_dict['pid'][random_index]\n",
    "    for i in raw_datasets['train'] :\n",
    "        if i['pid'] == random_pid :\n",
    "            # print('llll')\n",
    "            random_from_raw = i\n",
    "            break\n",
    "    # print(random_pid)\n",
    "    # raw_datasets['train'][]\n",
    "    # print(random_from_raw['summary'])\n",
    "    res = nlp(random_from_raw['summary'])\n",
    "    # print(res)\n",
    "    str_summary_lst = []\n",
    "    for sent in res.sents :\n",
    "        str_summary_lst.append(str(sent))\n",
    "    random_sent = str_summary_lst[random.randint(0, len(str_summary_lst) - 1)]\n",
    "    cmp_lst = []\n",
    "    \n",
    "    # positive_examples_lst = positive_examples['summary'].values.tolist()\n",
    "    for i in range(len(positive_examples_lst)) :\n",
    "        cmp_lst.append(random_sent)\n",
    "    # print(\"asdf: \"+cmp_lst[0])\n",
    "    return cmp_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case0: attempt0\n",
      "└------case0 attempts: 0\n",
      "└------case0 attempts: 1\n",
      "└------case0 attempts: 2\n",
      "└------case0 attempts: 3\n",
      "└------case0 attempts: 4\n",
      "└------case0 attempts: 5\n",
      "└------case0 attempts: 6\n",
      "└------case0 attempts: 7\n",
      "└------case0 attempts: 8\n",
      "└------case0 attempts: 9\n",
      "└------case0 attempts: 10\n",
      "└------case0 attempts: 11\n",
      "└------case0 attempts: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_83767/446231010.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mcmp_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_random_negative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_examples_lst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mcmp_lst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmp_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m30\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mcmp_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_random_negative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_examples_lst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m# if len(str_summary_lst) > len(positive_examples_lst) :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#     str_summary_lst_copy = str_summary_lst.copy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_83767/3112157037.py\u001b[0m in \u001b[0;36mgenerate_random_negative\u001b[0;34m(index, positive_examples_lst)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# raw_datasets['train'][]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# print(random_from_raw['summary'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_from_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'summary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m# print(res)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mstr_summary_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1011\u001b[0m                 \u001b[0merror_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_error_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m                 \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m                 \u001b[0;31m# This typically happens if a component is not initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cur_LOC = 0\n",
    "F1_lst = []\n",
    "threshold = 0.45\n",
    "# display(f) # display the bar\n",
    "\n",
    "\n",
    "neg_DF = pd.DataFrame(columns=['pid', 'document', 'summary', 'classification'])\n",
    "# generating negative examples from positive examples\n",
    "for i in range(len(cnt_dict['pid'])) :\n",
    "    # print (i)\n",
    "    num_of_positive = cnt_dict['cnt'][i]\n",
    "    # print(num_of_positive)\n",
    "    positive_examples = DF.loc[cur_LOC:num_of_positive]\n",
    "    # print(positive_examples)\n",
    "    positive_examples_lst = positive_examples['summary'].values.tolist()\n",
    "    # generate a random index\n",
    "    cmp_lst = generate_random_negative(i, positive_examples_lst)\n",
    "    while (not cmp_lst) or len(cmp_lst[0]) < 30 :\n",
    "        cmp_lst = generate_random_negative(i, positive_examples_lst)\n",
    "    # if len(str_summary_lst) > len(positive_examples_lst) :\n",
    "    #     str_summary_lst_copy = str_summary_lst.copy()\n",
    "    #     str_summary_lst = str_summary_lst[:len(positive_examples_lst)]\n",
    "\n",
    "    # while len(str_summary_lst) < len(positive_examples_lst) :\n",
    "    #     str_summary_lst.append(str_summary_lst[-1])\n",
    "        \n",
    "    P, R, F1 = bert_scorer.score(positive_examples_lst, cmp_lst)\n",
    "    attempts = 0\n",
    "    print(\"case\"+str(i)+\": attempt\"+str(attempts))\n",
    "    while np.average(F1.numpy()) > threshold :\n",
    "        print(\"└------case\"+str(i)+\" attempts: \"+str(attempts))\n",
    "        cmp_lst = generate_random_negative(i, positive_examples_lst)\n",
    "        while (not cmp_lst) and len(cmp_lst[0]) < 30:\n",
    "            cmp_lst = generate_random_negative(i, positive_examples_lst)\n",
    "        P, R, F1 = bert_scorer.score(positive_examples_lst, cmp_lst)\n",
    "        attempts = attempts + 1\n",
    "\n",
    "    for examples in cmp_lst :\n",
    "        str_pid = DF.loc[cur_LOC]['pid']\n",
    "        str_doc = DF.loc[cur_LOC]['document']\n",
    "        str_summary = cmp_lst[0]\n",
    "        str_classification = '0'\n",
    "        neg_DF = neg_DF.append(pd.Series([str_pid, str_doc, str_summary, str_classification], index=DF.columns), ignore_index=True)\n",
    "    F1_lst.append(np.average(F1.numpy()))\n",
    "    cur_LOC = cur_LOC + num_of_positive\n",
    "    # f.value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The class hierarchy didn't need to be included in this document.  Not sure why it was.\\nThe wiki is supposed to explain why you've written what you wrote.  But you seem to have copied the code and inserted only a line or two, not much more than in the comments in the code file.\""
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_from_raw['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.to_csv('positive.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_lst[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "673a99767848cb7d35ee205e5e64298b812442fab0c68f5f28d800550018a90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
