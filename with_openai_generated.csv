,pid,document,summary,openai_generated
0,E2011,"This page provides a description of the Expertiza based OSS project. <link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. The two major tasks for this project were the following: 1. Refactor existing test cases to follow good coding practices. This includes variable names, following the Don't Repeat Yourself (DRY) principle, and more. 2. Check coverage of assignment_creation_spec.rb and improve upon it through additional testing. The assignment_creation_spec file contains test cases that ensure proper functionality of an instructor's workflow in regards to the creation of assignments. An instructor, when logged into Expertiza, should be able to create new assignments where each assignment has its own assigned parameters, rubrics, review strategies and due dates. At the start of this project, all logic and handling of testing this instructor workflow was handled within a single file. This single-file implementation leads to problems with maintenance, and such problems within this implementation can be abstracted into one of these forms: 1. File is too long : This file exceeds 250 lines of code, and should not. 2. Block has too many lines : Within the file, the code used to handle a certain operation is implemented with too many subroutines within one block. 3. Similar/Exact block(s) of code found : Across the file, there were duplicate/near-duplicate blocks of code being used. 4. General syntax issues : This could include unnecessary whitespace, use of deprecated classes or things of the like. The first refactor that our team did was to extract methods from what otherwise would be duplicate code and large block sizes. The previous team had started this process, but we were able to follow it to completion. We also then moved all of these extracted methods into the helper class assignment_creation_helper.rb. Here is an example of extracted methods that the previous team had created: <code> The following is an example of how we were able to reduce block size and duplicate code with further extraction of methods into assignment_creation_helper.rb: <image> Another major refactor we did was to break up the one large 'describe' block in assignment_creation_spec, which contained all of the tests for that controller. Since assignment creation has many different pages, we created a separate file for testing each page or responsibility. Beyond the creation of the helper file, assignment_creation_spec.rb was broken up into the following files: 1. assignment_creation_dates_spec.rb 2. assignment_creation_deadlines_spec.rb 3. assignment_creation_general_tab_spec.rb 4. assignment_creation_page_spec.rb 5. assignment_creation_participants_spec.rb 6. assignment_creation_review_strategy_spec.rb 7. assignment_creation_rubrics_spec.rb 8. assignment_creation_topics_spec.rb In the relocation of assignment_creation_spec's functionality and creation of new constituent files, additional refactoring was done to ensure that trailing whitespace was deleted, files ended with a final newline character, and other unnecessary characters were removed. All of this was to remove any other problems that code climate detected. There were a few things that code climate detected that we decided did not need to be refactored. The first was a complaint about blocks being too large, even after we divided the one large 'describe' statement into many smaller ones. This is because, in rspec, each test has its own 'it' block, but all of those must be grouped in a larger 'describe' block. I suggest that this be discussed with the teams who may refactor the other test files or have code climate to be configured to instead look just at the 'it' block size. This is an diagram on how otherwise good ruby code may be flagged by code climate: <code> Additionally, code climate was suggesting to change DateTime to Date or Time. As assignments are due not only on a certain day but at a specific time and that this would require a large refactoring of the entire Expertiza system for tracking submission times, we decided it was beyond the scope of this refactor. As part of the refactoring, we fixed a few broken tests in the original assignments_controller_spec.rb and created additional ones to increase coverage. We used TDD to see which tests that were created were breaking and used that to drive our implementation of the controller. Here is the extensive list of test cases handled 1. assignments_controller_spec.rb -allows edit when an admin -allows edit when an instructor -does not allow edit when TA of course but not TA of current assignment -allows new when admin/instructor/ta -does not allow new when student -#new creates a new AssignmentForm object and renders assignment#new page -when assignment_form is saved successfully, it redirects to assignment#edit page -when assignment_form is not saved successfully, it renders assignment#new page -when assignment has staggered deadlines, it shows a flash message and renders edit page -during update when params does not have key :assignment_form, it shows a note flash message and redirects to tree_display#index page -when assignment is not saved successfully, it shoes an error flash message and redirects to assignments#edit page -when the timezone preference of current user is nil and assignment form updates attributes successfully, it shows an error message and redirects to assignments#edit page -when the timezone preference of current user is not nil and assignment form updates attributes successfully, it shows an error message and redirects to assignments#edit page -on action #show, it renders the #show page -when new assignment id fetches successfully, it 'redirects to assignments#edit page -when new assignment directory is same as old it should show an error and redirect to assignments#edit page -when new assignment id does not fetch successfully, it shows an error flash message and redirects to assignments#edit page -when assignment is deleted successfully, it shows a success flash message and redirects to tree_display#list page -when assignment is not deleted successfully, it shows an error flash message and redirects to tree_display#list page -when assignment is removed from course successfully, it removes assignment and redirects to tree_display#list page -showing list submissions (the following are the assignment_creation_spec.rb split into files by responsability) 2. assignment_creation_dates_spec.rb -it is able to create assignment with a new late policy -it is able to set the deadline for an assignment review 3. assignment_creation_deadlines_spec.rb -it is able to set the deadline for an assignment review 4. assignment_creation_general_tab.rb -it should edit assignment available to students -it should edit quiz number available to students -it should edit number of members per team -it should edit review visible to all other reviewers -it should check if checking calibration shows the tab 5. assignment_creation_page_spec.rb -it is able to create a public assignment -it is able to create with teams -it is able to create with quiz -it is able to create with staggered deadline -it is able to create with review visible to all reviewers -it is able to create public micro-task assignment -it is able to create calibrated public assignment -it is able to show tab review strategy -it is able to show tab due deadlines -it should set the deadline for an assignment review -it is able to show tab rubrics -it is able to show attributes in rubrics -it should sets attributes for review strategy auto selects -it should check to find if the assignment can be added to a course 6. assignment_creation_participants_spec.rb -it should check to see if participants can be added -it should display newly created assignment 7. assignment_creation_review_strategy_tab.rb -it should auto selects correct values -it should set number of reviews by each student 8. assignment_creation_rubrics_strategy_tab.rb -it should update review questionnaire -it should update scored question dropdown -it should update author feedback questionnaire -it should update teammate review questionnaire 9. assignment_creation_topics_spec.rb -it can edit topics properties -it procedes without topics properties -it can create new topics -it can delete existing topic -it hides topics tab when has topics is un-checked. Looking at the methods that were covered in assignments_controller.rb we decided to create the following additional test cases for assignment creation. These are additions to the existing assignments_controller_spec.rb. <image>. Links to RSpec screencasts for new test cases. 1. <link> 2. <link> 3. <link>. 92.86% for assignments_controller.rb Overall coverage increased (+28.04%) to 52.334%. 1. <link>.","The wiki was to the point and explains all the code changes they have made. Why they touched some parts of code and why they didn't touch the others. Their test plan mentions a list of all the test cases that are currently covered. It's not clear how that list is organized, and given that there are dozens of items, there needs to be a logical ordering to them. Also, they did not mention how they have tested it manually. Some reviewers complained that they did not know how to test it properly since their test plan did not cover it. ","You have done an excellent job explaining the complexities of the project and detailing the work you and your team have done. The description of the initial state of the code and the problems it featured was clear and well-organized. Your approach to refactoring was systematic and you provided illustrative and relevant examples which make it easier to understand the task that you were handling.

The breakdown of dividing the assignment_creation_spec.rb file into multiple specific ones, each with its own responsibility, was a great step towards better code organization. I also appreciate how you listed down the extensive list of test cases.

You were thoughtful about justifying which issues flagged by code climate were necessary to refactor and which ones weren't, this shows an understanding of practical programming considerations beyond simple adherence to a tool's recommendations. It was good seeing that you decided not to change DateTime to Date or Time, since it would require a lot of work outside of the defined scope of the project.

It is impressive that you were able to increase overall test coverage by more than 28% bringing it to a total of 52.334%. This represents a significant improvement in the overall robustness and maintainability of the Expertiza codebase and your team deserves to be commended for this.

In regards to future improvements, providing more context to the reader about terms such as DRY would be helpful. Not all readers may be familiar with these terms. Also, unless it is an image displaying code, figures should nearly always be supplied with a caption describing what they are demonstrating. The report would have greatly benefited from more explanations of the code snippets and images included in your submission.

The assignment was thoroughly done, and you should pride yourself on the detail and quality of your work. Overall, your submission is comprehensive and clear. Well done!"
1,E1682,"Expertiza is an open source project for school assignment management for instructors and students based on the Ruby on Rails framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and word documents. Expertiza provides a dashboard for all the assignments corresponding to a course and provides absolute control to the Instructors and Teaching Assistants. In addition to assignments, it encompasses peer reviews wherein participants are allowed to provide feedback anonymously about each other's work thereby providing scope for the better outcome. The due_date.rb file is responsible for informing the users about the deadline for submission of the each assignment. Due dates in Expertiza have their association with many other components like assignments, reviews etc. The purpose of the project is to improve the functionality of score calculation. The scores in expertiza were calculated by taking the sum of weighted scores to calculate the total every time it is called. This takes considerable amount of time as there is a calculation involved each time. The methodology behind score calculation in expertiza can be significantly improved. The design behind calculating and storing scores can be tweaked to offer significant performance improvements. To achieve this, it is ideal to store overall holistic stores in addition to individual criterion scores. The current drawback of the expertiza system lies in how the scores are stored: Expertiza stores the scores based on each response to each criterion, but no holistic scores are stored. As a result of this mechanism, the process slows down. This means that if we need to know what score user A gives to user B based on 100, we have to rely on the code to calculate it (since in answers table we only have the score that A gives B on each criterion). To overcome this bottleneck, two additional mechanisms can be included for handling the holistic scores. Expertiza currently calculates scores dynamically when a page is called by taking the weighted scores of each question into consideration. This calculation is a time consuming process with a considerable overhead that significantly affects the performance. To solve the issue we propose a solution to store the holistic scores in a database, retrieving it every time it is required. This reduces the calculation that is required every time the score is called. When the user wants to check the scores of a completed assignment, a method localDB_calc is called and expertiza retrieves the scores of the student from the database rather than calculating the total from weighted scores. But, when the scores of an ongoing assignment is required, a method on_the_fly_calc is called that calculates the current score of the user. To determine which method will be invoked(on_the_fly_calc and localDB_calc), the current system time will be compared with last_review_deadline 1. If system time is greater than last_review_deadline, indicating that the deadline has passed, the method localDbcal will retrieve the holistic score from the database 2. If system time is lesser than last_review_deadline, indicating that the deadline has not passed, the method on_the_fly_cal will calculate the holistic score and display it. The Dataflow diagram (DFD) for the proposed system is shown below. <image> flowchart. The two suggested mechanisms for handling the storage and calculation of holistic scores for peer-reviews, as specified in the requirements document are : 1. on_the_fly_calc 2. localDB_calc. When the assignment is still ongoing , this method is called and it calculates holistic scores over a set of data (in this case, a set of record in answers table, namely the responses from user A to user B on each criterion) and store it in localdbscores. This stored score is retrieved and printed when the user A clicks on the ""Your scores"" link. In the current implementation, when a user A wants to view the score given by user B, user A's score(i.e. out of 100) will be calculated everytime using the scores given by user B for each criterion (i.e.. score out of 5). Handles the calculation of reputations for each reviewer in the case of an ongoing assignment. Once the deadline for an assignment is completed, the method localDB_calc calculates the holistic score over a single db query (in this case, a query would be: “get the score that user A gives user B on assignment 999 on round 2”). The query can also ask to print the average of all the scores in round 1 and round2, this average will be retrieved from localdbscores and printed. This method handles the calculation of reputations for each reviewer in the case of a finished assignment. (all the reputations are calculated and stored since they are finalized). To store the holistic scores when an assignment is completed, a database localdbscores needs to be created. The value from this db is retrieved and displayed when the scores of a completed assignment needs to be viewed. The database Design is shown below. A table localdbscores will be created as: class CreateLocalDB<ActiveRecord::Migration def self.up create_table :localdb_scores do |t| t.column :id, :integer t.column :score, :integer t.column :round, :integer t.column :type, :string t.column :reference_id, :integer end with id, score, round, type, reference_id as its attributes as shown in the table below ""localdbscores"" will have the following scores <table>. A new function get_last_review_date is added which takes assignid as a parameter and returns the last review deadline of the assignment. The deadline obtained from AssignmentDueDate for the corresponding assignid is stored in last_review_deadline and is returned. ScoreCal stores the score calculated by its sub classes: on_the_fly_cal and LocalDbcal to the database. In the database, a new table localdbscore is created with the schema as explained in section 2.2. Depending upon the deadline_type, object of either on_the_fly_cal or LocalDbcal is created and the appropriate functions within the classes are called. This is a subclass of class Scorecal contains a method calc_score whose functionality is to compute the holistic score. An object of on_the_fly_cal is called when the current time has not yet surpassed the time stored in last_review_deadline variable which contains the review duedate indicating that the assignment is still ongoing and has not been completed. The individual scores are retrieved from the database ScoreView and is stored in QuestionnaireData from which the holistic score of a student is calculated . When the user accesses the scores for a review, the current implementation does not store a holistic score but rather calculates the holistic score from the score for every individual criterion. To calculate the total holistic score for a specific round, the individual scores are weighted and added. This functionality is achieved by on_the_fly_calc. A snapshot of the system before implementing the changes is shown below. <image> The proposed implementation involves computing the holistic score once and storing it in the local_db_scores database for a particular user and for a specified round. The stored value is accessed and obtained instead of computing the holistic score every single time. <image>. This is a subclass of Scorecal and contains a function calc_score in class localDbcal. An object of LocalDbcal is called when the current time has surpassed the time stored in last_review_deadline variable which contains the review due date indicating that the assignment has been completed. This subclass retrieves the score from the database localDbscores for a corresponding student. If the score is not found in the database localDbscores, the function calc_score of on_the_fly_cal class is called to calculate the total from the weighted scores of each question. This calculated score is then inserted into the database. This score is now returned to the view from where it was called. <image> The proposed implementation retrieves the round wise scores from the local_db_scores database and displays the average score once the deadline has passed rather than computing the average of the weighted scores for every access of the page as shown below. <image>. The current implementation of this was to calculate the score and display it which as we know is a time consuming process. It has been changed to check if the current time has crossed the last_review_deadline obtained in assignments.rb and call the corresponding class as required. If the current date has surpassed the last_review_deadline, it is an indication that the due date has passed and the class localDbcal is called to retrieve a value from the database as mentioned above. On the other hand, on_the_fly_cal is called when the current date has not surpassed the last_review_deadline, indicating that the assignment is ongoing and the holistic score is calculated and passed to the view. The ScoreCal superclass has 2 subclasses: OnTheFlyCal and LocalDbCal. ScoreCal acts as an interface to obtain the scores, either from OnTheFlyCal or LocalDbCal depending on the last_review_deadline obtained from the get_last_review_date() in the assignment model. This pattern is similar to strategy pattern where the client is the _review_tble.html.erb, interface is the superclass and the subclasses are called accordingly. <image>. <image> The actors are : 1.Reviewer 2.Reviewee 3.Instructor/TA The reviewer selects a topic from the list of topics to be reviewed and starts the review. He allots scores out of 5 for every question and the avaerage of this score gets stored in the database when the reviewer clicks on submit. The reviewee views this stored score when he clicks on ""view scores"". The testing for model: on_the_fly_calc is carried out by questionnaire_spec.rb in the spec folder. The minimum and maximum score that an user gives for each criterion is checked. Two more test cases to check whether the average score of each review falls within a given range:(0,100) will be added. For LocalDB_calc, the average calculated across round 1 and round 2 will be checked to fall within 0 to 100. These test cases will be added to questionnaire_spec.rb.","The doc could be significantly improved by providing code examples of how to use the SSO service on each use case. e.g., what did you change on the rainbow service to use the SSO?","This is a thorough and comprehensive assignment submission. Your detailed understanding of Expertiza and its score calculation process is impressive. You have demonstrated an understanding of how the system works and have proposed a well-thought-out solution that could improve its efficiency. Your diagrams illustrate your ideas very well, and the use of visual aids is encouraged as it helps with understanding complex systems.

For improvement, there are few areas that need to be refined. While your explanation of the proposed methodology is thorough, it could be more concise. Try to eliminate any redundancies in your writing. Also, clear organization of the information presented could greatly improve the readability. Using headings and subheadings can help readers more easily understand your proposal and follow your thought process. 

Furthermore, there are several typographical errors and a few instances of awkward phrasing throughout your proposal. Proofreading your work and utilizing a grammar correction tool could help you catch these mistakes in the future. 

Lastly, while you proposed to improve the score calculation functionality, you did not provide much detail about how this would be implemented and tested in practise. More information about the specifics of these changes would increase the practical feasibility of your proposal. 

In conclusion, this is a well-researched project with a lot of potential. Keep up the good work and take these suggested improvements into your future works.

Grade: B+"
2,E1628,"The main goal of the project is to present the data in more convenient way and also improve the existing visualization present in expertiza. We plan to improve /grades/view_my_scores and grades/view_team pages.Presently /grades/view_my_scores has got many line breaks between the reviews and score is displayed in text.In grades/view_team originally there was no option to sort the data.We plan to provide an option to sort the data by avg score and also display high scored reviews on left of the table so it would be easy to analyze at simple glance. 1. When a review is shown, use different background colors for adjacent responses or adjacent reviews, instead of so much whitespace. 2. In the “alternate view,” 1. Clicking on “Avg.” should sort the rows by average score, from highest to lowest. Clicking again should change the sort order to from lowest to highest. Clicking a 3rd time should change it back to highest to lowest, etc. 2. Clicking on some other button or icon should sort the columns in terms of total review scores. Clicking once should bring the highest-scored review to the right; clicking again should bring the lowest-scored review to the left, etc. 3. Hovering over a box that has a text comment associated with it should show the comment in a “tool tip” format. 4. Hovering over a number in the “Question id” column should bring up a “tool tip” that shows the text of the criterion (question). 5. The “Question ID” label should be changed to “Criterion”. In the view that displays the reviews for the given assignment, each of the reviews are individuals div elements. To make use of existing Bootstrap CSS for displaying individual reviews with different background color, the reviews need to be part of a table. After changing this to a table, the bootstrap's table table-striped class can be added to the table to get alternate grey and white rows. The extra white space tags, horizontal rules, are removed since the table will take care of separating individuals rows. To achieve task 2.a we intend to use tablesorter jQuery plugin. Tablesorter auto-detects the data types in the table and sort the rows either in ascending or descending order when a column header is clicked. Install Add the following line in Gemfile <code> Including tablesorter in the project Add the following line to app/assets/javascripts/application.js <code> Usage In the table add table sorter class as shown below <code> To achieve task 2.c and 2.d we will be including ""tooltip"" offered by Bootstrap to all the cells in the table with title attribute set to contain comment or criterion based on the data cell. The following attributes should be added to the respective cells in the table to get the tooltip text on hover <code> To achieve task 2.e we will be renaming ""Question Id"" table header to ""Criterion"". The UI mock-ups for the tasks of the project are shown below. Colored background for different reviews <image> Individual reviews before modification <image> Individual reviews after modification <image> Alternate view before modification <image> Alternate view after modification <image> Tooltip for individual cells (Note: The screenshot utility doesn't capture the mouse pointer) <image> <image>. These are the files that are modified 1. views/grades/_reviews.html.erb 2. views/grades/view_team.html.erb The review page involves different question types, and to reduce the whitespace and remove the obvious terms out of the way (like Score , Response , etc), changes were done to the corresponding HTML code. But, the HTML code for these in the project is not in the view, but generated in the model. So the following files were modified to get the concise look. 1. app/models/checkbox.rb 2. app/models/criterion.rb 3. app/models/dropdown.rb 4. app/models/response.rb 5. app/models/scale.rb 6. app/models/section_header.rb 7. app/models/text_area.rb 8. app/models/text_field.rb. Here are the steps necessary to perform UI testing on the project. Note that the accounts refer to the Expertiza VCL image. Note : The deployed code makes use of the expertiza-development database. About half of the assignments listed under a student's profile will lead to an error (probably because of missing/bad database entry). We have identified a couple of login IDs and the corresponding assignments that do not give any error. Those are listed below in the steps. Alternate IDs: 1. student1861 > OSS/Final project 2. student1864 > Final project 3. student4332 > OSS/Final project 4. student5555 > CSC 515 project.. 5. instructor6 > Go to tree_display->assignments. Search for 'Final project'. Click on 'View scores icon'(the one with a star). View the individual team scores. (Note that loading this page takes ridiculously long). 1. Login as student1864 , password is password . 2. Select the Final project assignment. 3. Select Your scores . 4. Select show reviews . 1.1. You'll see that reviews alternate in color between light gray and white. Some extra whitespace has been removed between reviews, so they appear more compact. 5. Select show review next to Review 1 in Round 2. 1.1. Here you'll see that the questions alternate in color between light yellow and light blue. The point value for the question is displayed in a colored circle. The colors are the same as in the heat table in the alternate view. The maximum point value is not located to the right of the question text. Extra whitespace has been removed. 1. Login as student1864 , password is password . 2. Select the Final project assignment. 3. Select Alternate view . 1.1. The Question Id column has been renamed to Criterion . 1.2. Hovering over a cell in the Criterion column will display a tooltip that shows the question text for that row. 1.3. Hovering over any cell in a review column will show the response text for the corresponding question and review. 1.4. The Avg column is sortable. Clicking it will sort in ascending order, then descending order, then back to ascending order. 1.5. The Criterion column is also sortable. This is so that the original ordering of the rows can be restored. 1.6. There are two links, ASC and DESC underneath the table. Clicking them will sort the review columns in the table in ascending/descending order of total review score. Some of the existing test cases involving the different question types were checking the actual HTML contents of the rendered page, and asserting them against an expected HTML code. While this is not the ideal way to test, the corresponding test case changes were made (owing to the change in the model files that generated the HTML code). The following Rspec files were modified to pass with the new code 1. spec/features/calibration_spec.rb 2. spec/models/checkbox_spec.rb 3. spec/models/criterion_spec.rb 4. spec/models/scale_spec.rb.","The score should be x out of y, or ""x/y"".","This is a comprehensive assignment, with clearly outlined goals on how you're planning to improve the current Expertiza interface. Your attention to detail and the different elements you've considered for a more user-friendly usage are commendable.

However, for future projects, another valuable addition would be justifying your choices. This means explaining why specific features were chosen or why you've made certain modifications. This helps to understand your thought process better and assess the feasibility of these changes. Likewise, make sure all code segments you've included are readable and clearly commented to assist in conveying the purpose and functionality of each piece of code.

I'm guessing illustrations and mockups of your proposed modifications were attached in the actual submission; these are crucial in providing a visual representation of your ideas and should always be included in your assignments.

Remember to make references to, or to explain, concepts or tools you've used for people not familiar with them, such as Bootstrap, jQuery, and the table sorter plugin. As an instructor, I understand their workings, but it's essential to maintain this clarity.

Good job on the detailed explanation of the tests run to ensure your new features work efficiently, and the different scenario handling. As for your next assignment, you might also want to consider discussing any limitations and future improvements that can be made to the files you've altered for enhanced clarity and comprehension. 

Overall, great job on this assignment! Keep up the good work."
3,E1758,"Expertiza is a web application developed using Ruby on Rails that serves as a peer-review system. The application allows students to submit and peer-review learning objects (articles, code, web sites, etc)[1][2]. It is an open source project and it's codebase is maintained in GitHub. We are contributing to Expertiza as a part of our Object-Oriented Design and Development's Open-Source Software (OSS) Project. Our goal in this project is to fix various issues related to staggered deadlines for assignments. A staggered-deadline assignment is an assignment in which different topics have different deadlines. In this Wiki Page, we will explain the changes that we have made for the same. 1. What’s wrong: When students' accounts are created by importing a CSV file on the Users page, they receive e-mails with their user-ID and password. But if an account is created by adding them as participants to an assignment when they don't already have an account, e-mail is not sent. Students should receive e-mails upon account creation, regardless of how their account is created. So this involves adding a call to the e-mailer … or, perhaps, moving an email call from the Users controller to the point where an account is actually created. Second, evidently if a submission is revised after review, the system e-mails the reviewer saying to revise the review. This is just fine ... except if the last round of review is in progress.The message telling reviewers to revise their reviews should not be sent after the last review deadline has passed. It would also be nice to fix the message so it tells which review (Review 1, Review 2, etc.) has been revised, and gives the reviewer a link directly to it. 1.1. There are also other circumstances when it would be helpful to send mail. Send out an email to the invitee when a participant sends out an invitation to another participant to join a team. The student who issued the invitation should also be e-mailed when the invitee joins the team. And also when a student responds to a teammate advertisement. In general, all activity on ad responses and invitations should be reported to the other party by e-mail (unless these e-mails are turned off in a (new) profile field). Notify an instructor by e-mail when a student suggests a topic. Modified Files 1.1. app/controllers/invitations_controller.rb 1.2. app/controllers/submitted_content_controller.rb 1.3. app/controllers/suggestion_controller.rb 1.4. app/mailers/mailer.rb 1.5. app/models/assignment.rb 1.6. app/models/assignment_participant.rb 1.7. app/models/course_participant.rb Added Files 1.1. app/views/mailer/partials/_user_invite_html.html.erb 1.2. app/views/mailer/partials/_user_invite_plain.html.erb 1.3. app/views/mailer/partials/_user_welcome_html.html.erb 1.4. app/views/mailer/partials/_user_welcome_plain.html.erb 1.5. app/views/mailer/send_mail_to_instructor.html.erb 1.6. app/views/mailer/send_mail_to_instructor.text.erb 1.1. app/views/mailer/partials/_user_accept_html.html.erb 1.2. app/views/mailer/partials/_user_accept_plain.html.erb 1.3. app/views/mailer/partials/_user_decline_html.html.erb 1.4. app/views/mailer/partials/_user_decline_plain.html.erb Approach Taken To Implement Changes NOTE: All the mails except the ones for the reviewer which are sent to mailinator , are sent to expertiza.development@gmail.com ,as this is already set in the development environment. 1) Enabled mailing when participant added to assignment : Initially the email were being sent to users when they were added using a CSV file on the users page only . Now we added a method in the assignment_participant.rb model to send mails when a participant is added to an assignment on the assignment page through a CSV file. def self.import(row, _row_header = nil, session, id) <code> Also we added a method in the course_participant.rb file to send the mails when the user is added on the course page using a CSV file. <code> 2) Put validation in case of last round of review : Initially whenever a submission was being revised ,a mail was being sent to the the reviewer to revise the review. We needed to make sure that mail should not go when it is the last phase of review. We put a check on the condition that if it is the last round of review then mail should not be sent to the reviewer for revision of his review. for that we created a method review_deadline in the assignment.rb file to check if the next due date round is equal to number of review rounds or not. 1.1. E1758 Fall 17 <code> We also created a method in the assignment_participant.rb file to check if the round is valid for mail. <code> end In the submitted_content_controller.rb we created a check <code> 3) Enabled mailing to inform participant about an invitation : Initially no mail was going to the receiver when a participant was sending an invitation to another participant. We have edited the create method to put the mail functionality in invitations controller def create <code> <code> <code> we also created two partials for the respective view namely. 1.1. app/views/mailer/partials/_user_invite_html.html.erb 1.2. app/views/mailer/partials/_user_invite_plain.html.erb 4) added mailing functionality for the participant on response by the invitee : As there was no mailing method for invitation there was also no method to notify the sender of invitation about the acceptance of his invitation. For this we made changes in the accept and decline methods of the invitations controller. def accept <code> <code> <code> Apart from that we created four partials for the respective changes,namely: 1.1. app/views/mailer/partials/_user_accept_html.html.erb 1.2. app/views/mailer/partials/_user_accept_plain.html.erb 1.3. app/views/mailer/partials/_user_decline_html.html.erb 1.4. app/views/mailer/partials/_user_decline_plain.html.erb 5) Added mailing functionality for the instructor on getting suggestion : When a student suggests a topic initially the instructor was not notified. We created a method send_mail_to_instructor() to send mails in the mailer.rb. <code> We called the above defined method in the suggestion_controller. <code> Now the instructor is recieving mail when a student is suggesting a topic. We also added two views which consist of the respective mail content. 1.1. app/views/mailer/send_mail_to_instructor.html.erb 1.2. app/views/mailer/send_mail_to_instructor.text.erb Testing Our project requirements do not include designing automated test cases and writing tests so we have done manual testing to make sure that it works well. The manual testing is shown in the video.The description for the manual testing is given below: To test the functionality regarding the first requirement we imported a csv file named test.csv , which contained the details of a student, from the course_participant page. With this import the student was added as a course participant and the mail was successfully sent to expertiza.development@gmail.com. Then we repeated the same procedure from assignment_participant page and this time also the added mailing functionality worked well. To check the email functionality for invitations we logged in as student5001 and sent an invite request to student5002 for program 1 and the invitation mail was successfully sent to expertiza.development@gmail.com. Then we logged in as student5002 and declined the invite request and mail stating a decline was successfully sent to the expertiza.development@gmail.com. We repeated the process of sending mail from student5001 but this time we accepted the invitation when logged in as student5002. This time also the invitation accepted mail was sent successfully. To check the deadline functionality : Testing this functionality was the most challenging part amongst other parts of testing and usually used to take around 15 to 20 minutes, and if any not successful, we had to repeat. Every time, we logged in as an instructor and then set the due dates in such a way that we could wait and perform the intermediate steps from student's part, say keep 2 minutes gap among each of the stages of the assignment. After the due dates were set up, we login from a student id and then upload link in the submission phase. We see that the reviewer gets the email as soon as review phase starts, and reviewer's email was set to expertiza@mailinator.com for development and testing purposes. Again, when submission phase starts, student uploads other link or upload a file, after it the reviewer gets the email. But if the student submits another link in the last review phase (we had set the assignment to have 2 submission rounds and 2 review rounds), then this time the reviewer does not get an email, and this is how it was expected to be. To check the email on submission functionality we logged in as student5001 and suggested a topic test1. As we submitted the suggestion the mail was successfully sent to the instructor. So our manual testing covers all the requirements and all the functionality works fine. Additional Links 1.1. Git pull link: <link> 1.2. Git compare link: <link> References <link> Team <link> <link> <link>. 1. app/controllers/invitations_controller.rb 2. app/controllers/submitted_content_controller.rb 3. app/controllers/suggestion_controller.rb 4. app/mailers/mailer.rb 5. app/models/assignment.rb 6. app/models/assignment_participant.rb 7. app/models/course_participant.rb. 1. app/views/mailer/partials/_user_invite_html.html.erb 2. app/views/mailer/partials/_user_invite_plain.html.erb 3. app/views/mailer/partials/_user_welcome_html.html.erb 4. app/views/mailer/partials/_user_welcome_plain.html.erb 5. app/views/mailer/send_mail_to_instructor.html.erb 6. app/views/mailer/send_mail_to_instructor.text.erb 1. app/views/mailer/partials/_user_accept_html.html.erb 2. app/views/mailer/partials/_user_accept_plain.html.erb 3. app/views/mailer/partials/_user_decline_html.html.erb 4. app/views/mailer/partials/_user_decline_plain.html.erb. NOTE: All the mails except the ones for the reviewer which are sent to mailinator , are sent to expertiza.development@gmail.com ,as this is already set in the development environment. 1) Enabled mailing when participant added to assignment : Initially the email were being sent to users when they were added using a CSV file on the users page only . Now we added a method in the assignment_participant.rb model to send mails when a participant is added to an assignment on the assignment page through a CSV file. def self.import(row, _row_header = nil, session, id) <code> Also we added a method in the course_participant.rb file to send the mails when the user is added on the course page using a CSV file. <code> 2) Put validation in case of last round of review : Initially whenever a submission was being revised ,a mail was being sent to the the reviewer to revise the review. We needed to make sure that mail should not go when it is the last phase of review. We put a check on the condition that if it is the last round of review then mail should not be sent to the reviewer for revision of his review. for that we created a method review_deadline in the assignment.rb file to check if the next due date round is equal to number of review rounds or not. 1. E1758 Fall 17 <code> We also created a method in the assignment_participant.rb file to check if the round is valid for mail. <code> end In the submitted_content_controller.rb we created a check <code> 3) Enabled mailing to inform participant about an invitation : Initially no mail was going to the receiver when a participant was sending an invitation to another participant. We have edited the create method to put the mail functionality in invitations controller def create <code> <code> <code> we also created two partials for the respective view namely. 1. app/views/mailer/partials/_user_invite_html.html.erb 2. app/views/mailer/partials/_user_invite_plain.html.erb 4) added mailing functionality for the participant on response by the invitee : As there was no mailing method for invitation there was also no method to notify the sender of invitation about the acceptance of his invitation. For this we made changes in the accept and decline methods of the invitations controller. def accept <code> <code> <code> Apart from that we created four partials for the respective changes,namely: 1. app/views/mailer/partials/_user_accept_html.html.erb 2. app/views/mailer/partials/_user_accept_plain.html.erb 3. app/views/mailer/partials/_user_decline_html.html.erb 4. app/views/mailer/partials/_user_decline_plain.html.erb 5) Added mailing functionality for the instructor on getting suggestion : When a student suggests a topic initially the instructor was not notified. We created a method send_mail_to_instructor() to send mails in the mailer.rb. <code> We called the above defined method in the suggestion_controller. <code> Now the instructor is recieving mail when a student is suggesting a topic. We also added two views which consist of the respective mail content. 1. app/views/mailer/send_mail_to_instructor.html.erb 2. app/views/mailer/send_mail_to_instructor.text.erb. Our project requirements do not include designing automated test cases and writing tests so we have done manual testing to make sure that it works well. The manual testing is shown in the video.The description for the manual testing is given below: To test the functionality regarding the first requirement we imported a csv file named test.csv , which contained the details of a student, from the course_participant page. With this import the student was added as a course participant and the mail was successfully sent to expertiza.development@gmail.com. Then we repeated the same procedure from assignment_participant page and this time also the added mailing functionality worked well. To check the email functionality for invitations we logged in as student5001 and sent an invite request to student5002 for program 1 and the invitation mail was successfully sent to expertiza.development@gmail.com. Then we logged in as student5002 and declined the invite request and mail stating a decline was successfully sent to the expertiza.development@gmail.com. We repeated the process of sending mail from student5001 but this time we accepted the invitation when logged in as student5002. This time also the invitation accepted mail was sent successfully. To check the deadline functionality : Testing this functionality was the most challenging part amongst other parts of testing and usually used to take around 15 to 20 minutes, and if any not successful, we had to repeat. Every time, we logged in as an instructor and then set the due dates in such a way that we could wait and perform the intermediate steps from student's part, say keep 2 minutes gap among each of the stages of the assignment. After the due dates were set up, we login from a student id and then upload link in the submission phase. We see that the reviewer gets the email as soon as review phase starts, and reviewer's email was set to expertiza@mailinator.com for development and testing purposes. Again, when submission phase starts, student uploads other link or upload a file, after it the reviewer gets the email. But if the student submits another link in the last review phase (we had set the assignment to have 2 submission rounds and 2 review rounds), then this time the reviewer does not get an email, and this is how it was expected to be. To check the email on submission functionality we logged in as student5001 and suggested a topic test1. As we submitted the suggestion the mail was successfully sent to the instructor. So our manual testing covers all the requirements and all the functionality works fine. 1. Git pull link: <link> 2. Git compare link: <link>. <link>.","Design doc is quite readable.  Would have helped if there was a subheading for each change.  Other than that, it seems fine.","Congratulations on the completion of your project! Your team did an excellent job contributing to the open-source project Expertiza. I appreciate the thorough explanation of the changes made to various controllers, models, and views. You've clearly done a great job identifying problems and providing efficient solutions based on the project's needs.

The approach taken to implement changes is well-explained along with your reasoning for each change made. Your idea of sending emails notifying various stages of the assignment process is excellent and would likely improve the overall user experience of the application.

It's also great to see that you have undertaken manual testing to ensure that each new function works as expected. However, it is always recommended to include test cases even if the project requirements do not state it. Automated testing will give better coverage and can minimize regression testing efforts in the future. 

It would also be beneficial to include actual code snippets and screenshots in your documentation for a deeper understanding and to support your explanation. It's a bit difficult to follow all your modifications without the related code.

Lastly, please make sure to properly cite references linking back to any code snippets, online discussions, or articles that guided your solution.

Great work overall - keep it up!"
4,E2016,"In the first round of the Expertiza reviews, reviewers are asked to give authors some guidance on how to improve their work. Then in the second round, reviewers rate how well authors have followed their suggestions. Revision planning is a mechanism used to carry the interaction one step further by having authors to supply a revision plan based on the previous round reviews. That is, the authors would derive their plan for code improvement from the previous round reviews and reviewers would later assess how well they did it. Revision planning is helpful because it makes the author think about what's necessary to improve the work before putting forth the effort to improve it. This leads to a more reflective work process and is likely to produce a better-finished product. When reviewers have an opportunity to give feedback to the author, they too will learn what a good revision plan looks like. According to the given instructions, a revision plan consists of a description of the plan, followed by any number of questions that would later be appended to the future review questionnaire. The revision plan is per AssignmentTeam-based, which means the authors’ questions would only be used to evaluate their submission and not anyone else. By adding the functionality of revision planning, it helps researchers study the effect of the reviewer’s suggestions on the code improvement. This functionality has previously been done by a team of students from the Fall semester of 2018. Their implementation was merged into the master branch but was reverted due to the following design concerns: 1. The relationship between `Questionnaire` and `SubmissionRecord` is unclear. 2. Uses a lot of special-purpose code when existing codes may fulfill the same job. 3. Revision planning cannot be enabled or disabled for an assignment. 4. Numeric labelings for the revision plan questions begin from 1 again, instead of continuing after the original rubric questions. 5. Codebase contains commented codes that are no longer wanted. Check out the wiki page and the pull request on GitHub if you would like to learn more about the previous implementation of this project. 1. <link> 2. <link> Please note that unlike the other teams we have reviewed, this project is a complete redo rather than modifications built upon the previous team’s codes because our approach to this problem would be different than theirs. Therefore, we will not mention the previous implementation in the later content. For this project, we identified 4 major work items that together fulfill the stated requirements. Sort out the relationship among classes and introduce the new abstraction of the revision plan to the system in a way that it doesn’t interfere with the majority of codes We decided to relate each Question object with team_id. A ReviewQuestionnaire may have both questions with no team_id and some questions with a team_id . A question with no team_id indicates that it does not belong to any assignment teams so it is a question set up by the instructor, that will appear on review forms for all submissions. A question with a team_id, in contrast, indicates that it belongs to a particular team so it is a revision plan question. Both types of questions will be saved under the same questionnaire used for a given round. In this way, we can maximize the usage of existing codes and the only major change should be contained within the Question class. Modify the existing views and controllers to accommodate the new functionality which includes 1. Allowing teaching staff to enable/disable revision planning for an assignment. 2. Allowing team members to create/edit their revision plan during each submission period after the first round. 3. Allowing both rubric questions and revision plan questions to appear on the same page and be serialized correctly. 4. Allowing feedback on the revision plan only to be viewed by the team that creates the plan and that team's instructor. This will involve some minor changes such as appending an optional trailing parameter to some method signatures, adding interactive elements to the views, and slightly adjusting the structure of certain view templates. In addition, we planned to: 1. Provide an adequate amount of tests to improve code coverage. 2. Do necessary refactoring and resolve any CodeClimate issues. After communicated with our mentor Dr. Gehringer, we have been clarified with the following two problem statements. Every new question must be linked to the second-round questionnaire. This means both questions from the team’s revision plan and questions from the review rubric should be displayed together in the frontend. Since we decided to add revision plan questions to the review rubric of the round, we automatically linked every new question to the questionnaire of that round. Every new question must be linked to the author’s submission By saying every new question must be linked to the author’s submission, it means that there should be some relationships between the team and the team’s revision plan questions presented in the database. We addressed this problem by associating them with a team_id field. See Database Design section for more details. This will probably involve a DB migration to add the team_id field to the questions table. The below image shows the control flow of the revision planning functionality. <image> [Better to test if you are in a resubmission period, since there are method calls to do that. If you tested if Round 1 had ended, you'd have to write queries and then do calculations on the data.] The below image shows the control flow of the revision planning functionality. It involves 3 types of actors, student (reviewee), student (reviewer) and instructor/TA who manages the assignment and review processes. To understand each actor’s responsibility, trace each colored line that arose from each actor in the direction specified by the arrows. The diamond shape represents a decision or precondition, that is, only after the condition meets can the next action proceeds. Summary of actions 1. A TA/Instructor can 1.1. Enable revision planning 1.2. Impersonate students to perform their responsibility 1.3. View feedback report of all teams 2. A student (reviewee) can 1.1. Make revision during the second round submission period, which includes reading first-round feedback and adding revision plan questions according to that feedback. 1.2. View feedback report of the team it belongs to 3. A student (reviewer) can 1.1. Give feedback on the team’s revised work by answering each question (including the team's revision plan questions) appeared on the review page. 1.2. View the feedback it wrote to the team. A revision plan should be similar to other review questionnaires. Since functionalities on the review questionnaire have been maturely implemented, we expected to make the least amount of interface changes by utilizing the existing view templates whenever possible. The subsections listed the changes we planned to make. Implementation of enabling/disabling revision planning for each assignment can be rather straightforward. We looked to add an additional checkbox under the ""Review strategy"" tab of the assignment’s edit page. This checkbox is labeled as ""Enable Revision Planning?"" to indicate whether the instructor wants to include this functionality in the newly-created assignment. It is most reasonable to place the checkbox here because it is review related and other similar functionalities like Self Reviews are also implemented in this manner. <image>. If the instructor decided to include revision planning in this assignment, then the link to “Revision Planning” would appear on the student’s assignment page but would stay disabled during the first round. After that, It would become clickable during every submission period and greyed again during every review period. By clicking it, students would be redirected to a whole new page explained under the ‘Revision planning page’ subsection. [Revision planning should surely come before ""Your scores"".] <image>. The revision plan is just like other questionnaires in that it contains a set of questions for reviewers to answer. The only difference is that the revision plan comes with an additional description to help reviewers understand what changes have been made so far. Therefore, it should make use of most existing view templates and controller codes with minimized changes. As the image is shown, the only modification made from the existing questionnaire creation template would be to include a link that redirects students to the submission page, where the uploading of the revision plan will be handled by the existing implementation. The advantage to upload an external link rather than typing everything to the textbox element is that the description can be well-formatted if it displays outside the form and not causing a distraction effect for reviewers during the review. We also decided to leave out (or hide) the place where instructors set the configuration stuff like the range of scores and the questionnaire's visibility. These configurations should use default values defined in the system rather than having students come up with their own. <image>. The format of the review page remains almost exactly the same. To distinguish between rubric questions set up by the instructor and the revision plan questions created by the team under review, all the revision plan questions are placed after the rubric questions, split by an enlarged “Revision planning” subheader. [Having a ""Revision planning"" header is reasonable, but if the author changes a sequence number to put one of their questions earlier in the rubric, that should be allowed.] <image> <image>. Teaching staff and students have different windows to access the feedback report. 1. Teaching staff : Manage->Assignments->Edit Assignment->Other stuff->View scores 2. Students : Assignments->View Assignment->Alternative View In addition, either instructor and TA can impersonate students to access the feedback report from their views. We would like to consider both cases and illustrate each of them separately. Scores for the second round review rubric and the author’s revision plan questions will be displayed on the same table and are serialized correctly. See the figure below for an example. Let say the second round rubric has only 5 questions, the remaining questions (6-10) will be revision planning questions written by a particular team. <image> For reviewer: if you reviewed our first draft design, you should notice that we originally chose to place revision plan scores on a distinct table. After our mentor clarified to us, we realized that there can be possibly more than 2 rounds of submission and review periods for a given assignment. Therefore, scores for revision planning questions can vary round by round. Therefore, our previous solution will not work since it confuses the user of which round the revision plan scores refer to. [It would be nice if there was a way to distinguish instructor questions from questions added by students. This might be done with a special symbol, or by shading the background of the cell with the question number, etc.]. The revision planning section will be added to the students’ view as shown in the snapshot below. It displays in the same order as how the review page does. A “Revision Planning” subheader is also used here to indicate the starting of the revision planning section. <image>. Here we present the diagram of our database design. As the yellow borders show, we only plan to modify the structure of the Question table and the Assignment table. <image> In the Assignment table, the column is_revision_planning_enabled? will be needed to indicate whether the instructor would like to incorporate the revision planning feature. Additionally, we add team_id to each Question object to distinguish where each question belongs to. A Question object with an empty team_id value will be the question under the original rubric, while the object with a non-empty team_id field will be the question created by the team associated with the team_id. That is, instead of creating a whole new RevisionPlanQuestionnaire class, we decided to dump all the revision plan questions that are created in a given round to the rubric that is used for that round. In this way, we minimize the change to the system to make the original rubric questions and the revision planning questions retrieved together more easily. controllers/questionnaires_controller.rb 1. action_allowed?: allow students could edit revision questionnaire. 2. edit: when params[:team_id] is exist, ""edit_revision_plan"" will be redirected. 3. update: extract the duplicate code as a new function update_questions . 4. add_new_questions: add team_id and round number which is set 2 to question, allow student to add new question for revision plan. 5. save_all_questions: The duplicate code is extracted as a new function update_questions . The function adjust_question_seq is used to adjust the sequence of the question in the revision plan based on the origin rubric. 6. edit_revision_plan: a new method that prepares view template and supplies revision planning questions that belong to the current team 7. update_questions: a new private method that could update questions that are already created. This method is extracted from original methods update and save_all_questions . 8. adjust_question_seq: a new private method that could move the questions created by students behind the questions in the original rubric. 9. question_params: add team_id controllers/questions_controller.rb 1. action_allowed?: allow students within a team to remove questions in revision plan. 2. destroy: add team_id , so that when student with team_id click ""remove"" buttom, it will redirect to editing revision plan page. 3. is_for_revision_planning?: a new private method that know the question is for revision planning or not. controllers/response_controller.rb 1. update/ new/ create/ set_content: use set_questions to get the questions from the original rubric and from revision plan proposed by the team with the corresponding reviewee_id . 2. set_questions: a new private method that gets a set of questions for each team in a given round through function questions in Questionnaire model. controllers/grades_controller.rb 1. view_my_scores：add @team_id to retrieve_questions method, so students could see the revision plan question in ""Your scores"" 2. view_team: add @team_id to retrieve_questions method, so students could see the revision plan question in ""Alternative View"". And a new method sort_questions defined in grades_helper is used to sort questions including questions in revision plans. 3. calculate_all_penalties: AssignmentParticipant is used to looking for the participant because the participant_id as a argument in function calculate_penalty is expected a AssignmentParticipant. models/due_date.rb 1. self.get_next_due_date: find all next_due_date and return the first one when all dates in ascending order. models/question.rb 1. Form association relationship with Team via team_id . 1.1. belongs_to :team, class_name: ‘AssignmentTeam’, foreign_key: ‘team_id’ 1.2. validates :team_id, numericality: true, allow_nil: true models/questionnaire.rb 1. questions: a new method could return questions in the original rubric and the team's revision planning questions if the team_id is supplied. The revision planning questions could be get through questions in RevisionPlanQuestionnaire model. models/response.rb 1. display_as_html: add team_id and round which could be passed to construct_review_response 2. construct_review_respone: add team_id and round which could be passed to questions in Questionnaire model, so the revision plan questions will be included in. models/assignment_team.rb 1. Form aggregation relationship with Question via team_id 1.1. has_many :revision_plan_questions, class_name: ‘Question’, foreign_key: ‘team_id’ models/revision_plan_questionnaire.rb 1. self.questions: a new model file could return the team's revision planning questions. views/questionnaires/_questioinnaire.html.erb 1. The code is extracted as a partial template named views/questionnaires/_questions.html.erb . views/questionnaires/edit_revision_plan.html.erb 1. It is a newly-added view file for students to create and edit their revision plan. It use some existing codes from the app/views/questionnaires/_questionnaire.html.erb view file to reduce code redundancy. views/questionnaires/_questions.html.erb 1. Extract codes from the app/views/questionnaires/_questionnaire.html.erb view file to make it a standalone partial template that will later be loaded by the app/views/questionnaires/edit_revision_plan.html.erb and app/views/questionnaires/_questioinnaire.html.erb . views/student_task/view.html.erb 1. Add a “Revision Planning” link for students to edit their revision plan. The link will lead students to the “Edit Revision Plan” page. If the revision planning feature is enabled, this link will appear disabled at first and only become clickable during each submission period after round 1. views/assignments/edit/_review_strategy.html.erb 1. Add “Enable Revision Planning?” checkbox for each assignment because not every assignment needs this feature. TA/instructor have the option to include this feature more flexibly. The “Revision Planning” link will disappear from the assignment page if the checkbox is not checked. views/response/view.html.erb 1. Pass the @map.reviewee_id and @response.round to function display_as_html . views/response/response.html.erb 1. The structure is changed. Because the origin structure couldn't show the sequence of questions correctly which means the first question will always be shown in last position. views/grades/_review.html.erb 1. Pass the participant.team.id and round to function display_as_html . helpers/grades_helper.rb 1. sort_questions: a new method that could sorts questions by sequence number 2. view_heatgrid: use Questionnaire model’s questions method with team_id and round to retrieve a proper question set for each team, and then the method sort_question is used to return a sorted questions. 3. retrieve_questions: add an extra parameter team_id whose default value is set to be nil. It then invoke Questionnaire model’s questions method with team_id and round , then retrieve a proper question set for each team. Assignment table : add one column named is_revision_planning_enabled? to indicate whether this feature has been activated. Question table : add one column named team_id to distinguish whether the question is from the official review rubric or from a particular team's revision plan. Controllers 1. spec/controllers/questionnaires_controller_spec.rb： 1.1. describe '#edit_revision_plan': function edit_revision_plan could renders the questionnaires#edit_revision_plan page Models 1. spec/models/question_spec.rb 1.1. Describe ‘#Questions’：function Questions will return the questions with or without team_id in ReviewQuestionnaire. 2. spec/models/questionnaire_spec.rb 1.1. Describe ‘#questions’: function questions will return the questions from the original rubric if no team_id and it will return the questions with supplied team_id. All tests are passed. We delete test of #display_as_html in spec/models/response_spec.rb because fixing them would cause more UI errors. Setup Login information 1. Visit xxx [expertiza deployment link] <code> Enable/Disable Revision Planning 1. Login as instructor6. 2. Go to an assignment’s edit page. Under the “ Review strategy ” tab, check the checkbox labeled “ Enable Revision Planning? ” to enable the revision planning feature. Enable/Disable the “Revision Planning” link 1. After the instructor configures the assignment to include the revision planning feature, the “ Revision Planning ” link will appear on the student's assignment page but will remain disabled and only be enabled during each submission period after round 1. Therefore, to enable the link: 1.1. Login as instructor6. 1.2. Go to an assignment’s edit page. Under the “ Due dates ” tab, change the round 2 submission date to whenever date in the future. 2. To disable the link after round 2 submission period: 1.1. Login as instructor6. 1.2. Go to an assignment’s edit page. Under the “ Due dates ” tab, change the round 2 submission date to whenever date from the past and change the round 2 review date to whenever date in the future. Create teams for the assignment 1. Login as instructor6. 2. Go to an assignment’s edit page. Under the “ Other stuff ” tab, click “ Add participant ”. 3. In the new page, add two students, student8030 and student8031, so one student can create revision plan questions during the submission period while the other can respond to these questions during the review period. 4. Go back to the assignment’s edit page. Under the “ Other stuff ” tab, click “ Create teams ”. 5. In the new page, group the two added students to separate teams. Functionalities Edit a Revision Plan 1. Login as student8030. 2. In the assignment page, click on the “ Revision Planning ” link. which redirects the user to a new page used to create a revision plan. Fill the blanks and click on the “ Save review questionnaire ” button, and the revision plan should be saved. Test retrieval of revision plan questions for a specific team 1. Login as student8030. 2. In the assignment page, click on the “ Revision Planning ” link after steps under Edit a Revision Plan have been done. The “ Revision Planning ” link should redirect the user to the Revision Planning edit page that is populated with previously saved questions. Check the Revision Plan questions in the questionnaire. 1. Login as instructor6. 2. Adjust the time frame to the second round review period. 3. Log out and log in again as student8031. 4. In the assignment page, click on the “ Others’ work ” link, which takes the user to the review page where one requests a new team’s submission to review. Go to the only other team’s review page and check if the questions are properly displayed under the “Revision Planning” subheader. Check responses to the Revision Plan questions 1. Login again as student8030. 2. In the assignment page, click on the “ Alternative View ” link, and see if student8030 gets responses for both the original rubric questions as well as its revision plan questions.","The document describes the project well in narrative fashion.  It seems to suggest that revisions can be solicited after any round, not just after Round 1.  I don't think that's consistent with the code.  There are at least two points where notes about the project are in brackets in the design doc.  These should have been removed for the final version.  I don't think that the code modifications, especially the ones to controllers, are adequately described.  They are just listed, with no explanation of why the change was needed.  Similarly, the testing plan should explain what is tested.","This is a very detailed and thorough assignment; I'm impressed with the amount of research and planning that went into this. The objective of the assignment was clearly defined, and you have taken into consideration the necessary components of the system, outlining the changes and improvements to be made. You discuss the project from various angles, such as user perspectives, testing, and implementation strategies, showing that you have a holistic understanding of the problem.

However, there are a few areas for improvement:

1. Clarity: While the overall structure of your report is organized, given the level of detail, it can be difficult to follow without clearer section demarcations. Consider more distinct breakpoints between discussion of different components or stages of the project.

2.  Broken down tasks: Because this proposal participates by different individuals or teams, it is crucial for tasks to be broken down and assigned to specific individuals or groups. This might involve designating tasks for front-end vs back-end, or dividing work by specific components or features.

3. Justifications for Design Decisions: It would be helpful to know why certain decisions were made during the design process, such as why a certain feature was deemed necessary or why a certain approach was preferred over another. 

4. Checks for Quality Assurance: Make sure that every modified and newly created function is functioning as expected by implementing a testing suite that checks the input, output, and reliability of the code.

The images can't be reviewed as they were not accessible in the submission. Make sure to include actual links or integrate the visuals directly into the document next time. Also, remember to include a conclusion summarizing what you have discussed in the document and what the next steps will be.

Overall, great job. I look forward to seeing future iterations of the project."
5,E1685,"Expertiza<ref> <link> </ref> is an open-source web application to create re-usable learning objects through peer-reviews to facilitate incremental learning. Students can submit learning objects such as articles, wiki pages, repository links and with the help of peer reviews, improve them. The project has been developed using the Ruby on Rails<ref> <link> </ref> framework and is supported by the <link> . Expertiza assignments are based on a peer review system where the instructor creates rubrics for an assignment through questionnaires which students use to review other students' submissions. The author of the submission is given an opportunity to provide feedback about these reviews. Expertiza displays reviews (i) to the team who was reviewed, and (ii) to the reviewer. A student user can see all the reviews of his/her team’s project. The instructor can see all the reviews of everyone’s project. The instructor also has access to a Review report, which shows, for each reviewer, all the reviews that (s)he wrote. Both score report and review report use different code so UI is non-orthogonal, it would be great if we can follow same UI structure for both score and review report which also reduce the DRY problems. There is no functionality for user to search between reviews of particular project, such a functionality will help user to search through all reviews for specific problem they are trying to focus on. The project requires completion of the following tasks: 1. A single way of displaying reviews that would be visible to students (reviews that they did, and reviews that their team received), and instructors (reviews that each team received, sorted by team; and reviews that each student did, sorted by student) For student view the UI is consistent in displaying reviews they have done and reviews they have received but for instructor's view the review report follows different UI and have different code. To make the UI consistent we have decided to choose the UI design of student view as the base and modify the UI design for review report in instructor's view. This will allow us to use the same code in both views, thereby following DRY principle. Previous View: <image> Updated View: <image> Implementation: Review report view is rendered in app/views/popup/team_users_popup.html.haml. In this view, we populate table by iterating over each question under each round. While same approach was used previously but here we replace each row by a predefined format used for rendering question similar to student view. <code> We replace the above code by code below, here in each row we invoke view_completed_question method defined in Criterion.rb for scored questions which insert the html code to render question,score,comments. <code>. 1. Add button/link to hide and expand all the reviews for a Round. In student view,for a particular assignment, the UI has show review button for each review in a round. Adding a single button will help student view all the review of a round with single click. Previous View: <image> Updated View: <image> Implementation: Review view is rendered in app/views/grades/_reviews.html.erb. In this view, we added show all reviews and hide all reviews buttons which when clicked call toggleAllElement function and displays all the reviews of a round. <code> We added toggleAllElemnet function in app/assets/javascripts/tableactions.js which toggles all the review of a round using existing toggleElement function. <code>. 1. Create a tabbed view for each review view type : Statistic, Reviews and Alternate Views tabs. Initially I weighed using TabsOnRails or Tabulous gems to create the tabs for this project but after doing some research these gems did not allow me to create tabs dynamically so Jquery UI was used to create the tabs. This was a plus since we did not need to install a new gem to the project. The review report will need to be modified to have the addition of the Statistic, Reviews and Alternate Views tabs at the top of the page. It will default to the Statistics tab which should look something like: <image> And the Reviews tab should produce a view like: <image> The Alternate View tab should produce a view like: <image>. To create the tabs on the view_my_scores view we used the following Jquery code: <code> The Stats tab was easy since we just took what was already in that view and moved it to only be displayed under the first tab. The Review tab was created by pulling up the rendering of the review partial out of the participant partial. This just needed to point the local variables to variables that were in this View. The Alternate View tab was a bit tricky since it was it's on view (view_team). So what was done was creating a partial named _view_team and moving all of the code that was in that view the partial and rendering the partial in the view_team view. This allowed us to access this view from the view_team and view_my_score views simultaneously while using the same code base. We were going to add the sub tabs for the Reviewers but after implementing the ""show all reviews"" buttons those tabs became tricky and the page got really cluttered. So we decided that we could just keep the existing scores Review layout with the changes of toggling whether to hide or show the reviews. To test this feature go to the view_my_scores page for the student where you should see the 3 tabs. Make sure that each tab gives you a similar view as described above. 1. Make review feedback more readable by changing UI or background color. 2. Option to toggle review question or score or answers. This task is to make feedback response more readable or more focused for user to read. Instructor suggested this can be done by graying out the question or we can change the background of the response text. The existing review also has this behavior. We added toggle button to show/hide questions/score/answers for a review based on instructor suggestion. Previous View: <image> Update View: <image> Implementation: The implementation of this functionality is similar to Task 2. A review is rendered in app/models/response.rb. We added toggle questions, toggle score and toggle answers button in a review view, which when clicked calls toggleAllElement function in app/assets/javascripts/tableactions.js that toggles respective view. <code>. When scores are view in alternate view(Heat map) it displays score received for each review in tabular format when we click on any review hyperlink it invokes view method of response controller which render unnecessary elements like submission content, upload file button,etc along with review and feedback, instead it should just show review and feedback. So we created a new view to implement this functionality and removed other unrequired elements. Files updated: <code> We have selected the unrequired element in below mockup image. <image>. 1. Log-in as student. 2. Go to particular assignment 3. Select alternative view 4. Click on any review hyperlink, to see reviews. 1. Add search box to search between reviews for particular string for a specific project(Student's view) or for specific user(Instructor's view). This functionality will help user to readily access the required content within the reviews. Below is the mock-up image of how functionality will look after implementations <image>. 1. To Test UI for student View 1.1. Log-in as Student. 1.2. Go to Assignment 1.3. Click Your scores 1.4. Click show reviews 1. To Test UI for instructor View 1.1. Log-in as Instructor. 1.2. Go to Manage Assignments 1.3. Click on review report of a particular assignment 1.4. Click on any item in team reviewed tab, to see reviews. <references/>.",The document has everything that we asked for. LGTM!,"Dear student,

You have done a commendable job on this assignment regarding the Expertiza open-source web application. 

Your understanding of the system and its functionalities is comprehensive. You have identified areas of improvement like code redundancy, differences in user interfaces, the absence of an effective search function, and more. The manner in which you propose solutions for these problems also shows a good understanding of DRY principles and user interface design.

You provided a detailed explanation of each task, both before and after the proposed changes, and went the extra mile by including details about how you implemented your solutions. This indicates deep developmental understanding and a practical grasp of real-world solutions. The implementation of concepts like toggling elements and jQuery coding is well done.

Your tutorial on how to test your solutions is also appreciated, as this allows any user or developer to properly understand the changes you've made. Making your solution accessible and user-friendly shows good foresight.

Furthermore, you made sure to include mock-up images of the before and after states, which help the reader visualize the changes you made. The visual representation promotes better understanding of your solutions.

However, as a small improvement for next time, try to ensure that you number your tasks correctly - your list goes from 1 to 1 instead of 1 to 7. Additionally, your post lacked appropriate referencing – you introduced numerous links without properly referencing them in a recognizable format. 

Overall, great job! Your work is thorough and detailed, making significant improvements in various areas of the application. Continue the good work.

Best Regards,
[Your Name]"
6,E1465,"Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.1.4. <link> 1.1.1.5. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link>. Expertiza<ref name=""expertiza> Expertiza <link> </ref> is a web application available to both students and professors. The Expertiza project is a system to create reusable learning objects through peer review. Expertiza supports team projects and the submission of almost any document type, including URLs and wiki pages. Students can keep a track of their assignments, teammates and can conduct peer reviews on diverse topics and projects. It is an open source project developed on Ruby on Rails platform. More information on Expertiza can be found <link> . The source code can be forked and cloned for making modifications. As a part of the coursework of Object Oriented Design and Development, we were expected to refactor the funtionality of some modules of Expertiza. This wiki provides an insight into our contributions to the Open Source Software project 'Expertiza' by Refactoring the Users Controller. The Users Controller deals with managing activities peripheral to the User registered with Expertiza. Users are mapped to different roles like super-admin, admin, instructor, teaching assistant and student with each role having different access permissions. The Manage Users module can be accessed by roles other than the student. It provides users with the functionality to search other users based on keywords like username, email, etc. New user can be created and existing user information and role can be updated. Classes : users_controller.rb What it does : Manage Users i.e.search and list users, create new user, edit/update existing users, delete users. What has to be changed : 1. Modify methods to conform to RESTful style 2. Reducing the number of instance variables per action to one 3. Code cleanup by using string interpolation instead of concatenation, replacing '==' with eql? and :key =>'value' with key: 'value', modifying declarations of Arrays and Hashes and removing commented out code 4. Use of routing helpers instead of hardcoded URLs 5. Replace find_by with where to follow Rails 4.0 conventions Follow the steps below to access the view for UsersController. 1. Access the homepage of application and login as either super admin, admin, Instructor or Teaching Assistant. <image> 2. Hover over the ""Manage"" menu option and click on ""Users"". <image> 3. The view rendered is the index view for UsersControllers. <image>. 1. Modifications to users_controller.rb : The purpose of the index method in Users Controller is to list all registered users. The list method was called from the index method to list all users. This implementation did not conform to RESTful guidelines. Hence, we refactored the list method in users controller to index. Further, we refactored all the references of list method in UserControllers, Users views, Users tests and routes.rb to the index method. Before Refactoring : <code> After Refactoring : <code>. It is a bad practice to have more than one instance variables in a controller's method as it indicates increased coupling. Coupling must be as less as possible and the view should have direct access to as few instance variables as possible. Helper methods should be defined in controllers through which the view can access variables of the controller class. The code has been refactored to make use of helper methods for the instance variables in index action. Before Refactoring users_controller.rb <code> show.html.erb <code> After Refactoring users_controller.rb <code> show.html.erb <code> Similar approach for reduction of instance variables has been implemented in other methods like index, show_selection, etc. Code cleanup in the controller so that the code conforms closely to Rails conventions and further enhances the readability of the code. 1. Replaced String concats with #{} in paginate_list Before Refactoring : <code> After Refactoring : <code> 1. Replaced '==' with eql? Before Refactoring : <code> After Refactoring : <code> 1. Replaced :key =>'value' with key: 'value' Before Refactoring : <code> After Refactoring : <code> 1. Modified declarations of Arrays and Hashes Before Refactoring : <code> After Refactoring : <code> 1. Removed unused methods like self.participants_in and commented out code. Routing helpers are a simpler alternative to the otherwise complex hard coded URLs which reduce the readability of the code.Routing helpers allow us to declare possible common routes for a given controller. Routing helpers have been implemented since they maintain consistency even if changes are made to the routing paths. Before Refactoring: <code> After Refactoring <code>. Rails 4 conventions dictate the use of 'where()' over the use of 'find_by_...' methods while querying ActiveRecords. The code has been refactored to replace the usages of find_by.. with where(). Before Refactoring <code> After Refactoring <code>. Major refactoring revolved around moving lines of codes between methods, modifying array and hash declarations, using helper methods for avoiding multiple instance variables in controller methods and implementing Ruby Conventions. 1. Lines of Code Original : 248 Post Refactoring : 224 1. Code Complexity (Compared on Code Climate) Original UsersController<ref name=""originaluserscontroller> Original UsersController <link> </ref> <image> Refactored UsersController<ref name=""refactoreduserscontroller> Refactored UsersController <link> </ref> <image>. 1. <link> 2. <link> 3. <link>. <references/>.","About half of the report is screenshots of existing functionality.  Only a few stylistic changes seem to have been made.  Style is now better, but these are not real refactorings.","Dear Student,

Thank you for your detailed submission on the Expertiza project's refactoring process. I can see that you've put significant effort into understanding the existing design and working on improvements.

There's a well-organized structure in your text, and you have effectively explained the need for each change you've made during the refactoring process. I appreciate specifically how you laid out the before-and-after scenarios for code snippets to clarify how modifications have enhanced the manageability and readability of the code.

Nonetheless, there are a few areas where your report could be further improved:

1. Description: While your submission does a good job explaining what solutions you implemented, it would benefit from more detailed analyses of why certain changes were necessary and how they improve the 'Users Controller'. Include possible consequences if these issues were not addressed.

2. Referencing: Ensure to include the full URLs instead of using generic <link> to reference your resources or supporting documents. This will allow the reader to follow and find the extended content easily. 

3. Presentation: Images or visual illustrations, especially in the section 'Follow the steps below to access the view for UsersController', would have been helpful to understand processes or changes made more intuitively. 

In conclusion, this is a comprehensive report demonstrating your understanding of the subject and your efforts towards improving the code. However, remember to ensure all your supportive links are working properly and incorporate the mentioned suggestions in your future assignments. 

Keep up your good work! 

Best,
[Instructor Name]"
7,E1852.2,"The objective for this project is to write unit tests using Rspec for participant.rb model, which is used to prepare data for participants enrolled in each course/assignment. By editing the participant_spct.rb, all class and instance methods are tested, and the path coverage is above 90% with all 97 lines covered. Expertiza is an open source educational web application developed on Ruby on Rails framework. Using Expertiza, students can submit and peer-review learning objects such as articles, code, and websites. The source code is available on Github and it allows students to improve and maintain. In software engineering, behavior-driven development (BDD) is a software development process that emerged from test-driven development(TDD). The behavior-driven development combines the general techniques and principles of TDD with ideas from domain-driven design and object-oriented analysis and design to provide software development and management teams with shared tools and a shared process to collaborate on software development. RSpec is a 'Domain Specific Language' (DSL) testing tool written in Ruby to test Ruby code. It is a behavior-driven development (BDD) framework which is extensively used in the production applications. The basic idea behind this concept is that of Test Driven Development (TDD) where the tests are written first and the development is based on writing just enough code that will fulfill those tests followed by refactoring. It contains its own mocking framework that is fully integrated into the framework based upon JMock. The simplicity in the RSpec syntax makes it one of the popular testing tools for Ruby applications. The RSpec tool can be used by installing the rspec gem which consists of 3 other gems namely rspec-score, rspec-expectation and rspec-mock. The initial unit tests’ path coverage is only 36.08% with 35 lines covered and 62 lines missed for participant.rb, which are not enough. The unit test should be improved by making the path coverage of more than 90% and achieve the highest possible branch coverage. A test file and two model files were modified for this project: spec/models/participant_spec.rb app/models/participant.rb app/models/assignment_participant.rb. 1. Install Virtual Box software form Oracle in PC 2. Download the Ubuntu-Expertiza image 3. Run the .ova file in Virtual Box 4. Run following commands in terminal git clone <link> cd expertiza ./setup.sh bundle install rake db:migrate rails s 5. Open up the browser and put localhost:3000 in the address bar. The expertiza login page should appear. participant_spec.rb participant_spec.rb is the file that test should be written in. participant.rb participant.rb is used to preparing data for participants enrolled in each course/assignment. It allows the user to review some information relate to the current course/assignment and execute operations such as sorting participant by their names and removing a current participant from the team. It also helps determine users' permission or authorization. assignment_participant.rb assignment_participant.rb is a model file related to participant.rb. AssignmentParticipant is a subclass of Participant class, and it overrides some methods of its superclass, which affects the process of writing test code. 1. The email method in app/models/participant.rb uses ""assignment_id"" which is not correct and causes the test cannot pass. After changed ""assignment_id"" to ""assignment.id"", the problem fixed. 2. Since AssignmentParticipant is a subclass of Participant class, and it overrides team method and score method of its superclass, the test cannot access the methods in the superclass. As a result, those two methods were removed to make the test pass. All of the mock instances are listed at the beginning of the test file. <code>. This case tests that all of the responses of the current user received show up when responses method is called. <code>. This case is given by the initial test file. <code>. This case is given by the initial test file. <code>. This case tests that the permission of whether the current user can review others' work should be returned when able_to_reveiw method is called. <code>. This case tests that an email about assignment registration will be sent to the current user when email method is called. <code>. Two cases are designed for testing this method. When the topic_name method is called, the dash (-) should show up when there is no such topic or the topic name is empty, or the topic name should appear. <code> <code>. This case tests that a list of users' names should show up alphabetical when email method is called. <code>. Two cases are designed for testing this method. <code> <code>. Four cases are designed for testing this method. The authorization of the current user is identified before returning the permissions this user has. <code> <code> <code> <code>. This test is a reverse version of get_permissions. <code> <code> <code> <code>. Two cases are designed for testing this method. When the handle method is called, 'handle' should be returned if the anonymized view is turned on, or the handle of the current participant should be returned <code> <code>. Three cases are designed for testing this method. When the delete method is called, it will check whether it is a force delete first. If it is a force delete, current participant, related response maps, teams, and team users will be deleted. Or it will check whether there are associations to determine whether the operation can be executed or not. <code> <code> <code>. Three cases are designed for testing this method. When the force_delete method is called, the current participant, as well as the team, should be deleted when the user is the only member. Or the other teammate should be removed from that team. If the current participant does not have a team, it should be deleted directly. <code> <code> <code>. With all class and instance methods tested, the path coverage is 100% with all 97 lines covered. Full video of running the test can be found at <link> . Behavior-DrivenDevelopment <link> Expertiza <link> Rspec Documentation <link> Github (Expertiza) <link>.","Would have been helpful to describe why those mock instances were created (why 2 participants, for example).  The individual get_permission and get_authorization contexts should be explained.  Otherwise, the descriptions are quite good.","Dear Student,

Impressive work on your assignment! Your thorough explanation of Rspec and behavior-driven development (BDD) are well-articulated. Your explicit detailing of participant.rb and assignment_participant.rb in relation to the Rspec test reveals your understanding of the role they play in the application. The detailed test cases you've devised shows an in-depth understanding of the functionality you were trying to test, which is good practice.

Your understanding of the relationship between AssignmentParticipant and Participant classes and the necessity to amend methods to let the test pass is commendable. This shows great qualities of being a good software engineer by being able to navigate and modify interconnected functionalities within a system. 

In terms of areas to consider extending your learning, you may want to give a bit more explicit reasoning on why certain methods are being tested. Providing a little more information on the specific problems you're solving will assist readers in thoroughly understanding your rationale behind the proposed solutions.

While there is no need to change anything for this assignment, moving forward, having such extensive details might not be necessary unless specifically asked for. Learning to communicate effectively and concisely is also an important aspect of your development as a software engineer.

Again, your assignment is very well done, detailing the processes robustly. Your depth of understanding of the subject matter is evident and commendable. Keep up the excellent work!

Best regards,
[Your Name]"
8,E1919,"Expertiza is a platform where assignments and related quizzes are managed. On this portal instructor upload assignments/questionnaires, create list of topics for students and edit the existing assignments. Students can form teams, work on projects and submit their assignments as URL or files. It also helps in improving the work quality by allowing students to provide anonymous reviews. It is an Open source platform which is based on Ruby with Rails. The existing code of ""Expertiza"" has many code smells which are not in compliance with the best practices of Ruby Rails. These smells were detected by CodeClimate. Code climate is a command line interface for the Code Climate analysis platform. It allows you to run Code Climate engines on your local machine inside of Docker containers. It provides automated code review for test coverage and maintainability. We were assigned the task to resolve code climate issues in models with names beginning with ‘H’ thru ‘Sc’. As per instructions, we were to fix all the issues detected by code climate except for below. Fix all code smells except 1. Assignment Branch Condition size for [method name] is too high 2. Perceived complexity for [method name] is too high. 3. Cyclomatic complexity for [method name] is too high. 4. Method [method name] has a Cognitive Complexity of XX (exceeds 5 allowed). Consider refactoring. 5. File [file name] has XXX lines of code (exceeds 250 allowed). Consider refactoring. 6. Class [class name] has XX methods (exceeds 20 allowed). Consider refactoring. 7. Method [method name] has XX lines of code (exceeds 25 allowed). Consider refactoring. 1. Set up CodeClimate locally on our systems by using the following guide. <code> 2. Use ""analyze"" command. We have used ""analyze"" command of Code Climate to find out the code smells. Analyze command lets you pass file paths as arguments to the codeclimate and also lets you specify engine options with -e or --engine. <code> 3. We have also used Rubocop documentation for resolving issues. RuboCop is a Ruby static code analyzer (a.k.a. linter) and code formatter. It enforces the guidelines outlined in the community Ruby Style Guide for its best practices. 4. Issue related to method names starting with get_ are ignored because it requires refactoring across multiple files in the project, which would in turn break existing functionalities. 5. some issues are ignored as they were breaking the rspec tests. e.g. 1. mass assignment : It is used to create an instance using multiple parameters 2. In some test files instance were created with multiple parameter along with the primary id. But in mass assignment primary id is dangerous if allowed in mass assignment. 1. mass assignment <code> We assign multiple values to attributes via a single assignment operator. It is implemented using attr_accessible method. It takes a list of attributes that will be accessible. All other attributes will be protected. <image> <image> 1. Active Record Associations : Adding ""inverse_of"" option. Associated objects do not point to the same in-memory objects by default. When you have two models in a has_many, has_one or belongs_to association, the :inverse_of option in Rails tells ActiveRecord that they're two sides of the same association. Knowing the other side of the same association Rails can optimize object loading. It lets you reference the same object in memory, instead of loading another copy of the same record. <image> 1. Add dependent property In the file roles.rb we have has_many :users We need to specify ""dependent"" option here. With associations of Active Record , we can make transitions smooth of such operations(relationships) by telling Rails that there is a connection between the two models. It would make more sense here if we add ""dependent :destroy"" option for users. If a particular role is deleted, all the users under that role must also disappear. <code> <code> <image> 1. useless assignment of a variable In the file role.rb, we have The variable e is not being used anywhere. Such values are assigned to ""_"" or rather do not assign them to any variable, so that it doesn't get assigned to a variable and uses space. <code> <image> 1. Using snake case for method names In file roles.rb, we have <image> A standard good practice is to follow snake cases for naming methods. 1. Use find_by instead of where.first In file scored_question.rb, we have <image> Rails prefers ""find_by"" over ""where"" as ""find_by"" returns a single record as result, whereas ""where"" returns an array of record, to which we need to append ""first"" or ""each"" to get single record out of it. <code> 1. Nested ternary operators Ternary operators must not be nested. Rather we should prefer if-else . <image> And, there were many more code smells which needed a fix. 1. 162 issues resolved 2. 42 Files changed 3. 215 additions 4. 163 Deletions 5. Travis CI build passed 6. No merge conflicts 7. coveralls : <code> 1. codeclimate bot <code> 1. travis-ci <code>. 1. app/models/http_request.rb 2. app/models/import_error.rb 3. app/models/institution.rb 4. app/models/instructor.rb 5. app/models/invitation.rb 6. app/models/join_team_request.rb 7. app/models/language.rb 8. app/models/late_policy.rb 9. app/models/logger_message.rb 10. app/models/markup_style.rb 11. app/models/menu_item.rb 12. app/models/menu.rb 13. app/models/metareview_questionnaire.rb 14. app/models/metareview_response_map.rb 15. app/models/missing_object_id_error.rb 16. app/models/multiple_choice_checkbox.rb 17. app/models/multiple_choice_radio.rb 18. app/models/node.rb 19. app/models/notification.rb 20. app/models/on_the_fly_calc.rb 21. app/models/participant.rb 22. app/models/password_reset.rb 23. app/models/path_error.rb 24. app/models/permission.rb 25. app/models/plagiarism_checker_assignment_submission.rb 26. app/models/plagiarism_checker_comparison.rb 27. app/models/question_advice.rb 28. app/models/questionnaire_header.rb 29. app/models/questionnaire_node.rb 30. app/models/questionnaire.rb 31. app/models/questionnaire_type_node.rb 32. app/models/question.rb 33. app/models/quiz_assignment.rb 34. app/models/quiz_question_choice.rb 35. app/models/quiz_questionnaire.rb 36. app/models/quiz_question.rb 37. app/models/quiz_response_map.rb 38. app/models/quiz_response.rb 39. app/models/requested_user.rb 40. app/models/response_map.rb 41. app/models/response.rb 42. app/models/review_assignment.rb 43. app/models/review_comment_paste_bin.rb 44. app/models/review_grade.rb 45. app/models/review_questionnaire.rb 46. app/models/review_response_map.rb 47. app/models/role.rb 48. app/models/rscore.rb 49. app/models/rubric.rb 50. app/models/scale.rb 51. app/models/scored_question.rb 52. app/models/score_view.rb In additions to above files, we have edited the following files as well as they were dependency on those. 1. ta.rb <image> 1. response.html.erb <image> 1. spec/models/scale_spec.rb <image>. 42 Files changed 215 additions 163 Deletions. 1. Pull Request: <link> 2. Files: <link> 3. Codeclimate analysis: <link> 4. Travis CI: <link>.","Good description of the changes made, and the rationale for them.  You attempted to summarize how many issues were resolved.  A textual summary of the most common would also have been helpful.","Thank you for your detailed assignment. You've done an extensive job of identifying and correcting many of the code smells in the Expertiza platform. This was no easy task, so well done! Your understanding and application of tools like CodeClimate and RuboCop is commendable.

Here are some points of feedback for you:  
1. Your handling of irrelevant issues was well thought out. Your reasoning for ignoring method names starting with 'get_' and other issues breaking the rspec tests due to their potential to affect existing functionalities was sound.
2. Your understanding and application of active record associations and usage of 'inverse_of', 'find_by' instead of 'where.first', and 'dependent :destroy' shows good understanding of how Rails optimizes object loading and handles associations.
3. I appreciate the attention to detail and care you've shown in addressing method naming conventions and suggesting suitable changes. Your understanding of best practices is evident from this.
4. The assignment could potentially have been enhanced by further explanations for the rationale behind certain actions. For instance, providing brief explanations on why a certain method was preferred over another could offer further clarity.
5. Also, ensure to avoid overlapping points in the future. Some points were repeated, which may lead to redundancy.

Overall, I am impressed by your effort, as you resolved a significant number of issues and displayed a strong understanding of Ruby & Rails code quality.

Keep up the good work!"
9,E1869,"After an instructor gave a grade to an assignment, there is no way to track who gave the grade. A grading audit trail must be created and the following information needs to be stored: 1. When a grade is assigned by an instructor, there needs to be an indication of who did it and when it was done. 2. Comments previously provided by other instructors must also be preserved. This information needs to be stored every time an instructor edits a grade/comment and clicks the save button. Currently, there are two places need to add grading audit trail: 1. Review grade : Log in as instructor -> Manage -> Assignments -> View Review Report 2. Submission grade : Log in as instructor -> Manage -> Assignments -> View submissions. We will create a database called grading_history in the system contains elements of instructor id, assignment id, grade type, student id, grade, comment, and timestamp. We will use MVC design to create a model, a controller, and a view for both of Review Grade and Submission Grade . Model: grading_history.rb. Has a list of attributes contains instructor id, assignment id, grade type, student id, grade, comment, and timestamp. Controller: grading_history_controller.rb. Saves a new entry into the database every time a review grade or submission grade is saved View: index_html.erb. Displays current submission or review's grading history. An existing example of this is a submission record in the system. We also need to modified grades controller, so that every time, a grade is submitted or edited, grading_history_controller.rb will call a method to create an entry saves into the database. <image>. <image>. <image>. Functional testing: 1. Test if SubmissionGradeHistory.create is being called when a submission grade is changed. <code> 2. Test if ReviewGradeHistory.create is being called when a submission grade is changed. <code> 3. Test if GradeHistory.where is being called when grading history button is clicked. <code>. <image>. <image>. <image>. 1. app/controllers/grades_controller.rb <link> <code> 1. app/controllers/review_mapping_controller.rb <link> <code> 1. app/views/assignments/list_submissions.html.erb <link> <code> 1. app/views/review_mapping/_review_report.html.erb <link> <code>. 1. app/controllers/grading_histories_controller.rb <link> <code> 1. app/models/grading_history.rb <link> <code> 1. app/models/review_grading_history.rb <link> <code> 1. app/models/submission_grading_history.rb <link> <code> 1. app/views/grading_history/index_html.erb <link> <code>. <link> <link> <link> <link>.","This design doc does not really say much about how the proposed solution is implemented.  There are no references to the code.  The need tor a new grading_history_controller is not established.  It would be better to include references to the changed code on Github and describe the changes that were made.  Also, the screenshots should be smaller, so that one does not need to zoom way out.","You have initiated a well-rounded design to solve a relevant problem in the grading system. Your attention to details, like the need for an audit trail, demonstrates you're not just looking at incorporating code but also deeply considering functional requirements. However, this submission could be improved in several areas:

1. Firstly, there's reference to multiple images and code snippets that are not present in your submission. Including these will give more clarity to your explanations and make your work more understandable for reviewers.

2. Secondly, several of your steps aren't very clear, such as the need for a 'grading_history' database and how it fits into the current structure of the system, its relationship with other models, and its real-time implementation. Remember to break down complex ideas into simpler terms for someone who might not be familiar with your line of thinking from the beginning.

3. Lastly, ensure your testing is exhaustive, covering all scenarios to ensure robustness of the system. 

You did a good job on explaining where to add the grading audit trail, describing the roles of each component in MVC design, the example of a submission record, and the modifications needed in grades controller. 

Your willingness to undertake such a task is commendable, and your general approach is in the right direction. Focus on providing clearer explanations, pay attention to details, and make certain your testing phase covers all possible scenarios. With these adjustments, I am positive your submission will be among the top. 

Keep going; you're on the right track!"
10,E1462,"Expertiza<ref name=""expertiza> Expertiza <link> </ref> is an open source web portal for the use of both students and professors. Expertiza allows us to create reusable learning objects through peer review. It allows project submission, team creation and the submission of almost any document type, including URLs and wiki pages. Students can access their pending and finished assignments, they can do peer reviews on several topics and projects. It is developed on Ruby on Rails platform. More information on Expertiza can be found <link> . The source code has been forked and cloned for making modifications to the to survey responses controller. This wiki provides an insight into our contributions to the OSS Expertiza application, focusing on Refactoring the SurveyResponses Controller. <image> <table> Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.1.4. <link> 1.1.1.5. <link> 1.1.1.6. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link>. Refactoring helps to<ref> <link> </ref> 1. Understand what led to poor code design 2. Fix code which is difficult to understand 3. Express each idea “once and only once” 4. Recognize missing or inadequately formed classes 5. Simplify overly complex relationships between classes 6. Achieve the right balance of responsibilities among objects 7. Make code easier to test and more maintainable. We identified the following categories of code smells in the helper module: 1. Fat Classes : No class should be fat. Ever. There is no need for your controllers, models or views to be fat; this shows laziness, as there's been no thought given to the application's design outside of deciding to use a particular framework. 1. Bad Class names : A good class name is expected to adhere to the Ruby style and design style guidelines. It is expected to convey a reasonable amount of functionality handled. 1. Lengthy Definitions : These are the methods that have too many responsibilities and collaborators. As a result of which, their overall length has grown too long reducing the maintainability and readability. 1. Duplicated Code : These are those pieces of code that does almost the same functionality of some other piece of code leading to a bad design style. They are usually too error prone since not everyone identifies all the code responsible for the same task and does the changes whenever the need arises. There are many documented refactoring techniques, and a few common ones are below.<ref> <link> </ref> 1. Rename Class : Controllers as per Ruby conventions should be plural. 2. Using Helper classes : No class should be containing lot of code, a better practice is to have all active record queries with in the model and in order to keep as much as Ruby code out of the views, helpers are used. Helpers are the only methods you can access, other than instance methods for an instance you have access to. 3. Extract Method : It consists of breaking up long methods by shifting overly complex chunks of code into new methods which have very descriptive identifiers. This class creates surveys and records the responses which can be viewed. On submitting the responses, the scores and comments are posted. Classes : SurveyResponsesController.rb What it does : Creates surveys, submitting surveys, views responses, posts scores and comments. What has to be changed : 1. Pluralize the class SurveyResponseController to SurveyResponsesController 2. Changing declarations of Arrays and Hashes,removing commented out code 3. Use of routing helpers instead of hardcoded URLs 4. Move active record queries to the model or another class 5. Reducing the number of instance variables per action to one. 1. A new survey_responses_controller.rb file is added : As per Ruby on Rails convention, controller names get pluralized while model names are singular. So, the controller name becomes survey_responses_controller instead of survey_response_controller for SurveyResponse modelclass. 1. Modified declarations of Arrays and Hashes Before Refactoring : survey_responses_controller.rb <code> After Refactoring : <code>. Controllers are best at parsing the inputs, they call the appropriate models, and then format the outputs. It is desirable to have a skinny controller responsible for parsing inputs and models doing actual validation. A bunch of Active Record queries that existed in survey_responses_controller have been moved to SurveyResponse model. Before Refactoring: survey_responses_controller.rb <code> After Refactoring: survey_responses_controller.rb SurveyResponse.get_survey_list and SurveyResponse.get_survey_list_with_deploy_id methods have been created in SurveyResponse model for active record operations. <code>. It desirable not to have more than one instance variables in a controller action as it indicates increased coupling. Our goal should be reducing coupling as much as possible and view should have direct access to as few instance variables as possible. Here persist_survey method has been created in the SurveyResponseHelper to minimize instance variables. Before Refactoring: survey_responses_controller.rb <code> After Refactoring: survey_responses_controller.rb <code>. Creation of a resourceful route will also expose a number of helpers to the controllers in the application. We modified the routes.rb file to include all the actions in the controller. resources :survey_response do <code> The resourceful routes generated the helpers given below: <code> <code> <code>. Comments and extra spaces have been removed and conventions have been followed to enhance readability of the code. Testing was performed by running 2 different VCL instances one with the original code and the other with the re-factored code. While performing the manual testing we noticed that when new course evaluations are created, the survey participants are random users and participants selection is not based on the courses. However, while displaying the pending course evaluations in the course evaluation list view, the courses are taken into consideration. Because of this difference we were not able to submit survey responses and view them. In below images we have shown that the output after refactoring and output without re-factoring for all actions in the SurveyResponsesController. <table>. 1. <link> 2. <link>. <references/>.","Writeup clearly explains what was changed, but not how it was changed.  For example a number of instance variables were removed and replaced by a call to get_assigned_surveys, but get_assigned_surveys is not described.  Design principles are mentioned, but no mention of design patterns.","Dear Student,

Firstly, I must commend you for an elaborate submission. You were thorough in the depth of your analysis for your chosen open-source software, Expertiza. The in-depth exploration of the software is extensive and commendable, which shows your understanding of the topic.

However, the assignment lacks clarity in certain areas. For instance, it isn't always clear what the ""<link>"", ""<image>"", and ""<table>"" placeholders are supposed to represent. If they represent certain elements in the text, proper references or substitutes should be used for better comprehension.

Moreover, the list for components in the middle of the assignment is quite confusing. If you were trying to list out the structure of this paper, it might be more beneficial to use headers or subheaders in order to make it clearer.

Additionally, there's a lack of referenced sources. If the ""<ref> <link> </ref>"" indications are meant to point to specific references, kindly ensure you include full in-text citations and a reference list at the end for those sources you've used.

The code refactoring explanation was well-handled, demonstrated clear understanding of the topic, and broken down in a digestible manner which is commendable. However, again if ""<code>"" represents pieces of code, please ensure to include the actual code snippets for proper understanding.

Lastly, your conclusion could have been more explicit. Critical analysis demonstrating success or failure of your refactoring efforts, mentioning any challenges encountered and how they were resolved, as well as the implications of your results would have added to the depth of your submission.

Keep working hard and consider these comments when reviewing your work for future assignments.

Best,
[Your Name]"
11,E1690,"This wiki page is for the description of changes made under E1690 FinalProject for Fall 2016, CSC/ECE 517. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.2. <link> 1.1.1. <link> 1.3. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.4. <link>. Expertiza is an Open Source web application developed on Ruby On Rails platform. It is a platform which allows students to access assignments posted by the course instructor. Expertiza also allows students to select assignment topics, form teams and submit their work. It also allows them to review other students' submissions and improve their work based on the feedback provided. The instructor can look at the feedback provided by students and rate the student based on feedback provided for others work. It helps organize and upload assignments and reducing the manual review process and helps students provide a peer feedback and also learn from reviewed work. Teams can be chosen by the student or can be assigned automatically based on a priority list inputted alongside each topic available for the assignment. Our final project consists of two cases of the password recovery process. Use case 1, Currently, when a user forgets his/her password and wants to reset the password, Expertiza system randomly generates a new password and sends the password as plain text in a email. It is normally considered as a bad practice to send passwords as paint text. We are replacing this practice by sending a reset password link that expires after a certain amount of time. Use case 2 deals with when a user enters wrong credentials. Currently, the login page simply shows an error. Irrespective of the number of times that a user enters wrong login credentials, the system produces a general error message. We are going to be replacing this system by using the alternative 2, using a captcha to verify that the user is indeed a human and not a bot trying to run a brute force attack on the system. This will add the needed layer of security and should serve as a great solution. Below are more details of our implementation. As a part of the project the files mentioned below were the ones, created/modified as needed. 1. auth_controller.rb 2. password_retrieval_controller.rb 3. password_reset.rb (model) 4. reset_password.html.erb (view). We have implemented the new password recovery system by sending a reset password link to the user's email. This link will be comprised of a generated path to a newly created view for resetting the password with a uniquely randomly generated token. This parameter will be a string attribute of a new model reset_password. This link will expire after a given amount of time. Using logic to compare the createdAt timestamp as well as the current time, the application would decide if the token is expired or not. We are also implementing a backoff system that will require the user to complete a smart captcha after 3 failed attempts. This smart captcha will be generated through Recaptcha gem and the user will then be redirected to the login page after successfully changing the password. This will ensure that the system is not vulnerable to Brute Force attacks as well as bots. Model: password_reset.rb Attributes 1. -id(autogenerated) -integer 2. -unique_tokenhash -String 3. -createdAt (autogenerated) -timestamp 4. -user_email -string Model Details When the user clicks on reset password, it will redirect to a view that has an input to enter the email address of the user. Reset password button will generate a random token (Long string) which will be hashed and saved in the database of the model reset_password. An expiration date will be generated and saved along with the user_id by looking up the user table using email id. The unhashed Token value will be appended on the url emailed to the user for the password reset page. www.expertiza.com/password_edit/check_reset_url?token=ZB71yObR-Tdssg-@#% On clicking the url, the link will take you to password_retrieval_controller that will direct you to a reset page. Before redirecting , the controller checks the parameters in the link (username and token) and makes sure that token username pair exists and not expired. Token from the params will be hashed again and checked with the DB. This prevents an attacker who has read access to the database from making a token for some other user, reading the value that was sent in the email, then sending the same value himself. Once the controller completes all the necessary checks, it will redirect to a reset password page for that specific user (based on the user_id / username) Each Email Address can have only one active token saved in the database. Every time a new token is generated, it will replace the existing one which ensures that only one reset link is available. Also, this will make sure that DB content of password_reset can never exceed the number of users registered in the application. This eliminates the need to clear out expired Tokens. <image>. The project will be using reCAPTCHA gem. reCAPTCHA is a free service from Google that helps protect websites from spam and abuse. A “CAPTCHA” is a test to tell humans and robot apart. This kind of service is important for websites or web applications with lots of user generated content. The test is easy for a human to solve, but hard for bots and other malicious software to figure out. After 3 failed Login attempts, a captcha would appear to make sure that a bot or a malicious software is not trying to attempt login using brute force. <image>. Adding this line to the Gem file allows us to have access to the recaptcha gem. <code>. To let reCAPTCHA work normally, we need to register the domains that the project will be deployed on [reCAPTCHA official website] <link> . Currently, we can use it on expertiza.com, 0.0.0.0, and localhost. Once the registration is done, two keys will be automatically generated -- site key and secret key. The site key is used in HTML, and the secret key is used for communication between the site and Google. To show reCAPTCHA in webpages is easy, all we need to do is add this code to _form.html.erb <code> And, we need to create a recaptcha.rb file into config/initializers folder, which stores our site key and secret key. <code>. In Auth Controller we added the following code. The variable @@attempts acts as a counter to track the amount of invalid login attempts a user makes. By utilizing the existing login code we were able to place the increment code. Once the attempts variable is greater than or equal to 3 we then force the user to use the recaptcha question in addition to their correct logic credentials. Once the new requirements to login are satisfied the user is redirected to the password retrieval, otherwise they are redirected to the root screen with the captcha question. <code>. To run the Rspecs test cases: <code> To test from UI: <code> Here is a short <link> demonstrating the same.","The most important limitation is that it doesn't really describe how the code structure has been changed.  It shows a couple of UML diagrams, but doesn't explain them.  Your slide show was quite helpful; would be good to link the design doc to it.","Dear Student,

Firstly, I want to commend you for an excellent job on your final project. It is evident that you put a lot of effort into it and your well written project report shows your in-depth understanding of the task.

I especially appreciate that you incorporated secure and robust practices into your password recovery system - replacing the plain text email system with a more secure reset link and adding a layer of security with the captcha function after three failed attempts. The comprehensive details that you provided indicate a thorough implementation of these capabilities.

Your clear explanation of the function of various attributes in the model, your demonstration of how the system operates, and your inclusion of diagrams are excellent.

Yet, there are some aspects which could be polished. The structure of your report initially seems disorganized due to the repetitive <link> without explanation or direction. If they are placeholders for your links, make sure to update them with the actual links when finalizing your Wikis; missing or unorganized information may prove to be confusing for someone who will then attempt to understand how your project works.

Further, while you’ve done well explaining your code and implementation, it would have been more beneficial to briefly explain the logic behind choosing to implement certain features -- specifically, why did you decide to implement captcha only after three failed attempts? This would offer more insight to your decision making process.

Additionally, consider mentioning the challenges you faced while working on the project and how you overcame them, the solutions you tried that didn't work and why, as well as areas you think you could have improved on. This would demonstrate a level of self-assessment, hindsight, and desire to improve in your future projects. 

Finally, remember to proofread your assignment to catch minor grammar and spelling mistakes. 

Good job, overall. I am looking forward to seeing more of your work in the future.
"
12,E1718,"The Expertiza project is a collaborative open source project that allows courses to create assignments for students. One of the main functions of Expertiza is to allow students to peer review the submitted assignments by their fellow classmates. This page covers the E1718 project. E1718 covers the system behind assigning peer reviews to students. The main focus of this topic is the thresholds that guide which submissions a student can review as well as how many they need to review, and can review. A review can either be assigned to a student by the instructor, or it can be requested directly by the student. When the student handles it they can choose to be assigned a random submission, or they can choose the topic which they wish to review. Assignments can be set up so that each student must review a minimum number of submissions, with the choice of extra credit for completing up to a maximum number of reviews. When review topics are chosen, Expertiza sets it up so that the student can only choose a topic that has a low enough number of other reviews. At times this can constrain the choices a student has, so to fix this the instructor can set the threshold to allow for more choices. The threshold itself is the acceptable range for the number of reviews a topic has compared to the least reviewed topic. For instance, lets say there are three topics: Blue, Red and Green. Blue has had 1 review, Red has had 2 reviews, and Green has had 3 reviews. If the threshold is set to 0, then the only topic that can be chosen for review is Blue. If the threshold is 1, then both Blue and Red can be chosen. If it is 3, then all 3 topics can be chosen. By solving the issues raised by E1718 this system will be improved in several ways. As currently set up, if a student has already reviewed all assignments within the minimum threshold, they will be unable to request another review. To solve this, when a student has reviewed all submissions within threshold k, the system should increase the threshold by m so that the student can review all submissions within threshold k+m. The current version of Expertiza also fails to show a student what the minimum number of reviews they must complete is, as well as the upper limit of reviews allowed. This will be fixed in this project so that an instructor can set the minimum and maximum number of reviews from the Review Strategy tab, and those limits show up on the student's end when viewing Others' Work. A previous issue that has since been solved was that a student was allowed to review their own submission. While this did not need further work, it did need automated testing to be written for it. Those tests were completed, as well as tests for the issues described above. 228: Increase the threshold for a student who has already completed reviews for all submissions with the minimum number. 402: Write automated tests to check if a student can review a topic only they have submitted on. 417: Implement a num_reviews_required (and num_reviews_allowed) field in the assignments table to say how many reviews per reviewer are required, and how many are allowed (default should be # allowed = # req’d.). Make it settable from the Review Strategy tab (see Issue 417) and viewable when a student clicks on “Others’ work”. Project Files (new or changed) 1. expertiza/spec/features/review_assignment.rb 2. expertiza/db/migrate/20170322074046_add_num_metareviews_required_to_assignments.rb 3. expertiza/db/migrate/20170322074238_add_num_metareviews_allowed_to_assignments.rb 4. expertiza/db/migrate/schema.rb 5. expertiza/app/models/assignment_form.rb 6. expertiza/app/models/review_assignment.rb 7. expertiza/app/views/assignments/edit/_review_strategy.html.erb 8. expertiza/app/views/student_review/list.html.erb 9. expertiza/spec/features/review_assignement_spec.rb Issue 228 According to this issue, the reviewers, having reviewed the submission with the fewest outstanding reviews, can't review any other submission until the submission they've just reviewed catches up to other submissions in number of reviews. Reviewers who have already reviewed the submission with the fewest reviews should be able to review the submission with the next fewest reviews, regardless of what the threshold is. Solution to this would be, every time a student requests for review, setup a proper filtering process with appropriate thresholds. If topic x and topic y has two reviews each and topic z has no reviews, the reviewer is allowed to review topic z, as it has the least number of reviews. He is not allowed anymore reviews until topic z catches up with x and y. To rectify this, changes were made to review_assignment.rb file where when review is requested, initially the responses with no entries, self submitted topic are filtered out from the review pool. Then, if the reviewer has done any other reviews before, such reviews are filtered out. Then the review pool is combed for submissions with least reviews and the minimum reviews count is obtained. This, added to review_topic_threshold becomes the benchmarch against which number of reviews for a topic is measured, and if it’s less than the benchmark, the review is assigned to the requestee. This way, the reviewer is provided with more flexible review policy than before. <code> Issue 402 This solution required the creation of the review_assignment_spec.rb file. It conducts tests to ensure that a student may not review a topic in which their submission is the only one. This tests the review_assignment.rb module, which is heavily used by assignment.rb and review_mapping_controller.rb. The specific tests that examined this potential error are as follows: <code> The first test checks to see if a student can be assigned their own submission if they request a review via the ""I don't care"" checkbox, which allows them to be assigned a submission from any topic. Doing so correctly triggered the warning message ""No topics are available to review at this time. Please try later."" This was further backed up by a test in which another student submitted an assignment and the same path was followed. This case did not trigger a warning and the student was correctly assigned the submission. This shows the check is working as intended. The second test checks to see if a student can choose a topic in which their assignment is the only submission. This was the main focus of issue 402. When choosing a topic the student must select a radio button for that topic and then request a review. This was no longer possible after the 402 fix as the student was unable to select the radio button for the topic if they were the only one who had submitted to it. Consequentially, this prevented the student from reaching the error message described in issue 402 ""There are no more submissions to review on that topic."" This test passed as expected showing the issue had been resolved. It was also tested whether they could select a topic in which they weren't the only submission, and this test passed as expected as well. Issue 417 The 4 variables - num_reviews, num_reviews_required, num_metareviews_required and num_metareviews_allowed - are added to the assignment table using rails migration. The default of these variables are set to 3. <code> These variables are viewable at ""others"" page for each assignment in students account, and settable at ""edit assignment"" page, ""review_strategy"" tab in instructor's account. The instructor are allowed to choose whether they want upper bound on number of reviews (num_reviews && num_metareviews_allowed) by clicking check box. By this way, the instructor can allow students to review as many submission as possible but grading only required number of reviews. Validations are done by checking whether the number of reviews required is less than number of reviews allowed. i.e.) num_reviews_required <= num_reviews_allowed. Similarly for condition follows for meta reviews. These validation are done in assignment.rb file and are executed before an update is saved into database. <code> Here num_reviews and num_metareviews_allowed are negative when the upper bound for reivews are infinity. The corresponding tests are written in assignment_spec.rb <code> The first test checks whether num_reviews accepts values less than num_reviews_required for which the validation should fail. The Second test checks whether num_metareviews_allowed accepts values less than num_metareviews_required for which the validation should fail too. 1. Please follow these instructions for testing these solutions manually. 228 1. Log in as instructor(user:instructor6) and create a new assignment and add four students to the assignment(user:student360,student361,student362,student364). 2. Log in as student, submit an artifact. (e.g:a test link) 3. Log in as second student and submit an artifact. 4. Log in as first student and review an artifact, since there is only one other submission at this point, second student's submission is up for review. 5. Log in as second student and review an artifact. 6. Now, log in as third student, submit an artifact and also do two reviews, naturally you would be reviewing first and second student's submissions. 7. At this point, first and second students' submission has two reviews and third student's submission has zero review. 8. Now, log in as the fourth student and review, you should be allowed to review all three artifacts instead of just the one with least reviews. 402 1. Log in with an instructor. 2. Create an assignment with topics to choose from. 3. Log in with a student. 4. Sign up for one of the topics from the previously created assignment. 5. Submit an assignment for that topic. 6. Go to the Others' Work tab. 7. Attempt to select that topic for review -OR- Check the box for ""I Don't Care"" 8. Attempt to request review 417 1. Log in as an instructor 2. go to edit page of an assignment and navigate to Review Strategy tab. 3. Change the allowed and required field of reviews and meta-reviews. 4. Try giving greater value for required field than allowed field. It should throw an error stating the relevant message. 5. Give the correct value and save it. 6. Sign in as a student who has enrolled for that particular assignment. 7. go to ""others"" page. 8. The allowed and required field are displayed saying that the assignment requires atleast k reviews. 9. If meta-review is enabled for that topic then the meta-review information is also displayed. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link>.","Code snippets are shown, but only the new code, not the old code that was modified.  In the introduction, the description of what is done when the current reviewer has reviewed the least-reviewed submission is wrong; it says that the threshold is increased by m.  In fact, only the threshold for the current reviewer is increased.  This is clarified later in the writeup.  Good description of what the code changes do.","Your work on the Expertiza project shows a profound understanding of the peer-review assignment system. Your detailed explanation of the issues and solutions demonstrates a thorough knowledge of not only what needed to be done but also why. Here are some points for further improvement:

1. Clarity: While your work is comprehensive, it might help to present your issues and solutions in a more simplified and structured format. Consider using bullet points or numbered lists to present your information in a more digestible format.

2. Connection with Course Content: Always try to link your tasks and solutions with the course content. Show your understanding of the course theories and principles that relate to your assignment.

3. In-text Citations: Make sure to provide the right acknowledgements if you're referring to the work of others.

4. Conclusion: Please summarize your findings at the end of your assignment. This should recap your solutions and issues, providing a holistic view of the project.

5. References: Although you provided links at the end of the assignment, it was not clear what these links referred to. Providing proper references helps to validate your work and gives credit to original sources.

Overall, your command over the technical part is laudable, and the testing instructions you provided are comprehensive and clear. Great work, keep it up."
13,E2056,"Prospective users are allowed to request Expertiza accounts over the web. When they are requested, the super-admin receives an email, and can go and approve or reject the request. The requester is then emailed as to whether the account has been approved, and if so, receives login credentials. The implementation is tedious to use, since all account requests since the beginning of time appear on the request page, and the super-admin needs to scroll to the bottom to find the current request. The requests can be approved/rejected only one at a time due to form design which can be improved. Also, the method names are quite nonstandard, when a lot of the methods have standard CRUD functionality. The steps to reach the Pending Account Request Page is as follows: 1. Log in as an admin or superadmin. <code> 2. Select Administration->show, which will bring up a list of features. 3. Click on “Pending Requests” from among the list of features to open the page containing requests from instructor/students. The admin or super admin can see a list of requests made by students and instructor in chronological order which means that the recent requests are at the bottom of the page. This makes the process cumbersome because any operation on newly created requests would be at the bottom of the page. Also requests can be handled only one at a time due to radio button forms format. Moreover, the code has places that are inconsistent with DRY principles and require some refactoring to make them more standardized. 1. Use authorization utilities from helper modules in action_allowed? to maintain code consistency. 2. Commenting on the method foreign to explain the purpose of this method. 3. Refactoring methods such as request_new and make the method more CRUD like. 4. Commenting on sections in create_requested_user_record which is a fairly long method, and includes several steps for creation of users which are not transparent. 1. Split the page into two components - a. Current(by default) b. History(Processed requests) <code> 2. Collapse all self introductions in requests to display them in one line and expand them on click for easier interaction. 3. Paginate the list to display only 10 results per page. There is an existing rspec file corresponding to the account_request_controller. The changes made in code involve renaming a lot of existing variables and adding a lot of comments for methods, so most of the existing tests are modified instead of creating new ones. 1. Beside ""Home"", click ""Administration"", then click ""Show"" and in Show click ""Pending Requests"". 2. Two tabs named Current and History are present. 3. Click on tab named ""Current"". It displays all the requests which are ""Under Review"" status and needs to be approved or rejected. 4. A checkbox is present right beside every request and you can select either all the requests which need to be accepted or all the requests which need to be rejected and click on ""accept"" or ""reject"" button. When you click on ""Accept"" button, all the requests selected will be accepted and will be moved from Current tab to History tab. Chicking ""Reject"" button, rejects all the requests selected and will move in a similar fashion. 5. Select tab named ""History"". It displays all the requests which are ""Approved"" or ""Rejected"" in reverse chronological order. In spec/controllers/account_request_controller_spec.rb we modified 6 test cases MODIFIED <code> ADDED <code> 1) According to the modification of each problem, we write test separately to test whether its function is realized or not. First, we modified method named ""request_new"" to ""new"" which creates a new request. <code> 2) list_pending_requested_finalized is clicked <code> 3) Modified the existing check with the new params. <image> <image> <image>. The function is designed to receive the information of the User who seeks the permission to access the website. The information is saved into the AccountRequest Model. The task was to split the function into different methods due to it being too verbose or write comments into the code. We chose to add comments into the function as splitting up would be inefficient. <image> <image>. The task was to design a logic to the existing code such that the administrator would be able to see requests in two different views as in 'Under Review' or 'Approved/Rejected'. An additional function 'list_pending_request_finalized' was added that would filter the requests into 'Approved/Rejected' and the original 'list_pending_request' that filters the requests with 'Under Review' status. By default the requests are ordered in descending order with respect to updated_time with the status - 'Under Review'. <image> <image>. In the account_request_controller_spec.rb file we found a few of typing errors and have corrected and committed as part of this project specification. <image>. The task was to rename the method names which are inappropriate and to rename CRUD like functions such as Request_new to CRUD function names. <image>. The method named ""Foreign"" is ambiguous and Method commenting is done describing the function and its parameters. <image>. The method action_allowed? has been updated to replace the existing code which used non standard code to check user privileges. Instead, the authorization_helper.rb methods that were added as part of project E1915 has been adapted to maintain code readability. <image>. The initial query receives all the requests from the database containing AccountRequest table without any form of order. This query that is being passed the list of requests has been modified in order to receive list in descending order of timestamp for updated_at field to show the recently changed requests at the top of list. The gem 'will_paginate' is used to access pagination features in pending request page in order to display only specific number of requests at a time for ease of navigation. Using the method ""paginate"", the number of results per page can be set. Also the corresponding paginate tab is added in the html page for navigating between pages. <image>. The list contains a field called ""Self Introduction"" in which the user writes a short description about themselves. This field can sometimes be large depending on how new requesting users modify it. To keep the view standardized, a limiter has been added to keep the display intact and expand/collapse the column on clicking it. For this we added a jquery plugin in layouts/application.html.erb <code> And the views/account_request/list_pending_requested.html.erb and views/account_request/list_pending_requested_finalized.html.erb are modified as well. <image>. <image>. We can see that we have two tabs named Current and History and in Current we can see all the requests which are in ""Under Review"" status and which needs to be either Approved or Rejected. It only displays 10 requests on each page for readability. <image> <image> All the check boxes which needs to be approved can be selected at once and get approved after clicking the approve button. <image> All the files which got approved are displayed above and gets moved to History tab. Same happens with Rejecting requests. <image> In the history tab, All the files which got approved are added to the previous requests which got approved or rejected. It only displays 10 requests on each page for readability. <image> In the requests table the column Self Introduction has a ""more"" link that lets the user expand the column to view overall content inside it and a ""less"" to collapse it back to original. <image>.","The document is not very readable.  The test plan precedes the outline of the solution.  The solution has 8 subsections, which is too many, and also, the outline is not clear.  That is the most serious issue. Too much of the formatting is ad hoc.  They number their lists manually, and not always with the same leader.","You have done a commendable job on this assignment. The thoroughness of your demonstration and analysis is clear, and you have provided a holistic perspective of the current issues and proposed precise solutions. I appreciate your understanding of CRUD principles and your attention to the importance of code optimization and standardization.

A couple of comments and suggestions for potential improvement:

1. Continue to work on your communication clarity. Despite its thoroughness, the assignment was challenging to follow at times due to convoluted sentence structures and a lack of clear transitions between your thoughts. An improvement in your writing clarity would significantly enhance the overall quality of your assignment.

2. While you have provided detailed insights into the code snippets, sometimes, there's a lack of context for understanding. Be sure to consistently explain the relevance or function of a snippet in your analysis.

3. Some parts of the assignment exhibit redundant information which could be avoided for the sake of brevity and to enhance readability. Essentially, brevity and clarity should be pursued without sacrificing detail and thoroughness.

4. I recommend visual diagrams or flowcharts to illustrate complex process flows. This could make your explanation easier to understand.

5. In your test cases, it would be beneficial to include both successful and unsuccessful outcomes to present a comprehensive analysis. Mention possible errors and solutions.

In your future assignments, consistently focus on structuring your thoughts coherently and briefly alongside maintaining your thorough and comprehensive analysis. Good job overall!"
14,E2003,"<link> is an open-source project based on <link> framework. The software allows the instructor and students with the following privileges,. 1. Create new assignments 2. Customize new or existing assignments 3. Create a list of topics that students can sign up for 4. Give grades/reviews for the students' submissions. 1. Form teams with other students to work on various projects and assignments 2. Peer review other students' submissions Note: Expertiza supports submissions across various document types, including URL and wiki pages. The assessment_360 controller is designed to gather data from all stakeholders about the performance of a student in a course. Thus, its purpose is to provide course-level statistics. At present, the controller provides only two top-level functions where each of them gives a list of students in the class. 1. all_students_all_reviews contains teammate and meta-review scores received by students for all assignments in the course 2. course_student_grade_summary gives a listing of students and what topic they worked on and what grade they received on each assignment during the semester. The assessment360 controller had three major issues. This project is aimed to address some of them, including: Issue 1: Methods all_students_all_reviews and course_student_grade_summary were too long. Common initialization and looping had to factored out by moving them into smaller methods with mnemonic names Issue 2: Method populate_hash_for_all_students_all_reviews is not easy to understand. It uses a special data structure to do a very simple task. That had to be refactored Issue 3: Method course_student_grade_summary stopped working and has to be fixed. This project aims at encouraging students to collaborate and contribute to open-source project in turn helping them understand what goes on in a full-fledged software deployment process. It also paves a way to understand how one can use Rails, RSpec to develop a system that does justice to the DRY code practicing principles. Problem 1: Refactoring all_students_all_reviews and course_student_grade_summary (a) The common elements in these files i.e., checking if the course participant list is empty or not is moved to a different function called inspect_course_participants (b) Adding on to this, all_student_all_review was broken down to two more functions, avg_review_calc_per_student and overall_review_count (c) The method course_student_grade_summary is broken down to one more function assignment_grade_summary Problem 2: Refactoring populate_hash_for_all_students_all_reviews The approach in this function is pretty straight forward when we try to break it down. It calculates, (a) The average score for each assignment for each course (b) The overall review grade for each assignment for all the students who have taken the course Passing the average score calculated from (a) checks if the student has teammates which could result in not having an average teammate_review_score. If we calculate (b) in our main function (this can be done) we would be repeating the checks that we are already doing for (a). Hence, this function is not changed Problem 3: Fix course_student_grade_summary The current implementation ran into an issue when it was comparing the Key-Value pair passed in peer_review_score . It was hard to check if each of the keys were present or not. The proposed solution makes use of a basic hash value presence check that retrieves a value from the array/hash, given a set of keys. If no value is found, it'll return nil. The current implementation of the method throws a nil error at the moment on the following line, <code> This is rectified by introducing, <code>. The functionality that the methods shared was that, both of them checked if there were course participants who had taken a particular course. This occupied 4 lines of code in both the functions. So, this is defined in a separate function called insure_existence_of and called from the two functions. <code>. The all_students_all_reviews method is one of the biggest methods in assessment360_controller.rb file. It finds the list of all students and assignments pertaining to the course. This data is then used to compute the metareview and teammate review scores for each student. The code before refactoring had 64 lines of code as shown below, <code> To calculate the average grade for each student on all assignments in this course that a student has taken in this course is refactoring in the base code by adding the avg_review_calc_per_student method. <code> To avoid a divide by zero error that is thrown when we try to calculate the average grade when a student has no teammate is handled by the overall_review_count method. <code> After refactoring <code>. This method finds the list of all students and assignments pertaining to the course. The data obtained is then used to compute the instructor assigned grade and peer review scores. It was the secong biggest method in the assessment360_controller.rb controller file. The code before refactoring is shown below, <code> In this function, all the functionalities pertaining to a course participant - student in this case, in a given assignment is invoked by introducing a new method called assignment_grade_summary. This method checks if a topic exists and if it does, it passes the final grade that is calculated for that student in that course. <code> After refactoring <code>. One of the methods devised in this project is use nouns instead of verbs. Ideally the name of a variable or method should be enough to identify it's function in the class. This is because assessment_360 controller, of course is an exception and does explain what each of the functions do on their function names, 1. all_students_all_reviews - Find the list of all students and assignments pertaining to the course. This data is used to compute the metareview and teammate review scores. 2. avg_review_calc_per_student - Calculate the overall average review grade that a student has gotten from their teammate(s) and instructor(s) 3. overall_review_count - To avoid divide by zero error 4. course_student_grade_summary - Find the list of all students and assignments pertaining to the course. This data is used to compute the instructor assigned grade and peer review scores. 5. assignment_grade_summary - To pull information about the student's grades for particular assignment 6. insure_existence_of - To make sure there are participants for the course 7. calc_overall_review_info - The function populates the hash value for all students for all the reviews that they have gotten. I.e., Teammate and Meta for each of the assignments that they have taken. This value is then used to display the overall teammate_review and meta_review grade in the view 8. find_peer_review_score - The peer review score is taken from the questions for the assignment. The main objective of improving the current Assessment 360 Controller testing is to make sure each of the functionalities are being looked into regardless of the test coverage because of the number of calculations that are actually being taken place inside the controller. In order to achieve this, tests were written for two main newly added methods in the controller. The first few tests have assumed to expect a normal condition i.e., a person exists and all other information do exist. The following test cases were made for the major methods added to the Assessment 360 Controller: 1. insure_existence_of - Checking if the course participants are empty - Check if function redirects to back - Check if function flashes an error if it's not present - When method is called, it should check if there are course participants and redirects to back and flashes error if there are no participants 1. assignment_grade_summary - Checking if the course participants are empty - Check if function redirects to back - Check if function flashes an error if it's not present - When method is called, it should check if there are course participants. When this passes, and when there are participants with team id, the total value returned for final grade should be valid. By following the below steps, a reviewer can manually test the changes made to the Assessment 360 Controller. 1. Visit <link> and enter the following credentials, <code> 2. From the menu bar, select Manage > Courses 3. Scroll down to find the respective course, and select the blue globe icon. The page should load. 4. Scroll down to find the respective course, and select the brown menu icon. The page should load. The changes made to the code is present on this <link> . Multiple comments and refactoring have been addressed in detail here. The initial build made out of pull request <link> , kept failing continuously since it was made to the master branch of expertiza. It changed the Gemfile.lock and also the database schema. This push was actually made because the beta branch and master branch of expertiza were not different at all. The new pull request <link> was made to the beta branch from our beta branch and it worked completely fine. 1. <link> 2. <link> 3. <link>.","They do a reasonably good job of describing the changes, but (1) they show the old and new versions sequentially, rather than in Github diff view, which makes the changes much more difficult to understand, and (2) in view of the lack of comments in some snippets of code shown on the wiki page, the documentation should have contained further detail on what the code does.  Would have been good for the test plan to give an overview of the testing code.","Dear Student, 

Firstly, thank you for this - a significant amount of work has been put into the completion of this assignment. The thought process behind refactoring the methods, as well as the organization of your code, is commendable. Your effort to explain each function and its role is appreciated and increases readability and understanding. 

However, I'd like to provide some constructive feedback:

1. Please make sure to follow the correct numbering sequence. There seemed to be a little mix-up in your numbering which can cause a bit of confusion.
2. Do ensure to add a brief overview summarizing the goal of your project before delving into technical details. It sets a base for readers who may not have specific background knowledge of your project or concept.
3. There are sections of your submission where the `<code>` tag is used but there is no code following. Kindly ensure to remove extraneous placeholders or replace them with the intended code before final submission.

On the technical side:

1. The method used in refactoring populate_hash_for_all_students_all_reviews is appreciated. Your solution seems to maintain the efficiency of the method while improving its readability.
2. The fixes for the reported issues in the assessment_360 controller are well thought out. Well done on also considering error handling, such as division by zero.

Definitely, continue to apply your concept of using nouns for method names; it's a good practice that improves code readability and maintainability. 

Lastly, the test cases provided were well thought out and comprehensive. Remember to also consider edge cases where inputs may be unexpected or uncommon to ensure your code can handle a wide variety of inputs.

Overall, well done! Your comprehensive approach to debugging, refactoring, and testing is a great demonstration of solid software engineering principles. Ensure to take the feedback on board for better assignment submissions in the future.

Keep up the good work! 

Best, 

[Your name]"
15,E1668,"Contents 1.1. <link> 1.2. <link> 1.3. <link> 1.4. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.5. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.1.4. <link> 1.1.1.5. <link> 1.1.1.6. <link> 1.1.4. <link> 1.6. <link> 1.7. <link>. <link> is a peer review system where the students can submit their work and do reviews on fellow students’ work. Expertiza is an open source project and is based on <link> framework. Expertiza facilitates easy creation of assignments and a list of topics for the same. It allows students to suggest a topic for an assignment as well. Students can form teams and invite other students to join their team for various assignments. Moreover, students can post team advertisements and describe the qualities they are looking for in their team members and other students can respond to the same. Expertiza overall gives a simple web interface for assignment management for both the students as well as instructors. There are various ways to use e-mail functionality in the Expertiza. To name a few examples: users should get welcome emails once they register successfully, they should get reminder emails if they missed deadline of submission of their works, they should receive notification emails when other users review their homework, or others finish reviewing one of their reviews. All of these above are functions belongs to emailing. However, currently there is no test for these functions in the Expertise, which should be added to ensure valid usage of e-mailling features. We will write feature test to check the e-mailling functionality, RSpec will be used as the testing framework. Example such as assignment record or participant record will be written with the use of fixtures. We will also use <link> to interacting with the Expertise. All possible valid or invalid cases for email functionality will be included in our tests. RSpec is a Behaviour-Driven Development tool for Ruby programmers. It is easy to write and understood thus become popular choice for BDD software development practice. Basically, we can add a new gem in the gem file, like this: <code>. Capybara is a tool which help to test web application by simulating how you can interact with you app. We will use it to test how we can set the emailing function on the web. We can include Capybara by first adding a gem file: <code> And then include it in the rails_helper.rb: <code>. FactoryGirl is a fixture used in Rails application, it is general easy to used and can be installed by adding a gem file: <code> And then include it in the rails_helper.rb: <code>. We use Docker to set up the environment to test Expertiza functions, then we install the gem files and create the expertiza_text database in SQL. These are required before we do emailing testing: <code>. T1: Test users can edit their email addresses in the email option field under profile page. T2: Test you can set emailing functionality for users under profile page. T3: Test after resetting password email can be sent to users. T4: Test after signing-up emails can be sent to users. T5: Test after updating homework emails can be sent to reviewers. T6: Test emails can be sent to users after their work get reviewed. T1, T2 and T3 are tested written in the edit_emails_spec.rb file. Testing email address can be edited successfully in the profile tab. Users can update their email addresses anytime by clicking the profile button in the header after they log in. They can fill in the new address in the ""E-maill address"" tab. We test if new address can be filled in successfully by using Capybara: <code>. Testing email option can be checked successfully in the profile tab. There are three attributes related to email functionality when we define a user: email_on_review, email_on_submission, email_on_review_of_review. These boolean values can be reset in the profile page under E-mail options checkbox can be checked/unchecked can be checked/unchecked successfully. 1) We first test that if the 'When someone else reviews my work' checkbox by using Capybara: <code> 2) Test that if the 'When someone else submits work I am assigned to review' checkbox can be checked/unchecked successfully: <code> 3) Test that if the ""When someone else reviews one of my reviews (metareviews my work)"" checkbox can be checked/unchecked successfully: <code> 4) Test that if the ""Send me copies of emails sent for assignments"" checkbox can be checked/unchecked successfully: <code> Below are the tests located in the email_notification_spec.rb file, we use a gem named 'capybara-email' to open the email we intend to send and check for the content for related mailing task: <code>. Testing email can be sent to users successfully if they reset their password. Users can reset their password if they forget about their previous ones. They can get a new password in email sent by the Expertiza system. We use capybara to test and check for password-reset content: <code> <code>. Testing welcome email can be sent to users successfully if they sign up successfully. Users will get welcome email once they get new accounts in the Expertiza, we use capybara to test and check for welcome email content: <code> <code>. Testing email notification can be sent to the users successfully once their assigned homework get updated. Each assignment are created with a contributor and reviewer, once the contributor updates their homework, the reviewer will receive a notification email informing about this action and view the update. We use capybara and check for the content for update email: <code> <code>. Testing email can be sent to the users successfully once their work get reviewed. Once a user's assignment get reviewed by a reviewer, a notification email will be sent to the user to check for the content of the review. We use capybara to test and check for the content for review email: <code> <code>. The tests were executed by submitting the following command from the terminal. <code> The results of our work shows below: <image> <image> <image>. According to our test, the emailing functionality works well under various scenarios. Possible future work may include setting up assignment examples along with participants and check emailing function work among related members. 1. <link> 2. <link> 3. <link>.",Good job of explaining the tests that were included.  Perhaps should have explained in some more detail how the tests work.,"Instructor's Feedback: 

Hello,

Firstly, I appreciate your overall effort put into this assignment and your thorough discussion of your testing process for the Expertiza system. It's evident that you've put a significant amount of work into detailing the steps and tools used, including RSpec, Capybara, FactoryGirl, and Docker - which is commendable.

However, a few things can be redefined to improve your work:

1) In your testing description, it would be helpful if you could provide an evaluation or summary of your test results. Did your tests pass? Were there any failures or bugs discovered? Giving such details may present a more comprehensive view of the entire testing phase.

2) Secondly, it seems like you've missed to provide an actual content in your 's where you've set ""<link>"", ""<code>"" and ""<image>"". Watch out for these and replace them with the necessary references, scripts, or screenshots. These elements will give your assignment the necessary context.

3) Also, your explanation of the tests performed (T1 to T6) can be a bit more descriptive. Try elaborating on the specific conditions or scenarios under which the tests were carried out to provide a clear picture of your testing approach. 

4) The presentation of hierarchical organized content seems to follow an irregular pattern. Make sure to stick to an incremental format, as it can improve the readability of the document. 

Lastly, I strongly recommend proofreading your work for typing errors or omissions, as they can often lead to misunderstandings or confusion.

Despite the minor issues, your work demonstrates a solid understanding of testing procedures within the Expertiza system. With a little more attention to detail and clarity in your presentation, your future assignments could be exceptional. 

Keep up the good work!"
16,E2004,"Expertiza allows the instructors and teaching assistants to store, retrieve, edit or delete assignments for a course that they are teaching. assignments_controller.rb is one of the biggest controllers that has a lot of scope for refactoring. This controller is responsible for creating and changing assignments. It consists of the CRUD operations for an assignment along with small helper functions related to the deadlines, meta-reviews, team formation and so on. The primary issues with the code in this controller are listed as tasks. Current implementation of create method has too many assignments and multiple layers of if conditions. It also has too many lines of code. <link> has identified following issues with the method: <code> We extracted a method called assignment_form_save_handler from the code to handle the case when assignment_form is saved. This allowed in reducing the number of lines in the create method from 33 to 15. Assignment Branch Condition size was also reduced from 56.37 to less than 15. <image> Following methods were extracted from assignment_form_save_handler : 1. fix_assignment_missing_path - to handle non existent directory path 2. update_assignment_form - to update assignment due dates, and questionnaire array in assignment form <image>. <link> shows following issue: <code> <image> This method had assignments and method calls that could be consolidated. By removing and grouping assignments and method calls into helper methods, we can still use them and reduce the branch condition size. Thus, the methods update_due_date , update_assignment_badges , and user_timezone_specified were created. 1. update_due_date contains the loop that adjusts due dates for an assignment. 2. update_assignment_badges updates instance variables 3. user_timezone_specified flashes an error if the user did not specify a preferred time zone for an assignment. <image> <image> <image>. <link> shows following issue: <code> The branch size of the copy method was inflated due to: 1. Assigning (old_assign and new_assign) things that are only used once or not all 2. Calling methods to assign values only used once <image> To reduce the branch size: 1. Group assignments into a helper method which reduces the assignment and method call count We created helper methods update_copy_session and check_same_directory? 1. update_copy_session contains assignments unused in the copy method, but relevant to the program 2. check_same_directory compares directories for two assignment IDs, consolidating the conditional used in the copy method. <image>. The current implementation of the empty_rubrics_list method has many different branches of the code that could be executed. <link> identified Assignment Branch Condition size to be too high. <code> These include multiple if/unless statements as well as loops that may or may not be executed. We sought to reduce this problem by breaking up the sections of the code with different branches into their own functions, reducing the branch condition size for empty_rubrics_list . We extracted code to remove questionnaire types from the rubric list that are already in existing assignment questionnaires into a method named remove_existing_questionnaire . Likewise, we extracted code that conditionally removes questionnaire types from the rubric list (such as removing the teammate review questionnaire if the team only has a size of 1) into a method named remove_invalid_questionnaires . <image>. This implementation uses nested and sequential conditional statements. While it works to decide which flash message should appear, it can be simplified by removing the nested structure and using elsif statements. <image>. The current implementation of the create method has a high cognitive complexity because there are nested iteration blocks. <link> shows following issue: <code> There are two .each blocks, which are used to update assignment_questionnaire and due_date . We have resolved this issue by extracting those blocks into separate method named update_assignment_form . The current implementation of the empty_rubrics_list method has a high cognitive complexity due to there being nested iteration blocks. <link> indicates following issue: <code> There is a .each block on the assignment questionnaires and there is a .reject block on the rubric list entries nested within it. We sought to solve this issue by extracting the .reject block into a separate method named remove_existing_questionnaire . The existing code had a line length of 180 characters. <code> <link> recommends line length to be less than 100 characters. We have used backslash (\) to split the line into two lines of 98, and 97 characters each. <image>. You may have noticed method names have been changed. This was done to clarify what the methods do, as there were no comments to explain the methods, and shorten the names. Methods have also been given comments to describe their functionality. RSpect tests exist for the main methods used in the assignments controller: 1. action_allowed? 1.1. when params action is edit or update 1.1.1. when the role name of current user is super admin or admin 1.1.2. when current user is the instructor of current assignment 1.1.3. when current user is the ta of the course which current assignment belongs to 1.1.4. when current user is a ta but not the ta of the course which current assignment belongs to 1.1.5. when current user is the instructor of the course which current assignment belongs to 1.1.6. when current user is an instructor but not the instructor of current course or current assignment 1.2. when params action is not edit and update 1.3. when the role current user is super admin/admin/instructor/ta 1.4. when the role current user is student 2. new 1.1. creates a new AssignmentForm object and renders assignment#new page 3. create 1.1. when assignment_form is saved successfully 1.2. when assignment_form is not saved 4. edit 1.1. when assignment has staggered deadlines 1.2. As value errors should be covered in the ability to make assignments, the only test needed for this is when deadlines are staggered. A reminder for specifying rubrics is also tested. 5. update 1.1. when params does not have key :assignment_form 1.1.1. when assignment is saved successfully 1.1.2. when assignment is not saved successfully 1.2. when params has key :assignment_form 1.1.1. when the timezone preference of current user is nil and assignment form updates attributes successfully 1.1.2. when the timezone preference of current user is not nil and assignment form updates attributes successfully 6. show 1.1. renders assignments#show page 7. copy 1.1. when new assignment id fetches successfully 1.2. when new assignment directory is same as old 1.3. when new assignment id does not fetch successfully 8. delete 1.1. when assignment is deleted successfully 1.2. when assignment is not deleted successfully These tests were included and not added to because they cover all the instances that the methods would be used under. Our additions to the code, helper methods, do not have tests as they are used in the main methods and do not need their own tests. Otherwise, there would be redundant testing. The helper methods did not change any functionality. Additional testing occurs in assignment_creation_spec, but that tests the integration of the assignments controller with other features. These may fail, but changes in the assignments_controller may not be the cause. Our build fails, but the fix is proposed <link>. To test our changes, follow <link> to set up the expertiza environment. If our repository produces errors during setup, verify if the issue is our repository or your setup by trying to setup the main expertiza repository. In a terminal do the following: 1. navigate to the experiza folder 2. enter: rspec /app/controllers/assignments_controller 1.1. for RSpec tests 3. enter: rubocop /app/controllers/assignments_controller 1.1. for Rubocop tests The assignments_controller.rb file has a testing file called the assignment_controller_sepc.rb . We ran rspec tests, and made sure all the tests passed with our changes. <image> We also ran rubocop for assignments_controller.rb file, and were able to eliminate the issues reported for methods we worked on. <image> Here is a <link> showing test results including rubocop results for assignments_controller.rb We have deployed our application on NCSU VCL. To access the application use this link: <link> , with following credentials: 1. Username : instructor6 1. Password : password. As can be seen from <link> , our changes have increased the coverage of assignments_controller.rb by 10.9%, from 30.5% up to 41.41%. While we did not make any changes to the tests, we did reduce the amount of testable code by reducing redundancy and extracting common code in the controller. 1. There are other portions of the assignments_controller that can be refactored. 2. There could be a collection of messages that are used in the application that can then be referenced in the code. This would have two benefits: allowing for a different message collection to be used for translations and also removing duplicate messages like are seen here: <code> 1. More thorough tests can be added to the assignments_controller spec to get the coverage closer to 100%. <link>.","Good writeup. They have added code in the form of screenshots but this makes it very easy to understand the difference between the old code and the new code. Each issue is separately addressed. Some descriptions could have been more specific, e.g., ""check_same_directory compares directories for two assignment IDs, consolidating the conditional used in the copy method..""  I wonder what ""consolidating the conditional"" means. ","Dear Student,

This was an impressive performance shown in paraphrasing the root cause of the issues found in the existing codebase and working towards a solution with stringent optimized ways. 

Your understanding of the code, identifying relevant issues, and working towards addressing them systematically showcases your well-refined coding skills. Your approach to reduce the complexity and improve efficiency by breaking down monolithic code into discrete helper methods is highly commendable.

Your efforts towards implementing single responsibility principle, reducing line lengths, simplifying conditional statements, and enhancing readability by renaming methods enhanced the quality of the assignments_controller. Additionally, your diligence in using RSpect tests to validate changes, rectify failing tests and improving code coverage is exemplary.

The lucidity in your thought process was well reflected in the way you have refactored the code into simpler methods. This not only increases readability but also assists in efficient debugging and maintenance. Your meticulous approach is also visible in the way you dealt with excessive assignments, complex branch conditions, and cognitive complexity.

It would have been more interesting if you included the code snippets alongside your report to provide more context to your explanation instead of just mentioning <code> or <link>. 

Additionally, while you've done a great job improving the existing tests, the mention about the absence of additional tests could use a little more explanation. It would be helpful to detail why no new tests were deemed necessary. Are they not necessary because of the coverage analysis? Is the existing test suite robust enough to cover all control flows introduced by the refactoring?

Moreover, more extensive implementation of error and exception handling mechanisms could add a great value to the code. This would ensure the application's resilience to unexpected failures.

In conclusion, you are showing strong progress in this area of study. There are always things to improve, but you are clearly demonstrating a solid understanding of the principles needed to refactor code for readability, maintainability, and performance. Keep up the good work!
 
Best Regards,
[Your Name]
"
17,E1555,"For users intending to view the deployed Expertiza associated with this assignment, the credentials are below: 1. Instructor login: username -> instructor6, password -> password 2. Student login: username -> student5762, password -> password 3. Student login: username -> student5763, password -> password 4. Student login: username -> student5764, password -> password Please make note that new accounts and password resets are disabled on the Expertiza deployment; That functionality is outside the scope of the assignment, and it is unnecessary to review that functionality. Expertiza is an open-source web-application with functionality to facilitate the submission and peer review of assignments in an academic setting. Expertiza supports team based assignments, student and instructor roles, allocation of assignments to students (e.g. sign-ups) with number limits. For this assignment, 7 Work Items were assigned, requiring the modification and testing of the Expertiza Ruby on Rails code. Of the 7 Work Items in the scope of our assignment: 3 of the Work Items involved making code changes to Expertiza, 3 other Work Items involved testing those changes, and one final Work Item had a deliverable of a recorded online video. Below is a list of the Work Items in scope, each with a ""WI#"" identifier, which will be used henceforth to reference the respective Work Item. 1. WI1 : Generate _team_name() exists in 2 places: team.rb line 41 and team_helper.rb line 62. Remove the one which is not used. 2. WI2 : Write test cases for the remaining generate _team_name() method. 1. WI3 : Test and fix (if any of them are broken) if export_fields(), import() and export() works for both assignment_team.rb and course_team.rb. 2. WI4 : Write tests for team exporting and importing for both assignment team and course team. 3. WI5 : Record a video which demos team exporting and importing, submit it to youtube and submit the youtube link to Expertiza. 1. WI6 : In add_member method, testing if the team can have more members (using “can_add_member” as flag variable) should be extracted to a single method. This method should be used by join_team_requests_controller.rb too. 2. WI7 : Write tests for adding members when both the team is full and not. Please note that below sections discuss the work done within the scope of each Work Item, but Work Item WI5 is not discussed. Please view the link in the submitted Expertiza assignment. 1. Work Item 1 ( WI1 ): The generate_team_name() method was removed from the <link> file. This method was removed because, during analysis and testing it was found that the Generate_team_name method (line 159) in the <link> model file was being executed. 1. Work Item 3 ( WI3 ): In the <link> file, updated the export function (line 39) to export the team members' names consecutively instead of with a space in between them. Making this change now made the export_participants method unnecessary, so that method was deleted. (The export_all_assignment_team_related_to_course function was also changed in the same manner, but that function is deprecated.) The add_member function (line 177) was added as a overriding function in the course_team function class, such that it doesn't check if the team is full. 1. Work Item 6 ( WI6 ): In the <link> , the add_member method (line 69) was refactored to check if the team can have more members. Additionally, the full? method (line 60) was customized such that it was more useful. The <link> controller-file was modified to add additional checks for handling the case of sending a team request to a team which is already full. (line 50). 1. Work Item 2 ( WI2 ): The <link> file was added, and the included test cases tested the generate_team_name() method functionality. The purpose of each test case is listed in a comment prior to the actual case. In summary, the cases test for name generation, additional name generation, name generation of a zero-length string, name generation of a null string, and name generation after a loop of 20 generated names. 1. Work Item 4 ( WI4 ): The <link> file was updated to cover more test cases. The <link> and <link> fixture files were added for better support. The cases test the retrieval if course information, general importing, importing of participants, exporting, field exporting, and testing a failed duplicate import. 1. Work Item 7 ( WI7 ): the <link> file was added, and the enclosed test cases tested the functionality of attempting to add members to a team, and whether the process was successful or not. The following list of fixture files were also added to assist in testing: <link> , <link> , <link> , <link> , <link> , <link> . The test cases test for successful member adds, failed member adds, and participant and non-participant adds. This <link> , which was created as one of the deliverables of the assignment, provides a good instruction to the forms and pages associated with the functionality in scope. To test the functionality under WI1 : log in as admin or instructor, navigate to Manage Courses, tab to assignments, for an existing assignment choose the icon to the right which navigates to creating and managing teams. Click 'Create Team'. To test the functionality under WI3 , please view the video above. To test the functionality under WI6 , log in as admin or instructor, click on the Assignments tab in Manage Content, for an existing assignment choose the icon to the right which navigates to creating teams. For an existing team, choose the green '+', then add a user's account name. 1. Perform analysis on the remaining generate_team_name methods to validate whether or not the two remaining versions need to continue to exist in the code. 2. Perform analysis to consider adding a more robust Teams view. Or, consider more clear functionality on how to go about getting to the Team functionality. 3. Consider a full-on usability/UX overhaul. The application as a whole has good functionality, but the UX is somewhat limiting. 4. Improve Deployment SOP. 5. The two below scenarios result in errors: Scenario 1: Assignment Teams Login as instructor -> Click Assignments Tab -> For some assignment, click Create Team button on the right Here adding a non participant to a team results in a flash message. Adding a non user (invalid username) results in a crash. Scenario 2: Course Teams Login as instructor -> Click Courses Tab -> For some course, click Create Team button on the right Here most of the functionalities seem to be broken. Here clicking the ""Create team"" option results in a crash. Adding members to existing teams also does not work. Deployment of Expertiza on Heroku: 1. Reserved a VCL machine with environment [CSC517, F15] Ruby on Rails / Expertiza 2. Cloned a copy of Expertiza from GitHub. 3. Did bundle install. (Faced some issue here and was fixed by running a command. Got help from Piazza posts) 4. Created the DB in dev environment and loaded all data from scrubbed db provided by TA. 5. Ran the server binding the ip to the ip of the machine.","If your charge was to create a two-page writeup, you did an excellent job.  Most of the reviewers asked for more detail, and we think that more detail should have been provided too.  Also, we suggest that the use of ""Garbage"" for team and course names conveys disdain for the project.","Hello,

Thank you for the detailed submission. Your detailed delineation of each work item and the resultant action taken does reflect your conscientiousness. 

You've successfully demonstrated a sensitivity to sounds code authoring principles—by replacing redundant functionalities, adding test cases, and enhancing methods to add quality checks. Your detailed elucidation on how to test each of the work items is instructive and clear. 

The 'improvements and recommendations' section shows that you have performed a thorough code analysis and have a deep understanding of the code architecture and possible pain-points. 

While you have referenced several links in your response, it doesn't link anywhere, and I am left guessing what the page entails. You'll need to ensure these links are working in your final assignment. Also, always validate any assumptions about the functions being deprecated. It would have been helpful to include brief comments on your decision for including or excluding certain features. 

We also noticed a couple of instances where the numbering resets back to 1. This may be a typo - please check and correct where necessary. 

Your account of the deployment process on Heroku is articulate and easy to follow. Nonetheless, you can better organise this by using bullet points, to outline the list of actions. 

For continued progress, I encourage you to consistently work on these identified areas and challenges. 

Keep up the good work. 

Best,
[Instructor Name]"
18,E1829,"<link> is an open source project based on <link> framework. The Expertiza project is a software that creates reusable learning objects through peer review. It is a web application where students can submit and peer-review learning objects (articles, code, websites, etc). It is used in some courses at NC State University and by professors at several other universities. It supports team projects, and the submission of almost any document type, including URLs and wiki pages. Expertiza enables the instructor to create new and customize existing assignments. It also enables the instructor to create a list of topics the students can sign up for as part of a project. Students can form teams in Expertiza to work on various projects and assignments. Expertiza supports submission across various document types, including the URLs and wiki pages. The import feature is the most helpful feature for instructors to set up assignments. The instructors usually have a list of students, teams, etc. from their learning management system. Being able to import these into expertiza saves a lot of time when setting up an assignment. Rename existing team when there is a conflict ->When importing teams there are different options to handle conflicting team names. We added an option rename EXISTING team when a conflict exists. <image>. Merge teams when there is a conflict ->When importing teams, and a conflict exists there is an option to merge the two teams by inserting the new members into an existing team. <image>. Validate file when importing participants If one attempts to import users or participants, and does not specify the file to import from, a NoMethodError error occurs. ->The error has been handled by validating the file before importing the teams, thus the file needs to mandatorily be uploaded in order to import team. <image>. Import of topics chokes on special characters It seems that non-ASCII characters in the description (e.g., a curly apostrophe, and perhaps also an en-dash) caused a SQL error in inserting the description string into the database. ->While importing the participants, the user can include special characters in the project description and is successfully stored in the database: <image>. Count of fields wrong in import When importing participants (or users), it is typical not to specify a password, but rather to have the system generate it. But if you do that, Expertiza reports that each record in the file you are importing does not have enough records. ->When the user tries to upload the file to import participants, password record should be made optional and let the user upload without password record: <image>. <image>. 1. We search the database to see if there is an existing team with the same name. In such a case we save the old team in the ‘team’ variable and set the team_exists flag to true. 2. We then cal the handle_dups method which handles the case if value chosen by the user is ‘insert into existing team’, inside the code this value is represented as ‘insert’. 3. Then the import_team_members function is called 4. We get the user through his/her name 5. If a user isn’t registered, we get a nil object and raise an ImportError 6. Else we add the user to the team if he/she isn’t already in the team 7. The add_member function only works till the team isn’t filled to its maximum capacity In file app/models/team.rb <code>. 1. We included a new option in the duplicate handler field. 2. We added a new handler in the handleDuplicates method to handle the given option as shown in the below screenshot. 3. We leveraged the existing generateTeam() method and sent the existing team id to this method and replaced the existing team’s team name as follows: In file app/models/team.rb <code>. 1. We validate the file before importing the teams. Thus, the file needs to mandatorily be uploaded in order to import team. 1. In the import method in user.rb file, there is a validation to check if the record length is less than 3 which is exclusive of password 2. If the record length is greater than 3, it indicates that there is a password in the record and we save the password in the database 3. If the length is equal to 3 then new system password is generated and saved for the user In file app/models/user.rb <code>. 1. Sql allows unicode values to be stored in the database. 1. <link> 2. <link> 3. <link>.","There are good and bad aspects to this document.  On the good side, it has a description of what has been done to fix each issue.  The description is very clear.  On the bad side, the section on some issues says nothing about what was changed in the code.","Your assignment showcases detailed exploration and understanding of the Expertiza project's functionalities. It is clear that you grasped the essential features, such as peer-review mechanism, support for versatile document types, the capability to customize assignments, and the proficiency to support team projects.

Your walkthrough on the import feature and its significance to instructors is commendable. Similarly, your attention to details is noted in explaining the conflict resolution during team imports and the validation required during file import for participants.

However, some areas still could be improved:

1. You could have provided possible personal improvements or further enhancement ideas on the system for added benefit to the existing functionalities.
2. Your description of technical implementations under the topics ""Rename existing team when there is a conflict and Merge team when there is a conflict"" is succinct but could be more precise and technical for a better understanding.
3. I appreciate your effort in describing how the import system handles special characters and mismatched field numbers, but it would be more informative to go into the specifics of how these resolutions are achieved in the backend.
4. Including the code snippets would be beneficial in providing a clear understanding of your explanation, unfortunately, the assignment simply states ""<code>"".

Lastly, when pointing out the existing functionality in Expertiza, make sure to also critically analyze areas that could benefit from optimizations, and further streamline the user experience.

Overall, your submission is insightful, well-ordered, and shows a good understanding of Expertiza. More concentration on specific technical elements could enhance more comprehension on the back-end operations. Keep it up!"
19,E1959,"<link> is an open source web application project developed using Ruby on Rails framework. Let us list some of the functionalities that Expertiza allows us to do under different roles: As an Instructor: We can create new assignments, edit the existing assignments, copy the assignments and also delete the assignment. The instructor can also add participants, reviewers to a particular assignment. As a Student: They can form teams to work on various projects and also bid for the projects they would like to work on. They can also review other student's work and can give feedback on them. They can also submit various types of documents including the URLs and wiki pages for their project or assignment submission. Design patterns are not applicable as our task involved just modification of existing methods. When an instructor or a TA logs in to expertiza, s(he) can see a list of assignments under the assignment tab. An instructor or a TA can copy an assignment to use the same event in another course or as another assignment. When the user copies the assignment, the assignment is being copied without providing required flexibility to the users. Majorly, we are focused on implementing two features that shall add flexibility to the copy functionality. Issue 1: While copying an assignment, the user (instructor or TA) is not asked whether they wants to copy the topics along with the assignment or not. Currently, it is copying the topics, without providing any choice for user to not have the topics. Issue 2: While copying an assignment, the teams/students assigned to each topic are not getting copied. The user might want to copy the teams/students mapped to the topics as well. 1) Login to expertiza.ncsu.edu using instructor credentials. 2) Navigate to Assignments section. (Hover on Manage Tab -> Click on Assignments) 3) Copy the assignment of your choice by clicking copy icon located on the right side of the specific assignment. Above steps copy the assignment. Remember that this process did not give you the flexibility of choosing whether to copy/not copy. 1) Topics linked to assignment. 2) Students/Teams linked to each topic. Present system copies the topics but doesn't copy the students, even if you don't want it this way. Our implementation is to provide the user with the functionality to choose to copy/not copy topics linked to an assignment and students/teams linked to each topic. We have modified 5 files and mainly we have modified code in two classes they are: 1. apps/controllers/assignments_controller.rb and 2. apps/models/assignment_form.rb. So before we made any changes, the flow was, when an assignment is copied: def copy in controllers/assignments_controller.rb is called which calls a function def self.copy in models/assignment_form.rb. To solve the issue, we have created a new web page that is triggered on clicking the copy icon for the assignment. The view page is the checktopicscopy.html.erb under the views/assignments folder. This page asks the user to select from 3 options, which are: 1. Copy without Topics. (Blank Assignment) 2. Copy with Topics. (Assignment with only topics) 3. Copy with Topics and Teams. (Assignment with topics and teams) Based on the option chosen by the user, this option is passed by the def copy in controllers/assignments_controller.rb to def self.copy in models/assignment_form.rb. <code> <code> The def self.copy in models/assignment_form.rb now receives this value and creates a duplicate of the assignment without copying the teams and topics originally. If the user chosen the option to just copy a blank assignment (i.e. without the topics or teams, the execution does not enter into any of the if conditions. If the user wants to copy the assignment with only the topics (but not the teams), then it goes into the first if (Line 330 [refer code below]) and copies the topics as well but does not enter the next if (Line 335 [refer code below]). If the user wants to copy the assignment with the topics as well as the teams, the code will enter the first as well as the second if condition and copy the topics as well as the teams. <code> The code modifications and their coverage have been covered in the following section. We have made changes to the test cases and both the models/assignment_form.rb and also the controllers/assignments_controller.rb have passed all the test cases. The tests can be executed rpec spec and the results for the 2 main files we have modified are shown below: <code> See the detailed coverage report below. 1. models/assignment_form.rb In this file, the coverage has increased from 61.39% to 85.65% after modification. Original file: <image> Modified file: <image> In the modified file, the following code has been added, <code> <code> 2. controllers/assignments_controller.rb In this file, the coverage has increased from 88.66% to 88.8% after modification. Original file: <image> Modified file: <image> In the modified file, the following code has been added, <code> <code>. By following the below stated process, you can test the implementation that we worked on, which is: Target 1: Provide the user with the option to select copy/not copy topics linked to an assignment. Target 2: Provide the user with the option to select copy/not copy students/teams linked to a topic. Step 1 : Visit <link> . Enter the credentials: Username: instructor6 Password: password Step 2 : On the top, hover on Manage tab. Click Assignments. Step 3 : Choose an assignment that you want to copy. We would recommend you choosing a robust assignment that has Topics and students/teams associated with topics. OSS Projects generally have these. [Please make sure that you are under the Assignments tab or select the assignment besides the course] If you want to check and see if an assignment has topics or not, click on Edit (pencil icon) on the right. - If this assignment has topics, you will see a tab named Topics on the right of General tab. If there are no topics, you won't see Topics tab. - On clicking the Topics tab, you can see the list of topics. If students/teams are assigned to topics, you will see student names (alias representations, like student1234 student2343) under each Topic name in 'Topic name(s) column'. If you don't see any such, it means that teams/students are not assigned to topics. Step 4 : After you chose the assignment that you want to copy, click on the copy icon on the right of the corresponding assignment. Where is the copy button located? Check the image below. <image> Step 5 : Clicking the copy button will take you to copy options page, where you can select the options for copying. The page looks like this: <image> Step 6 : Choose the option you wish to test. Click create. Now the assignment shall be copied with the options you provided. Step 7 : After copying, the application takes you to 'Edit' page for the assignment where you can edit/view the details pertaining to the assignment. Here, you can test our implementation. In step 6, if you chose to - copy without topics: You won't see 'Topics' tab near General tab. - copy with topics: You will see 'Topics' tab near General tab(As shown in image below). Navigate to Topics tab where you can see and check that the respective topics have been copied. You won't see students under each topic in 'Topic Name(s)' column(If there are topics under Topics tab in original assignment from which you created this copy). - copy with topics and students: You will see 'Topics' tab near General tab(As shown in image below). Navigate to Topics tab where you can see and check that the respective topics have been copied. You will see students under each topic in 'Topic Name(s)' column(If there are topics and students under Topics tab in original assignment from which you created this copy). <image> Step 8 : Please rename the assignment to some random string of your choice. Having it as 'Copy of'.. is creating issues of duplicate names when creating a new copy (more details in the section below, named 'Our Recommendation for a separate issue'. Not required for students). If not changed, the next tester might face difficulty while testing(which we don't want to see happening :)). Step 9 : This completes the testing. Reiterate from step 2, if you wish to test again. The code we created can be found below. 1. <link> 2. <link> 3. <link> The project could be run locally by cloning the <link> and then running the following commands sequentially. <code>. An error occurred while attempting to extract the child content.","""-The team has  done a great job on the writeup of the project.
-The screenshots of code are useful, but the changes could have been shown more concisely with Github diff view.
-All the required subheadings have been covered in the writeup.
-They also added a section on """"Our Recommendation for a Separate Issue (For Instructors only)"""", which includes the issue that the team feels should be addressed on priority. 
-They have also added enough information on how to precisely test their added feature which is great. 
-Explained the test plans 
","Hi,

Overall, a well-presented assignment. The problem you chose to take on was clearly explained and your approach in resolving it was methodical and well understood. Your thorough step-by-step process description provided a strong level of comprehension for both technical and non-technical readers, which is excellent.

There are a few things you should take into account for assignments in the future:
1. You mentioned that design patterns are not applicable to your task, which involved only the modification of existing methods. While it's true that you primarily worked with existing methods, remember that good software engineering practices, including the use of design patterns, are always relevant. In future tasks, consider how you might apply design patterns, even in modification tasks.

2. The <code> and <image> placeholders in the assignment seem to indicate where code snippets or images are desired. If those were intended, they shouldn't have been omitted, as they would provide crucial data for understanding your implementations.

3. Additionally, you've mentioned a few actions that the user can take, such as logging in with certain credentials or cloning a repository, and have included <link> placeholders. Remember to provide valid URL links to ensure understanding.

As for the improvements you’ve made to the Expertiza application, they make the process of using the copy function more intuitive. Giving instructors and TAs the ability to choose whether to also copy topic and student details is a great functionality as it addresses different use case scenarios. Good job!

In conclusion, the quality of work in your assignment is commendable. Keep it up. You have evidently put in an enormous amount of work, and you should be proud of your efforts. 

Best,
[Your Name]"
20,E1552,"Refactoring is the process of changing a software system in such a way that it does not alter the external behavior of the code yet improves its internal structure <ref> Refactoring: Improving the Design of Existing Code - by Martin Fowler, Kent Beck, John Brant, William Opdyke, Don Robert <link> </ref>. It is a disciplined way to clean up code that minimizes the chances of introducing bugs. In essence when you refactor you are improving the design of the code after it has been written. There are many benefits of refactoring as follows: <ref> Refactoring Software using Design Patterns - by Masatomo Noborikawa <link> </ref> 1. Refactoring improves the design of software. Refactoring often cleans up codes by deleting duplicates, divides a big chunk of codes into several methods, and makes the program more understandable. 2. Because refactoring makes a design cleaner, it helps the programmers understand codes better and see things that may have not been seen before. 3. Refactoring helps spot bugs since it makes the software more comprehensible. 4. Refactoring turns an adverse design into a good design, which allows for rapid software development. Contents 1.1. <link> 1.2. <link> 1.3. <link> 1.4. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.5. <link> 1.6. <link> 1.7. <link> 1.8. <link> 1.9. <link> 1.10. <link>. It is the process of evaluating work done by an individual or a team by another team or an individual with expertise in the concerned area. Types of Reviewing Strategies in Expertiza - 1. Instructor Selected Reviewing - Using this strategy the instructor assigns reviews to all participants of the assignment. After selecting this strategy the instructor has the following two options - 1.1. Set number of reviews done by each student. 1.2. Set minimum number of reviews done for each submission. Then the instructor can click on assign reviewers and map the students to the topics which should be reviewed by them. <image> Instructor selected Reviewing 1. Auto Selected Reviewing - If the instructor selects this strategy, students need to select reviews themselves. Either the student is given a list of topics to choose from and he selects which topic he wants to review, or he checks “I don’t care which topic I review” and he/she will be randomly assigned a topic to review. The instructor can also specify two parameters after selecting this strategy - 1.1. Review topic threshold: - Let us assume Topic 1 has a submission than has not been reviewed. Topic 2 has submissions that has been reviewed atleast 2 times and k is set 2. Then the student will not be able to select topic 2 until all of topic 1’s submission has been reviewed atleast 2 times. 1.2. Maximum number of reviews per submission: - This specifies the maximum number of times a particular top can be reviewed. <image> Auto selected Reviewing 1. Student Selected Reviewing - In this strategy the student selects a particular submission to review instead of a particular topic. This feature had never been used and did not work correctly. Hence it has been removed from the system. However there are a lot of places where the code for student selected reviewing exists however it not being called anywhere. 1. <link> 2. <link> 3. <link> (For Instructor - username: instructor6, password: password. For student - username: student5700, password: password). <code>. dynamic_review_assignment_helper.rb allows the system choose a team to review when a student chooses a topic to review. It helps the code choose topics that have submissions with fewer reviews than other topics. A threshold k is used to decide whether a particular topic can be chosen. If, e.g., Topic 1 has a submission that has not yet been reviewed, and Topic 2 has no submission that has been reviewed by fewer than 3 reviewers, then the incoming reviewer can only choose Topic 2 if k ≥ 3. This class does not actually decide what is reviewable, but it does make up a sorted list of the submissions by the number of the reviews they have. dynamic_quiz_assignment_helper.rb is similar, but for quizzes. 1. Keep only ""auto selected"" and ""instructor selected reviewing"". 2. The find_submissions_in_current_cycle method returns a list of participants. It should return a list of teams. 3. Making sure all the conditions mentioned at the beginning of the class are implemented in both the helper classes 4. The two classes have a lot of duplicated code. Remove all DRY problems. While making changes to the helper classes to remove student selected reviewing, a commit was made to the expertiza repository which deleted the page for student selected reviewing. <link> In student-selected reviewing, a student was allowed to review a particular submission and not just a particular topic.The functionality for “student-selected” reviewing was never implemented successfully. Hence, the methods corresponding to the aforementioned functionality was needed to be removed. An error occurred while attempting to extract the child content. Making sure all the conditions mentioned at the beginning of the class are implemented in both the helper classes. The helper classes while returning a list of teams should check the below set of conditions. Each of the below conditions need to be checked at one place to ensure better code readability and maintainability. 1. The article was not written by the potential reviewer. The potential reviewer should not be able to review its own submission and hence a check for this condition is required. However, it was already implemented in the code beforehand. 1. The article was not already reviewed by the potential reviewer. The potential reviewer should not be able to review a topic which is already reviewed by him/her. The same was also implemented along with the above condition. 1. The article is not on the same topic as the potential reviewer has previously written about. The reviewer should not be able to review on the same topic that he/she submitted as the reviewer could give biased reviews to make his/her own submission seem better. This was not implemented previously and was implemented in the code changes by checking the topic id. Implementation : <code> 1. The article does not already have the maximum number of potential reviews in progress. The reviewer should only be able to review topics that have not reached the maximum number of reviews. The check for the same is done in get_state method where the current_review_count is compared with max_review_count and make it unavailable. 1. The article has the minimum number of reviews for that assignment. The article is made available if it has the minimum number of reviews for the assignment and the same is checked in get_state method where the current_review_count is compared with least_review_count and make it available. Implementation: <code>. The following files had code for “student-selected” reviewing which needs to be removed. 1. dynamic_quiz_assignment_helper.rb (Entire file deleted) 2. dynamic_review_assignment_helper.rb (Entire file deleted) 3. review_mapping_controller.rb (Only specific method mentioned below deleted) The method show_available_submissions() in review_mapping_controller.rb was calling student selected reviewing. Since this was the only place the method was being called we decided to delete the below code snippet. <code> Also, this was the only call being made to dynamic_review_assignment_helper.rb and this helper is not used in instructor selected and auto selected reviewing strategies. For these strategies another view is being rendered specifically _set_dynamic_review.html.erb. Similarly dynamic_quiz_assignment_helper.rb is also not being used by any controller. Hence the two helper files have been deleted after confirmation from the developer. The project involved refactoring code which was used for student selected reviewing. However since this feature was removed from Expertiza during the refactoring, we had to delete the code and hence no design pattern is applicable. Since we have deleted the entire helper classes and there has been no code addition, we cannot add any new test cases for deleted code. However, we can manually test to ensure that the code deletion did not cause any broken links by following the steps mentioned below. Creating an Assignment: 1. Login using instructor. 2. Go to Manage-->Assignments-->New Public Assignment 3. Add couple of topics to the assignments from the topics tab. 4. Check “Allow reviewer to choose which topic to review” and “Enable authors to review others working on same topic” in the same tab. 5. Choose the review strategy as Auto-Selected in Review Strategy tab. 6. Choose appropriate deadlines in the due dates tab. 7. Go to Manage-->Assignments--><Your Assignment Name> 8. Add participants to the assignment. Signing up and submitting the Assignment: 1. Login using participant1. Select the Assignment from the list of assignments. 2. Sign up for a topic. 3. Submit your work before the deadline. 4. Repeat the same for all participants. Reviewing work of other Participants: 1. Login using participants. Select the Assignment from the list of assignments. 2. Click on Other’s Work. You will see a list of topics which are eligible for reviewing. Validation Criteria: 1. You should not be able to review your own submission 2. You can review other submissions of the topic if you have checked “Enable authors to review others working on the same topic” while creating the assignment. 3. You should not be able to review a submission which has already been reviewed by you. 4. You should not be able to review a submission which has reached maximum number of potential reviews. <references/>.","Your writeup mentions changes to self.find_submissions_in_current_cycle.  As far as we can tell, this method was removed from the code.","The information and structure of your assignment is excellent! You've clearly worked hard on this assignment and have demonstrated a good understanding of the concept of refactoring.

Here are a few points of feedback:

1. References: While you have effectively used references to support your points, creating a hyperlink for the reference would help make your content more user-friendly. Also, make sure to use citation appropriately.

2. Illustrations and Screen Captures: Including visuals, like screen captures, along with the descriptive <image> could have been more effective. This would give the reader more clarity about what is being discussed.

3. Code Segments: Well done on the code implementation and explaining the logic. It would be helpful if you include actual code snippets for references where you have written <code>.

4. Use of Subheadings: It would also be beneficial to break up the text into more subsections, which would make the assignment easier to read. 

5. Typing Error and Grammar: There are a few typing errors in your assignment. For instance, you wrote ""It is the process of evaluating work done by an individual or a team by another team or an individual with expertise in the concerned area"" after discussing the benefits of refactoring without any transition or subheading. 

Remember to always proofread your work for any typographical or grammatical errors before submitting it.

Overall, your assignment was good! Just keep these tips in mind for your future assignments."
21,E1507,"<link> is a <link> <link> application where students can submit and peer-review learning objects (articles, code, web sites, etc). It is used in select courses at NC State and by professors at several other colleges and universities. This Open Source application can be cloned from <link> , the latest active branch is <link> . There are 5 major goals for this project: 1. Fix Bug #483<ref> <link> </ref>, which causes some error and prevent users to get access to the submitted_content page. 2.Break up the complex methods such as get_comments , show_code_file_diff . Anything that can be modularized should be modularized (Single Responsibility) 3.While breaking up the complex methods, look out for possible helper functions. If there are any, move them to the review_files_helper.rb 4.Remove commented out code from the controller 5.Refactor the file based on Global Rules<ref> <link> </ref>. In ""Your works"" view, students can only submit links but no files. <image> This is caused by commit <link> where the line 13 in <link> was commented out. <code> But after uncommented line 13 in submitted_content/_main.html.erb and refresh the page, the Rails Server stopped responding. This <link> is responsible for handling the review files of the participants. This controller helps in uploading newer versions of reviews for an assignment and also in displaying all the versions (and diff between versions/code) with the help of <link> . There are quite a few complex functions inside these controllers. These functions can easily be broken up into much more smaller methods with specific functionalities. They also need to be refactored to meet the <link> . 1. review_files_controller.rb 2. submitted_content_controller.rb 3. review_files_helper.rb 4. review_comments_helper.rb 5. submitted_content/_main.html.erb 6. model/assignment.rb. Git log can be viewed in commit <link> 1. In submitted_content_controller.rb , line 19. <code> This else if must be a mistake, so we changed it to: <code> 2. In model/assignment.rb , line 489. <code> The Course model doesn't have an attribute called get_path , it should be directory_path , so we changed it to <code> 3. In submitted_content/_main.html.erb , line 18. <code> As in this page there doesn't have a parameter called assignment_participant , as it need to get the participant's id, so we changed this line to: <code> 4. In config/routes.rb . Added one more routes <code>. 1. Changed and and or to && and || to meet the requirements in the <link> . 2. In def get_comments , deleted unused variable: <code> 3. In def show_all_submitted_files , deleted unused variable: <code> 4. In def show_all_submitted_files , deleted unused variable: <code> 5. The method def get_comments is too complex, so we modularized part of its code in review_comments_helper.rb , we created a new method: def self.populate_comments , which returns handle, comment, authorflag these three variables. <code> 6. Rewrited all :key => value to key: value format according to the requirements in the Global Rules <ref> <link> </ref>. 7. The method def show_code_files_diffIn is too complex, we created a new method: def self.populate_shareObj in review_files_helper.rb to perform part of the show_code_files_diff . <code> 8. In review_files_helper.rb , created a new method: def self.find_review_files , which contains some statements in def show_all_submitted_files . <code> 9. In review_files_helper.rb , created a new method: def self.find_review_versions , which contains some statements in def show_all_submitted_files . <code>. 1. Changed and and or to && and || to meet the requirements in the <link> . 2. Rewrited all :key => value to key: value format . 3. Rewrited all param['string'] to params[:string]. 4. Added one more routes post :folder_action to config/routes.rb 5. Changed all array.size == 0 to array.zero? 6. Changed all find_by_x(val) and where(""x=val"") to where(x: val) 7. In def remove_hyperlink , deleted redundant line: <code> 8. In def download , deleted commented line: <code>. After fixing the bug #483, now the submit files function works. <image> The file is stored at: <image>. <references/>.","Writeup is too hard to follow.  It starts off with a bug description and does not say what role this played in the project.  In general, there is a lot of code and screenshots, but little prose tying them together.","Dear Student,

Thank you for your detailed submission. Your thoroughness is commendable and it is clear from your report that you have understood the assignment well and have put considerable effort into implementing the requested changes. 

For the bug fixing part, your analysis seems to be accurate. The way you identified the problem and subsequently rectified it, is indicative of a good understanding of the code base. It was good to see that you did not merely correct the error, but also determined the root cause.

The coding conventions you adopted and the refactoring you carried out are commendable. The changes made, such as usage of ""&&"" and ""||"" instead of ""and"" and ""or"", rewriting hashes, using 'params[:string]' instead of 'param['string']', and replacing 'find_by_x(val) and where(""x=val"")' to 'where(x: val)' are all representative of best practices and show that you paid attention to the brief.

Excellent work on modularizing the code. Breaking complex functions into smaller, easily manageable functions not only enhances readability but also improves maintainability. 

Also, good job on cleaning up the code by eliminating commented lines and removing unused variables. This makes the codebase more clean and efficient. 

However, just a small suggestion for improvement. It would be helpful if you could explain the changes a bit more, especially those pertaining to helper functions and refactoring. While it is clear that you know what you are doing, doing this would make your document much more understandable to someone who is not as experienced in coding as you are.

Overall, this was an exceptional submission that showed a high level of understanding and an ability to work thoroughly and effectively. Keep it up!

Kind Regards,
[Your Name]"
22,E2110,"While setting up an assignment, the instructor will be asked to choose different kinds of rubrics. Any of these rubrics can later be edited or changed to a different rubric. A problem arises when an assignment is underway (students have already started reviewing) and a rubric is edited or changed. Some students started reviewing with the old rubric and the rest of the students who had not started a review will be presented with the updated rubric. This usually happens when an assignment is copied from a previous year and the rubrics are not updated to match the current topic. It could be at a later point that the instructor/TA realizes this and changes it. If the instructor does edit or change a rubric while an assignment is in progress: 1. If the change affects only the wording of a particular rubric item (e.g., to clarify the statement), no action is necessary. 2. If a rubric is replaced, or the items/questions are changed, then all the reviews that have been done need to be redone. The system should then email the previously done reviews to the reviewer and delete the response object and all associated answer objects. (However, the response_map should not be changed.) This project was done in Fall 2019. However, it was not tested thoroughly. Our team's work in Spring 2021 is to improve the testing and readability of the code. *Using UML Use Case Diagram Syntax <image>. Note: This data flow diagram was originally made by the team from project E1982 in Fall 2019. Their wiki link can be viewed here: <link> <image>. We will write comprehensive tests and fix any bugs in the code written already for changing rubrics while projects are in progress. Some known issues already have been identified: 1. Additions: 1.1. A method comment is needed on in_active_period method in answer_helper.rb 1.2. Line-by-line comments are needed for all added functions 1. Refactoring: 1.1. The method find_review_period is possibly redundant as Find deadlines does exist already in the code. This method needs to be replaced/removed if possible 1.2. Split delete_existing_responses into more functions as it's complexity is reletively high 1.1.1. Contains some nested loops so these should be removed 1. Testing: 1.1. Email functionality needs to be thoroughly tested 1.2. Tests need to be more thorough and verify that correct rows are being deleted for delete_existing_responses function in answer_helper.rb 1.3. Confirm changes do not affect students who have not yet submitted their reviews by doing UI testing. 1. Additions: 1.1. Added more extensive comments to all added functions and lines of code for better readability 1.2. Added a popup confirmation message when deleting a question during active period similar to when adding a question to ensure instructor wants to delete all responses 1.3. Destroy response object instead of individual answers when editing a questionnaire during active period to return all students who submitted reviews to the 'begin' stage rather than 'edit' and give them a fresh questionnaire 1. Refactoring: 1.1. Split complicated functions from previous team, such as delete_existing_responses(), into more manageable and modular functions which only complete 1 main task 1.2. Fixed email formatting for email sent to users when questionnaire is edited 1.3. find_review_period() now uses find_due_dates() to search for assignment due dates. Reduced number of database calls in find_review_period() to reduce interaction, number of iterating loops, and incorporate DRY principles 1.4. answer data in log_response_info() now uses hash format for better readability 1.5. Local array and hash variables now instantiated correctly. 1. Testing: 1.1. Improved rspec tests for all files 1.2. Confirmed that changes do not affect students that have not yet submitted their reviews. The main actions this project affects are adding and removing questions from a questionnaire. These diagrams will show how these events now occur. Because these events are handled differently in Expertiza, the implementation is slightly different for both cases. *Note: As you can see in the diagrams below, the confirmation popup is thrown in different ways for ""Add"" vs ""Remove"". This is because in _questionnaire.html.erb: ""Add"" is implemented as a submit_tag which can easily have a confirm: attribute added to it causing it to throw a popup within expertiza. ""Remove"" is an <a> tag hyperlink rendered to the page by line <%=question.edit(i)%> which iterates through all questions in the questionnaire and renders their edit() functions. Edit() is a function in each question types model (criterion.rb, cake.rb, etc.). Edit() adds lines to the html for each field in the question table, including the ""Remove"" link. The ""Remove"" hyperlink has an href attribute which dynamically links to /questions/ + self.id.to_s based on the desired questions id. It then uses a data-method=""delete"" attribute to select the destroy method in questions_controller.rb. Because this hyperlink exists in each question types model, it is hard to implement a clean solution which does not edit all the model files. To do this, we added a short <script> to the end of _questionnaire.html.erb which scans for <a> hyperlink redirects with the [data-method=""delete""] attribute and throws a popup within the browser rather than expertiza. This popup works the same as the ""Add"" popup. The script returns the result (true/false) of this popup to the <a> tag. In html, the redirect is cancelled if a false is returned to the tag and continues if a true is returned. <table>. Here is a list of files and the functions that were added or edited, excluding rspec files. Helper module containing important functions for deletion of responses and answers when editing a questionnaire during review period. 1. delete_existing_responses(question_ids, questionnaire_id) <image> Calls log_answer_responses and log_answer_info to store responses users made to the questionnaire. If review_mailer can mail these responses to the user then delete_answers destroys the response object. 1. log_answer_responses(question_ids, questionnaire_id) Given a list of question_ids and a questionnaire_id, gathers reponse_ids for all users responses to the questionnaire. 1. log_response_info(response_ids) Given a list of response_ids, gathers users responses to a questionnaire and records their comments in a hash along with their name, email, and the assignment name. NOTE: The only issue we have found on this project stems from the way this function gets answers . Sometimes these review comments are sent to users in an email, and sometimes they are not. Our issue here <link> explains it in more detail. 1. review_mailer(email, answers, name, assignment_name) Given an email, answer list, name, and assignment name, calls notify_review_rubric_change() to send given information about previous review submission to user at given email. 1. delete_answers(response_id) <image> Given a response_id, set the response to be no longer submitted then destroy the response object. This destroys designated dependencies as well such as answers. 1. in_active_period(questionnaire_id, answer=nil) Given a questionnaire and possibly an answer, determine the assignment and round number. Use these to determine if the assignment is in a review period. Return true if in active period, false if not. 1. add_new_questions Added call to in_active_period. If in active period, call delete_existing_responses(). If not, continue as normal. 1. destroy Added call to in_active_period. If in active period, call delete_existing_responses(). If not, continue as normal. 1. notify_review_rubric_change(defn) Mailer function which set necessary attributes for sending an email about a deleted response including previous answers. Calls mail() to send email to desired user. 1. find_review_period(round) Determines the start and end dates of the rounds of an assignment and returns them. Using previous teams code as a base, we changed this function to make minimal database calls and iterate fewer times. 1. get_latest_assignment(questionnaire_id) Given questionnaire_id, returns assignment and round where questionnaire is used (if multiple questionnaires are used in an assignment). 1. Added in_active_period() call to display warning about edited questionnaire during active period 2. Added confirm: to submit_tag 'Add' to display confirmation popup when adding a question during active period 3. Added script to catch <a> tag redirects with [data-method=""delete""] to display popup when removing a question. Script only active if in active period. <image> <image> 1. New file containing email layout used when emailing students their answers after questionnaire is edited during active period. 1. Added: 1.1. app/helpers/answer_helper.rb 1.2. app/views/mailer/notify_review_rubric_change.html.erb 1. Edited: 1.1. app/controllers/questionnaires_controller.rb 1.2. app/controllers/questions_controller.rb 1.3. app/mailers/mailer.rb 1.4. app/models/assignment.rb 1.5. app/models/assignment_questionnaire.rb 1.6. app/views/questionnaires/_questionnaire.html.erb 1. Test Case Files 1.1. spec/controllers/questionnaires_controller_spec.rb 1.2. spec/models/assignment_spec.rb 1.3. spec/controllers/questions_controller_spec.rb 1.4. spec/helpers/answer_helper_spec.rb. Tests are created in the following files: 1. spec/controllers/questionnaires_controller_spec.rb 2. spec/models/assignment_spec.rb 3. spec/controllers/questions_controller_spec.rb 4. spec/helpers/answer_helper_spec.rb These tests cover the following cases: 1. Adding questions to a questionnaire during the review period 2. Adding questions to a questionnaire outside the review period 3. Determining if an assignment is in the review period 4. Determining if an assignment is outside the review period 5. Finding the start and end dates for a specific review period of an assignment 6. Finding the start and end dates for all review periods of an assignment 7. Deleting existing responses resulting from changes made to questionnaires during the review period 8. Deleting questions The same cases were also tested manually through the Expertiza UI, as shown in the demo video.","There are many diagrams to explain the flow. I would have liked to see more explanation of why all the files were changed.  Just saying ""Here is a list ..."" isn't very reassuring; it would have been better to see something like, ""If a question is added or deleted, that affects the question itself and the questionnaire. When a reviewer needs to be sent a copy of a rubric, this means that content needs to be copied out of answer objects ...""  That would explain how the pieces fit together.  I also think that the test plan should have described what was done in the tests for each class.","The work presented here demonstrates a comprehensive study into the dynamics associated with modifying rubrics during an ongoing assignment. I appreciate the detailed explanations and the objectives outlined for the team in Spring 2021.

The notable strides towards identifying and fixing possible code redundancies are praiseworthy. Efficient utilization of methods, removal of nested loops, and aiming for DRY principles strengthens your code.

The thoroughness of your testing plan, covering both automated and manual testing methods, stands out. It's commendable that you have thought about both the functional and UI facets of the changes introduced, ensuring a seamless user experience.

Adding comments for added functions and lines of code significantly aids the readability and could be helpful for future development work. Such kind of documentation is a great practice.

You've also succeeded in separating complicated functions into manageable segments, making the entire project more maintainable for future developers. The refactoring of existing functionalities has added to the quality of your work without hampering the original objectives. Also, aiming to reduce database calls in some methods stands out as a note-worthy improvement.

However, it would be beneficial if you can include example scenarios, inputs, and expected outputs for each test case in your test plan, to provide a clearer picture of its focus and coverage.

Also, including a brief explanation about how the UI changes affect the user experience would be helpful. 

In summary, your detailed refactoring, comprehensive test plans, and the effort to maintain coding best practices all exemplify commendable work. Keep up the great work!"
23,E2067,"The student_teams_controller.rb controller used in Expertiza to manipulate teams that are created for assignments. Primary functions that this controller provides is create a new team, update team name and delete members from a team. The motivation of our work is to improve the maintainability and readability of student_teams_controller.rb Controller. Furthermore, we also fix several occasions where the student_teams_controller.rb contains code snippets that actually belongs to the model classes. This will help enforce single responsibility principle and model-view-controller pattern. 1. Move return unless current_user_id? student.user_id into action_allowed method 2. Refactor code from view function into may or may not be necessary to add a method to the DueDates class 3. Remove variable current_team 4. Add comment for @users_on_waiting_list and also simplify the condition 5. Refactor @teammate_review_allowed into due_date.rb 6. Rename existing_assignments? to existing_teams 7. Add method comment for the update method 8. Change (matching_teams[0].name <=> team.name).zero? to (matching_teams[0].name == team.name)? 9. Add method comment for Advertise_for_partners and remove_advertisement 10. Rename sign_up into signup 11. Refactor code from remove_participant into waitlist.rb 12. Add method comment for the review method. 1. /controllers/student_teams_controller.rb 2. /models/waitlist.rb 3. /models/due_date.rb. The purpose of this section is to provide the before and after change comparison so the developer can perform code review to ensure the correctness of the change. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. File: spec/controllers/student_teams_controller_spec.rb <code>. 1. In the update method of student_teams_controller.rb, the 'elsif' needs a comment to explain its purpose. It is unclear as to why this conditional is present. 2. For student_teams_controller update method, simplify the condition logic by combining elsif and else into a single statement.","Document looks good with relevant details and screenshot of the before and after code provided. Some of the section headings are hard to parse, e.g., ""Refactor code from view function into may or may not be necessary to add a method to the DueDates class"".  However, the descriptions of code changes are clear.  In the test plan they have just attached screenshot of the original rspec file without any explanation. They have mentioned potential refactorings in the ""Future Work"" section and for this controller file","Firstly, I would like to commend your dedication towards improving the maintainability and readability of student_teams_controller.rb. It's important to aim for clean, efficient code and you clearly understand this.

Your approach to refactor parts of the project and implement principles such as the model-view-controller pattern for more robust code design is admirable. Furthermore, identifying where code responsibility should actually reside shows your strong comprehension of software architecture.

Here are a few points for your improvement:
1. As you know, the recurring ""An error occurred while attempting to extract the child content"" suggests there was an issue with your demonstration or documentation process. It's crucial to provide the 'before and after' code snippets for a clear understanding of the changes made, especially given the context of peer review and code assessment.
2. Your point about adding comments is worth noting. Good commenting makes maintaining code much easier and it's valuable that you have recognized this.
3. The suggestion to simplify the condition logic in the update method is a good observation; clean, simple code leads to fewer errors and better performance.
4. However, do ensure your proposed changes like renaming methods and refactoring parts of the code don't interfere with other dependencies in the application.

Remember, there's always room for improvement and it's fantastic that you've taken the initiative to propose these changes. Be sure to run extensive tests on the modified versions of the scripts so no existing functionality gets broken. Keep up the good work!"
24,E1783,"A feature that integrates Github metrics into Expertiza to help instructors grade the projects by providing more information of the workload of individuals and could do early detection on failing projects based on groups’ working pattern. This wiki page documents the changes made as a part of E1783 which allows users with an instructor to view Github metrics for a students' submitted assignment. Team: Kashish Aggarwal (kaggarw2@ncsu.edu) Sanya Kathuria (skathur2@ncsu.edu) Madhu Vamsi Kalyan Machavarapu (mmachav@ncsu.edu) Mentor - Yifan Guo. Expertiza is a web application where students can submit and peer-review learning objects such as assignments, articles, code, web sites, etc. Convolutional data extraction from Github integrates Github metrics into 'Expertiza'- an Open source project in order to help instructors grade the projects by providing more information of the workload of individuals and could do early detection on failing projects based on groups’ working pattern. By convolutional data, here we refer to the fields of the dataset which cannot be extracted directly, such as the working pattern, which is the amount of commits/code/files the pull request added/modified/deleted on each day during the whole project period. The project period is a range of days that can be tracked on Expertiza. For metrics we have considered following : o Number of commits everyday throughout the project’ s period. o Number of files changed everyday throughout the project’ s period. o Lines of code changed everyday throughout the project’ s period. Docker: The Docker has been set up on a Windows PC and steps are given below: Start Docker on Windows docker run --expose 3000 -p 3000:3000 -v //c//Users//Srikar//Expertiza://c//Users//Srikar//Expertiza -it winbobob/expertiza-fall2016 /etc/init.d/mysql start mysql -uroot -p show databases; quit git clone <link> cd expertiza cp config/database.yml.example config/database.yml cp config/secrets.yml.example config/secrets.yml bundle install rake db:migrate sudo apt-get install npm npm install -g bower On a Local Machine: We have used MacOS, so the following steps are in regard to MacOS. The following steps will help you set up Expertiza project in your local machine. The steps are a comprehensive amalgamation of steps mentioned in Development Setup, the document provided and also few steps that were missed in both. The order we followed: 1. Fork the git repository mentioned above 1. Clone the repository to your local machine Install <link> 1. Install RBENV brew update brew install rbenv brew install ruby-build 1. Install dependencies brew install aspell gcc47 libxml2 libxslt graphviz 1. Install gems export JAVA_HOME=/etc/alternatives/java_sdk bundle install 1. Change yml files 1. Go to expertiza/config and rename secrets.yml.example to secrets.yml 1. Go to expertiza/config and rename database.yml.example to database.yml 1. Edit database.yml to include the root password for your local MySQL in the “password” field 1. Install mysql ( <link> ) 1. Log into MySql as root (mysql is generally present in /usr/local/mysql/bin/) mysql -uroot -p 1. Create expertiza user create user expertiza@localhost; 1. Create the databases create database pg_development; create database pg_test; 1. Set privileges for expertiza user grant all on pg_development.to expertiza@localhost; grant all on pg_test.to expertiza@localhost; 1. Install javascript libraries sudo apt-get install npm sudo npm install bower bower install 1. Download the expertiza scrubbed library ( <link> ) 1. Load this sql file into pg_development database created using the method mentioned here. 1. Run bundle exec rake db:migrate 1. Run bundle exec rake db:test:prepare 1. Run rails s IMPORTANT : EXPERTIZA_GITHUB_TOKEN : Export this variable in bashrc file which contains personal access token value. 1. Open browser and test localhost:3000 1. Login credentials Username - instructor6 Password - password sudo rm /usr/bin/node sudo ln –s /usr/bin/nodejs /usr/bin/node bower install --allow-root thin start. We have modified the following files: o submission_records_controller.rb : Business Logic. The existing submission controller is responsible to retrieve submissions from submission_records table for a particular team id. We are leveraging the same page to show GitHub metrics for the submitted GitHub link which is stored in the 'content' column in the same table. Our code will pick the latest GitHub URL submitted for an assignment and then update the git_data table to store metrics for the same. At the same time, the code also clean up the dit_data table by deleting data for any previous submissions that are removed by the user. It is also responsible to initialize necessary instance variables including an array of authors that will work as an index for our graphs in the view. <image> o git_data_helper.rb We have written this helper class which is a wrapper on top of our rest service GitHub api calls. The methods need owner and repository name as parameters. An additional parameter i.e. pull request number and sha for commit is needs to fetch pull/commit specific data. These methods make the service calls and return the response as json. <image> o git_datum.rb This is a model corresponding to our git_data table which have following attributes 1. pull request number. 2. author, who committed in that pull request. 3. Number of commit done by that author in the pull request. 4. number of files changed by that author in the pull request. 5. number of lines added by that author in the pull request. 6. number of lines deleted by that author in the pull request. 7. number of lines modified by that author in the pull request. 8. data when the pull request was created. The model has a static method called update_git_data which is responsible to update the data in the table for the active submission record. The method calls the methods on git_data_helper to make the GitHub api calls, manipulate the data that is returned from the service and then push the data in the table. PS - Everytime the method is called it just process the delta (changes for the pull request since the last time this method was called). This makes sure that the updates are faster and avoid data redundancy. <image> o submission_records/index.html.erb The index view for submission_record has three charts which show the number of commits/files/lines that are committed/added/modified by every member of the team over the timeline. We have used two gems - 'chartkick' and 'groupdate' which helps us manipulate our data and visualize it in form of graphs on our view. Below is a screenshot of how these graphs appear on the page. <image> We have used the following tables mainly: o submission_records For storing the data in the submission record array such which has the data for all the assignments related to a particular team id performing the 'Submit Operation' for an assignment. o git_data For storing the data in the submission record array that has been updated and has to be used for visualization. <image>. <link> <link>.","The flow is reasonable and the writing is quite good, though there are occasional grammatical errors.  It's nonstandard to use all caps in Wikimedia section headers.  The code is pretty readable, but it is also very large, so it's hard to get much context on a single page.  Could it be shrunk?  Ditto for the screenshot.  Please use standard github itemization instead of ""o""s at the beginning of each item.","The feedback for the student's project are as follows: 

1. Well done on the detailed explanation of your project which integrates Github metrics into Expertiza. The motive behind your project is clear, that is to provide more insights about the individual's workload and to facilitate early detection of failing projects. This explanation is directly beneficial to your instructors and also peers in giving them a clear understanding of what your project is about. 

2. The layout and organization of your summary are clear. With the use of headings and sub-headings, you certainly made the project look structured. Excellent job!

3. You've done a great job detailing step-by-step instructions for setting up Docker on Windows PC and Project setup on the local machine. The inclusion of these details helps others to replicate your work, which is a crucial aspect of collaborative projects.

4. Excellent work on documenting the specifics of the code, and the explanation of the various components of the project like 'submission_records_controller.rb', 'git_data_helper.rb', and 'git_datum.rb'. This not only shows your in-depth understanding but also facilitates peer-to-peer learning. 

5. The inclusion of diagrams would be helpful, as ""a picture is worth a thousand words."" Though you mention ""<image>"", it seems that they have not been correctly uploaded or embedded. Please ensure these are viewable to improve the comprehensibility of your work. 

6. You thoroughly explained the updates made to various files and their impacts on the overall project, good job! Make sure to also discuss the challenges you faced and how you overcame them, it would further enrich the learning from this project. 

7. Finally, keep in mind for future assignments to remove personal email addresses from shared documents, as these should not be publicly disclosed for privacy reasons. 

In conclusion, this is a solid piece of work that demonstrates your understanding and application of the material covered in class. Continue in the same vein. Good work!"
25,E1729,"This project is an addendum to the bigger Expertiza project. The Expertiza project is software to create reusable learning objects through peer review. It also supports team projects, and the submission of almost any document type, including URLs and wiki pages. The requirement for this OSS project was to ' Export Scores In Detail'. <link>. The branch on which we developed this project on is called <link>. Expertiza provides a the ability for an instructor to export scores for an assignment. Whenever a user fills out teammate reviews, peer reviews, feedback reviews, and etc. the scores for each question on those reviews are stored in the database. Currently however Expertiza only exports a csv with aggregated scores which are computed as weighted averages of the scores given in reviews. This is not the most helpful for visualizing the score data by question, individual team/user, reviewer. So that is why our assignment is to implement the ability to export a more detailed csv that contained all the scores for each question for each review and review type within a specific assignment. After talking with our project contact, Ferry, it was decided that the csv would be organized by round and within each round by response type. Part of the implementation was to also include the ability to choose the delimiter for the csv and specify which columns they wanted to include. So the reason we implemented our feature a certain way is because there was already previous code for exporting an aggregate csv so we designed our feature in the same fashion. An export controller already existed so we added a new method in that for exporting details and modeled it based on the already existing export method. Assignment.rb already had the methods for setting columns/fields and getting aggregate export info so we added our implementations corresponding methods in that class as well. For the view, we simply added our code, that linked to the new controller method, in the same view where the other csv feature was implemented. No specific design pattern was used, but our feature was simply modeled after previously existing similar features. 1. app/controllers/export_file_controller.rb 2. app/models/assignment.rb 3. app/views/export_file/start.html.erb. 1. app/views/export_file/_export_details.html.erb 2. spec/controllers/export_file_controller_spec.rb 3. spec/features/assignment_export_details/expected_details_csv.txt. 1. export_file_controller_spec.rb This method is called when the 'Export Details' button is clicked and selects the delimiter and generates the csv with selected columns. It then passes the CSV into the assignment models method to populate it. <code> 1. app/models/assignment.rb This method is called to populate it the csv and is where the majority of our implementation lies. It finds all the ResponseMaps associated with this assignment, then finds all the Responses associated with that each ResponseMap. Then for each response it saves the Answer objects associated with it into an array that is stored in a hash that is indexed by round and response type (teammate review/feedback review/etc). <code> This method checks nil while populating a csv field headers to only add headers which the user selected from the checkboxes. <code> This method generates a CSV row by looping through the answers. <code> This method generates a hash of answers, which is used to populate the CSV. <code> This method checks for number of answers in a particular round/response type and returns nil if there are none since the csv doesn't need to output any header for this round/response type. If this round has some answers then the round number header is generated along with the response type. If the round number is nil, then we simply make the header say 'Round Nill' instead. <code> This method is called by the controller to set the columns in the csv. <code> This method is called by the controller to set the headers in the csv (including Assignment Name and Instructor) <code>. Flow Chart When exporting a detailed CSV, an instructor can choose to include all, some, or none of the headers and the assignment may or may not include answers. The chart below details possible scenarios. <image> <table>.","The test plan is outstanding. very detailed and logically structured. It could be improved by comparing the #of active records with #of lines in the CSV. or if all student participants in the CSV, etc. It's a shame that the design desc has too many code snippet, copied pasted from the source code, which I could have checked directly in GitHub. I would expect a more high level pseudocode / UML diagram for the documentation. ","Overall, the assignment is technically well written with elaborate descriptions of requirements, implementation methods, and linking code details. Good job! Here is my feedback:

1. The introduction is thorough and you've provided a good context about the Expertiza Project. This helps in understanding the background details and the requirements of this assignment. 

2. The objective of the task and the reason behind it are clearly stated, which gives a clear understanding of the problem you are trying to solve.

3. The explanations on how you implemented the feature and why you did it a certain way are insightful. It shows that you have a good understanding of the entire process and the architecture of the application.

4. The use of lists and subpoints to describe the different aspects of the project (Model, Views, Controllers, etc) makes your text easier to read. It also shows you have organized your thoughts well.

5. You've provided a thorough code walkthrough and explanation. This is important and it demonstrates your ability to explain the codebase clearly and to rationalize the decisions you made during coding.

However, there are also some areas that may need improvement:

1. Please provide citations to any referenced work and clearly state the role of the referenced work in this project.

2. Code documentation snippets were expected but aren't present. It would be good to see actual snippets of code to demonstrate the functions, methods, and classes being discussed, even as pseudocode if the actual code is too lengthy.

3. Be mindful of your wording and structure. Sentences can be a touch too long and convoluted in places. For instance, the last sentence in your third paragraph becomes a bit confusing due to its length. Consider breaking it down into 2-3 shorter sentences to improve clarity.

4. For the betterment of your project, it would be helpful if you included a brief explanation of what the details of the exported CSV file would look like, along with examples.

5. The document could be made more interactive and visually appealing by including diagrams that help visualize the implemented feature. I see mention of a flowchart and image but I do not see them here. Please ensure to include them as necessary.

6. Finally, you have not mentioned whether tests were performed for the added functionalities. It would have been wonderful if you could mention what tests were performed, difficulties faced and the ways to overcome them.

Continue the good work and apply the feedback for better improvements!"
26,E1659,"For users intending to view the deployed Expertiza associated with this assignment, the credentials are below: 1. Instructor login: username -> instructor6, password -> password 2. Student login: username -> student5431, password -> password 3. Student login: username -> student5427, password -> password. Expertiza is an educational web application created and maintained by the joint efforts of the students and the faculty at NCSU. It’s an open source project developed on Ruby on Rails platform and it’s code is available on Github. Using Expertiza students can bid for a particular project topic and the faculty assigns the same to different groups. Students can track their grades for previous projects and make new submissions for current projects. It also allows students to review each other’s work and improve their work upon this feedback. We worked on a module named on_the_fly_calc in this Expertiza based OSS project. We focussed on refactoring some methods which were very complex and also modified the language of the module to make it more ruby-istic. We also worked on refactoring the code to reduce redundancy. Our goal in this project was to make this model easier to read and maintain. A model was modified for this project namely: 1. On_the_fly_calc. On_the_fly_calc is a module that is included in assignment.rb. What this module does is that it calculates the score for both students and instructors. E.g., when a student clicks “view my score”, Expertiza calculates the review scores for each review. This is called “on the fly” because expertiza stores the review scores based on each question (in answers table), but does not store the total score that a reviewer gives to a reviewee. It directly calculates the total review score for each review, using the score values in the answer table during run-time. Eg: For a set of 4 questions a reviewer gives 5 on 5 points for 2 questions and 4 on 5 points for other 2 questions. So only these points are stored in the database and when a reviewee clicks to see the score given by this particular reviewer, on_the_fly_calc module helps calculate the total score i.e. 90% in this case. The main aim was to reduce the complexity grade of ‘on_the_fly_calc.rb’ module from “F” to “C” in CodeClimate, which was achieved. We worked on the following work items(WIs) in order to refactor the module: WI1 : Refactor ‘Similar Code’ in lines 34-42 and 62-70 in on_the_fly_calc.rb WI2 : Prefer ‘each’ over every instance of ‘for loop’ WI3 : Refactor ‘scores’ method to reduce ABC (assignment, branch and condition) size WI4 : Refactor ‘compute_reviews_hash’ method to reduce ABC (assignment, branch and condition) size WI5 : Refactor ‘compute_avg_and_ranges_hash’ method to reduce ABC (assignment, branch and condition) size. Lines 34-42 and 62-70 were similar in compute_reviews_hash method. Hence, a dedicated method ‘calc_review_score’ was defined and this method was called in the both instances inside compute_reviews_hash. Lines 34-42 in compute_reviews_hash: <image> Similar code in Lines 62-70: <image> Refactored method 'calc_review_score' for the two similar codes: <image>. In every instance where ‘for’ loops were used in on_the_fly_calc module, ‘each…do’ was replaced instead. This significantly reduced the Cyclomatic complexity of the code. The following screen shows the instances where for loops where replaced: <image>. 1. a) Method ‘scores’ was very complex, performing too many functions within a single method. Hence, every specific function was broken down into 4 separate smaller methods. This significantly reduced the Assignment, Branch, Condition size for ‘scores’ method. <code> b) The following 4 methods were created after splitting the first method i. participant_score <code> ii. assess <code> iii. calculate_score <code> iv. calculate_assessment <code> c) Complex and long statements or loops were broken into simpler multiple statements. For example, the unless condition in Lines 132-134 was refactored to Line 127. This reduced the Perceived Complexity of 'scores' method. <image> 2. a) We also refactored method ‘compute_reviews_hash’ which was very complex and modularized individual functionalities into 2 separate methods. b) The following 2 methods were created and called after refactoring: i. scores_varying_rubrics ii. scores_non_varying_rubrics 3. Similarly, method ‘compute_avg_and_ranges_hash’ was also refactored and a seperate method calc_contri_score was defined to calculate contributor’s score. This method was then called from ‘compute_avg_and_ranges_hash’. <image> <code> <image> <code>. 1. Login into Expertiza as a student or an instructor.(You can use the student ids in the peer review section above) 2. Go to an assignment which has some prior reviews for a previous project and click on view scores. 3. The total score for a review is calculated on the fly using this module. 4. You will be able to see the average score that each reviewer gave you on the top right of your page. 5. This ensured that the refactoring done by us didn't break the code and it delivered it's expected functionality. You can find a video illustration of the same in this link: <link>. We created unit tests as well to check that the module performs as it did earlier before we refactored it. There were no pre-existing test cases for this module. We first had to create a dummy class to test the module. The new test file can be viewed at the mentioned GitHub link. <image> <code>. Every code has future improvements possible. We have evolved the Code Climate Grade 'F' to a Grade 'C' currently by removing the Cyclomatic complexity, the Perceived Complexity and replaced with the ""for"" with the 'each' to reduce the size . There are modifications that can still reduce the ""ABC"" Assignment Branches and Conditions Score as we can include the variables and functions in the ""before action clauses"", and rename long names with shorter yet appropriate names thus moving towards the score of ""A"".","Generally good job of describing changes.  In places, there is too much code and not enough explanation (e.g., for the methods following scores).  Screenshot from Code Climate is gigantic.","Great job on this thorough analysis and the work you've done to refactor the code. Your focus on refactoring for more readability and maintainability has greatly improved the original code. I am impressed with how you broke down complex codes into smaller, simpler functions. 

Here are a few things I would like to point out to further improve:

1. While you mentioned several times that you achieved your goal of raising the CodeClimate grade from ""F"" to ""C"", there could be a more precise follow-up: was the code also easier to understand/maintain? Was the code effective in reducing the amount of redundancy? Justifying changes in code based more on tangible outcomes and less on the CodeClimate grade could be more helpful. 

2. It would have been helpful if you included the links or references to the code snippets or images you've referenced in your report. It would greatly help in following your analysis and assertions.

3. You mentioned in your final paragraph about potential areas of future improvement, such as reducing ABC scores and renaming long names with shorter ones. It would have been good if you provided specific examples of these areas in the actual code as this would not only substantiate your claim but also possibly provide a roadmap for future refactoring projects.

4. It's commendable that you’ve considered testing this module, given that there were no pre-existing test cases. Your assertion that you ensured the refactoring didn't break the code is reassuring. However, sharing specific tests and their results could further strengthen your argument.

5. Proofread your work to ensure there are no missing words, and sentences make sense. Some sentences seemed incomplete, which could confuse readers.

Keep up the good work! Your structured approach to refactoring the code, attention to detail, and understanding of how to improve a code's maintainability and readability is praiseworthy. I look forward to seeing more of your work."
27,E2060,"Expertiza <link> is an open-source web application to create re-usable learning objects through peer-reviews to facilitate incremental learning. Students can submit learning objects such as articles, wiki pages, repository links and with the help of peer reviews, improve them. The project has been developed using the Ruby on Rails <link> framework and is supported by the <link> . Expertiza assignments are based on a peer review system where the instructor creates rubrics for an assignment through questionnaires which students use to review other students' submissions. The author of the submission is given an opportunity to provide feedback about these reviews. Expertiza displays reviews (i) to the team who was reviewed, and (ii) to the reviewer. A student user can see all the reviews of his/her team’s project. The instructor can see all the reviews of everyone’s project. The instructor also has access to a Review report, which shows, for each reviewer, all the reviews that (s)he wrote. The score report and review report use different code so UI is non-orthogonal, it would be great if we can follow same UI structure for score and review report which also reduce the DRY problems. Exact issue on Github - <link>. 1. Currently Review report uses its own code to display reviews. This a pretty basic view, and it does not interpret HTML codes. It should be changed so that it calls the usual code that is used for displaying reviews, that gives the circle with the score inside. Currently, if you pull up a review report, and then click on one of the teams reviewed, e.g., the first one, you get a report that looks like this: <image> We need to change the views to existing templates in view_my_scores pages. For student view the UI is consistent in displaying reviews they have done and reviews they have received but for instructor's view the review report follows different UI and have different code. To make the UI consistent we have decided to choose the UI design of student view as the base and modify the UI design for review report in instructor's view. This will allow us to use the same code in both views, thereby following DRY principle. Updated View: <image>. 1. <link> 2. Code for displaying a review is essentially copied instead of parametrized and reused, violating the DRY principle. 3. No new tests added although they do have a well detailed manual test plan. 4. HTML codes [Breaks] are left visible in the view. 1. app/view/pop_up/team_users_popup.html.haml 2. app/view/pop_up/team_users_popup.html.erb 3. app/controllers/popup_controller.rb [Hot Fix] The previous implementation involved having a haml file with bare HTML. [app/view/pop_up/team_users_popup.html.haml] <code> We replaced this with an existing view following the DRY principle [app/view/pop_up/team_users_popup.html.erb] <code>. 1. Expertiza on test VCL instance - <link> <image>. Our test plan are mostly manual. There are two reasons why we choose UI testing: 1. As we only change the layout of several views. We can only test them from UI testing. 2. The existing templates view_my_score are also tested with UI, without any Rspec testing. There are two test cases for UI testing. 1. To Test UI for student View 1.1. Log-in as Student. 1.2. Go to Assignment 1.3. Click Your scores 1.4. Click show reviews 1. To Test UI for instructor View 1.1. Log-in as Instructor. 1.2. Go to Manage Assignments 1.3. Click on review report of a particular assignment 1.4. Click on any of the links from **Team reviewed** Rspec testing: Added the following test to the ~/expertiza/spec/controllers/popup_controller_spec.rb <code> Since the modifications are mostly on a view, a simple test would suffice. 1. <link> 2. <link> 3. <link>. 1. <link> 2. <link> 3. <link> 4. <link>.","The section on ""Issues with previous pull"" is not explained.  It is not clear why the previous implementation needs to be described in the document for the new implementation.  Normally I don't like raw code dumped into the documentation, but here you are just doing it to show how bad the previous implementation was.  So I wouldn't complain about that, except that you really only need to document the changes you made, not the bad changes made by the previous team.  It would be good if the test plan included some screenshots.","Overall, your work is detailed and explanatory. You've clear understanding about the problem you're trying to solve and propose to refactor the codebase by reusing the code from student view to follow DRY principle. 

There are numerous areas in your assignment where you've demonstrated commendable effort. An appreciation of this is needed as you've demonstrated a good understanding of the software being examined, and the issues concerning its UI design and violating DRY principle. Your proposed solution of unifying the UI for both student and instructor's view seems reasonable and efficient.

However, there are also areas you need to improve. While you state that you have chosen UI testing due to the nature of the changes being only in layout, better justification for choosing one testing method over another is required. It would also be better if you dedicated a section to describe the expected results of your test cases, and if any existing functionalities were affected while you made the revisions. 

As for the code fixes proposed, make sure to include a description and explanation of why these specific fixes were implemented and how they will improve the codebase. Also, when you're mentioning file paths like for instance 'app/view/pop_up/team_users_popup.html.erb', it would be useful to not only refer to the code changes, but also explain why that specific location in the codebase was edited.

For the references, it is better to describe these a bit instead of just linking to them. Further elaborations on how these were useful to your assignment would also make your report easier to understand.

Stay open to new ideas and suggestions, and remember: the aim of these tasks is to improve your critical engineering skills. Keep up the good work! Look forward to seeing your growth in next assignments."
28,E1784,"Expertiza is an open source project based on Ruby on Rails framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. Mass Assignment is the name Rails gives to the act of constructing your object with a parameters hash. It is ""mass assignment"" in that you are assigning multiple values to attributes via a single assignment operator. The following snippets perform mass assignment of the name and topic attribute of the Post model: 1. Post.new(:name => ""John"", :topic => ""Something"") 1. Post.create(:name => ""John"", :topic => ""Something"") 1. Post.update_attributes(:name => ""John"", :topic => ""Something"") Without the convenience of mass assignment, we'd have to write an assignment statement for each attribute to achieve the same result. Here's an example: 1. attrs = { :name => ""John"", :topic => ""Something"" } 1. post = Post.new 1. post.name = attrs[:name] 1. post.topic = attrs[:topic] Obviously, this can get tedious and painful; so we bow at the feet of laziness and say, yes yes, mass assignment is a good thing. With the help of mass assignment, when we create or update certain object, we do not need to write an assignment statement for each attribute. But mass assignment could cause security vulnerabilities. Hackers could add other parameters to do some bad things. For example: 1. @post = Post.new(params[:post]) Typically this is used when the user submits a form rendered by a form_for @post. In an ideal world, the params[:post] hash should only contain the fields we displayed on the form. However, it is trivial easy hackers to pass additional fields in their request, so in effect you're allowing a user to set any fields on @post, not just the ones displayed on the form. How to Deal With Mass Assignment? In models, we need to add ""attr_accessible"" to implement the whitelist. For example: <code> Here, we're explicitly listing out what can be mass-assigned. Everything else will be disallowed. The advantage here is that if we, say, add an admin flag to the User model, it will automatically be safe from mass-assignment. For controllers, Rails 4 introduces strong parameters, which is a new approach to protect mass assignment. For example: <code> Now, if you attempt something like user.update_attributes(params), you'll get an error in your application. You must first call permit on the params hash with the keys that are allowed for a specific action. So our group needs to resolve all these ""Unprotected mass assignment"" issues according to <link> . In models, we need to protect all attributes that we allow to be mass-assigned using ""attr_accessible"". Previously, we just removed all attributes after ""attr_accessible"" which fixed ""Unprotected mass assignment"" but would lead to failure when creating and updating models. So the testes could not pass. Therefore, we added all attributes after ""attr_accessible"" and tests passed. However, this time, Brakeman would report ""Potentially dangerous attribute available for mass assignment"". In order to solve ""Unprotected mass assignment"" and ensure that tests can pass, this is the best we can do. If there was no protection at all in the model file. We added ""attr_accessible"" and all attributes that we allow to be mass-assigned after it. <image>. We modified the code in an unobtrusive way, i.e. processing the mass assignment parameters with a function without changing them directly. Fix unprotected mass assignment in update <image> Fix unprotected mass assignment in new <image>. If the parameters come from requests, we can directly use ""params.permit()"" to implement a whitelist. However, if the parameters come from values of other objects, we cannot directly call that built-in function. Firstly, we need to build a hash with those values and pass the hash into ""params"". And then we can filter the parameters using permit(). Fix unprotected mass assignment in create <image> Fix unprotected mass assignment in new <image>. <image>. The Expertiza project provides 77 rspec tests under expertiza/spec. After modifying over 140 files, we want to make sure these tests could still pass. It turns out all tests could pass except models/tag_prompt_spec.rb. <image> In tag_prompt_spec.rb, we will create an instance of Criterion and specify the type of it. However, type is a reserved word for ActiveRecord. When we use type as a reserved word, it specifies the name of a model class. 1. (1)If we add :type after attr_accessible in Question(Superclass of Criterion) model Because you add it after attr_accessible, it will allow you to set the value of type. So, the code in tag_prompt_spec.rb above will try to create an instance of ""Criterion"" or ""Checkbox"" or ""Text"" which should be the subclass of Criterion. However, there are no such subclasses Checkbox and Text. Therefore, the test would fail. <image> 1. (2)If we do not add :type after attr_accessible in Question(Superclass of Criterion) model In this situation, when creating Criterion, the information (""Criterion"" or ""Checkbox"" or ""Text"") of type will be ignored. All three instances are created with type ""Criterion"" which is subclass of Criterion(itself). However, in the last test, ""expect(tp.html_control(tag_dep, an_long_text)).to eql("""")"" will check the type these three instances. Because the type of last two instances are actually ""Criterion"", not ""Checkbox"" or ""Text"", the test would fail. <image>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link>.","This is very readable writeup, and could be used by someone to learn about this security vulnerability in general.  It lacks a summary, which would have been useful, but other than that, it is one of the best.","Hello,

I have reviewed your comprehensive work regarding mass assignment in Expertiza. It's wonderful to see that you've not only understood the topic on a surface level but delved deep into its mechanics. 

Your extensive research into Rails' concept of ""mass assignment"" is praiseworthy. I am glad to see how you have connected it to the front-end security concern in forms and provided controls against it through the safeguard facilities in Rails models like `attr_accessible` and controllers via strong parameters. Your exploration of what happens when `attr_accessible` is removed and then different attributes are added gives a great discourse into the concept.

You correctly highlighted that mass assignment can be a potential security risk, indicating your appreciation of protective measures for web development. You also did well to caution about the need for controller-side oversight, such as Rails' strong parameters.

Your discussion concerning the obstacles encountered during the code patching is relevant. This knowledge propels you to have essential problem-solving skills that any programmer or software developer needs. 

One part of your assignment that wasn’t as clear is the section where you talk about `attr_accessible` and reserved keywords. It would be beneficial if there were more depth or explanation here. Also, I would recommend you avoid pasting long code snippets directly within your essay. Instead, link to a Github Gist or some similar platform.

Furthermore, your broken image links and non-specified links in your assignment make your work hard to follow in some sections. Please ensure they are correctly inserted before submitting your work. Also, when you perform tests, make sure to provide clear and detailed results to ensure your modification is compatible with the existing code.

Keep up the good work and continue challenging yourself in understanding not only the how but also the why of coding practices. You're heading in the right direction. The feedback is to handle code snippets better and provide complete and accurate results for the test cases conducted. Keep learning and improving.  

Best,
[Your Name]"
29,E1853.3,"Contents 1.1. <link> 1.2. <link> 1.1.1. <link> 1.1.2. <link> 1.3. <link> 1.1.1. <link> 1.1.2. <link> 1.4. <link> 1.5. <link> 1.1.1. <link> 1.1.2. <link> 1.6. <link> 1.1.1. <link> 1.1.2. <link>. For this project, our task was to achieve at least 90% code coverage on the menu.rb model. Menus (and their sub-component, Nodes) provide the foundation for navigation within the Expertiza platform. With the role of the user as input, they present to the user all possible options a user of their role can have from the top of each Expertiza screen. The Menu is critical for navigating Expertiza and exposing the correct functionality to the correct users. Testing is critical to ensuring that software is functional. A robust test suite which tests the returns of query messages and the side effects of command messages will help expedite development by quickly ensuring nothing has broken when changes are made. While manually testing the behavior of the menu is quite straight-forward, automating the underlying mechanics of the menu, which are abstract and generic, is a good best practice to prove that the system for generating menus is not broken. In order to fully test menu.rb, we composed a total of 29 tests, 12 for the Node class and 17 for the Menu class. 1. Node 1.1. Node#setup - Node#setup appropriately sets a Node's parent_id, name, id, and label to those of the MenuItem passed to it as an argument. 1.2. Node#setup - When MenuItem has a ControllerAction, Node#setup(MenuItem) makes Node's controller_action_id becomes that ControllerAction's id. 1.3. Node#setup - When MenuItem has a ControllerAction, Node#setup(MenuItem) makes Node's url become ControllerAction's url_to_use. 1.4. Node#setup - When MenuItem's ControllerAction has a Controller, Node#setup(MenuItem) makes Node's site_controller_id equal to Controller's id. 1.5. Node#setup - When MenuItem's ControllerAction has no url_to_use, Node#setup(MenuItem) makes Node's url equal to ""/#{controller.name}/#{controller_action.name}"", the controller_action's name appended to the controller's name. 1.6. Node#setup - When MenuItem has a ContentPage, Node#setup(MenuItem) makes Node's content_page_id equal to ContentPage's id. 1.7. Node#setup - When MenuItem has a ContentPage, Node#setup(MenuItem) makes Node's url equal to ContentPage's name. 1.8. Node#site_controller - #site_controller sets the @site_controller instance variable. 1.9. Node#controller_action - #controller_action sets the @controller_action instance variable. 1.10. Node#content_page - #content_page sets the @content_page instance variable. 1.11. Node#add_child - #add_child updates Node's children 1.12. Node#add_child - #add_child adds multiple children to Node's children. 2. Menu 1.1. Menu#select - it returns if select(name) is not in @by_name 1.2. Menu#select - when name is in @by_name, Menu.selected is equal to name, @crumbs ends with the lowest level node and begins with the highest level node, and #selected? returns true for all nodes from the selected node to the root. 1.3. Menu#get_item - returns nil when id is not in @by_id 1.4. Menu#get_item - returns the equivalent item when id is in @by_id (item is not identical, but all components of item are the same). 1.5. Menu#get_menu - returns nil if level has no children. 1.6. Menu#get_menu - return children of a level if level has children. 1.7. Menu#get_menu - return all nodes except root if level is root. 1.8. Menu#selected - returns root if nothing has been selected. 1.9. Menu#selected - returns the name of the last selected menu_item. 1.10. Menu#selected? - if nothing has been selected, selected?(root_node) returns true. 1.11. Menu#selected? - if a node has been selected, selected? returns true for selected node and all its parents. 1.12. Menu#selected? - if there are no menu items corresponding to the permission's of the role provided to menu, selected? does not return true. 1.13. Menu#selected? - if MenuItem returns an empty array, selected? returns false for all input. 1.14. Menu#crumbs - When top-level menu item is selected, crumbs has length one. 1.15. Menu#crumbs - When top-level menu item is selected, crumbs has the root node's id. 1.16. Menu#crumbs - When bottom-level menu item is selected, crumbs has two crumbs (assuming lowest level is two). 1.17. Menu#crumbs - When bottom-level menu item is selected, crumbs are ordered from child to parent and all are present up to root. Because of the nature of our assignment, our only design decisions were made with respect to making our Rspec tests as clean and readable as possible. We did not modify the application code itself. That being said, the Menu model is highly compositional, and it touches on MenuItem, ControllerAction, Controller, ContentPage, and Role (in addition to Node, which is in the same model). As a result, one of our main objectives was to make sure that we were transparent about all the different models which need to exist and how they interact with each other, in order for the Menu model to work. We address this issue by neatly creating all of the mock objects that we need in 'let' blocks before the tests, and explaining any of the tricky nuances (like how MenuItems and Roles interact using the role_(user_type).yml file). We also add additional comments to some of the more complex test cases (#select) to explain why we're expecting the particular side effects we're expecting, when our 'it' and 'context' block descriptions cannot easily convey all of the complexities. Here is an example of how we mock objects for the Node unit tests. <image> Here is a snapshot of the Node unit tests, which shows proper utilization of Rspec best practices. We utilize short, coherent expectations. We use contexts to provide more information about the branches in a function that we are testing. We avoid binding ourselves to implementation by stubbing methods which are called in other classes. <image>. In the future, it will be very easy to test whether changes to the menu model have broken the original functionality. It will also be easy to add more tests to raise our test suite's mutant-killing rank, as we have done the hard part of defining all the mock objects and prototyping the relations they all have with each other in this initial set of tests. We ended up with 100% code coverage, and mutation testing on our test suite yielded 90.21% mutant-slaying capabilities. We believe this is a demonstration of the exemplary thoroughness of our test suite, and that these changes should be pulled in to the Expertiza master branch. This image shows our test suite running. <image> This image shows an abbreviated version of /coverage/index.html page which is generate after running rspec. It shows us achieving 100% code coverage. <image> This image shows our mutation score. Of 531 mutations, we killed 479 and 52 were left alive. This is a mutation coverage of 90.21%. While we will leave it to the TA to verify this claim, examination of the living mutants shows that many of the mutations replaced lines with equivalent code (fetching a variable as opposed to just accessing it, or substituting equivalent variables for one another). Similarly, killing the remainder of the mutants would require binding our tests to implementation, to ensure that particular methods get called. As such, we believe our mutation score is quite good. <image>. The files involved in this commit are: 1. menu.rb - the model being tested. Contains the menu class and the node class. 2. menu_spec.rb - the spec file for menu. Contains all of our tests. 3. spec_helper.rb - we added a limit on how long tests can take to run, as one of the mutations which was generated had infinite runtime. A video of our test suite running properly can be found here! <link>.","Some of the tests are described very well, explaining what they test and what the outcomes are.  Other tests have little description.  Tests like the one for topic_name are long, so the various steps should be explained.","Dear Student,

Thank you for your comprehensive submission. It is evident that you have put in significant effort into the completion of this assignment and the test coverage you put in place was thorough. 

Your explanation of the testing approach and making the Rspec tests clean and readable demonstrates your understanding of the concepts. The use of 'let' blocks and descriptions for complex tests indicate good practice in clarity during testing. The screenshots of your tests and the results of the test suite offer great evidence of your efforts at ensuring your goal of 90%+ code coverage for the menu.rb model.

Your identification of the compositional nature of the Menu model and outlining of its interactions shows not only an understanding of the system but also a meticulous attention to detail. Your use of mock objects makes the test cases more robust and demonstrates good knowledge of Rspec best practices that are commendable.

Future thinking in test cases, efforts to ensure that the test suite's mutant-killing rank can be raised in the future, and emphasis on transparency is to be applauded. Achieving 100% code coverage and a 90.21% mutation score reflects thoroughness in your work. Your reflections on not binding tests to implementation and observing equivalent mutations illustrates a mature understanding of good testing practice.

Just one note, please check the hierarchy of content you provided at the beginning of the assignment. They all seem to be on the same indent level. Make sure the hierarchy is correctly formatted to improve readability and comprehension better.

Aside from that, your assignment shows a good understanding of software testing and a clear idea of what makes effective tests. Well done! Keep up the good work.

Best Regards,
[Your Name]"
30,E1990,"1. On Expertiza, students receive review comments for their work from their peers. This review mechanism provides the students a chance to correct/modify their work, based on the reviews they receive. It is expected that the reviewers identify problems and suggest solutions, so that the students can improve their projects. 2. It is observed that the students learn more by reviewing others' work than working on the project as it gives them perspective about alternative approaches to solve a problem. 3. The Instructor is facilitated with metrics such as average volume and total volume of the content of the reviews provided by a student. 1. The reviewers can fill in the review comments on others' work, however they do not receive feedback on how effective their reviews are for the receiver. It would thus make sense to have a feedback mechanism in place, which can identify whether a reviewer has identified problems and provided suggestions for a student or team's project. In order to achieve this, we need to identify the suggestions in the review comments as a way of determining how useful a review would be. This would motivate the reviewers to give better and constructive reviews. 2. We would want the instructor of the course to be able to view how many constructive reviews were provided by a reviewer in comparison to the average number of constructive reviews provided by the other reviewers of the course. The reviews could be graded on this basis. 3. To detect the number of suggestions in a text, there is a web service in place, developed previously by some contributors. We wish to integrate this suggestion detection algorithm and use its results to show the suggestion metrics to the reviewer as well as the instructor. 4. Please note that the web service mentioned above is currently not working. Thus we will use simulations to mock the response from the web service for this project. 1. The suggestion detection algorithm was expected to identify the number of suggestions in the review comments given by a reviewer. To mock this number, we used a random number generator. Now we expect to receive a value between 0-10 as the number of suggestions provided by the student in one round of review. (Refer to method: num_suggestions_for_responses_by_a_reviewer in review_mapping_helper.rb) 2. In order to be able to use integrate the suggestion detection algorithm in the future, we have included a function with the API calls to the service. This function and the corresponding call to this function is currently commented. (Refer to methods: num_suggestions_for_responses_by_a_reviewer and retrieve_review_suggestion_metrics in review_mapping_helper.rb.). 1. We wish to present the reviewer(student) with an idea of how useful their reviews are, in comparison to that of the class. 2. To achieve this, we have included the following in an alert when the reviewer clicks on ""Save"" or ""Submit"": 1.1. 1. The number of suggestions in the review comments provided by the reviewer for that round 1.2. 2. The average number of suggestions in the review comments provided by all reviewers of the class (Again, for the purpose of demonstration, we have used values from the random number generator mentioned above.). 1. We wish to present the instructor with comparison of the number of suggestions present in the review comments provided by a student and the average number of suggestions typically provided by the class. We have represented this data in the form of a bar graph showing the round-wise comparison for each assignment. This visualization adheres to the pattern of visualization which was present on this page for volume of review comments and average volume of review comments. Given below is the design flowchart of our proposed solution: <code> Once the student finishes (partly or completely) giving his/her review and clicks on the ""Save"" or ""Submit"" button, the web service API will be called and the review's text will be sent as JSON. The PeerLogic web service will send back the output(number of suggestions in the review comments) which will then be displayed in an alert to the student. For all the review scores received by the students, the aggregate data will be displayed to the instructor whenever he/she will view the Review Report for any assignment/project. This will be visible in the metrics column of the review report and will be displayed student-wise, i.e., for each student participating in the assignment. Please refer to <link> for the exact changes. We have modified the following files (added methods/ added code to methods/ replace code in the methods): 1. review_mapping_helper.rb: 1.1. display_volume_metric_chart(reviewer) - changes made to resize the bar graph for volume metric and removal of legend for every graph. 1.2. avg_num_suggestions_per_round(assignment_id, round_id, type) - as the name suggests, the goal is to obtain the average number of suggestions provided by the class in each review round of the assignment. 1.3. num_suggestions_per_student_per_round(response_maps, round_id) - the goal is to obtain the average number of suggestions provided by the student in each review round of the assignment. 1.4. comments_in_current_response(response_id) - provides a concatenated text consisting of all review comments in the current response. 1.5. retrieve_review_suggestion_metrics(comments) - this function has been added to be able to make calls to the API in the future, when it starts working. 1.6. num_suggestions_for_responses_by_a_reviewer(comments) - this function should make a call to the function mentioned above. Currently, we use this function to simulate the number of suggestions in each comment, using a random number generator. 1.7. num_suggestions_reviewer(responses) - this function provides the number of suggestion given by a reviewer to a student/team's work. 1.8. display_suggestion_metric_chart(reviewer) - this method sets up the colors, labels and data to generate the bar graph for the suggestion metrics. 1.9. initialize_suggestion_chart_elements(reviewer) - this method computes the number of suggestions provided by the student in each round, the average number of suggestions provided by the student in all rounds, the average number of suggestions provided by the class in each round and the average number of suggestions provided by the class in all rounds. This data is generated as a collection of lists. 1. _review_report.html.erb: changes are made to restructure the legend and add labels corresponding to suggestion metrics. 1. response.html.erb: jQuery changes have been made to get the current response stored in the params and calculate average of the same instantly, when the student clicks on ""Save"" or ""Submit"". Listed below are the major changes along with the screenshots of git diffs of those file/functions. 1. Changes made to display the suggestions metrics bar chart to the instructor in review_mapping_helper.rb file. <code> 2. Changes made to initialize all the metrics and get all their values from the web service / random number generator when the instructor views the Review Report. <code> 3. Changes made to call the web service (currently commented out since the service is not up) / random number generator. We call the function to get number of suggestions for the reviewer per round per team and for the class as a whole to calculate the average. Below is the git diff: <code> 4. Changes made to the response.html.erb where these functions are actually called from. <code>. 1. review_assignment_spec.rb: Tests have been added to test the feature of identifying the number of suggestions in a given review. 1.1. Check whether the student is able to see a suggestion score for his/her review - on clicking save 1.2. Check whether the student is able to see the average number of suggestions given by the class - on clicking save 1.3. Check whether the student is able to see a suggestion score for his/her review - on clicking submit 1.4. Check whether the student is able to see the average number of suggestions given by the class - on clicking submit 1.5. Check whether the number of suggestions displayed is in the valid range of numbers - on clicking save and submit 1.6. Check whether the the average number of suggestions given by the class is in the valid range of numbers - on clicking save and submit 1. review_mapping_helper_spec.rb : Test have been added to check whether the new legends for metric is now part of the ""Review reports"" page. Review reports page as visible to the Instructor, after the above mentioned changes. <code> Suggestion metrics as visible to the reviewer when saving the review. <code> Suggestion metrics as visible to the reviewer when submitting the review. <code>. <code> <code>. <code>. Following test cases were added to see whether the functionality works as intended. 1. Whether the alert renders the number of suggestions for a reviewee on save/submit. 2. Whether the alert renders the average number of suggestions in a class for a reviewee on save/submit. 3. Whether the function returns the number of suggestions in correct bounds and returns an Integer value. 4. Whether the function returns the average number of suggestions in correct bounds and returns an Integer value. <image> 1. . Whether the review report has the modified legend metrics. <image>.","I would have liked a more complete description of what suggestion detection is supposed to do.  You did describe it, but so tersely that I think readers would have had dififculty grasping the approach.

You have a good overview of code changes, but then you just dump the changes into the document without an explanation of how each piece of code works.  It is good that you listed what the automated tests do.  The screenshots stand by themselves, though; it would've been more useful to weave them into the document wherever they applied.","Your approach to designing a feedback system for peer review is commendable. Your deliberate step of using a random number generator to mimic the suggestion detection algorithm's output enriches the testing process during the web service's down times and provides representational data for exploration.

There's an extensive effort in describing the methods you've implemented, and your code organization appears logical. However, it might be easier for others to understand the new functions if you briefly describe the primary role they play in the whole system along with the technical explanations.

Your plan to include an alert pop-up to show reviewers how well they are doing is thoughtful and potentially very useful. This instant visual statistic feedback would be an excellent motivator for the students to write better reviews.

Your emphasis on test cases is particularly impressive, as testing ensures that your implementation works as intended. 

Remember to validate the random measurements to ensure the number of suggestions recorded align with the reality in future usage.

It would be valuable to seek feedback from students and instructors once these changes are implemented. Their input can guide you to make further improvements. 

You did a great job overall, though this submission could be even better if it was less verbose and more concise. Remember, brevity aids in clarity. 

Next time, please consider abstracting away some of the details and focusing on the high-level design and key implementation aspects. It would make it easier for people unfamiliar with your project to understand the purpose and flow of your work. 

Keep up the good work!"
31,E1818,"The project is created to enable role-based team-mate reviews. These roles can be better named as duties, corresponding to the duty of a team member in a particular project. Borrowing from different Agile methodologies like SCRUM, each team member has a particular role for example: architect,facilitator and implementer.A much more meaningful review can be done if the review rubric was duty-specific. Currently, there is a generic teammate review rubric for all assignments. This means that some review questions are not applicable for all team members. For instance, if there is a question “What percentage of the code was written by this member?” This may not be applicable for the team member who wrote tests or documentation.Similarly, design document specific questions may not be applicable to other members.The instructor should be able to use a different team-mate review rubrics for evaluating the contribution of students depending on their duty. <image> In a UML Class diagram, The relationships depicted above are as follows: 1. Between the User and Duty class, there is a bidirectional association. The user table is used for both the instructor and the student. 1.1. Each instructor can have multiple roles that he can choose from for a particular assignment/questionnaire. 1.2. Each student can have 0 or 1 role for a particular project. The value of the duty for that project team is stored in TeamUsers. 2. AssignmentsDutyMapping stores the value for all duties applicable to a particular assignment, hence it is an aggregation of the duties for an assignment. 3. AssignmentDutyQuestionnaireMapping adds the questionnaire_id for a particular AssignmentDutyMapping thus has a direct dependency to AssignmentDutyMapping and has an association with the Questionnaire table. 4. StudentTeams uses the AssignmentDutyMapping to table to find available duties for a particular assignment to allow teammates to select. It then uses the Duty table to fetch the respective name of the found duty_id. The project introduces changes from the instructor view and the student view. The changes are as follow: 1. Create Duties table: This table stores all the duties created by any instructor. <code> 1. Create assignments_duty_mappings table: If an instructor wants to add multiple duties for an assignment, storing it in the duty table will cause the duty to be overwritten. Thus we have created a table which maps an assignment and all its duties. <code> 1. Create assignment_duty_questionnaire_mappings table : This table is created to store the questionnaire for team-mate review rubrics and the corresponding duty id. <code> 1. Added a column entry named ""role_based_assignment"" in the assignments table which would be of type boolean. This field saves the status of the role based review check box. 2. Added a column entry named ""allow_multiple_duties"" in the assignments table which would be of type boolean. This field saves the status of the check box for allowing multiple students with the same role. 3. Added a column entry named ""Duties"" to the Users table of type string. This field saves the duty that a student would select if role based reviews are enabled. 1. For a particular assignment, in the 'Review Strategy' tab of edit assignment, a check box called ""Allow role based review?"" is created. This allows an instructor to enable a role based team-mate review for a particular assignment. <image> 1. When the check box is ticked, the hidden fields become visible. This includes the duties that have been already added, displayed in a drop-down. Also, a button ""Add Duty"" pops up. This takes us to the create method of Duties controller where an instructor can add new duties. <image> 1. In order to display the hidden fields, We call the java script function dutiesAssign() using the ischecked listener. The function queries the checkbox variable for role_based_review and depending its value(true or false), the hidden attributes i.e. duties_dropdown are displayed or kept hidden. <image> 1. The instructor can select from the dropdown of duties. We have allowed multiple duties to be selected at once.The duties created by an instructor are unique for that instructor and are not displayed for any other instructor. <image> 1. An instructor can decide the number of duties for a particular assignment. 2. When the assignment is saved, the duty_id is saved to the assignment_duty_mappings table and thus it is associated with that assignment. 3. The instructor can create Team-mate review Questionnaires for the different duties he created or can use any from the existing list of questionnaires. <image> 1. In order to do this, the instructor has to go to the Rubrics tab of edit assignment. There, if the assignment is role-based, a drop down menu displays the list of all the duties selected for an assignment. 2. When the assignment is saved, the questionnaire_id is stored in the assignment_duty_questionnaire_mappings table. This is later used while displaying team-mate review questionnaire to students. 1. When a student goes to “Your team”, they can see the team members, their selected duties and the option to review if these are enabled. Students will either see ""Review"" link to start the teammate review or a message that says that ""Teammate has not selected a duty."" <image> 1. The student can select their duty from a particular set of duties created by the instructor for that particular assignment. Upon clicking ""Select"" option in the Duty column, they are redirected to a new page where all the duties appear as radio-buttons and the student can select one of these. This occurs only if role based reviewing is permitted for that particular assignment. If not, the existing view will be displayed which does not give any such option. <image> 1. The logic for this is implemented in the 'student_teams' controller and view. This is enclosed in a conditional which only appears if role based reviewing is permitted. <image> 1. A student can only select one duty. <image> 1. A team member cannot change their role after the assignment submission deadline. 1. When a student selects a particular duty , it is stored in the database table of that user. Thus when a team-mate reviews that student , they will see a questionnaire corresponding to the duty of that student. This would enable reviews of the teammates to be accurate and specific to their role in a project. 2. After the teammate review questionnaire is opened once, 'View' and 'Edit' links are shown which redirect the user to view/edit the appropriate last saved response. Some of the new migration files we have created are 1. db/migrate/add_duties_table.rb <code> 1. db/migrate/add_reference_of_instructor_and_assignment_to_duties.rb <code> 1. db/migrate/add_duties_to_users.rb <code> 1. db/migrate/add_multiple_duties_to_assignments.rb <code> 1. db/migrate/create_assignment_duty_questionnaire_mapping.rb <code> 1. test/controllers/duties_controller_test.rb <code>. 1. app/views/assignments/edit/review_strategy.html.erb <code> <image> <code> <image> 1. app/views/assignments/edit/rubrics.html.erb <code> <image> 1. app/controllers/student_teams/student_teams_controller.rb <code> 1. app/views/student_teams/view.html.erb <code> <image> 1. app/controllers/response_controller.rb <code> 1. app/questionnaire/new.html.erb <code> 1. app/questionnaire/edit.html.erb <code> 1. app/views/duties/_form.html.erb <code>. 1. Instructor tests <code> 1. 1.1. While creating an assignment, in the Review Strategy tab, check the box for role based reviewing and expect the 'role_based_review' column of Assignments table to be true. 1.2. Ability to add new duties from the Review Strategy tab. Click on 'Add Duty' and get redirected to a new page where there is the option of adding a name for duty in the text-box and click 'Create Duty'. This new added duty will now be displayed in the Review Strategy tab if the role-based-review option is selected. 1.3. Select from already existing and newly added duties for a particular assignment. After saving, the changes should be reflected in the database 'AssignmentsDutyMapping' table. 1. Student (team member) tests <code> 1. 1.1. When a student visits 'Your Team' link, if the option of role based review is selected while creating the assignment, a link 'Select' should appear which enables the student to select the duty. 1.2. In the 'Your Team' tab, after clicking the 'Select' link, the student should be able to select one duty (radio button). This selected duty should now be visible on the 'Your Team' page. 1. <link> 2. <link> 3. <link>.",Logical organization.  Good description of how the code works in most places.  Test plan has been added with an appropriate level of detail.,"You have done a very comprehensive work on this project. The duties, association, added columns, and database tables are well-defined and concise. The UML Class diagram explanation provides a lucid understanding of the project structure and workflow. Here are a few points I would like you to take note of for improving your assignment:

1. Explanation: Although you've done a thorough job of explaining each step, some clarification and elaboration are needed in areas. For example, the reason behind the role-based review rubric system and the benefit it delivers to users can be explained in more details. 

2. Consistency: There seems to be a numbering issue in your explanation. It would be helpful if you can maintain consistency in your number lists. For instance, you start back at the number 1 several times. This makes it quite difficult for anyone reviewing your documents to follow along. 

3. Illustrations: Your assignment lacks sufficient images and codes. Remember to include images and screens where necessary, use <> to wrap your code blocks to improve readability.

4. Implementation: While the implementation seems technically sound, it would be beneficial if you provide an explanation about what each table, column, and corresponding data signifies. 

5. Testing: You seem to have also tested your application which is great. However, please attach screenshots of test results and write about how you concluded the results. Also, provide more information on your testing parameters and why you chose them. 

Overall, I am very impressed with the depth of your work. Please incorporate the suggestions, and your assignment would be even better. Well done!"
32,E1631,"On Expertiza, the bidding interface allows students to sort topics by preference. This is needed in order to run the team assignment algorithm to match students with others based off the similarity in their topic preferences. The problem with the present method is that the students have to type in their priorities into the boxes beside the topic. While doing this the students end up making mistakes in setting up priorities by assigning random numbers to the topics, sometimes, even numbers greater than total number of topics available to prioritize. This phenomena causes various problems when running the topic assignment algorithm. We built an interface in sign up sheet that would allow students to drag and drop the topics into the priority table. Where this priority table will be used to run the selection algorithm with ease. This interface would help avoid the errors caused by the previous interface. As shown in the picture below, in the old bidding interface users need to manually enter the priority. They can't repeat the same priority number twice. It's difficult for them to remember all the priority numbers entered previously. If they enter the same priority value, system throws an error. Some users made mistake and entered some random priority values (e.g priority value greater then number of topics etc). This caused many problems in the intelligent team assignment algorithm. This situations can be handled by adding more checks. But we can avoid these errors by only giving the users to order their topics by topic name and expertiza code can assign required priority numbers internally. <image> Old Signup Table. Under the previous interface users can only choose which project they want to work on through setting the priority of the projects based on some distinct integers, where any smaller integer has higher precedence, and empty represents the lowest. For instance “1” has the highest precedence among other integers. The user can input only one instances of the same integer. If no desired topics are selected, then the user will be assigned some topic depending on the heuristics used inside the selection algorithm. There exists a serious user interface problem with the previous design. Note when a user is scanning through a hugh list of the topics, he/she might want to choose the topic as they are reading the project description. In order to achieve it, they will have to remember the priorities of the less desired topics, thus they will have to constantly updating their priorities for other topics. Therefore this will cause a lot of trouble and inconvenience, compared with the new design, where the user just needs to drag the topics without constantly changing the previous priorities. 1. Improve the user interface 2. Allow the user to set their priorities based on the position of the topic in the selection list 3. Do not allow the user to set duplicate priorities. We proposed sortable list interface to solve the problem associated with the old interface. New interface has two tables. First table holds all the topic lists and second table holds all the chose user priorities. User can select the topic by moving the item from Topics table to Selection table. Users can also resort already selected topics. System also provides the ability to remove already selected topic from the selection by just moving it back to the topic selection table. <image> New Signup Table. These are the set of operations a user can perform on this signup page using the cursor: 1) The user can drag the topics from topics table on the left into the selection table on the right. As a result, the topics are moved from one table to another. 2) The user can rearrange the already added topics in the selection table. As a result, the topics can be moved up and down within this table. The order of topics in selection table on the right, from top to bottom, are taken in the order of high to low priorities. Then this list of prioritized topics are used to run the intelligent bidding algorithm. intelligent_topic_selection.html.erb This file has code to display Topics and selection table. This view is displayed if the assignment type is 'intelligent'. This page is only static. CoffeeScript is used to provide dynamic sorting functionality to the tables in this view. Whenever the user drags and drops the item, it calls corresponding CoffeeScript associated with the table body. Both topics and selection tables are assigned same class name ""connectedSortable"". This class name is used in the CoffeeScript to connect the tables. Only connected tables can exchange the elements between each other. <code> _suggested_topic.html.erb Instructor can allow students to suggest new topic. If the suggested topic is approved by instructor, it'll be displayed at the end of the page. Previously it was part of the list.html.erb file. New interface makes use of the same code. So we created _suggested_topic partial to display common code. <code> app/javascript/tablelist.js.coffee This file has a callback function for each table. This callback function is called when the user drags and drops the topic. This callback function generates post request to sign_up_sheet controller. This post method sends topic id of all the selected topics as a list to the controller. <code>. sign_up_sheet_controller.rb Two methods ( set_priority and list ) are changed in sign_up_sheet controller. Previous interface used to call set_priority method to set the manually entered priority of each topic. But the new interface should calculate the priority of each topic based on the order of selected topic list. This method receives the topic as an array and updates the priority of each topic based on the received order. <code> In the previous interface, list method used to display all topics in some random order irrespective of chosen topics priority. But with the new interface, expertiza displays selected topics in Selection table based on the indicated priority and remaining unselected topics in the Topics table. Seggregation of topics into separate tables and ordering of topics happens in list method. This method displays new view only if the instructor created assignment with bidding topic selection option. <code> view/sign_up_sheet/list.html.erb This view holds the code to display manual FCFS (First Come First Serve) style topic selection. This code also had code to display suggested topic list. New interface makes use of suggested topic list code. So we refactored suggested topic code into separate partial and we replaced that code block with single render method. <code> view/sign_up_sheet/_table_line.html.erb Old interface had lot of unnecessary table headers like number of waitlisted students, number of slots available etc. _table_line partial displays contents of each topic (data for set of columns). These columns doesn't give any useful information to students in bidding topic assignment because topic assignment happens at some predetermined time. We removed these columns from sortable topic list. Only FCFS style topic selection or Instructor/TA/Admin interface display's this information. <code> _table_header.html.erb _table_header displays header of the table. We added check to display only subset of column headers for intelligent topic assignment (bidding). <code>. There are only some implementation changes to the methods in the controller. But the end behaviour is not changed. So new unit test cases are not necessary. Existing unit tests cover all the behavior. We ran unit tests for sign_up_sheet_controller . All tests passed without any failures. <image> Testing Result. 1. You can access the deployment here <link> 2. Login as student : user name: student5432, password: password 3. Navigate to <link> 4. Topics table contains all the topics available for this assignment 5. Selection table contains all the selected topics. First topic indicates highest priority. Last topic in this table indicates least priority 6. Drag and drop the topics from Topics table to Selection table to bid for the topic. 7. You can also remove perticular topic from your selection by moving the topic back to Topics table from Selection table 8. This feature is already merged to expertiza master repository few days back. You already used this interface to select 2nd OSS project topics. Enabling the interface to use keyboard to select topics and drag them into the selection table. This will make the selection very intuitive.","Design doc is mostly screenshots of code, which don't explain enough about why the project was coded the way it was. ""There are too many checks of """"reviews_is_team"""".
Login issue with action_allowed as pointed out during demo. 
There are too many screenshots of the code changed in the design doc.""","Hello,

You’ve done a commendable job in outlining your approach in improving the user interface in Expertiza's Assignments section. I appreciate the extent of detail provided in your write-up.

Your approach of solving the issue with the old method by creating a drag and drop interface seems efficient and user-friendly. The method of ordering topics by preference could greatly enhance the user experience by allowing students to visually prioritize their choices.

Also, your new method of using sortable lists is a thoughtful way to mitigate common errors in the older system like duplicate and random priorities. The idea of having two tables for all the topic lists and user priorities is clever. Each step in your process from giving valuable context to outlining your coding and thought processes is well written.

One area that you might want to look into more is accessibility. You mention ""enabling the interface to use keyboard to select topics,"" and it's good to think about those who cannot use a mouse. However, make sure you're also thinking about other accessibility concerns, like those who rely on screen readers.

Also, for a document of this sort, it would be useful to integrate diagrams or screen shots to illustrate the old and new interfaces. This would help a non-technical reader envision the changes more effectively.

There is a hint of redundancy and repetition in your document. Try to succinctly consolidate and review your inputs to make it sharp and deliveries stronger. Also, using a spell checker or getting a peer review done can rule out minor errors like ‘hugh’ instead of ‘huge’.

Great work! It's gratifying to see you're making strides towards more intelligent and user-friendly systems. Looking forward to seeing your ideas come to life!

Best,
[Your Name]"
33,E1968,"This project fixed several bugs related to Assignment teams. Expertiza has Assignment objects, which represent an assignment usually assigned by an in structor for a course. If the instructor allowe teams for the assignment, the participants in that course can create teams with each other. Also, the instructor can create teams or add team membert to a exsiting team. Our project is focused on fixing bugs related to these functionalities. In this project we fixed three problems, the problems and the way to reproduce them is shown below. 1. Adding a member from the UI (typing the ID into the textbox) raises an error. <code> 2. Impersonating a student who has an assignment without affiliating to any course will cause an error. <code> 3. Creating a team by uploading a file. <code>. 1. The reason for the first problem was actually due to a key error. In teams_users_controller.rb line 35, 'assignment_id' was used to find AssignmentParticipant. But in the model of AssignmentParticipant, the foreign key name is acctually 'parent_id'. So, by changing it, problem solved. <image> 2. After our inspection into the file of ""expertiza/app/controllers/student_task_controller.rb"", we found the reason for the second problem was that before we used t.assignment.course.instructor_id, we had to confirm that t.assignment.course was not equal to nil. If there existed an assignment without being subject to any course, when this assignment was assigned to a specific student, it would raise an error when it came to showing the tasks of the student. Thus, in order to show student tasks correctly, we changed the code to at first checking whether the t.assignment.course was nil. If t.assignment was not nil, we could use t.assignment.course.instructor_id to retrieve data needed from the database, otherwise, we used t.assignment.instructor_id directly to retrieve data needed. <image> 3. The third one works fine. For each of the problems, we did feature tests with Rspec. They all follows the reproduction steps decribed above. 1. Problem 1: assignment_team_member_spec.rb Following steps needs to be performed to test this code: 1. Login as instructor. 2. Create a course and an assignment under that course. 2. Add at least two students as participants to the assignment. 3. Create a team for the assignment. 4. Add a participant to the team. 5. Check if the student is a team member of that team. 1. Problem 2: impersonate_student_spec.rb Following steps needs to be performed to test this code: 1. Create data for the test including an instructor, a student and an assignment without being subject to any course. 2. Log in as instructor. 3. Add the student as the participant of the assignment created. 4. Impersonate the student from the instructor account. 5. Check if the page of displaying tasks of the student is correctly shown. 1. Problem 3: assignment_team_import_spec.rb Following steps needs to be performed to test this code: 1. Login as instructor. 2. Create a course and an assignment under that course. 3. Create teams for the assignment by importing a file. 4. Check if these teams belongs to the assignment. Run the test locally: 1. Problem 1: The snapshot of results in the console when running rspec spec/features/assignment_team_member_spec.rb <image> 1. Problem 2: The snapshot of results in the console when running rspec spec/features/impersonate_student_spec.rb <image> According to above snapshot, after we applied changes in original code, the test was able to passed. Besides, we confirmed that our changes were successful by taking the same actions in our browser. 1. Problem 3:The snapshot of results in the console when running rspec spec/features/assignment_team_import_spec.rb <image>.","1) Clearly explained what their task was and how they resolved the issue.
2) Showed before and after code snippets side by side.  This can also be done with Github diff view.
3) Could have added test-case code snippets as well as explaining their test cases. 
4) The formatting is very basic, and consequently the various text elements are not well set off from each other.  Mediawiki markup (https://www.mediawiki.org/wiki/Help:Formatting) can be used to make it easier to read.","The detail and thoroughness you have shown in your assignment are impressive. Your operation of debugging and identifying the errors is particularly well done. The solutions proposed to address each of the problem segments show good critical thinking abilities and a sound understanding of the course content.

However, I am setting out a few areas for improvement for future:

1. Clarify numbering issues: There seems to be a repetition in the numbering of problems and their corresponding tests. Please be attentive to numbering for easier comprehension. 

2. Proofread For Typographical Errors: There are several minor spelling and grammar errors. For example, ""in structor"" should be ""instructor"", ""membert"" should be ""member"", ""exsiting"" should be ""existing"", ""acctually"" should be ""actually"". Precision in spelling and grammar enhances the readability of your work.

3. Ensure completeness: I notice that you mentioned that the third problem works fine but failed to include any information or explanation as to why this is the case.

4. Images: You have written '<image>' a few times in the project, however, these placeholders lack the corresponding images. I presume that this is more of a mistake than an omission. In future, kindly check your work to ensure that all placeholders have been properly replaced with the appropriate content.

You have done a good job of testing your code and documenting the process, including clear steps for reproduction. The use of screenshots is encouraged to illustrate your work visually, especially where you provide a snapshot of results. Keep up this approach and do utilize feedback to improve in upcoming assignments. Good luck!"
34,E1563,"<link> is a peer review based system which provides incremental learning from the class. This project has been developed together by faculty and students using <link> framework. Expertiza allows the instructor to create, edit and delete assignments, create new assignment topics, assign them to a particular class or selected students, have students work on teams and then review each other's assignments at the end. For the students, they can signup for topics, form teams, and submit their projects and assignments. Students then review the work done by other students and give suggestions to improve. Teams after reviews are allotted scores and they can refer to the peer comments to further improve their work. It also supports submission of different file types for assignments, including the URLs and wiki pages. Refactoring <ref>Refactoring <link> </ref> is restructuring of code without the need of changing any external behavior. It reduces complexity and improves readability. It also becomes easy to extend the application with respect to different modules and their functionalities. Some common techniques to refactor are: 1. Moving methods to appropriate modules 2. Breaking methods into more meaningful functionality 3. Creating more generalized code. 4. Renaming methods and variable. 5. Inheritance. Refactor AssignmentParticipant model which is a subclass of Participant model. The following tasks have been performed as per the requirements. 1. Refactor scores method to smaller methods. 2. In set_handle method, there is no need for a separate ELSEIF statement. Club the ELSEIF statement into IF statement as an another OR condition. 3. Remove methods like compute_quiz_scores(scores) , average_score_per_assignment(assignment_id) which are not being used. 4. Method cycle_deviation_score(cycle) is also present in CollusionCycle, remove it from this class. 5. Methods related to reviews like teammate_reviews, bookmark_reviews do not belong to AssignmentParticipant model. Move them to the appropriate class. 6. Methods related to files and directories like files(directory) should not be present in AssignmentParticipant model, move them to FileHelper module. The method scores has been converted to smaller methods scores , assignment_questionnaires , merge_scores , calculate_scores . It is a good practice to keep the methods not extremely long as they tend to complicate the functionality and the readability. <table>. The set_handle method had an unncessary ELSIF statement which was performing the same action self.handle = self.user.name . This has been clubbed as an OR condition to the IF statement and the first ELSIF statement has been removed. <table>. The files and directory methods from AssignmentParticipant model have been moved to the FileHelper module. The methods files , submitted_files and dir_path are appropriate for the FileHelper' module and hence been moved there. The below line was added to the AssignmentParticipant model. include FileHelper The AssignmentParticipant class would look like <code> Methods moved to FileHelper: 1. submitted_files <code> 1. files(directory) <code> <code> 1. submitted_files() <code> 1. dir_path <code>. The following methods have been removed as they were not being used by the application. def average_score_per_assignment(assignment_id) <code> <code> <code> <code> def quiz_taken_by?(contributor, reviewer) <code> def has_quiz? <code> def reviewees <code> <code> def two_node_cycles <code> def three_node_cycles <code> def four_node_cycles <code> def cycle_similarity_score(cycle) <code> <code> <code> def cycle_deviation_score(cycle) <code> <code> <code> def compute_quiz_scores(scores) <code> def review_response_maps <code> def members <code> def get_hash(time_stamp) <code> <code>. 1. The bookmark_reviews() method from AssignmentParticipant was being called once in get_assessments_for method of BookmarkRatingQuestionnaire class. It has been replaced by the method statement directly since it only had a single line of code. <table> 1. The teammate_reviews() method from AssignmentParticipant was being called once in get_assessments_for method of TeammateReviewQuestionnaire class. It has been replaced by the method statement directly since it only had a single line of code. <table>. Please follow the below instruction to test UI: 1. Login to Expertiza on <link> . 2. Enter username as 'student13' and password as 'password'. 3. You can select a previous assignment 'shivam test' or 'Pankti test'. 4. You should be able to access the pages further 1.1. Your team- The page content should be visible without any errors. 1.2. Your work - The upload button for submission should be visible. 1.3. Your scores- The page should give result 0 and not any error. When the user runs the application, the behavior of the application remains the same. The existing <link> test cases remain successful. The same can be checked by running Rspec spec The participant is able to log in to the system, view the assignments, submit links and files in assignment submission, view the scores, review peers, etc. Below are some of the execution screenshots after the refactoring of the model. The Expertiza Login Screen <image> User can see all the assignments as below. <image> View team members for the assignment selected. In this case, we have taken a dummy assignment we created. <image> View the submission page to upload the assignment. <image> View the scores of an assignment. <image>. 1. Expertiza Github repository<ref>Expertiza Github repository <link> </ref> 2. Our Github repository<ref>Our Github Repository <link> ]</ref>. <references/>.","Writeup is fairly readable.  Has a nice table at the beginning.  Showed only ""after"" code; did not compare ""before"" with ""after"".","Dear Student,

Firstly, I appreciate the time and effort you invested in this assignment. Your thorough understanding of the concepts involved in Expertiza, as well as refactoring and the different methods employed, is evident in your submission.

It's clear you managed to reduce complexity, improve code readability and made it easier for future extension of the application, which were our primary objectives.

On the specifics, I appreciate the succinct explanation you provide for each method you had refactored, moved or removed. Your detailed explanations, along with code snippets, provide an excellent understanding of the changes you made in the code and demonstrate your ability to analyze and improve the existing code base. 

It's also commendable that you paid attention to code that was no longer in use and removed it. Certain sections of your work like the removal of redundant ELSEIF statements are an excellent example of optimized coding.

However, I found that you haven't clearly stated the reasons for moving certain methods to the FileHelper module. While you mentioned that they seemed appropriate for the module, a clear rationale for why those methods don't belong in the original module would illustrate your understanding better.

Lastly, your testing part seems to be correctly done. In the future, please try to include a broader range of test cases to fully verify the code’s functionality after changes. Automated testing could also be beneficial in making this process more efficient.

Overall, this is an excellent assignment that showcases your understanding of the course material. There's always room for improvement, so I encourage you to continue refining your skills in code restructuring and refactoring. 

Great work!

Best,
[Your Name]"
35,E1997,"In Expertiza, meta-review is a feature that enables a third party to evaluate the quality of feedback that a reviewer gives a reviewee. meta-review is an important feature that can help students become better reviewers for their peers by providing detailed feedback that is actionable and positively formulated. Unfortunately, this feature is broken and the following issues were identified. Design patterns are not applicable as our task involved just modification of existing methods. When a user requests a new meta-review, (s)he should be able to click on the Begin button, which should redirect him/her to the meta-review questionnaire and when the user returns back (to the page where he can view the reviews and meta-reviews, by clicking on Others’ work in his/her assignment), (s)he should be then able to see view and update links for the meta-reviews (s)he has performed. But the issue is Begin and Edit are not working for the given scenario. 1. Log in as instructor6, click on Manage...-> Assignments 2. Click on edit assignment, navigate to Due Dates and check ""Use meta-review deadline"" checkbox 3. Select ""Yes"" for all of the following: Submission allowed, Review allowed and Meta-review allowed in all of the deadline types 4. Navigate back to Assignment Tree View and click on ""Add participant"" 5. Add couple of students(say student1 and student2) to the assignment 6. Impersonate/login as student1 and make a submission 7. Impersonate/login as student2 and Request for a new review under others work, submit the review 8. Impersonate/login back as student1 and Request for a new meta review 9. When Begin is clicked following will be displayed. Instead of this, the meta review page must be displayed. <image> 10. A template must be added to fix the broken link. The number of meta-reviews(refer to the snapshot below),should decrease when a user requests a meta-review.Also, the button to request a new meta-review should not disappear until the total number of reviews assigned has reached the allowed limit. Log in as instructor6, click on mange...-> Assignments Click on edit assignment, navigate to Due Dates and check ""Use meta-review deadline"" checkbox Select ""Yes"" for all submission allowed, Review allowed and Meta-review allowed in all of the deadline types Navigate back to Assignment Tree View and click on ""Add participant"" Add couple of students(say student1 and student2) to the assignment Impersonate/login as student1 and make a submission Impersonate/login as student2 and Request for a new review under others work, submit the review Impersonate/login back as student1 and Request for a new meta review When Begin is clicked, the meta-review count should be decremented. Currently, as clicking the begin button is not working, we are not sure if the counter is being decremented properly. Design strategy For Issue1 and Issue 2 The flow chart below describes the design we choose to implement the above two issues <image> Solution and Code Modification for Issue 1 and 2 Modification 1 Basically, the file named 'response.html.erb'(Exact navigation: <link> ) is looking for a partial named 'review' The code that expects partial is: <code> We have created partial named _review.html.erb at <link> It is a simple partial with code as follows: <code> Modification 2 The response_controller.rb(controller that works in tandem with response.html.erb view, which was expecting partial) required a minute fix, which is, - The existing code doesn't work if AssignmentTeam is found to be nil. Please check the below existing code: <code> The response is created(by Response.create) only if the 'if' condition is satisfied. The AssignmentTeam.find(@map.reviewee_id) shall return a nil(for metareviews), hence AssignmentTeam.find(@map.reviewee_id).most_recent_submission will throw an exception. The problem is, assignment team will be nil for meta reviews. Hence, existing code won't work. To cover this special nil case, we have modified the code as: <code> Modification 3 There's this issue of user being able to request and review more than allowed 'x' number of reviews. After user performed max allowed 'x' number of reviews, the button 'Request a new metareview to perform' shouldn't be visible. To handle this, following code change is made in file ( <link> ) <code> The code in elsif block shows the button using which user can request more metareviews. By modifying the code as above, we shall not render the partial set_dynamic_metareview, which contains the request button. By changing the code to above, we were able to handle the exceptions. Both the Issues 1 and 2 are now solved. For the test setup we performed, following screenshot shows that we were able to do metareviews(Issue 1 done) and count of metareviews remaining is being reduced(Issue 2 done). <image> Issue3 - View/Hide meta-review fields based on enabled/disabled status Background: An instructor can edit an assignment and can choose whether to have metareview in it or not. He can do so by following the below steps: 1) From Manage>Assignments, click on the Edit Assignment button for the appropriate assignment. 2) On the Due Date tab, the instructor can select if (s)he wants to have meta-reviews done for the assignment, by clicking on the “Use meta-review deadline” checkbox and setting a meta-review deadline below. 3) Under the “Review Strategy” tab of edit assignment, the instructor can set Allowed and Required number of meta-reviews per reviewer by checking the Has meta-review Limit? checkbox. Issue Description For an assignment, when 'Use Metareview Deadline' is unchecked, it means meta-reviews are not enabled for that assignment. The checkbox is as below <image> As said, when this box is unchecked, it means there is no meta reviewing system for this assignment. The issue is, there are some meta review related fields that show up even if the above box is unchecked. Like in below image <image> Also, when a new issue is created, the default # of meta-reviews allowed and required should be null. As soon as someone checks the Has meta-review Limit box on the “Review Strategy” tab, the UI should fill in 3 and 3 as the required and allowed number. Of course, the user can change this number before submitting it. Solution and Code Modification for Issue 3 As the checkbox and the content to be displayed on clicking the checkbox are located on different pages we cannot use the regular checkbox logic, so we used the concept of local storage and event listener. we have made changes to the below two files: 1)/expertiza/app/views/assignments/edit/_due_dates.html.erb 2)/expertiza/app/views/assignments/edit/_review_strategy.html.erb In the _due_dates.html.erb file: There is an existing code where on clicking the checkbox 'Use metareview deadline', a function called 'removeOrAddMetareview()' is invoked. The code snippet below shows the existing code: <image> The 'removeOrAddMetareview()' is called on click of the 'Use metareview deadline' checkbox. Now we implemented two new functions which are invoked inside this function they are 'hideMetaReviewLimit()' and 'showMetaReviewLimit()'. This can be seen in the below code snippet <image> Now on clicking the 'Use metareview deadline' checkbox, the new code will invoke the 'removeOrAddMetareview()' function which indirectly invokes the two new functions. Now let us look at the implementation of the two new functions, we used a local storage variable called 'meta'.So based on the status of the checkbox a value is assigned to the local storage variable. For example, if the 'Use metareview deadline' checkbox is checked then the local storage variable is initialized with the value 'show' and if the 'Use metareview deadline' checkbox is Unchecked we assign with the value 'hide' to the local storage variable. Now after storing the respective values for the local storage variable, the storage event is triggered by these functions. The below code snippet shows the implementation of the two new functions: <image> In _review_strategy.html.erb file: Small modifications have been made to the existing code that is the display of the table row with id 'meta' is given 'none' by default and also the status of the 'Has Meta-review Limit?' checkbox is changed to false. The below code snippet shows the modifications made: <image> we wrote a javascript code that handles the event triggered when the 'Use metareview deadline' checkbox has been checked or unchecked. In this javascript, the event triggered is handled by calling the 'onStorageEvent(storageEvent)' function. In this 'onStorageEvent' function we check the value in the local storage variable and based on that value we change the status of the display for the table row with id 'meta'. <image> Finally, the null value to the 'Has Meta-review Limit?' can be assigned during the creation of the table and on clicking the 'Has Meta-review Limit?' checkbox the UI displays '3' in the allowed number of metareviews that is num_metareviews_allowed variable is assigned '3'. Test Plan 1. Ensure that when an assignment is created, the number of meta-reviews is set to null. 2. Ensure that the meta-review fields in the review strategy tab are visible only when 'Use metareview deadline' is enabled in the Due dates tab. The flow chart below describes the design we choose to implement the above two issues <image>. Basically, the file named 'response.html.erb'(Exact navigation: <link> ) is looking for a partial named 'review' The code that expects partial is: <code> We have created partial named _review.html.erb at <link> It is a simple partial with code as follows: <code>. The response_controller.rb(controller that works in tandem with response.html.erb view, which was expecting partial) required a minute fix, which is, - The existing code doesn't work if AssignmentTeam is found to be nil. Please check the below existing code: <code> The response is created(by Response.create) only if the 'if' condition is satisfied. The AssignmentTeam.find(@map.reviewee_id) shall return a nil(for metareviews), hence AssignmentTeam.find(@map.reviewee_id).most_recent_submission will throw an exception. The problem is, assignment team will be nil for meta reviews. Hence, existing code won't work. To cover this special nil case, we have modified the code as: <code>. There's this issue of user being able to request and review more than allowed 'x' number of reviews. After user performed max allowed 'x' number of reviews, the button 'Request a new metareview to perform' shouldn't be visible. To handle this, following code change is made in file ( <link> ) <code> The code in elsif block shows the button using which user can request more metareviews. By modifying the code as above, we shall not render the partial set_dynamic_metareview, which contains the request button. By changing the code to above, we were able to handle the exceptions. Both the Issues 1 and 2 are now solved. For the test setup we performed, following screenshot shows that we were able to do metareviews(Issue 1 done) and count of metareviews remaining is being reduced(Issue 2 done). <image>. An instructor can edit an assignment and can choose whether to have metareview in it or not. He can do so by following the below steps: 1) From Manage>Assignments, click on the Edit Assignment button for the appropriate assignment. 2) On the Due Date tab, the instructor can select if (s)he wants to have meta-reviews done for the assignment, by clicking on the “Use meta-review deadline” checkbox and setting a meta-review deadline below. 3) Under the “Review Strategy” tab of edit assignment, the instructor can set Allowed and Required number of meta-reviews per reviewer by checking the Has meta-review Limit? checkbox. For an assignment, when 'Use Metareview Deadline' is unchecked, it means meta-reviews are not enabled for that assignment. The checkbox is as below <image> As said, when this box is unchecked, it means there is no meta reviewing system for this assignment. The issue is, there are some meta review related fields that show up even if the above box is unchecked. Like in below image <image> Also, when a new issue is created, the default # of meta-reviews allowed and required should be null. As soon as someone checks the Has meta-review Limit box on the “Review Strategy” tab, the UI should fill in 3 and 3 as the required and allowed number. Of course, the user can change this number before submitting it. As the checkbox and the content to be displayed on clicking the checkbox are located on different pages we cannot use the regular checkbox logic, so we used the concept of local storage and event listener. we have made changes to the below two files: 1)/expertiza/app/views/assignments/edit/_due_dates.html.erb 2)/expertiza/app/views/assignments/edit/_review_strategy.html.erb In the _due_dates.html.erb file: There is an existing code where on clicking the checkbox 'Use metareview deadline', a function called 'removeOrAddMetareview()' is invoked. The code snippet below shows the existing code: <image> The 'removeOrAddMetareview()' is called on click of the 'Use metareview deadline' checkbox. Now we implemented two new functions which are invoked inside this function they are 'hideMetaReviewLimit()' and 'showMetaReviewLimit()'. This can be seen in the below code snippet <image> Now on clicking the 'Use metareview deadline' checkbox, the new code will invoke the 'removeOrAddMetareview()' function which indirectly invokes the two new functions. Now let us look at the implementation of the two new functions, we used a local storage variable called 'meta'.So based on the status of the checkbox a value is assigned to the local storage variable. For example, if the 'Use metareview deadline' checkbox is checked then the local storage variable is initialized with the value 'show' and if the 'Use metareview deadline' checkbox is Unchecked we assign with the value 'hide' to the local storage variable. Now after storing the respective values for the local storage variable, the storage event is triggered by these functions. The below code snippet shows the implementation of the two new functions: <image> In _review_strategy.html.erb file: Small modifications have been made to the existing code that is the display of the table row with id 'meta' is given 'none' by default and also the status of the 'Has Meta-review Limit?' checkbox is changed to false. The below code snippet shows the modifications made: <image> we wrote a javascript code that handles the event triggered when the 'Use metareview deadline' checkbox has been checked or unchecked. In this javascript, the event triggered is handled by calling the 'onStorageEvent(storageEvent)' function. In this 'onStorageEvent' function we check the value in the local storage variable and based on that value we change the status of the display for the table row with id 'meta'. <image> Finally, the null value to the 'Has Meta-review Limit?' can be assigned during the creation of the table and on clicking the 'Has Meta-review Limit?' checkbox the UI displays '3' in the allowed number of metareviews that is num_metareviews_allowed variable is assigned '3'. 1. Ensure that when an assignment is created, the number of meta-reviews is set to null. 2. Ensure that the meta-review fields in the review strategy tab are visible only when 'Use metareview deadline' is enabled in the Due dates tab.",Very good description of the issues and how you fixed them.  Test plan needs to be better documented.,"This is a thorough and clear analysis of the issues with Expertiza's meta-review feature. Your detailed exploration of the problems and potential solutions reflects a great level of understanding of the code and the application's workflows. 

However, in this assignment, you have some repetition in the explanation of the issue and the solution. For example, you've explained the issue that occurs when 'Use Metareview Deadline' is unchecked twice. It seems you're providing the scenario and then explaining the step-by-step process which leads to duplication. Try to avoid repetition for the sake of conciseness and better readability.

Also, you've mentioned various code modifications and solutions you've applied to fix the issues but the actual codes are not visible in the assignment, as it shows only ""<code>"" instead of the actual code. Make sure to properly include these in your submission, ensuring they are correctly formatted and easy to understand.

Regarding the test plan, while you've mentioned what you are testing for, there's no clear explanation of how you're conducting these tests or the results. Including explicit steps for the tests, including expected and actual output, would make this section much more effective.

Overall, your approach to solving the issues is commendable and reflects an excellent problem-solving capability. Great job on providing additional relevant suggestions to improve the system. Keep up the good work, but ensure to make your submission less repetitive and more cohesive next time!"
36,E2075,"Expertiza is an open source project based on Ruby on Rails framework, created and maintained by the joint efforts of students and faculty at North Carolina State University. It allows the instructors to create new assignments and customize new or existing assignments. Expertiza also allows an instructor to create a list of topics the students can sign up for. Students can form teams on the web application to work on various projects and assignments together. Additionally, students can peer review each other's submissions allowing them to improve upon their work. Expertiza supports submission across various document types, including the URLs and wiki pages. The Expertiza project allows ""calibration assignments"" to be performed where students are asked to review work that has also been reviewed by a member of the course staff. Calibration is the term used for rectifying, or checking or determining something. In the context of this project, a 'Calibrated review' is one which is performed by a student, so that (s)he can verify their work by comparing it with the instructor's response for the same assignment. If the student’s review “resembles” the staff-member’s review, then the student is presumed to be a competent reviewer. Since calibration reviews are meant as reference for better performance of peer reviews (which are performed later), they are not graded. Calibration submissions should be copied along with calibration assignments. On creating a copy of a previous assignment, say for example Design Exercise, Fall '20 for the Fall '21 semester - the calibration assignments associated with it are not copied over. The instructor is required to impersonate extra participants, and submit work on behalf of each of the extra participants. This is obviously extra trouble, and it would be a lot more convenient if an instructor didn’t have to resubmit the same calibration submissions over and over, every semester. The following steps were taken to test the aforementioned issues: Step 1: On copying the Design exercise assignment <image> Step 2: The original file contains the following calibration reviews <image> Step 3: However, the copy doesn't contain any of the calibrated reviews <image>. The project is implemented in Ruby on Rails that uses MVC architecture. We have three separate modules namely User Interface, Database Model and Control Flow (Model, View and Controller). We tend to reuse the already existing functionalities and data to our design. The calibration reviews that are present in the previous exercise will be copied into the newly created exercise which would prevent the instructor from performing additional tasks of performing reviews repeatedly. This would also prevent code duplication and additional memory usage. The following must be added to the current implementation: 1. Participants with 'View' and 'Edit' actions in the calibration tab are copied over to the new version, as they are considered calibration submissions 2. All hyperlinks and files associated with the above mentioned participants are copied over as well 3. Participants with the 'Begin' action are not copied over 4. A check is put in place to make sure that these steps are taken only for copying assignments with calibration reviews. This is signified by a calibration tab in the tool bar, on the edit page. <image>. <image>. 1. app/models/assignment_form.rb 2. app/views/assignments/edit/_calibration.html.erb 3. db/schema.rb. All changes mentioned below have been made in app/models/assignment_form.rb <image> <image> <image> <image> <image> <image> <image> <image>. 1. To check if the UI is working as expected [No broken links] 2. The submissions [Files and Hyperlinks] are copied when an assignment for calibration is copied. The following steps must be performed to test the project UI: Step 1: Log in as an Instructor, with Username - instructor6, Password - password <image> Step 2: Find an assignment with calibration submissions present, which is represented by a calibration tab on the editing page. In this case, the assignment chosen is called ""Design exercise"" <image> <image> Step 3: Copy the assignment, by selecting the icon shown below <image> Step 4: On inspection of the copied assignment, it is observed that the calibration assignments have been copied over. <image> Step 5: In the similar way, if the calibration tab has any files attached by the reviewers, then the files would get copied along with the participant details. Below is an assignment in which one participant has submitted a file named review1.txt in calibration. <image> Step 6: As the assignment has a file in calibration tab, even the copy of the assignment will have the same file with same content copied over to the calibration tab. Below is the copied assignment's calibration tab containing review1.txt created by the participant in original design exercise <image>. <link>. Below are the rspec testcases used to test the application. <image> <image> <image>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.","Code changes are merely pasted into the document without any description.  This doesn't add much value over looking at a diff in Github.  This also applies to the test cases.  OTOH, the discussion of manual testing has screenshots that clearly illustrate the process.","The assignment you submitted effectively describes Expertiza which is impressive! You provided a well-detailed explanation about calibrations, the purpose and importance of calibration assignments, and the challenges with the previous system of copying assignments. 

Your proposed solutions were reasonable, showing a deep understanding of the system and the Ruby on Rails framework. The implementation steps and testing procedures outlined were straightforward and helpful. I appreciate the use of images and links to aid understanding, although note they are not visible in this format.

I would recommend providing a brief overview of what Expertiza is at the beginning of your essay for readers unfamiliar with the tool. 

It is also unclear if the steps you took to rectify the issues are hypothetical or if you implemented these changes yourself. Clarifying this would improve your discussion.

Furthermore, adding a conclusion that recaps the work done, the value added and any further recommendations would solidify your report.

Your report shows that you've gained a practical understanding of how to optimize processes in application management, which is a valuable skill in the software industry. Good job and keep up the great work!"
37,E2020,"<link> is an open-source project that is built using the <link> framework. At its core, it is a highly versatile tool that academic institutions can use to craft learning objectives centered around team projects, peer reviews, and highly-customizable assignments. The purpose of this project is to allow instructors or teaching assistants who are participants of an assignment to be able to review (before the last due date of the specific assignment) any team that has submitted the assignment. Beyond this general endeavor, there is also the condition that team members of the assignment should be able to view reviews done by the course staff that can be identified in an aesthetically pleasing manner. As an added feature, reviewers should see how their reviews differ from those done by the course staff. There are two main issues: 1. Allow the instructor and teaching assistants to review teams that have submitted assignments. 2. Allow authors to visually identify reviews done by the course staff. 1. A star icon will be used to distinguish whether a review was done by a course staff and will appear below the 'Review #' heading. 2. Add helper class grades_helper.rb to handle check to determine whether review was done by course staff based on the boolean flag attached to a response. 3. Change will be made in view_team.html.erb such that after verifying that a response was done by a course staff via identity_helper.rb, a star is displayed below the 'Review #' heading. Note: Previously, a review that was done by a course staff would not be visually recognizable by an author of the particular reviewed assignment. With the following changes, however, authors will be able to recognize reviews done under the ""Summary Report for assignment"" page, as reviews done by course staff will have a black star located immediately below the ""Review #"" header. A boolean check is done in the review_done_by_course_staff? method and used in view_team.html.erb to display a black star below a particular review if and only if review_done_by_course_staff? outputs true. Changed files: app/helpers/grades_helper.rb <code> app/views/grades/view_team.html.erb <code> Pull request can be found <link> 1. A staff user (Instructor, TA, Admin) will see the star for reviews done by another staff member as well as the names of all the reviewers. <image> 1. A student will still see the star for reviews done by a staff member but all names are anonymous. <image>. 1. app/controllers/assignments_controller.rb 2. app/controllers/response_controller.rb 3. app/controllers/review_mapping_controller.rb 4. app/helpers/grades_helper.rb 5. app/views/assignments/list_submissions.html.erb 6. app/views/grades/view_team.html.erb 7. app/views/response/response.html.erb 8. config/routes.rb. This flow chart demonstrates the desired functionality. While students must submit reviews in the review stage, instructors/TA's can submit reviews any time before the final deadline. In order to submit reviews, the instructor/TA must be added as a participant to the assignment. Then, they will go to ""View Submissions"" on the Manage Assignments page. If the final deadline for the assignment has passed, they will see an ""Assign Grade"" link next to each submission. Otherwise, they will see a ""Perform Review"" link if a review has not been submitted yet or an ""Edit Review"" link if a review has been submitted already. Students can view only the reviews they have performed and the reviews of their work, while instructors/TA's can see all reviews for the assignment. Reviews done by course staff will be marked with a star to distinguish them from students' reviews. <image>. This diagram represents the relationship between different models involved with our proposed solution. We do not anticipate any changes to the database schema. A model that's central to our proposed solution is the AssignmentQuestionnaire model defined in assignment_questionnaire.rb. It holds the user ID of the User (user.rb) who reviewed the assignment, from which we will determine the user's role: Instructor, TA, or student. It also contains the ID of the Assignment (assignment.rb) being reviewed. Additionally, the Questionnaire (questionnaire.rb) can be located by its ID defined in AssignmentQuestionnaire and consists of the Questions (question.rb) users use to review the assignment. <image>. Testing from the UI Manual UI verification of our added features can be found in the <link> in the Resources section. More details on the UI testing can be found in the sections below. Automated Testing with RSpec Comprehensive RSpec tests were added for all controller and model classes that we changed as well as automated UI tests for features we added. Test cases include: 1. Verify that instructors can be added as participants for assignments. 2. Verify that assignment reviews can be submitted by users with an Instructor, TA, or Student role assigned. 3. Verify if a instructor is not a participant, an ""Assign Grade"" is visible. 4. Verify if an assignment's deadline is passed and the instructor is a participant, an ""Assign Grade"" is visible. 5. Verify if an assignment's deadline is not passed and the instructor is a participant, a ""Perform Review"" link is visible. 6. Verify if a review has already been submitted by an instructor, a new ReviewResponseMap will not be created for the instructor when they load the list_submissions view. 7. Verify a star icon appears next to only reviews done by instructors/TAs in the responses view. This should be visible to both staff and students. All modified RSpec test files: 1. spec/controllers/assignments_controller_spec.rb 2. spec/controllers/review_mapping_controller_spec.rb 3. spec/features/assignment_list_submissions_spec.rb 4. spec/helpers/grades_helper_spec.rb. UI Testing 1. Login as an instructor 1.1. Username: instructor6 1.2. Password: password 2. As this test is an extension of the one conducted in Part 1, impersonate the student who the instructor performed a review for. Go to Manage -> Impersonate User and enter the student's user name. 3. Now impersonated as the chosen student, go to Assignments -> Project_Name -> Your Scores. 4. You should now be in the ""Summary Report for assignment"" page. Below whichever review that the instructor submitted, there will be a black star. <image> RSpec Testing Note: Additional tests were created for methods in the same grades_helper helper class that were not written by this team in order to abide by the philosophy that you should always leave code in a better position that they were originally. spec/helpers/grades_helper_spec.rb <code> <code> <code> <code> <code>. Coverage increased (+11.01%) to 41.493%. Forked Repo: <link> Expertiza Pull Request: <link> Demo Video: <link>.","In showing your code, it would be much more helpful if you show the changes you made and describe them.  In some cases you do, but for ""View changes"" and ""Changed files:"" below that, you just show the code.","Dear Student,

Thank you for your submission. I can see a lot of effort and thought has gone into this assignment. Let me share some aspects that caught my attention:

1. Explanation and Problem Solution: You went into detail explaining the problem and providing a solution including changes in code, which is commendable. The use of helper classes to handle specific tasks shows a good grasp of code modularity and object-oriented programming principles.

2. Visual Element: The use of images and flowcharts to support your text are very helpful and contribute towards visual understanding.

3. Testing: Your assignment covers and documents extensive tests, both manual and automated using RSpec, which inspires confidence in the functionality and reliability of your solution.

4. Documentation: Your documentation is thorough and comprehensive.

A few things that could be improved upon:

1. Organization : Some sections are a bit verbose. A more organized and precise approach would improve the presentation quality of your assignment. 

2. Markdown Use: Usage of markdown formatting will greatly enhance the readability of your submission.

3. Code Structure: Although your code seems to work, I noticed a few areas where best practices can be followed for better code structure, readability and maintenance. Inline comments explaining code blocks can be very helpful for others reading your work.

Overall, this is a great effort. You have shown your ability to understand a complex problem and your ability to deliver a thoughtful solution. Well done! Keep up the good work!

Best, 
[Your Name]"
38,E1848.2,"Assignment_team.rb in Expertiza provides a method for student to assign a team and finish one assignment. Features come at the cost of complexity; this project is focused on creating the test methods to ensure that user interaction with the assignment interface remains stable and reliable. 1. The forked git repository for this project can be found <link> 2. The pull request link can be found <link>. We use 'let' to define a memoized helper method. The value will be cached across multiple calls in the same example but not across examples. <code>. There are some examples for how this project create test methods for assignment_team.rb. The assignment_team.rb offers a method that could save files in one directory <code> Based on the above code, the test case can be created: <code>. The assignment_team.rb offers a method that could export the fields <code> Based on the above code, the test case can be created: <code>. Our test cases has coverage: 100% There are in total 127 relevant lines, and all of them get passed. The testing framework in the assignment_team_spec.rb used unit tests to test the functionality of each action in the class. The mock instances are created at the beginning of the file, so that during each test they don't need to be constructed again. In order to test each unit case without depending on other functionalities, the mocked actions, as well as the desired returns are built inside different test cases, depending on the need of the case. In building the test framework, the key is to understand the input, output and the desired action of each function that we want to test. The Rspec test format also has a steep learning curve, but the test shows stable and robust result on the assignment_team.rb.","The beginning of this document is quite readable.  The description of the ""Help Method"" should be expanded to explain why these objects are being created.  Later on, the prose description of test cases could be expanded to explain how the tests are being carried out.  It seems like the team may have run out of time, after starting very strong.","Your project on creating test methods for assignment_team.rb in Expertiza seems to be well-conducted. Good job on achieving 100% test case coverage and managing to pass all lines, this shows great thoroughness in your testing approach. 

The inclusion of explaining nuances such as the use of 'let' to define a memoized helper method shows you have a good understanding of your testing tools, and the point about understanding the input, output and desired action of each function is a crucial understanding to have in testing.

However, in your write-up, you could provide a bit more detail on what these methods in assignment_team.rb actually do separately. In addition, while you mention creating test cases based on the code provided, you didn't actually provide the code, just <code>. Including the actual code or detailed descriptions of the tests would give a better understanding of how your testing caters to these methods. 

The mention of Rspec's steep learning curve implies you have overcome a challenge in using it, which is commendable. But it would be more enlightening if you could offer one or two examples illustrating how you have conquered this learning curve. 

Overall, your submission reflects a good understanding of unit testing and successful application of the same. More explicit detailed instances from the assignments would add more insight into your working process.
"
39,E1791,"The expertiza project takes advantage of peer-review among students to allow them to learn from each other. To track the review time that each student spend on each submitted resources is meaningful to instructors to study and improve the teach experience. However, the time tracking of specific content on these resources is not perfect in the expertiza system. The previous team working on E1705 project has solved part of such problems by tracking the active time of windows opened from the submitted links. But for the submitted files which could be downloaded for local review, there is only a rough approximation solution yet. In this project, our team is going to solve this problem as well as improving previous time tracking methods using mature third-party APIs to record link review time more accurately. To accomplish this goal, here are the general solutions we designed and implemented in this project: 1. Designed a database schema for logging the time a reviewer spend on a submission; 2. Designed and implemented dynamic partial components using Javascript and Ruby to open students’ submissions in new windows to view online; 3. Used DOM to control the windows holding review submission files or links, and record the open and close time; 4. Modify Review report (views/review_mapping/_review_report.html.erb) to show the total and detailed time spent on each review submissions with visualization. Our team is going to solve the submission review time tracking by attempting to open the downloaded files inside popup windows of the web browser in order to record the time on the client side. For most of our tasks, there are two types of submitted files. 1. One kind is online links, such as github repo or pull request link, youtube video link, expertiza wiki page link, etc 2. The other one includes files such as pdf, txt, doc, images, etc and other download contents. (instructor can include more document types in /views/submitted_content/_submitted_files.html.erb). Strategy In this project, for each review page, we need to deal with different type of links. For online links, such as github repo, youtube link, etc, we use javascript to open a new window detect time when the window is closed. For submitted files, such as txt, jpg, we will open it with views/response/_submitted_files.html.erb. For other files that need to be download and open locally, we can only make approximation for review time. For this project, we need to design a database table to store all the time that we need to record for each review submission event. We would like to name the table as submission_viewing_events . For the table, we would use map_id in table response, which uses response_map_id as the primary information. Then we need to record reviewer_id and reviewee_id , source_link for submitted links or file names, as well as time start_at and end_at , then store them in the table. <image>. For each review, when the reviewer click on one link of the submitted files, we create an entry to the table review_time, we will write a function to record current time to the database. For how to determine time when the reviewer complete with the opened link, there are different cases. If the reviewer click on save or submit button, close the page, or logout, we need to write to all open entry (without end_at) respect to this review and save current time to end_at. But for how to decide when the review close the opened link is a little complicated. For github and youtube links and txt, pdf, doc, image files, we will open submitted files in views/response/_submitted_files.html.erb so that when the user click on the link, it opens a popup window that shows the submission, record time when it opens and closes. This is done by controlling DOM using jQuery javascript library, and then send back the time records through Ajax. For the other files that need to be downloaded, we can only make an approximation by record the time when the reviewer click on the link until the time he/she enter the reviews. For each task, reviewer might open each link several times, might also save the review process and restart it some times later, so we will have multiple records for each link. Every time the student click on the link, a new record is created and then the time in all records will be summed up to total time for every link and displayed on instructor page. <image>. After we record start_at and end_at time for each piece of review, we need to display time that each reviewer spent on each link. Because the reviewer may save the review and start again in the future, so for each link there might be several entries, we need to sum them together. We modifed code in review_mapping/_review_report.html.erb first to modify the view. This framework follows well the ""open to extension and close to modification"" principle, which makes further changes more feasible by adding additional view components without affecting current functions. <image>. 1. When user click on save or submit the review without closing opened windows, the system will search all records of response time for the reviewer and reviewee where end time is NULL, and update it with current time. 2. If the reviewer opens the reference links or download files, but leave them open and turn to focus other unrelated stuff, the review page will send a popup alert dialog to confirm if the review is still in review mode. If not, it will close these windows and save the time as approximation of end time. Otherwise, it will continue the review process. <image> 3. In some cases, reviewer might shut down the computer, close the browser, log out without saving, etc., we set up periodically saving reviewing events automatically such that we will lose as less information as possible. Currently the period is 30 seconds and this can be changed. For the cases described, shut down computer etc., there will be records written in data base with end time NULL, next time when the reviewer restart the review, the system will just drop all the records with NULL end time and start a new query. Also if reviewer does not interact with the review page for a long time, it will pause the timer and commit all existing related time record in database. The time limit is now 2 minutes. Both the period and non-interaction time can be adjusted by instructors in code file /views/response/response.html.erb. We will test the following cases during our development 1. When we work the review, if we click on GitHub link, GitHub pull request link, check whether the system record review time correctly. 2. When we work the review, if we click on doc, pdf, image link, check whether system open submitted files in views/response/_submitted_files.html.erb and recore the review time correctly. 3. Check if the reviewer save the process and start again with click on same clink, check whether the system will record all the entry, and on the view page take all entries for one link into account. Test of new model and function will be written and tested during project development: 1. Test the success of a review time record given valid start and end time; describe ResponseTimesController do <code> 1. Test whether the start time is updated to the end time last saved in the database when the user resumes a review; <code> 1. Test whether the end time is updated as the current time when the review is saved to the database. <code>. submission_viewing_events.rb submission_viewing_events_controller.rb responses_controller.rb helper/review_mapping_helper.rb helpers/submitted_content_helper.rb response/response.html.erb review_mapping/_review_report.html.erb review_mapping/_review_submissions_time_spent.html.erb view/popup/reviewer_details_popup.html.erb view/submitted_content/_hyperlink.html.erb view/submitted_content/_submitted_files.html.erb db/migrate/20171117190721_create_response_times.rb config/routes.rb. In this project, we accomplished the requirement defined in the project instructions. However, due to the complexity of the Expertiza system and limited time period, there are still several points to improve in the future: 1. Improve the accuracy of review time record. To record the exact time that the user spends on each link or file, it is more accurate to track the active time of each new window or tab of these links or online files. We attempted this design using 'window.focus()', but it does not work once the user moved away from the review page and turned to other applications. So either tweaking the web setting or using browser APIs may solve this problem. 2. Notify the user when no response on the review page. Occasionally the user may open the review page to do the review, but is interrupted to focus on other applications. In this case, we stopped the time recording but try to alert the user that if he wants to continue the review. However, this notice cannot show in time if the user is not focusing on that review page. So a global alert is necessary to save the time and provide notice on time. 1. <link> 2. <link>.","A number of reviewers commented on weaknesses in the test plan, but it appears that has been addressed,  Generally a good description of work to be done.","Overall, it is great to see the thoughtful detail and attention you have put into this assignment. You've obviously taken the time to understand the project requirements and applied creative problem-solving skills to developing your solutions. You have made a clear focus on the user needs within the Expertiza system, and the breakdown of your strategic plan was easy to understand and well articulated.

In terms of critique, considering the complexity and length of the project you're describing, it might be beneficial if you could organize your information into sections or headings. This can help guide the reader through the context, the problems faced, your strategy, and your hoped-for results. 

Secondly, your project will be adding various features or enhancements to the system, so you might want to explain how these will improve the system and why they are beneficial. You have already touched on some of this, but there's room to make the positive impacts you're hoping to bring about clearer.

Thirdly, code snippets or references to code would have provided better insights about your technical approach and might have offered a clearer picture of how you envisaged the system functioning after you've made the proposed changes.

Lastly, in your conclusion, you nicely captured points of future improvement. However, you can go one step further in suggesting what kind of strategies could be used to tackle those problems.

Overall, well done on displaying solid technical understanding and ability to reflect on your solution and its future prospects. Great work!
"
40,E2102,"In order for students to write effective reviews, they need to understand the work that they are reviewing. Expertiza can allow authors to create a quiz over their work. If an assignment is set up to use quizzes, then a reviewer must take the quiz over the author’s work before reviewing it. Then, based on how the reviewer scores on that quiz, Expertiza can weight that author’s scores accordingly in calculating a peer grade. Thus, reviewers who understand the author’s work better have more say in determining the author’s (peer) grade. quiz_questionnaires_controller , naturally, is the controller that administers a quiz. A quiz_questionnaire is a kind (subclass) of questionnaire in Expertiza. A questionnaire consists of a number of questions (or “items”) that the reviewer needs to answer. This questionnaire contains many violations of good programming practices. E2102 deals with refactoring the code inside quiz_questionnaires_controller.rb so that it is clear and conforms to DRY principles. Note: The majority of the issues listed in the previous section were solved simply by adding descriptive comments/messages or improving existing ones to clarify behavior, so those will not be shown in this section. Prior to changes, the code in the action_allowed? method had some repeated code. <code> This can be solved by using the authorization helper methods described in <link> . <code>. Some logic inside the new function of the controller is technically correct... <code> ...but can be improved by making better use of Ruby keywords. <code>. Within the save_choices function of the controller, there is an if-statement that determines what function to use when saving a question of a certain type, which can be either true/false or multiple choice. <code> We can make this more readable by substituting this structure with a function call to a newly defined factory method called question_factory ... <code> ...which contains the refactored if-else structure and saves questions of the appropriate type. <code> Code improvements can be viewed in much more detail in the E2102 pull request <link> . Coverage testing was disabled on our PR like many others so the most recent coverage is not available. However, the only change we had to make to a rspec file in our project was for the issue of *Line 31: Change message to, “This assignment is not configured to use quizzes.” . You can see in our file changes we simply fixed the expectations of the test case and the build passed for our controller file. Note: Our project is a refactoring of existing controller code. It cleaned up the controller and therefore does not really have anything to test besides if the app is still working. Steps: 1) Visit our hosted website (until the end of April 2021) at <link> 2) Login with the username instructor6 and password password 3) Click assignments at the top (to the right of ""Courses"" under ""Manage Content"") 4) For ""773HimesMakthalTest"" click the edit pencil icon <image> 5) Note that Has Quiz? is enabled and it has due dates and is assigned to student7366 6) At the top, go to Manage > Impersonate User > student7366 7) Under assignments, click the 773HimesMakthalTest assignment 8) Click ""Your work"" > Click ""Create a quiz"" if no quiz has been made yet 9) You can fill in the new quiz or edit an existing one. Also you can view the quiz. <image> Again, this all worked before we made any changes. Our project was just refactoring.","Very good point-by-point description of what was done.  Good to link to project board (but all issues have been resolved) and repo to view changes.  In Section 5, section headers are two-line sentences; a pithier heading should have been added.","Dear Student,

Thank you for your submission of Assignment E2102. You have done a great job in identifying issues with the `quiz_questionnaires_controller.rb` file and proposing refactoring techniques. I appreciate your effort to demonstrate clarity in your concepts regarding DRY principles, and explain how the code can be refactored efficiently.

Clearly, you have put much consideration in giving detailed explanations along with the processes that you undertook for refactoring. I encourage you to continue this in future assignments, as it helps in understanding your approach in solving the problem.

I find your suggestion on enhancing code legibility by ensuring suitable use of Ruby keywords – and substituting control structures with factory methods – quite interesting. Also, your focus on informing the readers about each of the steps associated with your hosted website and how to utilize it was noteworthy.

However, I observed that the assignment was more focused on the refactoring aspect of the project and improvements that were made. So, in the future, it will be beneficial to also illustrate in detail any related impacts on the functionality and performance considering these changes. This would provide a more holistic view of the updates you implemented.

Lastly, you could improve the presentation of your work by explicitly mentioning the original issues in addition to the comments/messages. Although adding comments is an effective method to clarify behavior, stating the issues directly tends to make your arguments more compelling and help draw a line between the initial problem and the provided solution.

You are on the right track, and your commitment to bring improvements in the project is praiseworthy. Keep up the good work!

Best,
[Your Name]"
41,E2072,"For users intending to view the deployed Expertiza associated with this assignment, the credentials are below: 1. Instructor login: username -> instructor6, password -> password 2. Student login: username -> student4340, password -> password 3. Student login: username -> student4405, password -> password <link>. Expertiza is an educational web application created and maintained by the joint efforts of the students and the faculty at NCSU and supported by MIT and the National Science Foundation. It’s an open source project developed on Ruby on Rails platform and it’s code is available on Github. It allows students to review each other’s work and improve their work upon this feedback. The following is an Expertiza based OSS project which deals primarily with the AssignmentParticipant model and Review Mapping helper. It focuses on refactoring unkept, unused and misleading methods within the aforementioned files. The project’s goal is to enhance some of the methods in use and clean up others that were either outdated or in need of improvement. Some other parts of the application were modified as well to work with our changes in the Assignment Participant model. Our project focused primarily on refactoring the assignment_partipant.rb Model file. The files modified for this project are: 1. assignment_participant.rb 2. review_mapping_helper.rb 3. assignment_participant_spec.rb 4. publishing_controller.rb 5. user.rb 6. quiz_assignment.rb 7. response.rb 8. response_spec.rb. This is a controller that helps students and instructors view grades and reviews, update scores, check for grading conflicts and calculate penalties. A couple of long and complex methods were refactored from this controller along with removal of some non-functional code and a few language changes to make it Ruby style. Three methods in particular, namely conflict_notification ,calculate_all_penalties and edit were found to be too long and were in need of refactoring into smaller, easier to manage methods. Few more compact methods were created for this purpose. There were no existing test cases for the controller. We have added a spec file named 'grades_spec.rb' under the spec folder. As no changes were done for the model, no tests for the model were included. This is a helper class that contained methods to help calculate and display information regarding participant reviews and the volume of each review. One non-functional method was removed from the file and two other methods were updated to support sorting the volume of an arbitrary number of review rounds. We worked on the following work items(WIs) WI1: Refactor self.grant_publishing_rights to assign_copyright WI2: Determine whether reviews_by_reviewer method is still needed. WI3: Refactor copy method name WI4: Refactor assign_quiz WI5: Refactor Review Score WI6: Rewrite Score calculation within the scores method WI7: Refactor Volume - # Distinct Words in a Review WI8: Provide documentation for Compute_Assignment_Score. Refactoring Review Volume This involved three methods in review_mapping_helper.rb, sort_reviewer_by_review_volume_desc, initialize_chart_elements and display_volume_metric. The first two methods worked together to sort the reviews by the average volume of reviews in each round of an assignment and then move the data of reviews in each round from a current round to prepare to display the information in chart form. The last method was found to not be used within the entirety of the project. The following changes were made: 1. The methods were originally implemented in a way that only allowed for the information from three rounds of an assignment to be gathered. The functions had to be re-implemented using a loop that could gather and initialize the data from any given number of rounds. 2. The display_volume_metric was no longer being used within the rest of the project and so was removed to clean up the file. sort_review_by_review_volume_desc loop re-implementation: <image> Initialize_chart_elements loop re-implementation: <image> <image> Display_volume_metric removal: <image> Rewrite Scores Method The scores method returns the scores that a specific assignment_participant has received Originally, the scores method contained several convoluted method calls with some unused and commented out code. Our team was tasked with rewriting the scores method in assignment_participant.rb to make it more readable and transparent. The following changes were made to accomplish this task: 1. Removed topic_total_scores (score calculations for a microtask) and moved it into the scores method, since this method was only called once and wasn't used anywhere else. I also removed the associated tests. <image> 2. Removed calculate_scores method and refactored the code into the scores method, since this method was only called once and wasn't used anywhere else. I also removed the associated tests. <image> 3. Refactored the merge_scores method which is called by Scores. 1. DRYed out the code by adding a new update_min_or_max method that dynamically sets the min or max <image> 1. Refactored merge_scores to use update_min_or_max method. <image> 1. Added 6 RSPEC tests for this new update_min_or_max method 4. Added comments for the scores method and merge_scores method <Image Here> Refactor assign_quiz Method The assign_quiz method was originally located in the assignment_participant.rb file and was requested to be moved into quiz_questionnaire.rb. However, upon further investigation, it was discovered that there existed two assign_quiz_dynamically methods, one which called the aforementioned assign_quiz method. Our investigation concluded that a newly constructed assign_quiz_dynamically method, located in review_mapping_controller.rb, had become the primary method of performing the tasks associated with assign_quiz and assign_quiz dynamically. Hence, following the consultation of our mentor, we elected to remove the definition and all instances of assign_quiz (assignment_participant.rb) and assign_quiz_dynamically (quiz_assignment.rb). The following changes were made: 1. Removed definition of assign_quiz method (assignment_participant.rb) <image> 2, Removed all unused instances assign_quiz_dynamically (defined in quiz_assignment.rb) 1. Alternative assign_quiz_dynamically method located in review_mapping_controller.rb became the primary method used in recent years <image> 3. Ensured all instances of assign_quiz_dynamically (review_mapping_controller.rb) were untouched and operational as expected 1. This definition does not implement assign_quiz method from assignment_participant 4. Removed #assign_quiz spec test from assignment_participant_spec.rb (see ""Testing Details"") Investigate reviews_by_reviewer Method The reviews_by_reviewer method returns the reviews of a certain assignment_participant. However, for the past 5 years or so all reviews have been of assignment_teams, not assignment_participant. Our team was tasked with investigating the reviews_by_reviewer method in assignment_participant.rb to determine whether it is still used, or would be useful to continue maintaining. The following determinations were made: 1. Determined that all reviews are of assignment_teams and not of assignment_participant 2. The only calls to reviews_by_reviewer method happen in CollusionCycle. 3. After verifying with Yang and Dr. Gehringer, we determined that Collusion Cycle is no longer used in the application. CollusionCycle was originally a piece of code that helped detect whether bias existed when teammates gave reviews of other teammates' work. 4. Because CollusionCycle is unused, we deemed it appropriate to make the following changes: 1. Removed the method definition from assignment_participant.rb <image> 1. Removed the rspec test for this method <image> Refactor copy Method Name The copy method was determined to have a misleading name for a method that copies a participant to a course. As a result, the copy method name was refactored into 'copy_participant'. The resulting changes were made to correspond to the name change: 1. Refactored copy method in assignment_participant.rb into 'copy_participant' <image> 2. Refactored all instances of copy_participant associated with a assignment_participant 1. Spec test in assignment_participant_spec.rb was only instance found (see ""Testing Details"") Refactor self.grant_publishing_rights to assign_copyright Aside from simply refactoring the name of self.grant_publishing_rights into assign_copyright, upon further investigation, we noted that the definition of the method in assignment_participant.rb, did not require the participant parameter and participant loop, but was simplified by moving this functionality to wherever the method is called in the application. The following changes were made: 1. Refactored self.grant_publishing_rights into 'assign_copyright' 1. Refactored definition of the method in assignment_participant.rb, removing the participant parameter and participant loop; moving this functionality to wherever the method is called in the application <image> 2. Altered functionality of the method call in def generate_keys (user.rb) to handle the 'participants.each do' loop <image> 3. Altered functionality of the method call in grant_with_private_key (publishing_controller.rb) to handle the 'participants.each do' loop <image> 4. Built spec test for modified assign_copyright method in assignment_participant_spec.rb (see ""Testing Details"") <code> Refactor review_score method The review_score method returns the review score for a particular questionnaire. The issue originally stated that the method should be able to determine the review score for any round of review. The original method returned the first round (index position 0) review score. We made the following determinations: 1. The review_score method only returns the first round review score which is from index position 0: <image> 2. We determined that review_score method is only being called in collusion_cycle.rb, which is no longer used in the Expertiza application. 3. We determined there was a reference to a “review_score” model in question.rb but there is no model that this refers to: <image> Changes Made: 1. Since review_score was only being called in collusion_cycle.rb, and collusion_cycle.rb is no longer used in the application, we deemed it correct to remove the review_score method from assignment_participant.rb: <image> 2. Removed the reference to “review_score” model which appeared to be made in error since there is no review_score model. This change was made in question.rb file. <image>. Response.rb Additionally, in making some of the changes to the way expertiza calculates volumetric scores, we noticed incompatibilities because the methods in assignment_participant.rb call other methods to retrieve score information and calculations, which were hard coded for a maximum of three rounds of review. We identified two methods in response.rb which dealt with the comments for different rounds of reviews, but would only calculate up to three rounds. These two methods were *self.concatenate_all_review_comments* and *self.get_volume_of_review_comments*. Although these methods are in response.rb which is not the primary focus of our project, our mentor instructed us to change the related methods to be able to run their calculations for any number of rounds of reviews. The original methods (before our changes) were as follows: <image> As you can see, self.get_volume_of_review_comments relies and directly calls self.concantenate_all_review_comments. Thus, we needed to rewrite both of these methods to use the same convention as in sort_review_by_review_volume_desc where the calculations should be for any number of rounds, not just three. We rewrote these two methods as follows to work with any number of rounds of reviews and comments. <image> In the rewritten code displayed above, our team has changed both methods to function to concatenate all review comments and then get the average word volume for each of those review comments for any number of rounds. This makes the code far more functional and universal to our changes elsewhere in the application. We also made changes to the RSpec tests for these methods, which will be discussed in the Rspec Testing Section below. For testing our changes, we focused on updating and designing new automated RSpec tests for every method. We also made sure to design a UI test to display that more than three rounds of reviews can be displayed on a page. See the <link> section. For RSpec testing, we focused on designing an extensive suite of rspec tests for the assignment_participant model that we primarily dealt with. However, whenever we made any sort of change, we immediately went and updated/created the test cases regarding our changes. All RSPEC test changes are listed below in the <link> section. Refactor assign_quiz Method Removed assign_quiz spec test from assignment_participant_spec.rb to correlate with the deletion of the assign_quiz method itself. <image> Refactor copy Method Name Refactored copy to copy_participant in all spec test instances (assignment_participant_spec.rb). <image> Refactor self.grant_publishing_rights to assign_copyright Following refactor, a new spec test needed to be built for the modified assign_copyright method in assignment_participant_spec.rb. 1. Creates new RSA key-pair for a participant 2. Assigns the public key of this key-pair to the user.public_key attribute. 3. Tests if key matches using assign_copyright <image> In this test, we created a new RSA key pair in order to effectively test the functionality of the assign_copyright method. We then call the assign_copyright and pass the private key to this method. In order to test whether the function succeeded, we test to make sure that the permission_granted field is set to true for this participant. Rewrite Scores Method As described in the previous section, during the rewrite of the scores method our team cleaned up the merge scores method as well, by creating a new update_max_or_min method and abstracting/DRYing out the code. We wanted to make sure to thoroughly test this new method by adding the following rspec tests: 1. Removed topic_total_scores tests 2. Removed calculate_scores tests <image> We verified that the current scores tests were testing the functionality well and no changes were made to these tests. 3. We added 6 new tests to the rspec file to test the new methods for update_max_or_min. As displayed below, we test updating the min, and the max, under three different conditions. <image> Reviews_by_reviewer Method Since we decided to remove this method because it is unused in the application (besides Collusion_cycle.rb), we removed the associated rspec tests as well: <image> Review Score We also removed the Rspec tests for review_score method which we removed as stated in the previous section. <image> Collusion Cycle As discussed in previous section, we also removed some failing tests in collusion_cycle_spec.rb, as per request from Dr. Gehringer, which began failing after we removed methods Collusion Cycle called from assignment_participant.rb. These test removals are displayed below: <image> <image> <image> <image> <image> Response As discussed in a previous section, the response.rb file had to be edited so that the methods in this file are able to perform the comment volumetric calculations for any given number of rounds. Because of the changes discussed in the previous section, we had to update the corresponding Rspec tests to work with the new return format. <image>. Following steps needs to be performed to test the volume refactoring in the UI: 1. Login as instructor and enter anonymized view using the manage tag. 2. Go to the manage tab and enter the assignments page <image> 3. Choose any of the listed assignments, under the action section, click “view reports” <image> <code> 4. Select the view button <image> 5. You should see the volume of reviews by round for each reviewer. <image>. 1. We found that scores are calculated in many different places and in many different ways throughout the code. An interesting future project would be to identify where these different calculations are made, and refactor so they are all made in one place for the same type of scores. This will make the code more universal and easier to follow and understand. 2. Currently, if there are no reviews for an assignment you are thrown an error when trying to review the report. We did not fix this, due to it being out of scope of our project, but this error could be caught and the user could be redirected which would make the project work much better.","The URL does not contain the name of the project as required.  I didn't want to copy the whole page, but I did add the project title to the first line of the page.  The description of changes made is quite readable, but you simply boldfaced the names of the changes.  If you had made them section headers in Mediawiki markdown, they would have appeared in the table of contents, making it much easier to see at a glance what had been done.  Unlike the description of the refactorings, the description of the tests is not as detailed.  More prose describing how they would would have been helpful.","Dear Student,

Thank you for your well-detailed project work on Expertiza. You have shown a significant amount of dedication and attention to detail. Your communication of the process used in tackling this project was articulate and informative. The detailed summary of what each method does, the changes made and the reasons for these changes were explained very clearly. The logical structure of the report made your work easy to follow.

Furthermore, the fact that you not only looked for problems but also came up with specific solutions is commendable. The difficulties you noticed with the scores being calculated in multiple places and the error thrown up when there are no reviews for an assignment have been noted. Your suggestions on how to rectify these issues show initiative and an ability to think critically.

You have demonstrated an excellent understanding of software testing by designing extensive RSpec tests and ensuring every significant change made to the codebase had a corresponding test. This kind of thoroughness is a critical part of building reliable and robust software.

Your understanding of the Ruby on Rails platform as exhibited by your thorough code walkthrough is clear and commendable. Your ability to find unused methods, refactor long code blocks into more manageable chunks and simplify complicated processes shows solid critical thinking skills and a deep understanding of efficient code management.

I also appreciate that you took the time to include steps that other developers can follow to test your work on the User Interface. This will undoubtedly enable your peers to easily understand your work.

In future, consider including comments in your code snippets directly, or have inline notes in your report to indicate which parts of the code have been modified and why. 

Overall, your analysis was superbly done and very thorough. You approached this project with an impressive level of dedication and detail that demonstrates strong software engineering skills.

Keep up the outstanding work!

Best,
[Your Name]"
42,E1796,"Expertiza is an open source project based on Ruby on Rails framework. It is a web application where students can submit and peer-review learning objects (articles, code, web sites, etc). It is used in select courses at NC State and by professors at several other colleges and universities. It also supports team projects, and the submission of almost any document type, including URLs and wiki pages. Expertiza enables the instructor to create new and customize existing assignments. It also enables the instructor to create a list of topics the students can sign up for as part of a project. Students can form teams in Expertiza to work on various projects and assignments. Expertiza supports submission across various document types, including the URLs and wiki pages. In the Expertiza portal presently when an instructor wants to create a new assignment then as he selects a new assignment option only a few metrics are asked for while for mentioning the other metrics the professor needs to edit assignment and then under that he is shown the options to edit all the other metrics. Also, when we press the save button while creating or editing an assignment it goes to HTML form request, instead it should be changed to AJAX request so that the page does not need to get refreshed every time user saves the changes. Few other minor issues are validating the user entries and fixing tooltips so that they are supported across all the browsers.( Chrome, Safari, Firefox etc.). Issue1: Here we will be unifying the edit assignment view and new assignment view and for that we had to understand how the page requests are being sent on the background on the edit assignment page and accordingly change and implement the changes on the new assignment view. In edit assignment when we switch between the tabs a update request with all the parameters are sent on the background but the user doesn't know that. So incase of new assignment page we have to avoid doing that since we wont be having an assignment id yet to update the values. Issue2: For validating user entries we had to check what all are the entries which are not being validated before saving and then accordingly update the models of the respective fields with regular expressions according to the field limitations and restrictions. Issue 3: We need to create a ajax request instead of a form HTML submission request which is being sent when we save changes on edit assignment page and making sure prompt messages are not affected since ajax handling will again need the prompt messages to be shown since the user needs to know whether it is being saved or not. Issue 4: For this we decided to check the functionalities of tool tips across all the browsers and see whether hovering over the tooltips display the message which is intended to so that the user understand what the tooltip will do upon clicking. Specific Improvements to assignment creation by navigating the user for creating a new assignment to edit assignment page(view/assignment/edit_assignment). Making sure the edit assignment has blank fields in case of new assignment and saved fields in case of editing. When an Instructor creates a new assignment, he should be able to see a table to set DueDates, Review Strategy options and Rubrics associated with the assignments. These options are currently available to the instructor while editing an assignment. We will be adding options to be set during creation of new assignment. Fields to add suggested topics will be excluded for new assignment creation. Validating the user entries which is submission directory. It states that it is mandatory field and there should be no spaces but does it actually validate. Fixes to tooltips so that it is supported across all the browsers Change the save button to AJAX request instead of HTML form submission so that the page doesn’t need to get refreshed every time the user save the changes. <image>. This page is displayed in the present system when a professor wants to create a new assignment as we can see there are only very few metrics on this page which are being displayed. <image> While under Edit assignment the professor can now mention all the various metrics regarding the assignment on this page. <image> In the present implementation of the project, under the edit assignment page, even if we change the tab or click a tab a save request is sent in the background and the metrics are being saved. So, in this case when we have to save a view for a assignment page, we cannot actually do that because on every tab or every change of tab it needs an assignment id. But in case of new assignment page, we do not have an assignment id yet and we did not create the assignment. New assignment creation form will render forms to set Due Dates, Review Strategy and Rubrics as a table. Currently application ID is required to edit these options for an application. We will modify application/views and application controller to support adding these options while creation without application ID without breaking existing edit functionality. In the present implementation the save button is handled by JQuery but only until a point where necessary attribute checks are done. Now, we need to prevent the page from reloading which can be done by mentioning a remote value as true in the form tag for the edit assignment page. In the improved view of New Assignment instructor will be able to specify details under four tabs as shown in the below screenshots <image> In the General tab the instructor is now able to see all the options from the old view. <image> In the improved view, in addition to supporting the General tab, now there are new tabs like ""Rubrics"". This tab allows the instructor to select the various rubrics for the new assignment. This page also allows the setting of different rubrics for each round of the assignment. <image> In the improved view, there will be an additional new tab titled ""Review Strategy"". This tab allows the instructor to set the various policies for review of the new assignment. This page also allows assigning manual review strategies. <image> The new view also renders tab a titled ""Due Dates"" where the instructor can select the deadlines for various rounds of the selected rubrics. This tab also allows the instructor to select the late penalty policy The instructor can also choose to make a new late policy instead of selecting an existing policy created by the same instructor. In the assignments_controller.rb controller, under the function create, we created a condition or blocking it from saving and then updating all the tabs with the assignment id it needs. <code> In the general.html.erb for ajax view if there is an error or if the saved changes are updated then it shows a flash message. <code> <code> In the edit.html.erb following code changes were made. Setting the remote to true ensures that the following is an ajax request and not and html request. <code> The following code was added in the assignment.rb for validation of our page. The below implementation ensures that there are no special characters in the submission directory field, course_id is unique and name is always present. <code> In general.html.erb for ajax view, the following code is rendered for displaying the flash messages. <code> <code>. The Tooltips functionalities are throughly checked in various browsers and the following screenshots show that they are supported across various browsers. The images show in Firefox and Internet Explorer browsers. <image> <image>. view/assignment/edit/.* views/assignment/new.html.erb views/assignment/* controller/assignment_controller.rb assignment_creation_spec.rb assignments_controller_spec.rb. 1.MVC – The project is implemented in Ruby on Rails that uses MVC architecture. It separates an application’s data model, user interface, and control logic into three distinct components (model, view and controller, respectively). 2.Dry Principle – We are trying to reuse the existing functionalities in Expertiza, thus avoiding code duplication. Whenever possible, code modification based on the existing classes, controllers, or tables will be done instead of creating the new one. Manual and automated testing to be done for below cases. As an Instructor, clicking on Manage->Assignments should display all created assignments with correct directory, creation date, updation date, instructor id, and actions. As an Instructor, clicking on Manage->Assignments->actions of an assignment should successfully redirect to action page. As an Instructor, clicking on Manage->Assignments->new public assignment,will redirected to ""Create New Public Assignment"" Page. As an Instructor, clicking on Manage->Assignments->new private assignment,will redirected to ""Create New Private Assignment"" Page. As an Instructor, clicking on Manage->Assignments->new public/private assignment, ""Create New Public/Private Assignment"" should render a table with tabs ""General"", ""Rubrics, ""Review Strategy"", ""Due Dates"". As an Instructor, clicking on ""Rubrics"" tab from ""Create New Public/Private Assignment"" page, the tab should display table to select Questionnaire, menu type, display style, weight and notification limit. As an Instructor, select review type, author feedback type, and Teammate review option from the drop down from ""Rubrics"" tab. As an Instructor, select Review Strategy from drop down on ""Rubrics"" tab from ""Create New Public/Private Assignment"". As an Instructor, set number of reviews done by each student on ""Review Strategy"" tab from ""Create New Public/Private Assignment"". As an Instructor, Set minimum number of reviews done for each submission on ""Review Strategy"" tab from ""Create New Public/Private Assignment"". As an Instructor, Set both calibrated and uncalibrated artifacts on ""Review Strategy"" tab. As an Instructor, select Anonymous Review option on ""Review Strategy"" tab. As an Instructor, select allow self review on ""Review Strategy"" tab. As an Instructor, set due dates on ""Due Date"" tab from ""Create New Public/Private Assignment"". As an Instructor, set number of submissions allowed on ""Due Date"" tab from ""Create New Public/Private Assignment"". As an Instructor, set number of reviews allowed on ""Due Date"" tab from ""Create New Public/Private Assignment"". As an Instructor, set number of teammate review allowed on ""Due Date"" tab from ""Create New Public/Private Assignment"". As an Instructor, after updating the fields on all tabs and clicking on save should create an assignment form in database. As an Instructor, after saving the new assignment, redirect to edit page to update Signup topics. As an instructor, save should not reload the page while creating a new assignment. Test when instructor creates a empty template for assignment form. Test when name of the assignment is not unique. Test when late policy is not created for instructor, and instructor tries to create a new assignment. All Users should be able to see tooltip of respective actions on all Browsers. As an instructor, delete an assignment. Form submission validates the attributes of all associated models. Below are some of the test cases added <code> <code> <code> <code> <code> <code> Test cases which were modified <code> <code> <code>. 1. <link> 2. <link> 3. <link> 4. <link>.","When you say ""metrics"", you mean ""settings"",  The prose is rather difficult to read, perhaps because it does not provide enough context.  The ""code changes"" section should be matched up with the rationale for the changes, perhaps by linking back to previous sections.  This should be a single narrative, rather than a set of independent descriptions of changes, so everything should be linked together in the prose.","Your assignment essay reflects a deep understanding of the system you were tasked to examine. The meticulous description of issues and clear proposal of solutions suggests good command of analytical and problem-solving skills. Your attention to detail, especially in creating user journey tests, is commendable. Your ability to anticipate potential problems is demonstrated in your creation of both manual and automated tests, and your adherence to best practices, such as the MVC architecture and DRY principle, is noteworthy.    

There, however, are a few opportunities for improvement. Here are a few points to consider: 

1. Some long sentences make comprehension slightly challenging, and thoughts could have been better expressed if broken into shorter sentences.

2. The structure of the content could be improved to enhance readability. Using headings and subheadings, bullets, and numbering to organize ideas and steps may make a big difference.

3. Be sure to differentiate each issue clearly. Some of the items seem to overlap, which might cause some confusion. 

4. You didn't mention any challenges encountered, this would help to outline the complexity and give an idea of the obstacles you faced during your project.

5. It would be great to see some more reflection on your own contributions and what you've learned. 

6. The code within the essay could have been organized better or explained more clearly. Besides, anonymized hyperlinks would have made the essay more professional and readable. 

Please revise the essay considering these suggestions. Keep up the good work!"
43,E1769,"Expertiza is a web application where students can submit and peer-review learning objects (articles, codes, websites, etc). Instructors add and edit assignments to Expertiza. Students can be assigned in teams based on their selection of the topics. The task of the project is to refactor assignment_form.rb and write unit tests for it. assignment_form.rb is a fairly complex file. It contains a lot of methods that are long and hard to understand. These methods need to be broken down into simpler and more specific methods that are easier to read/understand. Also, the few instances of code duplication that exist should be removed. 1. Refactor `add_to_delayed_queue` method 2. Rename method `is_calibrated` to `calibrated?` and all other places it is used 3. Use `find_by` instead of `where.first` 4. Complete pending tests in sign_up_sheet_controller.rb. 1. Refactor the assignment.rb 2. Refactor the assignment_form.rb 3. Complete relating tests in assignment_form_rspec.rb and assignment.rb 4. Complete tests in sign_up_sheet_controller_rspec.rb. `add_to_delayed_queue` is a long method with some duplicate codes and hard to understand. In order to encourage code reuse and make it easier to understand semantics of the function, we split it into three methods, name the added two as `get_diff_from_now` and `add_delayed_job`. The changes are displayed below, Original Code: <code> Modified Code: <code> <code> <code>. In Ruby, the common naming pattern for a method which return a boolean value is an adjective followed by '?', so the method name 'is_calibrated?' is bad and a preferable one should be directly 'calibrated?'. We refactorer this method by using 'Refactor' operation in RubyMine. We renamed it to 'calibrated?' and RubyMine found all place it appeared then changed them. Before: <code> After: <code>. If we use 'where' and then use 'first' method to return the first record matches the condition, the application will find all eligable records and return the first one. However, 'find_by' method will return a record once it find one and then terminate itself. Therefore, conpared with 'where.first' method, 'find_by' is much more efficient. That's why we use 'find_by' instead of 'where.first'. Before: <code> After: <code>. We write rspec test for relating methods in assignment_form_spec.rb. We test `add_to_delayed_queue` method <code> <code> Next we test `change_item_type` method <code> We also add test for `calibrated?` methods. <code> <code> We also completed remaining tests in `sign_up_sheet_controller_spec.rb`. There are a lot of methods in `sign_up_sheet_controller.rb`, and it can be executed by 'rspec spec/controllers/sign_up_sheet_controllers_spec.rb' <code>. Youtube: <link>.","The motivation for the refactorings is described well.  There is a good beginning at describing the refactorings themselves, but I think it would have been helpful to describe the changes in more detail.  The tests, on the other hand, are not described in prose.  The reader is asked to read the code, which is harder to do.","Dear Student,

Thank you for your submission on the assignment of refactoring assignment_form.rb and writing unit tests for it. It's clear from your work that you have understood the concepts deeply and applied them effectively.

The effort you've made in simplifying the methods of the `add_to_delayed_queue` is commendable. You've successfully broken it down into two functions `get_diff_from_now` and `add_delayed_job` which has significantly improved the readability and manageability of the code. 

I also appreciate how you scrutinized the naming conventions in Ruby, and correctly renamed `is_calibrated?` to `calibrated?`. This maintains the idiomatic Ruby principles and enhances the readability.

Your execution of using `find_by` instead of `where.first` was marvelously done, making the program more efficient without causing any loss in functionality.

It's delightful to see that you've not only polished the code but ensured its functionality through comprehensive testing in assignment_form_spec.rb and sign_up_sheet_controllers_spec.rb. The kind of extensive tests you wrote for `add_to_delayed_queue` and `change_item_type` methods assure that the refactored code is still working as expected. 

There's one small detail that needs to be improved though. As your submission includes code snippets but doesn't provide a context. Please keep in mind that it is important for your assignments to be self-contained and understandable. Thus, including some context before each code snippet could make your submission more polished.

Lastly, remember to provide the video link in 'Youtube: <link>' to facilitate easing understanding of your work.

Your work reflects your dedication and understanding of the subject matter. It's an impressive blend of refactoring, efficiency improvements, and unit testing. Keep it up!

Best,
[Your Name]"
44,E2105,"When testing our deployed app, use the login credentials below: <code> Then follow along with the methods outlined in the testing section to help you get started!. Currently in Expertiza, students complete peer review questionnaires during the many rounds of an assignment. This is a great way to gather information about submissions and complete lots of testing while also exposing the reviewing student to practices and skills used in industry. The instructor can view these reviews on the ""Review Reports"" screen. This can be found by getting the ""Management"" dropdown -> Assignments to list all assignments for that instructor. On the far right of each of these rows, one will see multiple buttons for possible actions, select ""Review Report"" <image> . Once the page has loaded, clicking the ""View"" button while ""Review Reports"" is selected in the dropdown will open the reports. A list of students who have completed reviews, the teams they reviewed, the amount of written text they submitted in comments, as well as other metrics will be displayed. The issue with this system is that there is no metric currently for how long a user spends on reviews. Because this project involves logging data real-time, the interactions with the database also need to be minimal. This project was created to give the instructors more information about how students complete reviews, specifically the time they spend on a review. This will give the instructor insight into each review and allow them to improve the teaching experience when it comes to peer reviews. This ""review time"" metric should be broken down by each link in a submission. The previous project teams and their Pull Requests and Wikis are listed here <table>. With the general functionality outline by previous groups, our team was asked to: 1. Design a database schema for logging time a reviewer spends on a submission 2. Modify the Review Report to show the time spent on each submission 3. Add tests for the code written. Overall, our implementation works using a proxy pattern for data storage and the façade pattern to get the requested data and statistics. When the reviewer navigates to a page from the expertiza review page a submission_viewing_event is created for that url and a start time is saved. Once the reviewer closes this page an end time is saved in that same submission_viewing_event, a total time is calculated and this is saved to local storage using pstore. As the reviewer navigates to different links from the review page, submission_viewing_events are created for each link accessed and these accumulate a total time spent with the link open. This is done using polling for all external links. Once the reviewer saves or submits their review, these events are saved to the database from local storage, and deleted from local storage. This minimizes the amount of times the application is interacting with the actual database. If the user is returning to finish a saved review, these rows are pulled from the database, added to as stated above, and saved to local storage again until saved or submitted. When the instructor goes to view the ""Review Report"", each row from that students review is pulled for display as seen here: <image> The pop-up shows: 1. Percentage of total review for each link in a pie chart 2. The time the reviewer spent on each link 3. The total time spent on the review 4. The average times spent on each link for this submission by all reviewers 5. The average time spent reviewing this submission by all reviewers 6. Class statistics including: 1.1. Average review time for all submissions 1.2. Median review time 1.3. Standard deviation for review times. *Links provided as scale of development is very large. Our Pull Request can be found <link>. Along with the tasks above, upon reviewing existing code and discussing with our mentor we realized there was more to be done. A refactor of the previous teams code was needed as well as proper comments to document how this feature functioned. This extended the scope of our project significantly. Our list of tasks included: 1. Review and understand previous teams code 2. Refactor and comment usable code from previous groups (Added after reviewing previous code) 3. Create new UI for viewing data 4. Improve current database schema to hold the total time spent on a review 5. Add tests. Upon reviewing all the previous groups code, it seemed that E2080 (our previous group) had the best starting point for our project having improved their previous groups code. They had a way of tracking the time spent on a review, storing it in a local file, saving this file to the database, and displaying the data. We did however find the code was hard to follow and needed to be refactored if we were to have this feature merged with the main Expertiza repository. Pulling E2080s code as a base, we refactored this code to have comments, proper formatting, and move most functionality out of client side javascript to the rails controller. 1. Most of the client side javascript is now located in <link> and <link> 2. Functionality like calculating time between entries is now done in <link> using functions from <link> to assist with any math. As we moved a lot of the functionality from the previous groups UI to the controller and helper functions, we then wanted to improve the UI to still function correctly but also easily display the given information and be easily edited for future use. We did this using simple javascript calls in <link> to get the relevant information using the controller and moved much of the formatting to <link> . This new UI is displayed above in the Overview and Pattern section. The schema as it stands only recorded start time and end time for accessing a link. This becomes a problem as users creating reviews normally access a link multiple times. To allow for this, we added a new column to the submission_viewing_events table allowing for total_time to be calculated as the user moves between links. New Submission_Viewing_Event Database Schema: <image>. When conducting live testing, you need to create a new review so the system can gather the timing data. (This is why most reviews show 0 as they were made before our implementation). NOTE: This is our process. We have listed it here as getting to this feature and functionality can be confusing without knowledge of the Expertiza site. This is a guideline to help our peers. Please feel free to test the functionality beyond this. To do this, here is our method: 1. As instructor6, find assignment ""Final project (and design doc)"". This is a previously created assignment that functions correctly. 2. Add a new participant to the assignment using the options to the right of the row. (We found student2150 and up to be easiest) 3. Impersonate the added student. ""Management"" dropdown -> impersonate user 4. You should now see a pending review for ""Final project (and design doc)"". Select this to get to the review page. 5. Select the available submission and begin the review 6. Now you should be taken tot he questionnaire for that assignment. Conduct the review however you like. Your activity will be timed. 1.1. Note: You must open the teams submitted links and files from the review page for it to be timed 1.2. Note: If you have a link open, you will not be able to open it again 7. Once complete, submit the review 8. You can now ""Revert"" back to your instructor account using the button in the Expertiza site heading 9. Navigate to the ""Review Report"" page as outlined in the Background section of this site 10. Find the student account you used and there will be an R1 or R2 next to your review. Click on these to see the breakdown of your review times for that respective round. Edge cases that we tested using the UI include: 1. Not opening a few or all of the links submitted 1.1. This will result in those links not being displayed in final breakdown 2. User closes browser mid-review 1.1. pstore contains data 3. User spends 0 seconds on a review 1.1. Displayed as ""No Data"" on report page. Our automated testing spans our controller and our helper functions. Rspec file: <link> <code>. Rspec file: <link> <code>. Rspec file: <link> <code>. Due to the size of our feature, our PR contains many additions. We have limited these to new files as much as possible in order to maintain the current Expertiza files and avoid unnecessary conflicts. Added Files or Changes: 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. <link> 8. <link> 9. <link> 10. <link> 11. <link> 12. <link> Refactored Changes: 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. <link> 8. <link> 9. <link> 10. <link> 11. <link> Untouched Changes by Previous Teams: 1. <link> 2. <link> 3. <link> 4. <link>.","This page is very good, except that it does not show any of the changes to the code or explain them.  The high-level description is good, but the reader should be provided some insight into how the code was changed.","Dear student,

I appreciate your detailed work and intense effort invested in this project. The new feature of tracking the time spent by students on peer reviews is a valuable addition and you've presented it comprehensively. 

The following are some suggestions and commendations for your work:

1. **Structure of your report**: Your report is extensive and packed with lots of detail - this is great. However, consider using headings, subheadings and bullet points to organize and present the information for better readability. Consolidate related information under appropriate sections. 

2. **Explaining usability**: The manner in which you explained how to test the system you've developed is admirable. It will help the instructors and fellow students understand the system's capabilities efficiently.

3. **Consideration for edge cases**: Your consideration of potential edge cases is commendable. It demonstrates careful thought and precision, and that you're ready to handle unexpected situations which showcases your analytical skills.

4. **Code refactoring and commenting**: Excellent work on the refactoring and commenting of the previous group's code. This will make the code healthier and more understandable for future developers. 

5. **Test Cases and Results**: Although you've mentioned the testing processes you used, including the results and specific examples of test cases would further strengthen your report. It would help track the performance and reliability of the system.

6. **Improvement of UI**: Great job on improving the UI while retaining its functionality. It is important to ensure that information is easily accessible and visually pleasing to users.

7. **Database Schema is explained well**: The modification of the schema and reasons for the same, like accounting for multiple accesses of a link, is explained properly.

Remember, the user experience is pivotal in software development. Therefore, continue working on the UI to make it more intuitive and user-friendly. I'm particularly impressed by the pedagogical aspect of this project, allowing professors to better understand how students are engaging with peers' work. Keep up the excellent work and continue bringing innovative ideas to life. 

Kind Regards,
[Your Name]"
45,E1401,"Assignments in Expertiza have many components--due dates and topics, for example. Due dates and topics are objects in their own right (DueDate, SignupTopic); we need a way to have sets of due dates and topics associated with an assignment. There are also separate forms to create and edit an Assignment and its components (Topics, Due Dates), these forms should be unified into one form for every component of an Assignment. Also, it'd be nice if we could sort assignment due dates in order of next due. 1. Remove the separate New and Edit forms for assignment 2. Create a form object to encapsulate the creation and editing of Assignments, Due Dates, and Topics 3. Add the ability to sort Due Dates. 1. controllers/assignments_controller.rb 2. controllers/due_date_controller.rb 3. controllers/sign_up_sheet_controller.rb 4. models/due_date.rb 5. models/sign_up_topic.rb. 1. All CUD (Create, Update, Delete) operations on Assignments, Due Dates, and Topics should be performed through an AssignmentFormObject 2. Assignment, Due Date, and Topic views and controllers should be subsumed into a combined AssignmentFormObject view and controller. As a bit of background, form objects<ref> <link> </ref> could be thought of as a fake model that is not itself persisted but persists all its component models. The name comes from the idea that in many cases forms require information for several models at a time, rather than just one. Creating a series of forms to work with each model at a time is tedious and frustrating, both for the coder and for the end user. A form object fixes this problem by acting like a model. It can have validations, persistence strategies, and a save method that returns the object if and when it is saved, just like a model. Behind the scenes it is intelligently manipulating other models to provide this functionality transparently, encapsulating the required logic. Our design uses one form object, AssignmentFormObject, to store data about the base Assignment model, Due Date, and Topic models associated to that Assignment. In this way we can achieve both objectives, utilizing the form object to create, update, and delete Assignments and associated Due Date and Topics without having to have separate controllers and views for each. The form object inherits from ActiveRecord (though is not a subclass of) in order to be able to mass-assign attributes and create custom validations and Virtus<ref> <link> </ref> to handle attributes like a normal model. We need these custom validations because the attributes of the form object include arrays of attributes for models, something the default validations cannot handle on their own. In addition, we need to run validations on the parameters passed in for each of the models contained within the form object, again something that the default validations cannot do. The logic behind persisting a form object is somewhat more complicated than a normal model (in which you very rarely have to override the default save operation). This is because form objects must persist several models at once, as shown below. <code> The form object starts a transaction (in order to guarantee that either everything or nothing is saved) then attempts to create (or update) the Assignment. If this succeeds, it moves on to the components of the Assignment, doing the same. If any one of these operations fails (for instance, if a topic is not able to be saved), the entire operation is rolled back, removing all of the partially saved changes and reverting to before the form object attempted to persist. In this way we make sure that the save operation is atomic like a normal model's save operation. Because the form object can be treated like a model, writing a controller to populate views with it is just as easy as with a normal model, as shown. <code>. Basically, we have added the ability to add most of the same attributes to a new assignment as when editing an existing assignment. Previously, you could only provide an assignment name, then you had to add due dates, etc. There are still some limitations to this process due to the complicated relationships between models. To view the changes, navigate to ""~/assignments/new"". The addition of Rubrics and Review Strategies is currently not implemented for new assignments, and this should be addressed in future works. In addition, you may only add one topic to a new assignment, then you must add more topics at the edit page. The addition of due dates uses a partial view that is in need of refactoring. In addition some validation is necessary for date times. For submission due dates and review due dates, please provide a date time. Changed existent classes 1. controllers/assignments_controller.rb 2. models/due_date.rb 3. views/assignments/new.html.erb 4. views/assignments/edit.html.erb 5. views/assignments/edit/_add_signup_topics.html.erb 6. views/assignments/edit/_due_dates.html.erb 7. views/assignments/edit/_general.html.erb 8. views/assignments/edit/_rubrics.html.erb Added classes 1. models/AssignmentFormObject.rb 2. controllers/assignment_form_object_controller.rb 3. helpers/assignment_form_object_helper.rb 4. views/assignment_form_object/new.erb 5. views/assignments/new/_add_signup_topics.html.erb 6. views/assignments/new/_due_dates.html.erb 7. views/assignments/new/_general.html.erb 8. views/assignments/new/_late_policy.html.erb 9. views/assignments/new/_review_strategy.html.erb 10. views/assignments/new/_rubrics.html.erb. In order to run the project locally (for feature testing or for running unit tests) please follow these steps: 1. Clone the GitHub repository ( <link> ) 2. Run ""bundle install"" 3. Run ""rake db:create:all"" 4. If you have a database dump, run it. For this project, we used the one located here: <link> ""mysql -u root pg_development < expertiza-scrubbed.sql"" Note that this may not be the name of the zipped dump, but you can customize to your needs. You may also need to specify your mysql password using ""mysql -u root -p ..."" depending on your mysql setup. 5. Run ""exec rake db:migrate"" 6. Run the rails server using ""rails server -p 3000"". You may substitute 3000 with a port number of your choice. For this project, we used RSpec for unit tests. These are located at spec/models/assignment_form_object_spec.rb. The tests are primarily unit tests for the model, and it required a lot of testing of other models that were not well tested (or tested at all) elsewhere. As with every project there are always more things to be done. With the use of a form object there are side benefits that we can take advantage of with more effort that we just didn't have time for. There are also some problematic areas we uncovered during the project that could use cleaning up. The following additional steps (or features) should be taken (or implemented) by anyone continuing with the project. Struck out lines indicate features that have already been added in continuing work. 1. Ability to add multiple sign up topics from a new form 2. Ability to add rubric details from a new form 3. Redo the due dates partial to be more readable and use rails conventions rather than JavaScript 4. Redo the due dates partial in general, it is very messy and difficult to work with 5. Relocate JavaScript scripts to another.js resource file rather than in-line in the html 6. Eliminate the need to have multiple calls to the same controller methods for every table entry for due dates on the edit pages. <references/>.","Very intuitive description of what was done.  Howeer, they don't indicate what changes were made to existing code, and don't show what functionality ended up in which classes.","Hello,

Thank you for your detailed assignment submission. It is evident that you've put a significant amount of effort into understanding and implementing the assignment's requirements. Here are some observations:

1. I appreciate the attention to detail and thoughtful analysis that you've displayed in your assignment. I can gather a deep understanding of the problem you're tasked with solving. This is a great step in developing a robust system.

2. You clearly laid out the changes to existing controllers, models, and views in your report, and the additional ones you have created.

3. Your understanding of a form object's operation and how they facilitate data encapsulation is well articulated. Your explanation demonstrates a good understanding of the form objects and their role in the Rails ecosystem.

4. It's clear you've understood the importance of keeping the operation atomic by using transactions. This ensures the integrity of data which is a key aspect in database systems.

5. You've created and mentioned all the necessary tests, which is good to see. Testing is an integral part of software development. In future, it would be beneficial if you could also indicate key areas where additional testing may be needed.

6. The section mentioning the future steps to be taken is a good example of forward thinking. It's always good to review your own work, and suggest improvements based on the limitations you found during the development process.

Areas you could improve upon:

1. Please ensure to remove all placeholders, such as ""<link>"", ""<ref>"", and ""<code>"" before submitting.

2. For more complex projects like this one, consider creating a flowchart or conceptual diagram. It provides a very clear visual aid to anyone reading your work or waiting to work on future extensions on the project.

3. In the section explaining the form object's operation, your explanation is good but it could be more concise and organized. 

Overall, great job, and I look forward to seeing more of your work!"
46,E1928,"Expertiza is a web application through which students can submit and peer-review learning objects (articles, code, web sites, etc). The Expertiza project is supported by the National Science Foundation. It is used in select courses at NC State and by professors at several other colleges and universities. A similar review bidding feature was implemented in the previous semester, by making use of the Top Trading Cycles (TTC) algorithm. Link: <link> However, there were a few issues with that implementation, notably: 1. The lack of color-coding feature. Solution: We implmented the color coding feature in our bidding list and the selection list. Following is the screenshot for that implementation. 1. Ordering was done by team IDs, which is not a reasonable ordering. 2. The content of some newly-added file are very similar with existing ones. 3. The UI could have been cleaner. Solution: Some of their existing code was not DRY and they had some smelly code in their implementation. We have tried to remove most of these inconsistencies in the code. 1. There is only one list while topic bidding interface has two lists, one for the the available list of topics and the other list for topics that are selected for the bidding. Solution: We have implemented the two lists as seen below: <code> <image> <image> 1. There was no ""add link to submission"" in the bidding list. Solution: After much deliberation, this feature is not required. 1. This implementation altered too many lines of existing Expertiza code. Solution: The project required us to implement review_bids and student_review models, controllers and view for student_review. We also applied migrations to the existing database to incorporate this functionality. 1. Many irrelevant tests were included. Solution: We have not included any of the team's irrelevant tests. While we would not be writing this implementation from scratch, we would instead be using their <link> and remove the possible defects that they had. Students currently are able to ""bid"" for topics that they want to do as an assignment. We plan to implement the same bidding feature for reviewing others' work, which is currently assigned on a ""first-come-first-serve"" basis. The current first-come-first-serve approach to assigning reviews to students is not efficient since sometimes the same project is requested to be reviewed by multiple students, while other projects are not in demand. By letting the students bid on topics they're interested in, the reviews are assigned more efficiently based on user interest. In this project we will make use of the Top Trading Cycles algorithm on Expertiza, to implement the review-bidding feature. Before talking about the functionality of review mapping, it's necessary to describe some of the related models and controllers in Expertiza and how they are organized to fully implement the functionality. It should be noted here that this is an implementation of the bidding feature for assignment topics. <image> 1. When an assignment is released, an instance of Assignment is created and corresponding topic instances of SignUpTopics are also imported, indicating that different topics are available for students to choose from within this assignment. 2. Students are assigned as instances of AssignmentParticipant to this assignment and form up their teams (Model Team). 3. Each team registers for several topics and becomes a candidate instance of SignUpTeam. After topics bidding, some of the candidate teams become an official signed-up team of a particular topic. 4. After assignment submission, participants choose their preferred topics and response mappings between assignment (reviewed object), assignment team (reviewee) and assignment participant (reviewer) are created. 5. After the mapping, participants can submit their response and the afterwards is out of discussion range of this document. <image>. Currently, Expertiza employs FIFO strategy on review assignment. In the ReviewMappingController, the method ""add_reviewer"" is invoked when students try to request a peer review. When it's done, a new mapping is created, that is why review assignment is in FIFO style. To understand the basic workflow of bidding on topics, we can look at the LotteryController: Firstly, teams have different preferences towards available topics. For example, let's say there are three topics within an assignment, namely A, B and C and there are 4 teams W, X, Y, Z. Let's assume each teams preferred order of topics is as follows: W: B, A, C | X: B, C | Y: C, A, B | Z: A, B, C This data structure is passed to the back-end service <link> by method ""run_intelligent_assignment"" of LotteryController. The peerlogic service runs top_trading_cycles algorithm to let the teams have a fair bidding over the topics. Now, consider a similar bidding approach to peer review assignment. Why is it workable? The following diagram illustrates the similarity of the two bidding model. <image> As for topics bidding, a few available slots of a particular topic are open for teams contending. In the left part of the diagram, there are 4 slots so only 4 teams can successfully contend for it. Slot is described as ""max_choosers"" of a sign_up topic in Expertiza. Consequently, there will be 4 different responses after the submission, and this time it is the participants that contend for the responses. Some discrepancies need additional attention. 1. Slots can be left unoccupied if no team is willing to respond. However, every response needs to have at least some reviewers. 2. The size of bidding data is different, since the number of teams are usually 1/2, 1/3 or 1/4 of the participants. 3. The policy of bidding may be slightly different. Participants are not allowed to review a response submitted by themselves. However, the topic bidding doesn't have this constraint. In the paper School Choice: A Mechanism Design Approach, author Atila Abdulkadiroglu, and Tayfun Sonmez have described Top Trading Cycles Mechanism. The intuition of the mechanism is students who have the highest priorities are allowed to trade the schools. Students who are assigned to schools are removed and other students who have the highest priority will compete for schools. The mechanism is as follows: Step1: Each school has a counter (No. of seats/ capacity). Each student has a priority list. Each school points to the student who has the highest priority to the school. A cycle is formed which is an ordered list (s1, i1, s2, ...., sk,ik). Every student in the cycle points to the school he/she is admitted and removed from the list. The counter of school is reduced by one and when it becomes zero it is removed from the list. Step k: Remaining students point to their favorite school among the remaining schools and each remaining school points to the student with the highest priority among the remaining students. There is at least one student. Every student in the cycle points to the school he/she is admitted and removed from the list. The counter of school is reduced by one and when it becomes zero it is removed from the list. The algorithm terminates when all students are assigned a seat. 1. Top Trading Cycles algorithm: <link>. As part of this assignment, we have to analyse the implementation of the stable marriage problem which is a stable sorting algorithm. The following summary of how the algorithm works, is taken from the ""College Admissions and the Stability of Marriage (1962)"" by D. Gale and L. S. Shapley. A certain community consists of n men and n women. Each person ranks those of the opposite sex in accordance with his or her preferences for a marriage partner. We seek a satisfactory way of marrying off all members of the community. Imitating our earlier deﬁnition, we call a set of marriages unstable (and here the suitability of the term is quite clear) if under it there are a man and a woman who are not married to each other but prefer each other to their actual mates. Deﬁnition: An assignment of couples will be called unstable if there are two men α and β who are married to women A and B, respectively, although β prefers A to B and A prefers β to α. So, we can ask the question: For any pattern of preferences is it possible to ﬁnd a stable set of marriages? Before giving the answer let us look at some examples. Example 1. The following is the “ranking matrix” of three men, α, β, and γ , and three women, A, B, and C. <table> The ﬁrst number of each pair in the matrix gives the ranking of women by the men, the second number is the ranking of the men by the women. Thus, α ranks A ﬁrst, B second, C third, while A ranks β ﬁrst, γ second, and α third, etc. There are six possible sets of marriages; of these, three are stable. One of these is realized by giving each man his ﬁrst choice, thus α marries A, β marries B, and γ marries C. Note that although each woman gets her last choice, the arrangement is nevertheless stable. Alternatively one may let the women have their ﬁrst choices and marry α to C, β to A, and γ to B. The third stable arrangement is to give everyone his or her second choice and have α marry B, β marry C, and γ marry A. The reader will easily verify that all other arrangements are unstable. Based on this approach, in the existing implementation of Expertiza, we have match_new_teams_to_topics method in the lottery_controller that performs this stable sorting algorithm for teams that have bid for an assignment. Our objective would be to implement a similar strategy, but we would use students instead of teams since there are no ""team reviews"". Every student selects their own assignment to review. Almost all of the functionality for our project has already been implemented in the review portion of the Expertiza system - where the teams are allowed to bid on topics they want to work for their project. We plan to reuse the code to keep the implementation DRY but we need to add some additional features to make it work for the review bidding functionality. Delegation is a way to make composition as powerful for reuse as inheritance. The Delegation pattern will help us reduce the coupling of methods to their original class as we have components that seem to behave identically, but we realize that this situation can change in the future. <image>. Because of this, we plan to approach this project by first using delegation pattern to add biding capability to the <link> for choosing topics. Apart from this, a new controller, <link> is implemented to handle interactions similar to the one done in <link> . It handles the following implementations. 1. Trigger the bidding by sending a request to PeerLogic backend with proper parameters retrieved from ReviewBid records. 2. Process the response from PeerLogic and transform it into records of ReviewResponseMap. The bidding interface for reviews is followed from <link> implementation for topic bidding. We need to modify the code to implement the heat-map showing us the demand density for each project to be reviewed, the list of all available topics to review and the list of topics selected already. Color Coding Scheme: The color coding scheme would range from Red for the most in-demand topics to green for the least contested topics. The top 10% of in-demand topics will be coded in Red, the next 30% of the topics will be in orange, the next 30% in yellow and the last 30% in the green. We are using percentages instead of hard-coding the color coding scheme so that it works dynamically with changing number of students. After we allow the student users to bid for their topic of interest we need to provide access to instructors to start the bidding algorithm. To maintain the original functionality of Expertiza as well as to add review bidding, a new model to handle bidding data called ReviewBid is created. ReviewBid contains bidding assignment information, its biddable topics as well as the participants' preference. ReviewBid is served as the input of the bidding algorithm. We decided to let participants bid on assignment teams rather than topics for simplicity. Here is the definition of ReviewBid: <table>. Allow Instructor to set review strategy to bidding : <image> After setting the review strategy to bidding , participants are assigned a default bidding list, ordered by topic's name. <image> Participants can drag the items up or down to alter the priority. <image> Instructors can start bidding by clicking the following icon. <image> After the bidding is done, participants can login and see what they are assigned with. <image>. Automated tests are to be written for model ReviewBid, controller ReviewBidController. We also plan to write basic tests to check the correctness of Gale Shapley algorithm. UI Tests: In addition to automated tests we will also perform manual testing of the newly added features which include the following: 1. The student should be able to bid the reviews when Professor enables bid option for students on that particular assignment. 2. The reviews prioritized by the student should show colors i.e. green, orange and red indicating how likely he is going to get the review that he bid. 3. At maximum, a student should be able to four assignments. 1. College Admissions and the Stability of Marriage (1962), D. Gale and L. S. Shapley <link> 2. CSC/ECE_517_Fall_2018/E1856_Allow_reviewers_to_bid_on_what_to_review <link> 3. Pull Request #1322 (E1856. Allow reviewers to bid on what to review) <link> 4. Top Trading Cycles Algorithm <link>.","For design doc: You did quite a good job describing how your tests work; unfortunately you did not do the same for the code.  The ""Decisions"" section does that to some extent, but it would be more useful if it structured in terms of what code files were changed.  Simply listing the files to be changed is not very helpful; it asks the reader to figure out for himself (her) what has been done.","Dear Student,

Thank you for investing a lot of effort in this ambitious assignment. You've displayed a deep understanding of the Expertiza system's existing logic and how to optimize it to include a review-bidding feature.

1. Overview: You provided a thorough explanation of the current system and the motivation for your chosen improvements. It's clear that you understand the need for students to bid on the reviews they would like to undertake. This is beneficial not just in enhancing student engagement, but also in achieving a more efficient and balanced review assignment.

2. Problem Identification: You intelligently highlighted the limitations of the current system and presented well-thought-out solutions. Your focus on color coding, removing irrelevant tests, and streamlining the UI is particularly commendable.

3. Algorithms and Technical Application: It is evident that you have a solid grasp of algorithms, as shown by your analysis and application of the Top Trading Cycles and the Stable Marriage problem. Your attempt to delegate certain tasks to reduce the coupling of methods is impressive. 

4. UI Design: Your detailed explanation of the new UI design shows your consideration for user experience, which is an essential skill in software engineering. 

However, there are a few areas where you can refine your work:

- Clear and Precise Writing: Be mindful of repeating some points. Make sure your numbering system is accurate to avoid confusion.

- Code Explaination: When you include screenshots of code or make reference to coding solutions, ensure to explain thoroughly or discuss the logic behind your approach.

- Testing: Your focus on automated and manual testing for specific new features is encouraging, but it would be beneficial to consider a broader range of tests and potential edge cases.

In general, you've shown a promising approach to problem-solving, critical evaluation, and practical implementation. With more attention to clarity and precision in your writing, you can significantly improve the quality of your work. 

Keep it up!
"
47,E1982,"1. When a rubric is replaced or the items/questions attached to it are changed, all the active students’ responses object to that rubric will be deleted are created again, that means students need to redo the reviews if they have already done. 2. The system will email the students who have done reviews to notify a redo request after deleting the response object and all associated answer objects. 3. The “active” in the first goal means the replacement action happened during the task duration and the student responses have done in the task duration before the replacing rubric action. For example, a rubric starts from Sep.9th and ends at Sep.13th. An instructor replaces the rubric on Sep.12th, when 60 of 100 students have already finished their reviews. Then the response objects will be deleted and re-created to be new objects in the system, and students need to redo their reviews based on the new rubric. 4. Write comprehensive tests for the above implementation to confidently prove they are correct. If the instructor does edit or change a rubric of the assignment while an assignment is in review progress, it will make previous review record make no sense. So it is supposed to delete previous response and notify all those students who have submitted review before to re-submit a response of new rubric. The function classification change as two kinds: Minor change & Major change. 1. Minor Change defined as the change makes no difference to reviewings so that we could also use reviewing before change made.(e.g. Delete questions or clarify the statement). 2. Major Change include situation as below: 1.1. add a new question which not mentioned before, which make previous response lack of sone answer. 1.2. Any question is edited to a different question, which make previous response make no sense. 1.3. rubric is replaced by a different rubric, so everyone should re-submit a response on new rubric. Since Minor Change still could be used to scoring so that we could also use reviewing before change made.(e.g. Delete questions or clarify the statement). And major change has some questions cant be found in previous rubric, system would delete all related reviewing records and email those reviewers to redone reviewing in such situations. 1. In Practice, after rubric is replaced or rubric is edited, doing such process: 1.1. give a confirmation to client to verify change 1.2. make sure it is a rubric of assignment which in reviewing period 1.3. sending e-mail to who has already submit review 1.4. deleting previous responses of such rubric 1.5. update the rubric formal in database. <image>. <image> The main goal of the code is to edit the rubric. There are 3 types of action: edit, add, and delete questions. We classify these actions into two types: major change and minor change. Note: Editing questions refers to editing only the text of the questions. Changing the type (multiple-choice, simple-text...) of a question is not allowed in Expertiza. You have to delete the old question and add a new one. Minor change: Edit questions. In this case, we simply update the text of the questions. There’s no other actions needed. Major change: Add/Delete questions. In this case, we have to check if there are any reviews done by students in the active period, i.e. the period of time when students can submit reviews. If there are any, we have to notify the affected students by email asking them to re-submit a review using the updated rubric, and delete their old reviews. The solution has five parts: 1. Check the changes made by instructor. Major or minor? 2. Check if the change to the rubric is made during the task duration (or if there is any active response?). 3. Process updates when a major change is made. 4. E- mail notification is sent to request students to redo their reviews. 5. Test the implementation thoroughly. After a change is made, the system will check if the date is during the task duration to determine whether it needs to update existing response objects. The function method will get params as the start time and expire time of the target rubric to proceed a checking. If the change is not during an active task duration, then nothing further needs to be done. If the change is during an active task duration, then the system will do the following work. Changes are categorized to be major or minor. Minor changes affects only the wording of a particular rubric item. In this case, no action is necessary. Major changes involves rubric replacing and changing items/questions. In this case, all the reviews that have been done need to be redone. To tell a major change, the params passed to the controller includes a tag/identifier that indicates if a new question was added, hence a major change. If the previous process returns that a major change has been made, the system deletes existing response objects and re-creates new updated object in database when a student press on “review”. As for minor changes, updates affects only the objects that created after the change. Once controller notice instructor makes a major change of the rubric, and some students have begun the peer review, email notification module is initiated. In this circumstance, the system will generate ActiveRecord and send it to those students. (Their email address could be found in user’s table.) After email successfully sent, record of this student in this assignment and period will be deleted from the database. When students receive the email and update their review, the questions now correspond to the new rubric. And students can see all the details of the old questionnaire in the email, so they won’t have to rewrite the same questions’ answer. Our test is designed to three parts: common cases, invalid cases and extreme cases. Details of test plan are included in the Test Plan section below. Firstly, we create in_active_period: Find the review period for a particular questionnaire. If an answer is specified, it checks whether the answer is written in the period. If not, it checks whether the current time is in that period. <image> And we add a confirmation base on ""in_active_period"" method performed like follow: <image> <image> At back-end, when we determined that assignment is in active period, then call delete_existing_response to delete response and send email. <image> delete_existing_reponses: Find all the answers to the questions specified by question_ids. Then, delete the answers and send emails to affected student. In delete_answers, the response is set to ""not submitted"" to let the students who already submitted edit their responses. <image> <image>. The major changes we have made are in questionnaires_controller.rb, answer_helper.rb, and question_controller.rb. Each component of the system is tested in a dedicated test file in the spec directory, and the test file name is according to the function tested. When a question is added or deleted, add_new_questions method of questionnaire_cotroller.rb will check if the current time is in active period before it makes future process. It asks AnswerHelper to check the condition via in_active_period method. The test cases of questionnaires controller expect the helping method in_active_period and delete_existing_responses are called using correct parameters and provide expected results back to the controller. <image> <image> The answer_helper.rb helps questionnaire controller check period conditions, send email to the according reviewers, and delete existing responses. To test these methods, we pass corresponding parameters into the method and check the outputs. When the current time is not in the review active time period, this method returns false. When the current time is in the review active time period, the in_active_period returns true. And a bound case: when the round number is not recorded in database, the method will check all due dates in this assignments. <image> Delete existing responses test case expect AnswerHelper to receive user information, check if email is sent to reviewer, delete the corresponding responses and check the existence of the responses in database. So the review_mailer should be called and the existence check should return false. <image> To test the sending email function, the test case expects Mailer to receive a notify_review_rubric_change request once for an active user. <image> Deleting a question from a questionnaire is now considered a major change, so we added active period condition check in question_controller.rb. The corresponding test is below. It ensures the result message and expects call requests to in_active_period and delete_existing_responses. <image>. 1. Project description: <link> 2. Github repository: <link> 3. Pull request-1: <link> 1.1. In this pull request, when a major change is made to the rubric(add/delete/edit question), the system will delete existing reviews and send emails after user confirm. 4. Pull request-2: <link> 1.1. In this pull request, when a rubric is replaced, the system will delete existing reviews and send emails after user confirm. 5. Introduce video: <link>.","Good description of the project, except ... it is not clear how you tell whether the wording of a question has been modified, or the question has been replaced by another question.  I also don't understand what ""task duration"" is.  Is that the same as the active period?  Description of what the code does is good.","Your detailed exploration of the effects of changing or replacing a rubric during student review is commendable. The distinction between major and minor changes, as well as the thoughtful consideration of how to notify students and manage their work in response to these changes, is well elaborated upon. 

However, it is important to ensure that your writing is concise and clear. The initial sections of your assignment seem to be repetitive and could be condensed for clarity.

Coding-wise, your approach of considering whether a change is major or minor, the conditions around the change (whether it's in the active period), and taking appropriate actions is a smart strategy. The use of ActiveRecord to generate automatic correspondence with the students is a good use of Ruby's capabilities. The detailed illustrations and explanation of the code is appreciated but the overall layout could be neater.

Detailed testing of the application is also a strong point in this assignment. You're not only testing the common cases but also analyzing invalid cases and extreme cases. Consider not only showing the results but also discussing potential areas for improvement or future developments.

Also, remember to always correctly cite and reference external sources and documents. Remember to hyperlink your website and Github repository. I noticed that you included the line, '<link>,' instead of providing the actual URLs.

In future assignments, try to focus on clarity, precision, and organization in your description. Also, ensure that all aspects of the assignment instructions are thoroughly met, this includes providing applicable links. 

Good work overall, and looking forward to seeing your development in the next assignments."
48,E1576,"Expertiza<ref> <link> </ref> is a project developed using Ruby on Rails<ref> <link> </ref>. It provides features like peer review, team assignments and submission of projects. This can be achieved by submitting code base, URL of hosted code on remote server and Wiki submissions. It is an <link> application and the code can be cloned from <link> . This application provides an efficient way to manage assignments, grades and reviews. This makes the process easier and faster when the class strength is large. 1. assignment_participant.rb 2. assignment_team.rb and 3. views related to submitted hyperlinks and files ( submitted_content/_hyperlink.html.erb , submitted_content/_submitted_files.html.erb ). It handles the display, submission, deletion of hyperlinks and files by the teams. The submitted hyperlinks and files are stored in participants table, which means they are associated with individuals instead of team. This is not a good design because in Expertiza, students are always grouped in teams, even when there is only one person in each team (individual assignments). Currently, when a team member wants to see all the submitted hyperlinks of his team, Expertiza needs to load all the submitted hyperlinks from each participant in this team and merge them all before display. Similar overhead happens when a team member wants to delete a submitted hyperlink. Also, the directory_num field needs to be moved from the participants table to the teams table. It signifies the sub-directory which stores all the files submitted by this team. Intuitively it is clear that each team should ideally have only one common copy of directory_num . 1. Create a new column hyperlinks in the teams table. 2. Write db migration, move all the participants’ submitted hyperlinks from participants table into teams table. Duplicate hyperlinks need to be removed. 3. Write db migration, remove the hyperlinks field from participants table. 4. Rewrite the hyperlink-related methods in both assignment_participant.rb and assignment_team.rb to make sure the new code works with the new db design. 5. Make sure when doing the peer-review, the reviewer can see the submitted content from the reviewees. 6. Make sure when instructor see the peer-review records, they can see the submitted content from the reviewees. 7. Write db migration, move the directory_num field (also the content, of course) to the teams table. 8. Move the set_student_directory_num method from participants_controller to teams_controller , then refactor this method into smaller methods. 1.1. This method no longer needs to test all the participants. 1.2. Check if any of them have directory_num . If so, instead, it should just check the directory_num from teams table. 9. Make change to the submitted-file-related code to make it work with the new design. 10. Write test cases to test student-submitted hyperlinks and files. This project can be divided into four major work items: 1. Moving the hyperlinks field from the participants table to the teams table. After this change, relevant changes are needed in the code to support this database change. 2. Moving the directory_num field from the participants table to the teams table. After this change, relevant changes are needed in the code to support this database change. 3. Moving the set_student_directory_num method from the participants_controller to the teams_controller . It just needs to check directory_num from the team table. 4. Write test cases to verify student-submitted hyperlinks and files. Expertiza files that will be modified for each work item along with the description: <table>. Consider a simple use case where we need to retrieve the submitted hyperlinks and files corresponding to team_id , say, 23841 . Since there is no existing correlation between teams and submitted content, we will first need to look up the participants in the team using the teams_users table. And then, using those user_id values one at a time, we need to look up the participants table. <image> Finally, we need to merge the results before displaying it. <code> So, it becomes a tedious 3-step process. It is evident from this example that the current design is inefficient. Instead, if the hyperlinks data were available in teams table, we could directly access all the submitted content for a team in one shot, making it much more streamlined. As a part of this change, we’ll have to move the following routines in assignment_participants.rb , which deal hyperlink handling to assignment_team.rb . <code> Similar refactoring work needs to be done for the directory_num field as well. Finally, the refactoring needs to be thoroughly tested by writing test cases for student-submitted hyperlinks and files by making sure that: 1. the submitted hyperlinks and files are correctly displayed on the submitted content page. 2. the reviewer can see the submitted content from the reviewees. 3. the instructor can see the submitted content from the reviewees. Use Case 1: Submit hyperlink for an assignment by student. Description: A student who is an assignment participant should be able to submit hyperlink on the “Your work” section of an assignment. Preconditions: Student should be a participant for the assignment he is trying to submit the hyperlink. Postconditions: The submitted hyperlink should be stored in the teams table of the database. Success Scenario: 1. The submitted hyperlink is visible every time the student views the “Your work” section for the Assignment. 2. All other team members should be able to view the submitted hyperlink. 3. A reviewer should be able to see the submitted hyperlink. 4. An instructor should be able to see the submitted hyperlink. Use Case 2: Submit file for an assignment by student. Description: A student who is an assignment participant should be able to submit a file on the “Your work” section of an assignment. Preconditions: Student should be a participant for the assignment he is trying to submit the file. Postconditions: The directory_num field which stores the directory number of the directory storing all the submitted files for a team should be stored in the teams table of the database. Success Scenario: 1. The submitted file is visible every time the student views the “Your work” section for the Assignment. 2. All other team members should be able to view the submitted file. 3. A reviewer should be able to see the submitted file. 4. An instructor should be able to see the submitted file. Use Case 3: Delete hyperlink for an assignment by student. Description: A student who is an assignment participant should be able to delete submitted hyperlink on the “Your work” section of an assignment. Preconditions: Student should be a participant for the assignment he is trying to delete the hyperlink. Postconditions: The deleted hyperlink should be removed from the teams table in DB. Success Scenario: 1. The deleted hyperlink should not be visible the next time the student clicks on “Your work” section. 2. All other team members should not see the deleted hyperlink. 3. A reviewer should not be able to see the deleted hyperlink. 4. An instructor should not be able to see the deleted hyperlink. The project was divided into 4 categories: 1. Database migrations 2. Refactor submitted_hyperlink related methods 3. Refactor directory_num related methods 4. Testing We followed the steps listed below in the process of refactoring the submitted content controller: 1. Writing database migrations to move the submitted_hyperlinks and directory_num attributes from the Participants table to the Teams table. 2. Rewriting submitted_hyperlinks related methods in the Participants model to read from and write to the Teams table. 3. Modifying the corresponding views to read hyperlinks_array instead of hyperlinks . hyperlinks_array stores the the submissions of all the team members of a team. 4. Removing directory_num related methods from the participant model. 5. Rewriting directory_num related methods in the team model. 6. Rewriting the corresponding views to read directory_num from the teams table instead of the participants table. 7. For testing, we first created fixtures for all required tables. 8. We tested our changes by writing functional tests to test the SubmittedContentController. 9. Our test suite included the following tests: 1.1. Testing submission of a hyperlink by one student - Check the count of submmited hyperlinks, verify that the hyperlink is stored properly in the database and displayed correctly from the UI. 1.2. Testing submission of two hyperlinks by two students in a team - Check the count of submmited hyperlinks, verify that the hyperlink is stored properly in the database and displayed correctly from the UI. 1.3. Testing submission of the same hyperlink by two students in a team - Check that the duplicate hyperlinks does not get stored. 1.4. Testing deletion of a hyperlink - Check the count of submmited hyperlinks and the updated list is displayed correctly from the UI. 1.5. Testing submission of one file by one student - Check the submission of a file and check the updated count of submitted files. 1.6. Testing deletion of one file by one student - Check the deletion of a submitted file and check the updated count of submitted files. 1.7. Testing submission of multiple files by multiple students - Check the submission of multiple files and check the updated count of submitted files. 1.8. Testing deletion of multiple files by multiple students - Check the deletion of multiple submitted files and check the updated count of submitted files. We can conclusively say that, after refactoring the submitted content controller, the query time for retrieving submissions will improve significantly as they are stored together on a team-basis rather than for each participant. Video demo of our work can be found at <link> GitHub repository containing the refactoring changes can be found at <link> Link to the pull request to Expertiza is <link>. A proposal for further improvement would be to possibly create a new submitted_content table in the database. This table could include attributes like user_id , team_id , can_submit , hyperlink , directory_num , uploaded_at , updated_at . This approach would resolve the existing hyperlinks issue and more importantly, aid in recording a history of the submitted hyperlinks. There could be a “Show previous submissions” view for a team. So, if ever there’s a scenario where a student or an instructor needs to revert or go back and check a previous submission, he/she can easily access it from this table. <references/>.",They didn't fix the db like we told them to; otherwise they'd have gotten 95 or so.,"Dear Student,

Well done on a comprehensive assignment. Your submission clearly demonstrates that you understand the structure of Ruby on Rails and how to refactor it. The presentation and explanation of your process of modification is detailed and articulate. The illustrations and images used were well placed and supported your explanations. Great initiative in suggesting improvements for the project.

Here's my feedback on your submission:

1. Splitting the project into clearly defined tasks was a great approach, as it showed a logical workflow and good planning.
2. Your description of design flaws was quite clear, demonstrating a solid understanding of basic database principles.
3. Your step-by-step modification of the code and the explanation of each step was done well.
4. The test cases created are in line with the changes made, which indicates a good understanding of the testing process.
5. Your use cases are thoroughly thought out and well-presented. All relevant scenarios are mapped out accurately.

However, there's a few areas that need more attention:

1. I noticed that you included `<link>` without actual web addresses. Please ensure to provide the actual links in your final work.
2. There were a few ambiguous mentions like `<image>` and `<code>`. Please ensure to replace these with actual data for clarity.
3. Finally, be conscious of the assignment's formatting, for example, use proper indentation and headings for better readability.

Overall, great job! Continue in the same spirit, and remember to incorporate the suggestions made in your future projects.

Best,
[Instructor's Name]"
49,E1858,"Expertiza provides Teammate Reviews under View Scores functionality for each assignment. Purpose of this project is to augment existing assignment submissions with data that can give a more realistic view of the work contribution of every team member using external tools like GitHub. This external data may include: number of commits, number of lines of code modified, number of lines added, number of lines deleted from each group’s submitted repository link from GitHub. 1. Teammate Reviews functionality in the View Scores page gauges teammate views on how much other team members contributed to the project. We need to augment this data with data from external tools like GitHub in order to validate that feedback. New metrics will be appended under each student data under the same functionality. 2. Github Metrics under View Submissions page should include a bar chart that shows number of commits by the team throughout the assignment timeline. This will help instructors to get a team overview, and aid grading process. While this data will not have marks associated directly, it will prove useful to the instructor in differentiating the performance of team members and hence awarding marks as per contribution. Overall data for the team, like the number of committers and number of commits may also help instructors to predict which projects are likely to be merged. <image> Previously, view submission does not show work contribution per teammate. <image> Teammate review shows peer review amongst teammates. Currently, however, there is no way to validate and verify these reviews. Checking commits performed by each team member on GitHub is a solution, but that is inefficient from instructor's/reviewer's perspective as there are many assignments, submissions, and tight deadlines. <image> 1. Use Case diagram of two approaches to append 'GitHub contribution metric' in teammate review. 2. Use Case diagram explaining approach to add new column 'GitHub contribution metric' in 'View submission. Actors: 1. Instructor: This actor is responsible for viewing GitHub metrics of teams and team members of an assignment. Pre-Conditions: 1. The Team should have submitted the assignment with a PR link or GitHub repository. Primary Sequence: 1. The instructor should login. 1. The instructor should browse teams for an assignment. Post Conditions: 1. Instructor will be able to see the team contribution done by each team member in 'View Submissions' page using graph diagrams, as shown in the figure. 2. Instructor will be able to see the work done by each student in 'Teammate Review Tab' with new metrics table appended at the end, as shown in the figure. 1. The first thing was to determine what metrics we are looking for exactly. These are what the solution supports: 1.1. Number of commits per user and total per team. 1.2. Lines of Code added 1.3. Lines of code deleted. 1. The next thing was to narrow down what hosting service for version control we would use. For now, we only support GitHub integration due to its popularity, ease-of-use and API documentation. Future projects could add in support for Gitlab and others, though it is far easier to just require that all students use GitHub. 1.1. The main impact of this change will be that all submission repositories need to be made public as we need access to pull in the data. 1.2. We also considered whether to ask students for GitHub repository link separately (changes to views) or to parse all the uploaded links and determine the correct one (extra logic, students uploading multiple links or not giving links at all). We decided to go with parsing the links as giving the link to PR is anyway mandatory. 1. An important question was whether we needed to store metric information in our own db at all. 1.1. An older investigation came up with <link> schema, but this would likely cause issues with stale information and would have been difficult to maintain. 1.2. Having a db was redundant as every time a user wants to see the metrics, we would need to sync the db with GitHub and then show the results. So we end up hitting GitHub API anyway. 1.3. An alternative to the above approach was to take snapshots of metrics and store them in the db right on the submission deadline of projects. This would allow for fairer grading by making sure we pull in data at the correct moment. Unfortunately, doing this for so many projects would put a lot of load on the server. Also, for open source projects, this would mean that we don’t have the latest data to work with (people will keep committing past the deadline). Thus, this approach might have been good for grading purposes but wouldn't have helped with determining the current status of a project. 1.4. We have decided against using our own tables for this data and will be getting the GitHub data on-demand directly using the GitHub API. 2. We also considered if we needed to account for different branches. We only consider the master branch. 1. With respect to showing GitHub metrics in the View scores page, it would have been very difficult to map Expertiza users and their names to public GitHub profiles as students may use a different name. So instead of appending GitHub data to Teammate reviews table, we will be showing a new table below it to display the metrics. This will allow the instructor full view of how teammate rated each other and how that maps to factual information from GitHub. 1. The instructors will need to spell out exact guidelines for committing to the project's repositories (like everyone should commit their own code, keep the master as PR branch, commit regularly, be mindful of squashing too many commits for one user), so that we can have proper and correct data and, also so that students can’t weasel their way out later claiming they worked but forgot or didn’t know. 1. MVC – The project is implemented in Ruby on Rails that uses MVC architecture. It separates an application’s data model, user interface, and control logic into three distinct components (model, view and controller, respectively). We intend to follow the same when implementing our end-point for pulling GitHub data. 1. Dry Principle – We are trying to reuse the existing functionalities in Expertiza, thus avoiding code duplication. Whenever possible, code modification based on the existing classes, controllers, or tables will be done instead of creating the new one. 1. The Github metrics that need to be integrated with Expertiza were finalized as below. These metrics are captured on a per-user basis: 1.1. Total number of commits. 1.2. Lines of Code added 1.3. Lines of code deleted. 1.4. Pull Request Status ( includes code climate and Travis CI Build status) 1.5. User Github metrics: 1.1.1. Committer ID 1.1.2. Committer Name 1.1.3. Committer email ID 1. A new link ""Github Metrics"" is provided under “View Submissions” for an assignment in the instructor view.This link opens a new tab and shows a stacked bar chart for number of commits per user vs submission timeline from assignment creation date to the deadline. 2. In ""View Scores"" for an assignment in the instructor view, under Teammate Reviews tab, a new table for Github Metrics is added, which shows following Github metrics per user: Student Name/ID, Email ID, lines of code added, lines of code deleted, number of commits 1. For GitHub integration, we have used GitHub GraphQL API v4. We have used github-omniauth gem for authentication/authorization purposes. 1. We parse the link to PR to get data associated with it. We have also handled projects which do not have PR link, but just a link to the repository. We excluded expertiza and servo projects as right now a PR link is expected. Future enhancements can look into getting separate GitHub submission links. 1. We also show the status of check runs in the View Github metrics view to help instructors view the status of various tools on the repos/PRs without having to go to the actual GitHub page. 1. app/controllers/auth_controller.rb 2. app/controllers/grades_controller.rb 3. app/helpers/grades_helper.rb 4. app/views/assignments/list_submissions.html.erb 5. app/views/grades/_tabbing.html.erb 6. app/views/grades/_teammate_reviews_tab.html.erb 7. app/views/grades/view.html.erb 8. app/views/grades/view_team.html.erb 9. config/application.rb 10. config/initializers/load_config.rb 11. config/initializers/omniauth.rb 12. config/routes.rb. 1. app/views/grades/view_github_metrics.html.erb 2. config/github_auth.yml. 1. A new table ""Github Metrics"" is added under Manage-> Assignments -> View Scores -> Teammate Reviews. Below is the screenshot of the implementation. <image> The GitHub metrics table shows results for each team member. 1. The second change is in the View Submissions page, where we have added a link ""Github Metrics"" to a new page. <image> At present, view submission shows group assignments are submitted as a single submission and 'view github metric' link shows work contribution per teammate. 1. The new page appears after clicking on the link ""Github metrics"", that shows bar chart for # of commits per day. We have also added other relevant information about Pull Request, such as total commits, lines of code added, lines of code modified, PR merge status, check status. <image> The bar chart <image> The Github summary. 1. Added below new functions to implement Github Integration in View Submission page <code>. Change 1: GitHub metrics in teammate reviews 1) Log in as an instructor (instructor6/password) 2) Navigate to assignments through Manage --> Assignments 3) Select ""View scores"" icon for the assignment of your choice 4) Select the team for which you wish to view scores 5) Go to ""Teammate Reviews"" tab 6) View data per team member based on different GitHub metrics (e.g. lines of code added/changed/removed etc.) Change 2: Bar chart for # of commits changed by the overall team 1) Log in as an instructor (instructor6/password) 2) Navigate to assignments through Manage --> Assignments 3) Select ""View submissions"" icon for the assignment of your choice 4) Click on the ""Github metrics"" link for the team whose metrics you wish to view 5) A new page opens and shows # of commits changed per team member since the start of the assignment, also bottom of the page shows summary from Github submissions. 1. Following feature tests were added to the Grades_Controller_Spec.rb <code>. <link> <link> <link> <link> <link>.","The document contains quite a good discussion of the problem to be solved and the tradeoffs made in solving it.  It shows the visualizations that were implemented.  The weak part is that the code is simply pasted in with no explanation.  No one is going to read the code in this format.  They will look at it on Github.  It would have been much better just to include a link to a diff in Github.  Also, the code shown has a complete lack of comments, which is unconscionable.","This is a very well detailed and carefully considered project. It is evident that you have done a thorough job of studying the existing functionality and requirements before proposing your improved solutions. Your thoughtfulness in identifying potential issues with stale data, and your detailed approach in considering the mapping of Expertiza users to their public GitHub profiles is impressive.

We especially liked how you maintain consideration of the current use cases of Expertiza, and aim to augment and integrate external tool data without disrupting existing functionalities. When implementing such changes, maintaining existing functionality while introducing new features is always important, as sudden changes can be challenging for existing users.

Your documentation of the project is excellent. You have explained your reasoning process, considerations, and technical decisions in great detail. Your proposed GitHub metrics integration is very detailed and comprehensive. It seems like it will be a great addition to the Expertiza platform. Additionally, your proposal for additional guidelines for instructors to ensure the data's integrity is thorough and considered.

However, there might be areas that need more clarification or work. For example, the numbering in your document seems inconsistent - there are several points that start again from 1. Please fix this for better readability. Also, consider elaborating on your choices of using Ruby on Rails and MVC architecture. 

Overall, you have shown a good understanding of how Expertiza works and have provided a thorough proposal for improving it. The next stage would be to start implementing these changes and observing their effectiveness and ease of use for instructors. Keep up the great work!"
50,E1985,"Peer review is a great way for students to learn about how well they have developed their application. However, sometimes, the peer reviews may not be thorough and the team/person's work reviewed might not reflect the actual status of the development. By letting course staff perform reviews as well, the reviewer and the reviewee both benefit, improving the overall learning experience. Currently, there exists no method for the instructor/TA to perform reviews of assignments submitted by the students. Hence this is what this project aims at, allowing instructor/TA to perform reviews. Thus, the primary aim of this project is to allow instructors to submit reviews of student work, using the same review form that students use to do reviews. Our project aims at enabling the instructor/TA to review the submissions using the same form that a student uses while peer-reviewing. For this, our implementation has been divided into 3 parts, and can be described as follows: 1. The first part involves the primary functionality of letting the staff perform a review on students submission. 2. The second part involves allowing the students to identify from their end, which review has been performed by an instructor/TA. This will help students improve their project as the opinions presented by a staff member would be valid. 3. Thirdly, we implemented an additional feature that allows the instructor/TA to add himself as a participant while creating/editing an Assignment (This way seemed to be more convenient rather than going to the “Add Participant” page and adding themselves as a participant.). Note 1: “Instructor/TA” will be referred to by “user” here onwards. Note 2: To be able to perform a review, the user has to be a participant of that assignment. We have implemented “Add as Participant” as an additional feature which is explained in Part 3. If the user is not a participant, he will only see the link to “Assign grade” that too after the assignment deadline passes. Now, for each assignment, there is a page called “List Submissions” where the user can view all the submissions. So we have modified this page so that for each team submission a link for “Begin review,” “Edit review,” “View review,” “Update review,” or “Assign grade” may appear depending on the <link> in which the assignment is. The following describes the flow of our project considering a fresh assignment. 1. When the assignment is created, it is by default is in the “submission” stage. Hence the user will not see any link on the list submission page. 2. When the first deadline passes, the assignment goes into the “review” stage. Hence the link “Begin review” will be visible for each team submission, where the instructor/TA can click on to submit the review. Two cases can occur here: 1.1. If the user “submits” a review, they will be redirected to the list submission page where they’ll see the option “View review” or “Update review.” Being an instructor/TA, they are given the flexibility to update their review at any time during the “review” stage. 1.2. If the user “saves” a review, they will be redirected to the list submission page where they’ll see the option “View review” and “Edit Review (as they have not submitted it yet.)” 3. After the first review is over, if more stages of “submissions” and “reviews” exist, it will follow the above 2 steps until the final assignment deadline does not pass. Note that at any round of the review, the user can “Begin review” for a submission which they had not reviewed in the previous rounds. This is to provide flexibility to them as per the requirement. 4. Finally, after the assignment deadline passes, the assignment goes into the “Finished” stage. This is when the “Assign grade” link will be visible to the user. Along with this, depending on whether they have reviewed a particular submission or not, the begin, view, update links will be visible to them as they should be able to perform the review even after the assignment deadline for the students has passed. Files Edited The following are the files (controllers and views) edited for the implementation of the review process. The comments are given along with the code to explain what is being done. 1. Controller: app/controllers/response_controller.rb <code> 1. Controller: app/helpers/assignment_helper.rb <code> 1. View: app/views/assignments/list_submissions.html.erb <code> 1. View: app/views/grades/view_team.html.erb <code> 1. View: app/views/student_review/_responses.html.erb <code> ---. Currently Scenario: There is no way for the student to know which review was by the instructor. Requirement: This helps the student to identify the review made by the instructor from the other reviews. Implementation: A simple check is made to determine if the reviewer is a TA or Instructor. app/assets/images/staff.png is displayed to make an instructor performed review stand out from other reviews. If the mouse hovers over the icon a tool tip appears saying ""Icon indicates this review was done by course staff"" <image> Files Edited 1. Helper: app/helpers/grades_helper.rb <code> 1. View: app/views/view_team.html.erb <code>. Current scenario The instructor/TA will be able to perform student reviews (after implementation of Part 1) for the assignment, only when he is a participant of the same assignment. Thus, every time he creates an assignment and wants to add himself as a participant in order to perform student reviews, he is supposed to do the following Go to list of assignments -> Find the required assignment -> Click on add participant -> Type user Id -> Click on add The same flow is as shown below where the instructor/TA has created a new assignment say “Program 1 Github” wherein he wants himself as a participant to be able to perform student reviews : To overcome the hassle, we added a check box through which the instructor/TA will get an option to add himself as a participant while creating the assignment. Also, he will be able to add/remove himself as a participant while editing the assignment. Implementation The checkbox has been provided to Create New Assignment’s page under the Review strategy tab. It is added as follows: <image> If the instructor/TA selects the box while creating the assignment, then he will be added as a participant for the same assignment. Files edited: 1. View: app/views/assignments/edit/_review_strategy.html.erb In this file, code for displaying the checkbox has been added which is as follows : <code> Thus the checkbox ""add_instructor"" if selected adds the instructor as a participant to the currently being created assignment. Thus, instructor being a participant allows him to perform reviews for the students for this assignment. 1. Controller: app/controllers/assignments_controller.rb The file contains extra code which adds the instructor/TA as a participant if the checkbox has been selected while creating the assignment. Also, while editing the assignment, he will be able to add/remove himself as a participant for this assignment. The following methods are added to the controller : <code> The method ""is_instructor_a_participant?"" returns true if the instructor is already a participant for the assignment, else returns false. This method is required to verify that the instructor/TA is not a participant of the assignment, and thus he can be added as a participant if the checkbox has been selected. Also, during editing the assignment, we need to show checkbox being selected if the instructor is a participant and vice versa. Thus, this method serves that purpose as well. <code> The method ""add_instructor_as_participant"" is been called from create and update methods in the Assignment controller. It checks if the ""Add yourself as participant"" checkbox is selected for the currently created/edited assignment. If it is selected during creation or editing, then the instructor is added as a participant to the currently created/edited assignment. The participant is added by using the already existing method ""add_participant"" in the model assignment.rb Also, if the option is unchecked during editing, then the instructor is removed as a participant. <code> The method ""delete_instructor_as_participant"" removes instructor as a participant for the assignment when the checkbox is unchecked during the editing of the assignment. UI Testing 1. Login in as an instructor. 1.1. Username: instructor6 1.2. Password: password 2. Choose any assignment from the list of assignments which involves teams; since an assignment without teams does not include the review procedure. For example, “Final project (design and doc)” is a good assignment to choose. 3. Now, while testing this functionality, it is recommended to keep the following pages opened in different tabs by clicking on the small icons in the same row as the assignment that you want to test: a. “Edit” -> “Due Dates” tab <image> b. “Add participants” <image> c. “View Submissions” <image> 4. Now add the instructor as a participant (3.b). and edit the ALL due dates (3.a.) of different stages to any date later from now (hence the assignment goes into the “submission” stage by default). Save both these changes. 5. Now refresh the view submissions page (3.c.), you will see a list of assignments with no link to review or assign grade. 6. Now switch to edit due dates tab (3.a.) again. Set the due date for submission to a previous date which has passed, hence the next due date will be for the “review” stage by default (which will have a later due date from now.) 7. Refresh view submissions page (3.c.), you will see a list of assignments with a link to “Begin Review.” 8. You can click on it. If you “save” your response, you will see that the link has been replace by “View review” and “Edit review” now. Whereas, if you “submit” the response, the link will be replaced by “View review” and “Update review.” 9. Depending on the number of stages that an assignment has, you can edit the due date at every stage and check whether the links are displayed appropriately. 10. Finally when the last deadline of the assignment is set to a previous date which has passed, you will see the link to “Assign grade” in view submissions (3.c.), and the user will still be able to begin, edit or update a review in order to provide flexibility as per the requirements. Edge Cases: 1. If the user is not a participant of the current assignment, they are shown a list of all submissions made by all teams of the current assignment. They are shown the link to “Assign Grade” only when the final deadline of the assignment passes. 2. During any review stage or even after the deadline, the user is offered the flexibility to Begin, Edit, View or Update their review. UI Testing 1. Login as an instructor and change the due dates for the assignments to be tested. Here the assignment chosen is Final project (and design doc). 1.1. Username: instructor6 1.2. Password: password 2. Login in as student. Here we have logged in as student8434 1.1. Username: student8434 1.2. Password: password 3. Go to Assignments-> Final project (and design doc). Here click on the assih=gment for which the due dates were changed. 4. Click on Your scores There we can see the icon for reviews reviewed by staff. <image> Part 3: Add instructor/TA as a participant while creating the assignment UI Testing 5.1. Login in as an instructor. 5.1.1. Username: instructor6 5.1.2. Password: password 5.2. Go to Manage-> Assignments 5.3. Click on add assignment 5.4. Enter the required details- Assignment name, course etc 5.5. To add instructor/TA as a participant, go to Review Tab and select the ""Add yourself as a participant?"" checkbox. 5.6. Click on Save The assignment has been created and the instructor/TA is added as a participant to the assignment. Edge Cases : 5.1. If the instructor/TA does not select the ""Add yourself as a participant?"" checkbox while creating the assignment, then he is not added as a participant 5.2. If the instructor/TA selects the ""Add yourself as a participant?"" checkbox while editing the assignment, then he is added as a participant 5.3. If the instructor/TA unchecks the ""Add yourself as a participant?"" checkbox while editing the assignment, then he is removed as a participant Rspec Testing : <code> External Links 1. Forked Repository: <link> 2. Pull Request: <link>. UI Testing 1. Login in as an instructor. 1.1. Username: instructor6 1.2. Password: password 2. Go to Manage-> Assignments 3. Click on add assignment 4. Enter the required details- Assignment name, course etc 5. To add instructor/TA as a participant, go to Review Tab and select the ""Add yourself as a participant?"" checkbox. 6. Click on Save The assignment has been created and the instructor/TA is added as a participant to the assignment. Edge Cases : 1. If the instructor/TA does not select the ""Add yourself as a participant?"" checkbox while creating the assignment, then he is not added as a participant 2. If the instructor/TA selects the ""Add yourself as a participant?"" checkbox while editing the assignment, then he is added as a participant 3. If the instructor/TA unchecks the ""Add yourself as a participant?"" checkbox while editing the assignment, then he is removed as a participant Rspec Testing : <code>.","On the code you displayed, yes, it does contain comments that the reader could peruse to understand the code.  But the reader could gain the same info just by reading the code from the repo.  What would be useful is prose explaining what changes were made and why.  Just like you did later in Part 3.  But then when you wrote about automated tests, you just pasted in the code again.","You made an impressive effort to allow instructors to review student work using the same form students use for peer reviews. Your project seems to be guided by a clear vision and process, and the three-part implementation strategy demonstrates methodical planning and organization.

Upon reviewing your work, I have several comments:

1. It's commendable that you have done significant justice to your primary aim and developed a system that enables the instructor/TA to review the submissions. This feature is critical to offering instructors additional insight into the student's progress and can aid in more accurate grading and feedback.
   
2. The way you explained the different stages of the assignment, starting from creation to the final 'Finished' stage, was comprehensive, coherent, and easily understandable. It gives a complete flow of the project.

3. Your process of identifying an instructor's review for the student is a noticeable feature. It will give students a clear idea about the significance of the review.

4. The feature that you added, which permits the instructor/TA to add him/herself as a participant while creating or editing an assignment, is well thought out and offers convenience. It demonstrates attention to detail and consideration for enhancing the user experience.

5. Coming to the UI Testing part, it's commendable that you have conducted thorough testing. I appreciate your effort to test for various edge cases as well.

6. You have edited and modified the views and controllers efficiently for functionality implementation. Providing the explanation for code modifications and additions is useful as it offers context to the changed code.

7. However, the text seems to be quite extensive and there are some repetitive statements. It could have been more concise without sacrificing clarity.

8. Also, please replace placeholders like <image>, <link>, and <code> with actual content.

9. While going through the testing parts, it wasn't always clear what you were referring to, particularly regarding the images and representation. Ensure to provide visual aids or clear narrative details where necessary.

Overall, it appears that you have exhibited good comprehension of the project and displayed a strong capacity for software development. With a few adjustments and improvements, this would be an excellent project. Keep up your enthusiasm and creativity for the next phases of the project. Your dedication and meticulous approach are commendable!"
51,E1571,"Expertiza has Assignment objects, which represent an assignment that is done by some number of users. An instructor or a TA can perform several kinds of operations on assignments, such as, ”Add participants”, “Create teams”, and “View scores”. These operations can be seen: First, on the homepage, under the “Actions” column in assignment list when a user (instructor or TA or admin) logs in and navigates to Manage -> Assignments. Second, when editing an assignment (by clicking on edit logo above), on the tab called “Other stuff”. This project in particular intends that the students collaborate with each other and work on making enhancements to the code base by applying the concepts of Rails,RSpec, DRY code,Test driven development etc. This provides an opportunity for students to contribute to an open source project and learn further about software deployment etc. Currently, the Assignment controller holds methods which are deprecated and also has a few lines code in its Edit and Update methods which could be removed to make the code DRY. In addition to that, it houses a few actions where the code could be refactored to make it DRY and follow the Ruby style guide and Rails 4 syntax. 1. Refactor edit and update method 2. Remove irrelevant comments from the create action. 3. associate_assignment_with_course and remove_assignment_from_course logic should be moved to model. 4. Change to new redirect method rather using controller and action explicitly. 5. Refactor the update_due_dates from AssignmentForm. using the DRY principle 6. Refactor code to follow ruby style guide and Rails4 syntax. 1. controllers/assignments_controller.rb 2. models/Assignment.rb. Edit function contains many manipulations that need be refactored into separate functions. The following block contains manipulations such as checking if due_date name or description is not defined. <code> This part of the code is moved into a separate function. <code> There are lots of redundant code in the following snippet.And, constants are hard coded inside the code rather than defining constants. <code> Redundant code is removed and made it more efficient and understandable. <code> <code> Hard coded constants are removed and necessary constants are defined in the deadline_helper.rb helper file. <code> And, manipulations such as checking if metareview, drop_topic,singn_up and team_formation are allowed need to be refactored into separate functions. <code> <code> <code> <code> The following snippet constructs a string that need to be shown to the user when rubrics are not set by the instructor. <code> Adding code such as above directly into the controller action made the edit function bulkier. The above snippet is also refactored into a separate function. <code> Refactoring out into separate functions makes the code more readable and understandable. Update function of the Assignment controller helps in updating the resources after editing it. The following code retrieves the data of the user logged in. <code> The above statement checks the cookies every time, when we want to retrieve information about current user. As it is inefficient and wrong, we need to use helper functions to retrieve such information. Explicit URL creation using controller name and controller action is refactored in such a way that helper functions create the URL when required. <code>. The Create action has a few comments which are irrelevant and make the method bulky. These could be safely removed from the code. This is currently defined as an action in AssignmentsController. The action logic could be moved to Model by passing the current user object to the corresponding method we create in the Model. The method in the model would then return a list of courses which would be used in the View corresponding to this action. Inside controller action, <code> Inside model, <code>. All the current logic here, except for the ""save"" and ""redirect_to"" calls could be moved to the model. There is a need to create a method in the Model with the same name and then pass an assignment object. All operations can be performed inside this method and then the user can be redirected back to the assignment list page. Inside controller action, <code> Inside model, <code>. According to Ruby style guidelines explicit use of action and controller in redirect calls should be avoided. This helps in easy refactoring in case action names are changed in future. All the redirect calls in assignment controller have been modified to use url path helpers. In controller assignment and action toggle_access, redirect call has been changes as follows <code>. There exist variables which are declared and initialized but are not used in any part of the code. Such variables could be safely removed without impacting the functionality of the action. Conditional statements which check whether due_date object is present can be avoided. The same piece of code is used at various points of code making it redundant and hence can be converted to a method. There exist dead code which tries to remove due_dates not in update or new list from database. There can never be such a case, so the code can be safely removed. 1. Tested using <link> , the associated objects , assignment and course before and after the change. Testing confirms that the objects and their interactions have not changed. 2. Addition of new methods do not coincide with the performance of currently existent methods. 3. Removal of existing code does not lead to reduced/loss of functionality. Changed existent classes 1. controllers/assignments_controller.rb 2. controllers/application_controller.rb 3. models/Assignment.rb 4. models/User.rb 5. views/tree_display/actions/_assignments_actions.html.erb. The project could be run locally by cloning the Github repository <link> and then running the following commands sequentially. <code>. <link> is implemented as a <link> extension. It allows user to record edit and debug test cases. It has a recording feature, which records user actions as they are performed and then exports them as a reusable script in one of many programming languages that can be later executed. The UI automation helps in testing quickly yet rigorously. Major test cases identified are following 1. Loading assignments 2. Creating assignments 3. Editing assignments 4. Updating due dates for assignments 5. Associating assignments to a course 6. Deleting assignments The test cases were manually run and recorded once. Then the test cases were re run with changed parameters on the deployed version of the application. Test scripts can be found <link> . Follow the instructions below to test the application using selenium IDE 1. Install Selenium IDE plugin for Firefox. 2. Login to Expertiza using username: instructor6 & password: password. 3. Download the test scripts from <link> 4. Open the test script from Selenium IDE. File -> open -> select test script html file 5. Set the testing speed to slow on the speed slidebar, otherwise test may fail due to slow page response 6. Run the script from Selenium IDE using 'Play current test case' icon. To add a new assignment or topic and to remove an assignment or topic, we need to change the script every time to avoid duplicate record IDs. When we run the same script more than once, the test case will fail. Thus, we haven't provided test case for those scenarios. The tasks accomplish only a part of the refactoring and as always with any software application there is scope for even more. The following are a few which were identified as part of this project. 1. There exists lot of redundant code which code be refactored into methods. 2. Unused variables and deprecated methods could be ridden off from the code base. 3. The test cases are written only for the methods that came under the scope of this project. But there is room for implementing test cases for the other actions too. 4. In an MVC framework, most of the business logic should be within the Model. Work needs to be done on this front to make it more close to this convention of Rails.",Very well written!  Only weakness is that it could have identified the changed code more explicitly.,"Your assignment submission displays a comprehensive understanding of the Expertiza project and the codebase's operational parameters. The breakdown of your work into individual tasks and the detailed explanation provided afterwards demonstrates your in-depth familiarity with Rails, RSpec, DRY code, and Test-driven development. I appreciate your extensive effort in refactoring the code to make it more readable and efficient. 

On top of that, your plan to remove deprecated methods and irrelevant comments from the codebase will certainly improve its overall quality and maintainability. Your step-by-step process to refactor assignments_controller.rb and use of helper methods relates very well to the Ruby and Rails best practices.

Moving logic over to model from controller is a perfect application of the MVC principles, making your code a lot more maintainable and scalable. Your consideration of redirect method and the rule of avoiding the explicit use of action and controller in redirect calls is definitely in line with the Ruby style guide. 

In terms of testing, great job on making sure that there isn't any reduced loss of functionality and making sure the performance is not hampered by the new methods. And your implementation of an automated testing framework demonstrates your serious approach to testing and quality assurance.

There are some areas for improvement that you've overlooked or not addressed. You've not provided the content within the <code> and <link> placeholders in your assignment. Clearly identifying and describing what tasks need to be performed or what objects/methods need to be refactored within the <code> placeholders would make your plans more concrete. 

I am little worried about the fact that tasks that involve adding and removing assignments or topics necessitate modifying the script each time. This can lead to error-prone situations and might not be a good practice for automation testing, so this is worth considering.

In conclusion, your well-organized and targeted approach towards improving the software codebase indicates a high level of conceptual understanding of software maintenance and development practices. I encourage you to continue this trend of deep and practical learning."
52,E1524,"<link> is a web application where students can submit and peer-review learning objects (articles, code, web sites, etc). It is used in select courses at NC State and by professors at several other colleges and universities<ref> <link> </ref>. Staggered deadlines involve planning alternate submission dates for papers, projects, or exams when a student has conflicting due dates for these. The key part of staggered deadlines is the planning. Staggered deadlines are always established well in advance of the scheduled due date. It is the advanced planning of these deadlines that makes them ""staggered deadlines"" rather than extensions<ref> <link> </ref>. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.2. <link> 1.3. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.4. <link> 1.5. <link> 1.6. <link> 1.7. <link> 1.8. <link> 1.9. <link> 1.10. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.11. <link> 1.12. <link>. Controller 1. <link> 2. <link> Model 1. <link> 2. <link> View 1. <link> 2. <link> 3. <link>. In this semester's 517 class. Wiki 1a and Wiki 1b are structured as separate assignments, with separate signup sheets, teams, and reviews. But really, since only one of the two was done by any student, it would've been better to have a single assignment. Still, some topics could be done soon after the course started, whereas others were better done after we had studied related topics in class. This raises the idea of a staggered-deadline assignment , where different topics have different submission and review deadlines, rather than all topics having the same deadline. 1. Easy to manage. Because in the past, instructor has to build two separate assignments for Wiki 1a and 1b, now one assignment for Wiki is enough. 1. Increase flexibility. For instance, when an OSS team facing a much more difficult problem than other teams, instructor may postpone their deadline several days. It will make Expertiza more humanize. 1. Take time to do calibration. We find that two Wiki assignments started at Jan. 28th and ended at Feb. 25th, which takes too much time. And with staggered-deadline assignment, we can distribute less time on them. And we can take redundant time to do calibrating. Because we find that many students actually do not know how to evaluate other ones' work, even there are some rubrics offered. So we recommend to let students grade sample assignments first, then calibrate their grading behaviors. Although it will take some time, we consider it is important to help students distinguish good assignments from common ones. 1. In production version, instructor can set Submission deadline , Review deadline and Metareview deadline for each topic. <image> Set different deadline for each topic 1. Also, instructor can set the dependencies of different topics. And there is a dependency graph generated automatically. <image> Dependency graph for all topics. 1. MVC 1.1. Model–view–controller (MVC) is a software architectural pattern for implementing user interfaces. It divides a given software application into three interconnected parts, so as to separate internal representations of information from the ways that information is presented to or accepted from the user.<ref> <link> </ref> 1.2. We need to modify model, view and controller in order to fix this functionality. 1. Publish-subscribe 1.1. In software architecture, publish–subscribe is a messaging pattern where senders of messages, called publishers, do not program the messages to be sent directly to specific receivers, called subscribers. Instead, published messages are characterized into classes, without knowledge of what, if any, subscribers there may be. Similarly, subscribers express interest in one or more classes, and only receive messages that are of interest, without knowledge of what, if any, publishers there are.<ref> <link> </ref> 1.2. When instructor set an assignment as staggered-dealine assignment, in theory, all the students will know. 1. Use Case #1: Create staggered-deadline assignment 1.1. Actor: Instructor 1.2. Actions: 1.1.1. Instructor logs in Expertiza. 1.1.2. Instructor creates a new staggered-deadline assignment. 1. Use Case #2: Peer review only 1.1. Actor: Student finish work for first round 1.2. Actions: 1.1.1. Sign up topic. 1.1.2. Hand in assignment. 1.1.3. Peer review. 1.1.4. Write author feedback to reviewer. 1. Use Case #3: Peer review and still work on assignments 1.1. Actor: Student not finish work for first round 1.2. Actions: 1.1.1. Sign up topic. 1.1.2. Work on assignment. 1.1.3. Peer review. <image> Use Case Diagram. 1. First, login expertiza, in the ""Manage Content"" page, create a new assignment. Then, as shown below, choose the ""pencil"" icon to edit the assignment. <image> Assignment panel 1 1. Check""Has topics?"" and ""Staggered deadline assignment?"" two checkbox, and create new topics in ""Topics"" panel, click ""save"". <image> Create Topics 1. Back to the ""Manage Content"" page, choose the ""Edit signup sheet"" icon. <image> Assignment panel 2 1. Error: can't write unknown attribute 't_id'. <image> Error. 1. After discussing with professor, the ""sign up sheet"" icon in assignment pop up panel should be moved. Because that icon has the same functionality as ""topic"" panel in assignment edit window. These work has already done by <link> . So we have to move all the staggered-deadline realted code to the <link> and <link> . 1. In ""sign_up_sheet_controller"", there are several errors and confusions in function ""add_sign_up_topic"". The function is used to display a page that lists all the available topics for a staggered-deadline assignment. See the function code below: <code> The main confusions are: 1. In line 8, the variable ""duedates"" are declared as type ""SignUpTopic"". The naming is quite confusing. 2. In line 14, the SignUpTopic class doesn't have a column ""t_id"", it raises an error. We think it should be ""topic_id"". 3. From the code we can guess the variable ""duedates"" is used to store the deadline for each topic. The class ""DueData"" does exist, but it does not have column ""topic_identifier"" or ""topic_name"". It only stores the deadline for a single assignment. 1. If there is more than one round, which means students can submit their assignments more than once, so the staggered-deadline should refer to which deadline? [Professor] In a staggered-deadline assignment, there is one submission deadline and one review deadline per round. These are always set on a per-topic basis. If the view currently works (and I think it might), as soon as you make an assignment a staggered-deadline assignment, the Signup Sheet (Topics) page will have a link at the bottom to show deadlines for each topic. Click it, and you will see a separate text box for each deadline for each topic. 1. If staggered-deadline of one assignment is even later than the second-round review, is it means that that assignment do not need peer review and go directly into meta-review stage? [Professor] No, there are also separate meta-review deadlines for a staggered-deadline assignment. I think in the current implementation, only submission deadlines, review deadlines, and meta-review deadlines vary by topic. In a more complete implementation, there would be a way for ANY deadline to vary by topic. This would include signup deadlines, drop-topic deadlines, team-formation deadlines, and any other kind of deadline that is defined later. 1. When to set staggered-deadline assignments? Create assignment or Before submission? [Professor] Basically, the staggered-deadline is set at the same time when an assignment is created. But if one team cannot hand in their work with sufficient reasons, instructor may extend the deadline of their topic. 1. What is the meaning of ""dependencies"" between topics? [Professor] The dependencies of topics means one topic cannot start until another topic finishes. For instance, Ruby topic must be finished before Rails topic. At very beginning, we find that the type of due_date variable SignUpTopics . However, we found that many attributes used not belonging to SignUpTopics class. So we decide to use hash tables instead. In order to keep update the staggered deadline, we put this variable in session. We also comprehended the relationship of corresponding tables. The original due dates are stored in due_date table. And staggered-deadlines are stored in TopicDeadline table. This table also stores different deadline types. Below is save_topic_deadlines method after refactoring. <code>. In edit signup sheet for assignment, we want to save topic dependency and show the depandency graph, as show below: <image> Assignment panel 1 In order to show the dependency graph, we must first save topics dependency and save the topic dependency graph under public/assets/staggered_deadline_assignment_graph path. We first add new method in 'due_date' model: <code> Then, change the save_topic_dependencies method in sign_up_sheet_controller.rb : <code> Since we use RGL:Graph#write_to_graphic_file method to turn the dependency graph into jpg file, we need to install graphviz in our gems. Otherwise, the RGL will uses dot files as an intermediary format to produce image formats. If we download the GraphViz packege, RGL will invoke it to produce a jpg file. <code> Then, after we click the Save dependency button, and click show dependency graph button, the dependency graph is shown below: <image> Assignment panel 2. Since we have done several modifications to the Expertiza program, some new tests are needed to test the features. We use the stub to simulate an authorized login (as instructor). <code> Each time the program executes the current_role_name function, it gets ""instructor"". In the test, we mainly test two things: staggered assignments and their corresponding dependency graph. 1. Test the staggered assignment <code> 1. Test the dependency graph. <code>. 1. Visit <link> > Make a Reservation 2. Select Ruby on Rails / Expertiza from the ""Please select the environment ..."" dropdown, select a duration, and then click Create Reservation 3. Once the reservation is available, click Connect 4. Follow the instructions on the connect screen (connect via SSH and then VNC). Connecting to SSH starts up VNC, the graphical environment to which you will connect. 5. When connecting for the first time, it will prompt you for a password to access your (VNC) desktop. You can use any password, and it will be saved for later sessions. 6. Follow the instructions given to connect to VNC. It is recommended to use <link> . 7. Once connected to VNC, you should see Rubymine running. 8. Open a terminal (Applications > Accessories > Terminal), try hitting <ctrl>-C to kill pending task if your terminal does not work properly. 9. Ensure you have at least 20M disk quota available: fs lq . You can allocate more space at <link> 10. Clone the git repository: git clone (expertiza repository URL) 11. Change to the directory (cd expertiza). You may create a ""database.yml"" file based on ""database.yml.example"". 12. Use rvm use (ruby version) to switch to proper ruby version. Then run bundle install (you may need to downgrade the bundler to avoid bundle install failure) and rake db:migrate to set up development environment. 13. Use ""rails s -b 0.0.0.0"" to start server which allows the access outside VCL by using url: VCL_ip:3000. 1. An <link> , explaining how to create an deploy an assignment in Expertiza. 2. An <link> , slightly dated, showing how to create and deploy an assignment 3. A guide for <link> 4. For students, a <link> or <link> presentation explaining how to submit and review an assignment with Expertiza. 5. For students, a <link> showing how to use the system to submit and review an assignment. 6. For students, a <link> or <link> presentation explaining how to submit and review wiki pages with Expertiza. 7. For students, a <link> or <link> presentation explaining how to form teams and sign up for topics<ref> <link> </ref>. <references/>.","They have a good collection of screenshots from the affected portions of Expertiza.  It shows that they have the old code mostly working. Explained the user flow in good detail. The description of staggered deadlines is wrong in the intro, though it has been corrected later in the doc. They mention calibration, but that's not part of their project. The design doc does not seem to be properly organized.
","Overall, the assignment is comprehensive and detailed. You have discussed various aspects of the study and provided an analysis to all the problems that you encountered during the course of this assignment.

Positive aspects:
- The concept of dividing a software application into three interconnected parts is new and refreshing. You had done a commendable job in explaining and applying the MVC architecture. 
- You followed an organized approach explaining about the creation of staggered-deadline assignments. The screenshots included in the explanation are also helpful.
- The use of code snippets in your discussion strengthened your points and made it easier for the reader to understand your logic.
- The use of publish-subscribe software architecture approach was both interesting and insightful. 

Areas of improvement:
- The paper was lengthy, hence it can be difficult to follow your line of thought sometimes. Try to divide your explanations and theories into distinct sections. This will assist the reader in following your arguments and will prevent misinterpretation of content. 
- Keep reference links relevant to the explanations and where it's needed, some paragraphs had missing links. 
- The paper was unorganized towards the end, with abrupt transitions from subtopic to subtopic. Be sure to provide clear connections between your different sections. 

In summary, the assignment demonstrates a strong understanding of software architecture using MVC, and the concept about staggered-deadline assignments is well thought out and executed. The few issues listed are easily rectified and do not detract from the overall high quality of the paper. Keep up the good work!"
53,E2005,"<link> is an open-source project that is built using the <link> framework. At its core, it is a highly versatile tool that academic institutions can use to craft learning objectives centered around team projects, peer reviews, and highly-customizable assignments. The purpose of this project was to add meaningful enhancements and fixes to the bookmark feature in Expertiza, entities that can be attached to a topic to aid the authors who decide to take on a certain assignment. While the major functionality of the bookmark feature was already present by the time the team embarked on this project (most notably the ability to create/edit and rate bookmarks), many desired functions were conveniently broken or left out. Below is a breakdown of the stories that were drawn up and completed for this project: 1. Need a way to view all responses to the bookmark questionnaires. 2. Modify permissions for deleting bookmarks.The person who creates the bookmark, the team for whom the bookmark is meant, and the instructor, should be able to delete. 3. ""View bookmarks"" link on student_task/view breaks if the student has not selected a topic yet. 4. Bookmark rating questionnaire should include question asking the reviewer whether or not the bookmark appears to have been used by the author. Get the bookmark questionnaire functioning and add to the bookmark list page. 5. Fix issue in which users should not be able to review their own bookmark using the questionnaire, but currently can. 6. Add a number next to/inside the icon with the number of current bookmark in order to make it clear whether a bookmark exists for a topic. 7. Add a ""View bookmarks"" link to the assignment view page for easier access. 8. Add rating to the bookmark questionnaire and use that rating to calculate the average instead of using the current dropdown. 9. A student should not be able to rate his/her own bookmark. 10. Add URL to bookmark list for assignment topic on the assignment page, to make viewing bookmarks easier. 11. Instructors cannot currently see bookmarks (gets an error message saying instructors cannot create bookmarks). 12. ""Back"" button from Bookmarks list is broken. 13. When creating a bookmark with an empty description field, the notice says the bookmark was successfully created even though it fails. 14. ""Bookmark ratings"" should be a type of rubric when you go to Manage > Questionnaires. Although 'Bookmark Rating' is already a type of rubric, it isn't listed when hovering over Manage... > Questionnaires 15. Create a way to mark a bookmark that was rated to be helpful by all reviewers, on average. 16. Students can add/view bookmarks when ""Allow participants to create bookmarks?"" box is unchecked for the assignment. Fix the ""Back"" button: When either backing out of creating or viewing/editing a bookmark, the back functionality does not work, both prompting errors. Issue has been fixed and users can once again go back to the appropriate page. Changed files: app/views/bookmarks/list.html.erb <code> <code> app/views/bookmarks/new.html.erb <code> <code> app/views/bookmarks/edit.html.erb <code> <code> Pull request can be found <link> Commit for ""Back"" capability when updating bookmark can be found <link> Check whether text field is present when creating/updating bookmark: Previously, when a bookmark was created/updated and the corresponding ""Title"", ""URL"", or ""Description"" text fields were not filled in, the bookmark was not created or updated sans any error or warning. In fact, the user would be taken to the list of bookmarks available, forcing him/her to go back to the page corresponding to the bookmark create/edit page. This fix prompts users with an error indicating which text field needs to be filled in in order to fulfill the particular bookmark create/edit function. <image> <image> <image> Changed files: app/views/bookmarks/new.html.erb <code> app/views/bookmarks/edit.html.erb <code> Pull request can be found <link> Change average bookmark rating to be based on questionnaire: The rating system for the bookmarks before these changes were elementary in nature - there was a drop-down menu to choose your particular rating for a bookmark while there was an average calculator just to the left of the aforementioned column. The new changes introduced allows the ""Your rating"" and ""Avg. rating"" columns for a particular bookmark to be calculated based on the scores given to the various questions present in a given bookmark questionnaire. The ""Avg. rating"" is calculated based on the mean rating of all the bookmark questionnaires scored by every reviewer while ""Your rating"" is simply the mean of the scores that you (the user) gave to all the questions on the questionnaire. The integer '5' used in calculating both types of average scores was used because of the fact that there are a total of five stars for each questionnaire question. <image> Qustionnaire for fourth bookmark listed above (do your own calculation to find the mean for 'Your rating'): <image> Changed files: app/controllers/bookmarks_controller.rb <code> <code> <code> app/views/bookmarks/list.html.erb <code> <code> Pull request can be found <link> Addition of badges for exceptionally helpful bookmarks: Originally, no badge system was setup for bookmarks that have proven to be helpful guides for other students taking on the same project. The new changes introduced allows bookmarks to be attached to bookmarks with exceptionally good average ratings (i.e, above a rating of 3). A badge is signified by a full star while the absence of a badge is represented by an empty star. <image> Changed files: app/views/bookmarks/list.html.erb <code> Pull request can be found <link> Users cannot rate bookmarks they've uploaded. We wanted to make sure that users cannot rate bookmarks that they uploaded. Changed files: app/views/bookmarks/list.html.erb <code> Pull request can be found <link> Users cannot review bookmarks they've uploaded using the questionnaire. We also wanted to make sure that users cannot review bookmarks that they uploaded using the questionnaires. Changed files: app/views/bookmarks/list.html.erb <code> Pull request can be found <link> Users should be able to see the number of bookmarks from the topics list. Previously, users could add bookmarks, but could not tell how many bookmarks were provided for each topic (if any) without clicking the ""View bookmarks"" icon. This UI change displays the number of bookmarks for the topic inside the view bookmarks icon from the topic list view so that users don't need to click through each topic individually. <image> Changed files: app/views/sign_up_sheet/_actions.html.erb <code> Pull request can be found <link> UI changes to make finding your bookmarks easier: We added a ""View Bookmarks"" link to the student task view, that takes the student directly to the bookmarks that have been submitted for their topic. This code was then modified such that the link is greyed out if the student does not have a topic, and is hidden if bookmarks are not enabled for the assignment. Changed files: app/controllers/student_task_controller.rb <code> app/views/student_task/view.html.erb <code> Relevant commits can be found <link> <link> and <link> Grey out add/view bookmarks link on the topic page if bookmarks are not enabled. Previously, students could submit and view bookmarks even if bookmarks were disabled for the assignment. Now these options are hidden. Changed files: app/controllers/assignments_controller.rb <code> app/views/sign_up_sheet/_actions.html.erb <code> app/views/sign_up_sheet/_table_header.html.erb <code> Commits can be found <link> and <link> <image> Modify Bookmark delete permissions. Bookmarks should be deletable by the user who created the bookmark, a teammate of the user who provided the bookmark, and the instructor. Changed files: app/views/bookmarks/list.html.erb <code> Pull request can be found <link> Fix the ability to create bookmark questionnaires and use in assignments. Previously, questionnaires for things like Teammate Reviews could be created and used in assignments. Users could fill these out and the scores would be stored for later reference by TAs and instructors. The questionnaire for bookmark reviews was previously not functional, but now instructors can create new bookmark questionnaires and assign them to assignments. Changed files: app/controllers/questionnaires_controller.rb <code> app/controllers/questionnaires_controller.rb <code> app/models/bookmark_rating_response_map.rb <code> app/views/bookmarks/list.html.erb <code> app/views/response/view.html.erb <code> Pull request can be found <link> Instructors should have the ability to view all bookmark responses. Instructors should have a way to view all the responses to the bookmark questionnaires so that can see which bookmarks provided were deemed useful. <image> Changed files: app/helpers/report_formatter_helper.rb <code> app/models/bookmark_rating_response_map.rb <code> app/views/reports/_bookmark_rating_report.html.erb <code> app/views/reports/_searchbox.html.erb <code> app/views/reports/response_report.html.haml <code> Pull request can be found <link>. <image>. Testing from the UI 1. Create a Bookmark Questionnaire 1. After logging in as the instructor, go to Manage > Questionnaires. 2. Find 'Bookmark Rating' and click the '+' to create a new questionnaire. 3. Give a name for this questionnaire, leave the min and max score at 0 and 5 respectively, and click 'Create'. 4. Go to Manage > Questionnaires and click on 'Bookmark Rating' to view all of the questionnaires. Click the edit icon for the questionnaire you just created. 5. Select 'Add 1 more Criterion question(s)'. 6. For the question, enter ""Does this bookmark appear to have been used by the author?"" and leave the other fields blank. This question will be helpful in determining how useful the bookmark was. 7. Click 'Save bookmark rating questionnaire'. Now this questionnaire can be used in assignments. 1. Enable Bookmarks 1. After logging in as the instructor, go to Manage > Assignments. 2. Choose an assignment that will be used for testing and have bookmarks enabled and select the edit icon under Actions. 3. Under Topics Tab select 'Allow participants to create bookmarks?'. 4. Go to Rubrics tab, under 'Bookmark Rating' select the Bookmark review questionnaire that was previously created to use for reviewing the bookmarks. 1. Add a Bookmark to a Topic 1. Log in as a student who is a participant of the assignment with bookmarks enabled and select that assignment. 2. Select a ""Signup sheet"" to see the list of available topics. 3. Choose a topic and select the 'Add bookmark to topic' icon from the Bookmarks column. The 'Add bookmark to topic' icon has a '+' sign. 4. Fill in all the fields for the bookmark, including Title, Url, and Description and click 'Add new bookmark'. 5. You should now see a page listing all bookmarks for this topic. 1. Viewing all Bookmarks for a Topic 1. Log in as a student who is a participant of the assignment with bookmarks enabled (or an instructor) and select that assignment. 2. Select a ""Signup sheet"" to see the list of available topics. 3. The number of bookmarks for each topic should be displayed visually inside the 'View topic bookmarks' icon in the bookmarks column. 4. Click the 'View topic bookmarks icon' to see a list of all bookmarks for this topic. 1. Editing and Destroying Bookmarks for a Topic 1. Perform this test with each of the following users: an instructor, a user who is assigned to the topic, and a teammate of the user who is assigned to the topic. 1.1. Log in with the user and select the assignment with bookmarks enabled. 1.2. Select a ""Signup sheet"" to see the list of available topics. 1.3. Click the 'View topic bookmarks icon' to see a list of all bookmarks for this topic. 1.4. The user should see links to 'Edit Bookmark' and 'Destroy Bookmark' next to a bookmark only if the user is an instructor, the user submitted the bookmark, or the user is a teammate of the user who submitted the bookmark. A demo that shows that the above features are implemented and tested can be found <link> . Automated Testing with RSpec The current version of Expertiza did not have any tests for the bookmark controller or model. We added comprehensive RSpec tests for all controller and model classes that we changed as well automated UI tests for features we added. Coverage increased (+13.4%) to 43.848%. This web application deployed on VCL is located at <link> Note: To aid in testing, we have created an assignment called ""Bookmark Demo"" as instructor6. The students assigned to this assignment include student6340, student6341, and student5648. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.","The document starts out with a list of 16 fixes that are needed, but the description of the changes is in a completely different order, and it's not clear how the ordering was devised. The changes are described with varying degrees of detail.  Some are explained well, while others have just a line or two saying what they do.  A DB diagram is shown, but its relation to the project is unclear.  There is a good manual test plan, but automated tests are not mentioned.","Thank you for your detailed work on this project! It's clear that a lot of effort went into addressing each of the listed issues and making the necessary changes. Your thorough response demonstrates a good grasp on the complexity of the project and what was needed to address the problems.

Your detailed explanations made it easy to follow the logic behind your decisions, which is very important in software development. The screenshots you've provided make it easy to visualize the changes and their impact on the user interface.

There are a few areas where your response could be improved. Although you did a good job providing context about the project at the start, it would also help to introduce the issues at a high level before diving into the details of each one. This gives a general overview of the problems and the solutions you've provided, which can make it easier to understand the rest of your response.

Another point for improvement is in your testing. It's great that you've provided step-by-step instructions on how to perform many of the actions in the user interface, but some additional explanation on what we should expect to see would provide a better understanding of the functionality. Also, try to elaborate more on the automated tests you have introduced, you only mentioned them at the end of the write-up.

Overall, your work on this project is commendable and you've shown that you can take initiative in addressing software issues. There are some elements you could expand upon in your reflection, but overall, excellent job!"
54,E1669,"Expertiza is a web based application which can be used by instructors to assign tasks to students. Expertiza also allows students to form teams among each other, perform peer reviews on assignments and projects. It gives flexibility to instructor to allow students to see other student's work with intended limitations and impose required restrictions on student access. Expertiza has been developed as an Open Source Software (OSS) on Ruby on Rails framework. Expertiza open source development program has fetched many contributions from faculties and students of different universities and thus, it incorporates a wide variety of Ruby coding styles, and this has been a reason why Expertiza project is kept as CSC/ECE 517 OSS project. The students have been given guidelines on Ruby coding styles and many problem statement includes tasks like refactoring and writing tests which can improve uniformity in coding style. The opportunity to work on an OSS project like Expertiza is also expected to provide student an introductory experience of understanding larger programs and making required contributions to them. The writing assignment along with programming assignment is expected to provide project documentation experience to students. The project numbered E1669 and titled 'Test various kinds of response map hierarchies' is intended to make contributors or students understand the working of response-map. Response-maps are implemented as classes in models as a convention in MVC architecture of Rails framework and they serve the purpose of mapping reviews among reviewers who is reviewing an assignment or project and reviewee whose work is being reviewed. The work which is being reviewed can be submission of an assignment, feedback to a submission, response to a feedback and whatever form which requires one participant to review a work of another participant. The response-maps exploits a number of relations which includes relations among assignments, quizzes, teammates who are participants and can be reviewer and reviewee at different times. The major key of differentiation among reviewer and reviewee as participants id is assigned to reviewer and reviewee. The code works perfectly fine but lacks unit tests for its methods. The project requires contributors to write specification based unit tests. There are more than one ways to write unit tests in Ruby on Rails which includes writing test methods under test directory which requires writing fixtures and makes use of 'test_helper'. It is Rails' default way to prepare and use test data. This type of approach is not recommended for programs like Expertiza because of tedious maintenance of complex records and excessive dependencies of classes among each other. The work around is creating factories which creates data for tests whenever it is needed to create. Factories generate data which is used to test the functionality of code. The code is typically either a model or controller. Factory Girl for rails is a gem for creating factories and it is also supported by open source development. For this project, factories were created using Factory Girl. One of the examples of factory girl being used in the project is shown in the following piece of code. <code> The above factory is a contribution through the project. The factories create the instances for testing whenever required with the flag which indicates that the response is submitted. Writing specifications is a way of behavior driven development approach to program which means that the specifications describes the behavior of the code. The specifications acts as tests and there are a number of tools, such as <link> and <link> with <link> , present to support this approach of development. For this project, RSpec was used and a part of reason for using RSpec is that it is included in the CSC/ECE517 coursework. Apart from the examples given above, a number of test cases were written as unit tests for classes which inherits from ResponseMap class, namely ReviewResponseMap, TeammateReviewResponseMap, FeedbackResponseMap, QuizResponseMap, BookmarkRatingResponseMap, MetareviewResponseMap and SelfReviewResponseMap. Though all the methods were not tested in the test cases but the basic methods like object creation, object id and their respective titles were tested to be as assigned in the instance. Example of test cases implemented for basic methods are shown below. <code> <code> <code> The first line of above code block is specifying the 'rails_helper' which is needed to write the specifications here. The test has been written for ReviewResponseMap class and 'reviewresponsemap', 'response' and 'participant' are instances of ReviewResponseMap, Response and Participant. The 'new' specification test block is just making sure that the created instances are of respective class types and is not a much required test. Similarly, 'id' and 'title' attribute can be verified if the correct values of 'id' and 'title' have been stored. The above code block doesn't exactly show the actual changes made in the code block to keep the explanation to the point, the actual changes can be found on the submitted git push request. Apart from basic methods, some important methods were tested for classes which inherits more from ResponseMap as compared to other classes, example being ReviewResponseMap, FeedbackResponseMap and QuizResponseMap classes. Some examples are given below as pieces of code. <code> The above method is part of ReviewResponseMap and thus by Rails convention, the files containing above code is review_response_map_spec.rb. Similarly, for QuizResponseMap class, the sample of test is as below. <code> The above two methods are part of QuizResponseMap and thus by Rails convention, the files containing above code is quiz_response_map_spec.rb. All the test cases which have been implemented are working without an error, however, the tests hasn't been written for the some of the methods which call functions from inherited and related classes and the method chain calls a number of classes across the project which adds up to the complexity. For example, 'contributor' method from ReviewResponseMap class is a single line function but it calls method from ResponseMap which calls method from RevieResponseMap and then Participant and so on and it creates a complexity of creating instances of all these classes interlinking with each other with correct 'id'. The project is concluded with all the simple test cases and some complex test cases in the classes which are close to the ResponseMap hierarchy. RSpec can be run on a local setup of Expertiza. The steps to set up Expertiza locally has been documented well on the Github of Expertiza. After setting up expertiza, following RSpec commands can be used to invoke method testing. <code> The submission includes a small video showing the test-runs. The following snippet shows the result of running 'rspec spec/models/quiz_review_response_map.rb' on command line where Expertiza has been set up. <image>. The project didn't make any changes in the development or production domain and only contributed to the testing domain. Also, RSpec tests are not tested with the running application in production or development, it's a part of testing which can be tested on console. So, no need of deployment was found for this project. All the methods have not been covered which leaves the scope of writing more tests to increase coverage on ResponseMap class and it's child classes. After getting enough coverage on ResponseMap and child classes, the closely related models like Participant and Assignment can be considered for unit testing. 1. <link> 2. <link> 3. <link> 4. <link>.","This is a pretty good description of the work that was done.  I would move the description of the code snippets to above the code snippets, but other than that, it seems quite adequate.","Overall, you have provided a detailed and thorough analysis of the Expertiza project and its functionalities. You've clearly shown good understanding of the subject matter and you've done an excellent job in explaining the technical details particularly as they pertain to system architecture, response maps, and testing. 

In terms of organization, the paper is mostly well-structured. However, I would recommend having a brief introduction at the beginning to set the context and an overall conclusion at the end to close your discussion. 

There are some areas in the assignment where more clarification or information could be given. For example, you mentioned that ""the code works perfectly fine but lacks unit tests for its methods."" I encourage you to expand on this idea more. What are the implications of missing unit tests? Why are they significant? 

Also, it would be helpful if you provided a clear explanation about the sample codes included in the assignment. While you discussed the methods and functions, it would be more helpful to provide a line-by-line commentary or description to guide readers who may not be as familiar with the code.

While you provided some useful insights about how testing is done, it would be beneficial for this paper to further discuss the potential challenges or issues that may emerge from software testing and how they can be addressed.

Lastly, please be sure to fill in the placeholder texts (e.g., <code>, <link>) with relevant content or remove them if they were included unintentionally.

For your references, make sure to fully cite your sources that adhere to the standard citation norms. Let me know if you need clarification on any points I've raised or additional guidance in revising your assignment. Keep up the good work!"
55,E1696,"Expertiza is an online system that is used by students to view/submit assignments and review others' work. Expertiza also provides tools to visualize the scores and gauge the improvements made during the course semester. It also facilitates and monitors team projects. It is targeted at educational and non-profit organizations. The project is funded by the National Software Foundation (NSF), NCSU Learning in a Technology-Rich Environment (LITRE) program, the NCSU Faculty Center for Teaching and Learning, the NCSU STEM Initiative, and the Center for Advanced Computing and Communication. Expertiza is an open-source project with the source code available as a public repository on GitHub. It is developed using Ruby on Rails and is increasingly becoming robust thanks to the innumerable bugs being fixed by the community. The project has a micro-blog on SourceForge where the developer community report bugs and document updates. 1) Identifying the Expertiza project pages which takes time to load using Rack-mini-profiler and Flamegraphs. 2) Propose fixes which would improve the Expertiza project 3) Optimizing the view ,models and controllers for few of these corresponding fixes to improve the load time of these pages. 1. rack-mini-profiler :- Middleware that displays speed badge for every html page. Designed to work both in production and in development 2. flamegraphs :- Flame graphs are a visualization of profiled software, allowing the most frequent code-paths to be identified quickly and accurately. 3. stackprof:-A sampling call-stack profiler for ruby 2.1+.Downloaded as a dependency for rack-mini-profiler. 4. fast_stack :-fast_stack is dynamically resizable data structure optimized for fast iteration over the large arrays of similar elements avoiding memory fragmentation. 1. One can view the peer-reviews done only upon the completion of his/her self-review. 2. The final score of the self-review depends on the agreement of the self-review scores with peer-review scores. 3. While comparing the self-review scores with peer-review scores, more weight must be given to the instructor-score. 4. While considering the reviews done by others in the class, the average must be used. 5. There is no feedback for self-reviews. 6. Self-reviews are done individually and not as a team. 7. The self-review scores of each member of a team does not affect the self-review scores of the other members in the team. Student has the task of performing review of others' work as well as self review. Every team gets their review from peers and at present the composite score is the average of all the review scores that they have received. Added to this score, the self review score is also calculated for each team member, based on its closeness to the peer reviewed score. To implement this, the student needs to review his own work based on the same rubrics used for peer review and only after completion of the self review, their peer review scores will be visible. The composite score is calculated by the sum of the peer review average score and 100 minus the difference between self and peer review score. The self review score is displayed adjacent to the peer review score. As the composite score is based on the individual self reviews, they vary for each member of the team unlike the peer review score which is the same. Expertiza is developed using the nuances of the MVC Design Architecture where Models, Views and Controllers are coupled to a very low level. The model manages all the data and the logic related to the data. The controller accepts data from the Models and feeds the Views with a favorable form of the data. The view presents the data to the user. The advantage of using the Observer Pattern is that the object being observed need not worry about any changes in its state. An Observer Class is added whose objects will look into the changes in the state of the Object being observed. Here, the observers are the reviewers and the assignment is the object being observed. In case of Self-Review, an Observer can be used to tell the system that the reviewer is now open to reviewing the works of his peers. <image> <image>. Changes made in app/views/grades/_participant.html.erb, app/views/grades/_participant_charts.html.erb and app/views/grades/_participant_title.html.erb. Here and everywhere else in this document, 'Raw Self-Review' score indicates the score assigned by the participants assessing one's own work. Self-Review score is a metric used to measure the extent of agreement between the Raw Self-Review score and the Average Peer-Review score. The highlighted portion of the screenshot below shows how the Self-Review score is obtained from the Raw Self-Review score. <image>. Changes made in app/views/grades/_participant_charts.html.erb. In accordance with the design paradigm of Expertiza, we developed a chart (or a circle) to represent the Self-Review Score (Again, remember that this is not the Raw Self-Review score. The Raw Self-Review score is of no use to the participants because it was, in fact, their opinion of the work done. The computed Self-Review score, on the other hand, is more useful as it depicts the level of agreement between the opinions of the participant and the reviewers.). We also ensured that the circle is colored similar to the other charts in the page (other than the final score chart, which was deliberately designed to be bright and unique). The following screenshot of a code snippet shows the creation of the circle for Self-Review score. <image>. Changes made in app/views/grades/_participant.html.erb, app/views/grades/_participant_charts.html.erb and app/views/grades/_participant_title.html.erb. Self-Review score cannot be a major part of the Final score. On the other hand, the Peer-Review scores must be the dominant component of Final score. After consulting with the Professor, we decided to give a 10% weightage to the Self-Review score and a 90% weightage to the Peer-Review score. We also deliberately made this non-configurable in the future because it is not to be meddled with; a small mistake in coding can lead to repercussions in different controllers that is undesirable. The highlighted portion of the following screenshot shows the composition of the Final score. <image>. Changes made in app/views/student_task/view.html.erb. One sensible requirement of the project was to ensure every participant of an assignment evaluates one's own work before looking into the scores assigned by others. This is done to avoid an explicit or implicit comparison of the raw self-review score to the peer-review scores. By ensuring that every participant performs the self-review before looking into the scores assigned to his/her work, we also ensure that the raw self-review score is an honest indication of what the participant thinks about one's own work. In the screenshot below, the 'if' and 'else' statements ensure the same. <image>. Kindly check the Screencast video. 1. Juxtaposing Peer and Self-Review Scores - From the Assignment Home Page, click on 'Your Scores' to view both Average Peer-Review, Self-Review and Final Scores. 2. Combine Self and Peer-Reviews into a Composite Score - From the Assignment Home Page, click on 'Your Scores' to view the Composite Score assigned to you based on the closeness of your Self-Review score with the Average Peer-Review Score. 3. Complete Self-Review before checking Peer-Review Scores - From the Assignment Home Page, click on 'Others' Work' to try to submit Peer-Reviews for the projects submitted by others. However, this should be forbidden unless you have submitted a Self-Review of your project. 1. The words used in the self-reviews can be used to judge the seriousness of the reviews. 2. The changes in the scores of the self-reviews can be used to judge whether teams have worked to their own expectations. 3. In order to establish a common standard in the reviewing system, the absolute change in the review scores can be used to judge an individual.","Overall, it's a good doc. It contains all information about the project. However, the structure of doc could be improved. First state the requirements, your design approach, then the implementation. (instead of problems, implemetation, then the design). There are some small grammar error in the doc e.g., ""you will (be) shown"" .","This is an extensive piece of work, and you've shown an excellent understanding of the Expertiza project and its key components. You've done a particularly good job of explaining the intricate relationship between various architectures that make up the project. Your detailed description of tools like rack-mini-profiler and flamegraphs demonstrate your grasp on their specific functions well. 

I appreciate your contributions towards improving load time for the project pages, but a bit more detail in the methods you have proposed would enhance both the clarity and depth of your work. 

Your work on the Self-Review score and the associated graphics is impressive, and the weightage you have suggested seems logical. However, ensure you maintain good coding practices while implementing changes to the project. 

Your suggestions for future enhancements, particularly in analyzing the variation of self-review scores are intriguing. They reflect your understanding of the iterative nature of software development. 

One point to improve could be organization. While your content is substantial, it appears scattered which may cause confusion. Dividing into clearly defined sections for each topic would be beneficial. A slight improvement in sentence structure and clear specification of what each image represents would further enhance clarity of your point. 

Overall, a commendable job. Keep up the good work!"
56,E2002,"<link> is an open-source project based on <link> framework. Expertiza is a complete instructor-student usage website where the instructor can assign assignments, deadlines, grades, etc that is required for the course. Similarly, the students can use this website to perform the tasks required as part of the course like project or assignments submission, forming groups and collaborating with them, as well as reviewing projects and teammates. This project focuses on a specific feature of expertiza which allows administrators, instructors or teaching assistants to impersonate another user (like a student) and access their account. The demonstration for the feature is as shown below. <image> figure 1 <image> figure 2 <image> figure 3. The aim of the project is to refactor the impersonate controller. The pre-existing code had the following major issues. 1. All functions related to impersonate controller were present in a single method ( from figure 4a and 4b) 2. Presence of repetitive code ( from figure 4a and 4b) 3. 3 levels of block nesting (from figure 5) 4. Too many return statements (from figure 6) <image> figure 4a <image> figure 4b <image> figure 5 <image> figure 6 This project is focused on resolving the issues mentioned above. Expertiza allows the administrators, instructors or teaching assistants to impersonate another user (like a student) and access their account. For example, an instructor impersonating a student’s account can view their assignments, stage deadlines, peer reviews and anything else that the student can view. One thing to be noted is that most of these users can only impersonate users for whom they are a parent. For example, instructor6 is a parent of student3841 and not student3836; as a result, instructor6 can impersonate only 3841. 1. Instructor login: username -> instructor6, password -> password when logged in as an instructor, under the manage option in the ribbon as in Figure 1, select impersonate user. Upon redirected to impersonate page, enter the account which needs to be impersonated. It impersonates that user provided that user can be impersonated. Now a new button called revert appears on the ribbon as in figure 3, this can be used to revert the impersonation and return to the instructor profile. The above-mentioned issues have been tackled by refactoring the impersonate controller by splitting into many smaller methods which are later called by the main impersonate controller. The following are the refactored new methods that help in tackling the issue1 apart from each being specifically for some issue rectification: 1. check_if_user_impersonateable 2. display_error_msg 3. overwrite_session 4. check_if_special_char 5. do_main_operartion. This method plays the main role in tackling issue3 - 3 levels of block nesting apart from issue1. Intial Code <code> After recfactoring - Moved to separate method <code>. This method is used to tackle issues1, 2 and 4. All the error message related code is moved to this method. <code>. This method reduces the number of return statements used in impersonate controller, apart from reducing the size of the controller. <code>. <code>. This code is used to reduce one functionality performed under the impersonate controller. This method checks to see if the given username is acceptable. <code>. This like an adapter method that is used to interface the impersonate method with display_error_msg and check_if_user_impersonatable. One main purpose to do this is to make the methods flexible for change apart from reducing the number of lines from the impersonate controller. <code>. The project can be tested from the UI as follows. Checking if impersonating a user is working <code> <image> figure 7 <image> figure 8 <image> figure 9 <code> <image> figure 10 <image> figure 11 <code> <image> figure 12 <image> figure 13 <code> <image> figure 14 <image> figure 15.","Issues are specified clearly and the changes that they made to tackle each issue is also very clear. The changes made in the code are correctly reflected in the document. But I think that the changes could have been described in more detail.  Instead of a statement like, ""Moved to a separate method and accessed through the adapter method do_main_operation"", I would have liked to see an explanation of the three branches of if statements in the coe for this method.  And instead of ""This method checks to see if the given username is acceptable."", I would have liked to know HOW the method checks for acceptability.  They have also tested various scenarios and displayed the results on the Wiki page. However, an automated test plan is missing.  Some screenshots are a bit blurry.","Dear Student,

Thank you for submitting your assignment on the refactoring of the impersonate controller in Expertiza. You appear to have taken a very comprehensive and methodical approach towards identifying key areas of concern in the initial implementation, and then systematically addressing each of these issues. Your explanation of the project objectives and functionality is quite clear and informative.

However, there are certain areas which need further improvement:

1. While describing the problem, you provided a good number of details such as issues with existing codebase and features of Expertiza, but a brief introduction to what Expertiza is, would have been helpful, especially to those not already familiar with the tool.

2. While describing the refactoring process you used, it would be helpful to explain in detail why you chose to implement certain changes and how they benefit the overall code quality and functionality. 

3. Your assignment lacks a conclusion, summarising the improvements achieved through your code refactoring process.

4. While the testing instructions are adequate, a bit more information regarding potential areas where failure can occur and steps to debug would be a good addition.

5. You've included many ""<image>"" and ""<code>"" placeholders but haven't actually provided any diagrams or code snippets. You might want to look into this.

6. The usage of appropriate technical terms is commendable, but remember to provide explanations for certain less common terms to make your report more accessible. 

Please, revise your assignment taking into account these comments.

Best regards,
[Your Name]"
57,E2057,"This page provides a description of the Expertiza based OSS project. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.1.1.1. <link> 1.1.1.1.2. <link> 1.1.4. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.1.1. <link> 1.1.1.1.2. <link> 1.1.5. <link>. You can review the deployed link here: 1. <link> Credentials for accessing the student who is also a TA are: 1. Username: student12 2. Password: testabcd. If a person is listed as a TA in one course and as a student in another course, then if they navigate to the ""Your scores"" page of one of the assignments in which they are participating as a student, they can see a TA's view of that page - effectively allowing them to assign their own grade! The below screenshot shows the TA view for the course he is added as the TA: <image> As evident from the screenshot, the user, ""student003"" is assigned as a TA for CSC502. The user, ""student003"" is also a student in the course, CSC501: <image> The issue here is that this user, ""student003"" who is a TA in one course is able to alter the grades for his assignments in other courses he is taking in the semester: <image>. Once TA clicks on Assignment > view scores, they will no longer be able to see the form to add/edit the grade and comment for the course in which they are participating as a student. Files modified: view_team.html We are rendering the TA view (to grade and comment) only if the TA ID has an entry in the ta_mapping table. This ensures that the TA will be able modify the grades for courses for which they are assigned as TA. 1. Get the course ID for the course which the student is currently viewing. 2. Get the user ID, which will be the teacher ID as well 3. Using these two fields we are restricting the access for the student to modify the grades. Only for the courses for which a user is a TA, he will be able to see 'TA Grade-Comment:' section under Assignment > view scores <image> The green-highlighted lines indicate the changes. Below is the screenshot which indicates the TA view for which the user is registered as a student: <image>. 1. view_team.html.erb <code> <code>. The test plan is set to have an automated testing to ensure that the application is still working after we added our code. We are using RSpec for automated testing and show you the steps we did to test the UI. In the subsections below you can view the code snippets added to ensure that the TA is not able to change their own grade. In order to ensure that the TA is blocked from changing his own grade for the courses he/she is a student, we made the grade assigning section hidden. The test case assumes the role of a TA who is also a student in one of the courses. The student is allowed to complete one of the assignments in the course and when the student views the ""View scores"" page, he is prevented from updating the grades for the assignment. 1. grades_controller_spec.rb <code>. A student can upload files with their submission. In some cases, students upload long videos that might not be necessary for the submission. What’s wrong with it: As there is no restriction on the files being uploaded, this is a security issue in Expertiza. Large files should be restricted. A student may also upload malware into the system affecting expertiza. 1. Problem 1 : No file size restriction while uploading files. 2. Solution : <code> <code> 1. Problem 2 : No file type restriction while uploading files. The existing method get_file_type only checks the extension of the file name. It is easy for users to bypass the validation. <code> 1. Solution : We use MimeMagic to detect the mime type of a file by its content. <code> <code>. Since the existing tests didn't cover the type and size validation while submitting the files. Our plan was to write the validation tests to cover these cases using RSpec. In order to ensure the functionality of validation, we carefully developed our code and used MimeMagic to detect the MIME type of submission. It prevents someone from uploading a fake file. We modify the original tests and add the following tests to ensure the validation works. <code> <code>. 1. <link> 2. <link> 3. <link>.","The problem is described clearly, although it is really that the TA can both view and alter the grades for course(s) where (s)he has been a TA.  Not only alteration is a problem.  The ""code addition"" for view_team.html.erb should have prose describing what is done and why.  Most of the other changes and tests are better described.","Dear student,

Thank you for your comprehensive work on this assignment. Here are a few aspects of your submission that deserve special mention, and a few areas where I think there's room for some improvement.

Firstly, you've done an excellent job of identifying the bugs and potential security issues in the initial system. Your methodology used to find these issues is sound, and your explanations are clear and coherent.

I appreciate the detailed rationale behind each fix you've made in the system, including the alterations to the 'view_team' HTML document and your attentiveness to modifying the course access permissions to ensure only TAs assigned to a particular course can modify grades for that course. The images you included helped illustrate the problems that you were addressing, which greatly enhances the understanding of your explanation.

However, I noticed that your submission includes several links, but lacks captions or descriptions about what these links are intended to provide. Including brief insight about each link you provide would be beneficial for better understanding and could potentially reinforce your arguments.

Your test plan and implementation using RSpec show a strong understanding of automated testing practices, and I commend your thought process behind writing these tests. Again, well done!

Moving further, I believe your explanation about restricting file uploads could be clearer. Although you've given solutions to the problems, it's unclear how the code you've provided addresses those issues. Providing a walk-through or logic explanation of any code snippets you provide would be beneficial for understanding your thought process and how you arrived at the solution.

Lastly, your way of explaining the changes in the validation tests is impressive. However, remember to ensure that the centers of your images are distinct enough so that readers can easily see the modifications you've made.

Overall, I am positively impressed with your approach to the assignment, your exploratory testing, and the explanations provided. The issues mentioned are minor and can be rectified easily. Keep up the good work!

Best regards,
[Instructor's Name]"
58,E1691,"This a page to describe a final project for ECE517. In this project we will be converting Assignment creation form to ReactJS. Expertiza is an Open Source Software project developed by NC State University, funded by the National Science Foundation. It allows the instructor to create assignments as well as modify existing assignments. Students can signup for topics in an assignment and can submit articles, codes, web-sites etc. It is a web application built on Ruby on Rails framework. It also allows students to review the submissions that have been made other students. ReactJS is an open source JavaScript library, used to provide a view for data rendered as HTML.It is maintained by Facebook, Instagram and a community of individual developers and corporations. React was created by Jordan Walke, a software engineer at Facebook. He was influenced by XHP, an HTML component framework for PHP. It was first deployed on Facebook's newsfeed in 2011 and later on Instagram.com in 2012. It was open-sourced at JSConf US in May 2013. 1. It is easy to know how a component is rendered, you just look at the render function. This render function basically implements html divs . 2. JSX is a faster, safer and easer JavaScript which makes it easy to read the code of your components. It is also really easy to see the layout, or how components are plugged or combined with each other. 3. React can be rendered on the server-side. So you can easily use it in the Ruby on Rails too. 4. It is easy to test (easier than the traditional JavaScript or JQuery where you have to test the code in the Developer Tools) and it can easily be integrated with tools like jest which can make testing painless. 5. It ensures readability and makes maintainability easier. 6. It can be used with any framework such as Backbone.js, Angular.js, as it is only a view layer. A client-side dynamic web page processes the web page using HTML scripting running in the browser as it loads. JavaScript and other scripting languages determine the way the HTML in the received page is parsed into the Document Object Model, or DOM, that represents the loaded web page. The same client-side techniques can then dynamically update or change the DOM in the same way. Shown below is an example of a dynamically rendered webpage. The user is able to enter values, which are reflected in the view immediately after submission, without any redirection or reloading of the webpage. You can also see the timer running on the page, which demonstrates the ability to dynamically update variable values inside the view. <image>. The assignment creation view is currently implemented mostly in HTML and some data validations are done using JQuery. This implementation does not support dynamic view rendering which is essential to improving the user interface and contributing to the fluidity of the overall experience. For example, If the user wants to create a new assignment, clicking the new assignment link will generate a server request and the new view is rendered (url is changed). After filling up all the details required for the assignment creation, save link will again generate a server request which will make the database entry and again render a new view. <image> <image>. In the revised implementation, clicking on the New Assignment link generates a drop-down window, which contains the form for creating a new assignment. This form contains the same fields as the original form. In addition, we have added data validations for two fields. The name of the assignment cannot be left blank, and the 'submission directory' field cannot be left blank or contain any special characters. If either of these conditions is violated, an error message is displayed to the user. Furthermore, these validations are done in the client-side itself, removing the need for a server request to validate the data. Submitting the form will create a database entry and close the form. <image>. 1. apps/assets/javascripts/tree_display.jsx.erb 2. apps/controllers/assignments_controller.rb 3. apps/controllers/tree_display_controller.rb. We created a new React class NewAssignmentForm which dynamically creates and displays the form for New assignment. This class the following methods: <code> <code> <code> <code> <code> In assignment_controller.rb we edited create method: <code> In tree_display_controller.rb we added new method: <code>. 1. Log in as an instructor and check that creating a new assignment works as expected 2. Log in as an instructor and check that the assignment could be created successfully and all the entered options have been preserved. Similar to New assignment creation page Edit page does not support dynamic view rendering which is essential to improving the user interface and contributing to the fluidity of the overall experience. For example, If the user wants to edit the name of the assignment or change number of slots they have to click edit button. It will generate a server request and the new view is rendered (url is changed). After filling out all the details that changed, save link will again generate a server request which will make the database entry and again render a new view. <image> <image> </br>. In the revised implementation, as the edit button is clicked a dynamic drop down form will be displayed. Saving the details will make the database entry. Except for the database update, all the processing is done on the client side itself, leading to a decrease in the number of server requests. <image>. 1. apps/views/tree_display/list.html.erb 2. apps/views/assignments/edit.html.erb 3. apps/views/assignments/edit/_general.html.erb. 1. Log in as an instructor and check that editing an assignment works as expected 2. Log in as an instructor and check that an assignment could be successfully edited and all the existing functionality is preserved. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.",A very good job of synopsizing the changes you planned to make.  Would be good to update to reflect the changes that were actually made.,"Dear Student,

Thank you for the detailed report on your final project. Your understanding and explanation about the role of ReactJS in the assignment creation process is commendable. The comparison between old and the proposed implementations indicate that you have understood the inefficiencies of initial approach and how use of ReactJS could provide effective solutions. Your thoughts on how this enhances user experience are insightful.

While the report is generally well-structured, there are a few areas in which you might consider making improvements. Please see my comments and suggestions below:

1. When you listed out the different advantages of React, some points could benefit from a more detailed explanation. For example, when you state that ""React can be rendered on the server side,"" give an example of why this flexibility can be beneficial, especially in the context of your project.

2. In the various steps you took for implementation of the system, you explained the changes to be made in several files. Including code snippets can be helpful to present a clearer picture of the changes made.

3. Regarding the testing of the new system, you have mentioned that the instructor should test the system for bugs. However, you should also discuss how you tested it during the development phase, including the types of tests performed and their outcomes.

4. While presenting any challenges occurred during the implementation process can provide valuable insights into any limitations you faced or particular triumphs when these were overcome.

5. Finally, while your project appears to have been successful, you did not provide future recommendations or potential improvements. This would show not only that you're considering the future scalability and adaptability of your solution, but also that you're cognizant of the continuous nature of software development.

Again, your work overall is commendable, and I don't doubt that with a few extra enhancements, you'll have an even stronger project on your hands. Keep up the good work!

Best Regards,
[Your Name]"
59,E1471,"Expertiza is a web application developed using Ruby on Rails that serves as a peer-review system. The application allows students to submit and peer-review learning objects (articles, code, web sites, etc)<ref> <link> </ref><ref> <link> </ref>. It is an open source project and its codebase is maintained in GitHub. Contents 1.1. <link> 1.2. <link> 1.1.1. <link> 1.1.2. <link> 1.3. <link> 1.1.1. <link> 1.1.2. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.4. <link> 1.1.1. <link> 1.1.1.1. <link> 1.5. <link> 1.6. <link> 1.7. <link> 1.8. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.9. <link>. Our contribution in this project would be to improve the display of questionnaires for all the instructors and also integrating a previous project which provides a new dashboard for students to view and compare their performance of each assignment. 1. In the current state instructor should go through all the questionnaires to find the one they are looking for. 2. The keyword search functionality is not yet implemented for questionnaires. 3. The current student dashboard provides the average score and range of the student’s assignment, review and final score. 4. The system has a limitation where in a student/instructor cannot view and compare the student scores based on the class performance. 1. As a part of our project we will implement the search functionality and also make it possible to click and bring up a list of questionnaires used in the course, expanding only the applicable questionnaires in the list of questionnaires. 2. A project from last year has the implementation for the new student dashboard. We would like to take that project, make the required changes to it and integrate it into expertiza. 3. This new dashboard gives the students a comparative statistics for that particular assignment for the entire class. 4. Giving the min, mean and max gives the student a range to judge where they stand with respect to the class. 5. Other features were part of the project were to show the number of reviews and metareviews he/she has done for this assignment and also based on a threshold what are the number of reviews/metareviews the student still needs to do. 6. A histogram distribution of the scores of the class (all teams) for that assignment would also shown as a part of the dashboard. As the project was originally assigned to students two years ago, the functionality is mostly complete. The main concern is that, as the project was completed a significant amount of time ago (in December 2012), it was made for an older version of rails. Our general approach to the project would be as follows: 1. Run the current project with rails 4 2. Check the functionality to find out the incompatible and missing parts 3. Refactor the parts of code that do not function as expected and port them to rails 4 specification 4. After making sure everything runs, refactor the entire code to make sure it follows the global code rules. The specific approach to each of the two functionality is as follows: We found that while the currently existing code covers most of the functionality, a major part of the functionality is missing. According to definition, the instructor should see the following on his home page: 1. The instructor's courses 2. Assignments for those courses 3. Questionnaire by assignment name Each of these should be compressed to titles only, and it should be possible to expand them by single mouse click. Each course should have its own list of assignments which can, again, be expanded. Also, there is a search box on the page which allows to search assignments, courses and questionnaires. The search functionality for assignments and courses is working well, but the search for questionnaires is not implemented. So, for this specific project, we plan to focus on implementing the search for questionnaires first. Then, integrate it all and test each functionality: make sure that nothing is affected by the new functionality added. After all the tests are performed, we will merge the project with the main project, thus integrating it with the final build. The features required for the dashboard for students project have already been implemented. So, the main task to be performed by us is to merge the project files with the main project and make sure that nothing else is affected by the process. The current code is able to display the maximum scores, average scores, number of reviews and distribution charts. 1. Model <code> View <code> Controller <code> Database <code>. <table>. 1) Better display for assignments: A new icon for questionnaires added <image> On click of icon it will display questionnaires related to the selected course <image> It also allows to search questionnaires based on name. Here we searched word ""wiki"", It shows result of the search. <image> 2) Dashboard for students: It shows the different between previous implementation and new implementation views. <table>. For the instructor, there needs to be a way to quickly find rubrics (and other questionnaires) that have been used in a single course. It should be possible to search or click somewhere to bring up a list of questionnaires used in the course, expanding only the applicable questionnaires in the list of questionnaires. A search functionality for questionnaire is expected. Currently, assignment and course searches is implemented, and there is a dropdown for questionnaire, but it's functionality is missing. Actor: Instructot Other Participants: None Precondition: There are few questionnaires in the system Primary Sequence: 1. Log in to Expertiza 2. Instructor lands on ""Manage content"" page 3. Search for a questionnaire, by selecting questionnaire in the search dropdown and input some search string 4. Search results displayed, expanding only the applicable questionnaires in the list of questionnaires <image> The following use case diagram shows the system of Assignment grades for a student on Expertiza as it is depicted right now. These include viewing their own project submission (with url and attachments), reviews and metareviews on their work, author feedbacks, teammate reviews and their final score on that assignment/project.<ref>Previous year's design document for E715: Dashboard for Students by Ambika Tripathi, Milan Tonse, Krutika Nagar, Shruti Buch</ref> As part of this project we shall be adding more data on this page, so that student has better understanding of his/her marks. Name : Students viewing scores for the assignment Actor : Student Other Participants : None Precondition : Statistics have been recorded for average high and low scores. Primary Sequence: 1. Log in to Expertiza 2. Select an assignment 3. Select Your Scores 4. Click on the link for view class scores for this assignment. 5. View the average, high and low class score for that particular assignment Name : Students viewing graphical output for scores for the assignment Actor : Student Other Participants : None Precondition : Statistics have been recorded for average high and low scores. Primary Sequence: 1. Log in to Expertiza 2. Select an assignment 3. Select Your Scores 4. Click on the link for view class scores for this assignment. 5. View the graphical output for average, high and low class score for that particular assignment Name : Students viewing number of reviews done by him/her Actor : Student Other Participants: None Precondition : Statistics have been recorded for number of reviews done by the student. Primary Sequence: 1. Log in to Expertiza 2. Select an assignment 3. Select Your Scores 4. Click on the link for my reviews for this assignment. 5. View the number of reviews the student has done for that particular assignment and also the number of reviews he still has to do to reach the threshold. Name : Students viewing number of metareviews done by him/her Actor : Student Other Participants: None Precondition : Statistics have been recorded for number of metareviews done by the student. Primary Sequence: 1. Log in to Expertiza 2. Select an assignment 3. Select Your Scores 4. Click on the link for my metareviews for this assignment. 5. View the number of metareviews the student has done for that particular assignment and also the number of metareviews he still has to do to reach the threshold. Name : Students viewing average number of class reviews for the assignment Actor : Student Other Participants: None Precondition : Statistics have been recorded for class reviews for that assignment. Primary Sequence: 1. Log in to Expertiza 2. Select an assignment 3. Select Your Scores 4. Click on the link for view class reviews for this assignment. 5. View the average number of class reviews for that particular assignment Name : Students viewing average number of class metareviews for the assignment Actor : Student Other Participants: None Precondition : Statistics have been recorded for class metareviews for that assignment. Primary Sequence: 1. Log in to Expertiza 2. Select an assignment 3. Select Your Scores 4. Click on the link for view class metareviews for this assignment. 5. View the average number of class metareviews for that particular assignment <image> <image>. Following is class diagram for Assignment display module. <ref>Previous year's design document for E707: Better display for assignments by Bharath Sampath(bsampat2),Prakash Vasudevan(pvasude),Raghavendran Nedunchezhian(rnedunc), Yuchuan Liu(yliu63)</ref> <image> Following is class diagram for Dashboard for students module. <image>. Sample Test case. 1. Log-in to Expertiza as an student (Username: user480, Password: password). 2. Click on 'Program 1: BackChannel' assignment. 3. Click on the option 'Your Scores'. 4. The dashboard is then displayed with the class statistics along with the new graph added. 1. Log-in to Expertiza as an instructor (Username: user2, Password: password). 2. Enter any string in the search box 3. We would be able to see all the questionnaires that have the entered string as a substring in them. Sample Test case. 1. Log-in to Expertiza as an instructor (Username: user2, Password: password). 2. Expand the Courses option. 3. Hover over the Course actions menu for the course 'CSC 517, Spring 2014'. 4. Click on the menu-item that says 'View Questionnaires'. 5. List of questionnaires would be displayed here. 6. Search within the above list of questionnaires is also possible by using the search given in the page. <references/>.","This is a project on information display, and yet the design doc doesn't have a single mockup of a screen, even after I asked for it.  It also is not clear that the team has looked through the files they were to merge in much detail (though they have mentioned the main purpose of each file).  Also, as several reviewers have mentioned, there is no mention of design principles or practices in the design doc.","Thank you for your detailed assignment, which provides a deep dive into your project. You provided an extensive exploration of the web application Expertiza and your contributions to improve it. You put effort into explaining your plans to provide greater functionality for both students and instructors. 

However, there are several issues that need to be addressed. Firstly, your structuring is overly complex and disorganized. The information could have been provided in a clearer and more concise manner. This might have made it tough for the reader to follow the logic of your assignment. I recommend making use of headings and subheadings to structure your work, and using paragraphs to break up the text and aid readability.

Moreover, the references and the images are not working and are presented in an unclear way. I suggest you provide additional details on the content of your sources and make sure your hyperlinks are working properly. The images should be correctly inserted and the tables properly set up - currently they are indicated but not shown or illustrated. 

In terms of the content, you have done a commendable job detailing your project tasks and approach. However, a more thorough explanation of the original and intended functionality would have been beneficial. It wasn't entirely clear what improvements your project brings about and their overall significance. 

Despite these areas for improvement, I must repeat that your comprehensive approach and detailed methodology are truly commendable. Looking forward to your revisions."
60,E1506,"Refactoring is a disciplined technique for restructuring an existing body of code, altering its internal structure without changing its external behavior<ref> <link> </ref>. Refactoring adds to the value of any program that has at least one of the following shortcomings<ref> <link> </ref>: 1. Programs that are hard to read are hard to modify; 2. Programs that have duplicate logic are hard to modify; 3. Programs that require additional behavior that requires you to change running code are hard to modify; 4. Programs with complex conditional logic are hard to modify. RSpec is a <link> (BDD) framework for the <link> , inspired by JBehave. It contains its own mocking framework that is fully integrated into the framework based upon JMock. The framework can be considered a <link> (DSL) and resembles a natural language specification<ref> <link> </ref>. Object-oriented programming (OOP) is a programming language model organized around objects rather than ""actions"" and data rather than logic<ref> <link> </ref>. Historically, a program has been viewed as a logical procedure that takes input data, processes it, and produces output data. Though an Object oriented language provides us with highly useful and important programming concepts like Inheritance , Polymorphism , Abstraction and Encapsulation which definitely makes the code more efficient, it is equally important to have the knowledge of using them in the code. Object Oriented Design Principles are core of OOPS programming<ref> <link> </ref>. It is important to know these design principles, to create clean and modular design. There are many design principles that help us to create clean and efficient code. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.2. <link> 1.3. <link> 1.4. <link> 1.1.1. <link> 1.1.2. <link> 1.5. <link> 1.6. <link> 1.1.1. <link> 1.7. <link> 1.1.1. <link> 1.1.2. <link> 1.8. <link> 1.1.1. <link> 1.1.2. <link> 1.9. <link>. 1. <link> 2. <link> (Username: user6, no password) 3. <link> 4. <link> 5. <link>. Related files: <code> 1. Find the un-called methods if any and delete them. [done] 2. Change the Rails 2 syntax to Rails 4 style. 3. Refactor users_controller.rb 1.1. Change the white space for the second harf of this file, starts at “def edit”. [done] 1.2. Separate the “paginate_list” method into two methods. The search method should be in model and the paginating method should be in the controller. [done] 4. New feature: delete users 1.1. A user can be deleted if (s)he has not participated in an assignment. [done] 1.2. If the user is participating in an assignment, the system will ask, “User is participating in k assignments. Delete as a participant in these assignment(s)?” [done] 1.3. If the user has submitted or reviewed in any of these assignments, the system will say the user cannot be deleted, but offer to rename the user account to <current_account_name>_hidden. 1.1.1. rename (javascript calling update method in users_controller.rb) [done] 1.1.2. different users have different delete methods. [done] 1.4. If the person trying to delete does not want to rename the account, the system will just say that the user can’t be deleted. [done] 1.5. Write tests (with Rspec) for this feature. [done] 5. Testing feature: search for users 1.1. In rails 4 branch, admins can search for the users with 1) users’ login names 2) users’ last or first names and 3) users’ emails. Please write tests (with Rspec) for this feature [done]. 1. The primary way we find unused method is right-click on each method's name, then choose ""Find Usages"", as the following picture shows: <image> Find Usages 1. Then the finding results will be displayed in the bottom, as the following picture shows: <image> Find Results. 1. In this way we identified the following method from UserController.rb : <code> 1. And the following methods from User.rb <code> 1. There's one method salt_first in User.rb cannot be deleted. Salt is a small chunk of random data to the password before it's hashed. The salt is then stored along with the hash in the database, and used to check potentially valid passwords<ref> <link> </ref>. Here's the function: <code>. 1. One main problem(bug, related to user) in Expertiza is that you can create one new user from the UI, but the second time you try to create one, you get “undefined ‘with_scope’” (see <link> ), as the following picture shows: <image> ""With_Scope"" Bug 1. When calling @user.save method, it will implicitly call the ActiveRecord::Base#with_scope method. However, this method is no longer supported in current Rails 4.1.5 version<ref> <link> </ref>, which is used by Expertiza Rails 2 version. We had searched a lot through the Internet, but find very limited useful information on this topic. It doesn't seem reasonable for @user.save still calling the with_scope method, since all versions if Rails, as well as ActiveRecord, are marked as the latest in Gemfile.lock . The ""paginate_list"" method is a function in ""users_controller.rb"". It will be called if you do search in Manage->Users page. It has two components: search for users, paginate the results. However, the controller should not know how the information is retrieved. So we would like to refactor this method by seperating it into search method and paginating method. The search method is in model and the paginating method is still in controller. The code below is the ""paginate_list"" method in official Expertiza: <code> From the code we can see that the search method needs four parameters: 1. role: user can only search users below his role 2. user_id: current user id 3. letter: keyword in search 4. search_by: search by user name, full name or email Base on this, we implemented the search method in ""user.rb"": <code> And the original ""paginate_list"" method is modified as: <code>. At the very beginning, we decide to use ""Cascading Delete"" to delete users. Because there are many relationship between different users. They can be reviewer, reviewee, teaching assistant, and so on.If we have to delete an user, we have to not only delete the record in user table, but also other related tables. So, we divide all users into two set, one is new user without any relationship, the other is the old user with some relationships. And we find that it is quite easy to achieve the functionality of deleting new users. When deleting old users, we find some problems. Because old users may be a reviewer before and score some assignments. If we delete some old users, the assignments' review scores will be a mess. After discussing with professor, we decide to deprecate""Cascading Delete"". And we use below algorithm to handle user deletion. <image> Confirm box flow diagram 1. A user can be deleted if (s)he has not participated in an assignment; 2. If the user is participating in an assignment, the system will ask, “User is participating in k assignments. Delete as a participant in these assignment(s)?”; <image> Delete confirm box 1. If the user has submitted or reviewed in any of these assignments, the system will say the user cannot be deleted, but offer to rename the user account to <current_account_name>_hidden; <image> Rename confirm box 1. Rename (javascript calling update method in users_controller.rb); <image> Rename success 1. If the person trying to delete does not want to rename the account, the system will just say that the user can’t be deleted. <image> Cannot delete. We add a userDeleteConfirmBox.js file to implement this unique confirm box algorithm. 1. First, we overwrite the Rails default confirm function. <code> 1. Then, we write code to achieve customed confirm box using our own algorithm. <code> 1. After that, we all the if condition in /users/show.html.erb file. So when deleting the old users, Expertiza uses the functionality and customed confirm box we define; when deleting the new users, Expertiza will use the default confirm box. <code>. We write some features test to test ""search for users"" functionality. 1. Mock two users in spec/features/helpers/login_helper.rb file, one is instructor, the other is student. <code> <code> <code> 1. Instructor searches users by login names. <code> 1. Instructor searches users by first name or last name. <code> 1. Instructor searches users by email. <code> 1. Instructor deletes new users. <code>. <code> <image> Rspec feature test pass. <references/>.","Generally good, but certain sections, e.g., Implementation, need more prose to be easily understood.


Writeup has an overall description of the project, but not what was done by this team.  They have showed code, but haven't said how it related to the changes they made.  Nor do we have a prose description of what they did.
This is a good description of some of the changes that the team made.  The initial description of Sahana could be shortened, given that anyone who was going to extend this project would already be familiar with Sahana.  The ending is very abrupt, without any indication of how they had improved functionality, or how their changes could be built upon.","Dear Student,

Your assignment is a great attempt to look at 'Refactoring' and the importance of 'Object-oriented programming (OOP)' through the use of RSpec and code restructuring.  It's evident you have invested ample time and effort into this task.

Your explanation of why refactoring is important when dealing with hard-to-modify programs is subtly clear and simple to understand. Your highlighting of efficiency in the OOP model through concepts like Inheritance, Polymorphism, Abstraction, and Encapsulation is accurate. There's a decent attempt to throw light on Design Principles that drive clean and modular coding.

However, the overall structure of your assignment lacks clarity and focus in some areas. There are several occurrences of ""<link>"", ""<code>"" and ""<image>"", which I presume would hold important content or illustrative media. Remember, these elements shouldn't be left unresolved as they can considerably disrupt the flow of understanding.

While you meticulously talk about some functions and their refinements, the contents and related-files section seems quite confusing. The details associated with certain functions, particularly 'paginate_list', the decision to override the ""Cascading Delete,"" and aspects outlining the delete and rename logic for users are comprehensive and deep-rooted. But please ensure to keep the transitions between topics smooth and uninterrupted.

The implementation of the search feature, writing several tests (with Rspec), addressing bugs, and creating mock instances for testing are explained lucidly, which indicates your adeptness in these areas. The rename confirm box, cannot delete sign, and RSpec feature test pass are particularly intriguing features.

Your references section seems to be missing or incomplete - please revise and make sure to provide full and proper attributions where necessary.

In conclusion, while your assignment demonstrates a good understanding of refactoring and object-oriented programming, it would benefit from addressing the incomplete links, codes, images, and a cohesive structure. Keep on refining your style and focusing on creating a succinct, well-structured assignment. Good job!
"
61,E1553,"This page provides a description of the Expertiza based OSS project. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link> 1.1.8. <link> 1.1.9. <link>. <link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. The following tasks were accomplished in this project: 1. Improved the clarity of code by improving the variable and parameter names. 2. Long character strings were taken and given appropriate names. 3. Handled pagination by a separate helper module, which can be used by multiple controllers. 4. Implemented action_allowed for access_control to prevent unauthorized access of methods. 5. Prevented displaying of all versions for all users and tables when a user views the index page. 6. Added missing CRUD methods to Versions Controller 7. Added RSPEC testcases for testing changes done in Versions Controller. This class manages different versions of reviews. If a reviewer reviews a submission, and after that, the author revises the submission, the next time the reviewer does a review (s)he will create a new version. Sometimes it’s necessary to find the current version of a review; sometimes it’s necessary to find all versions. Similarly, a user may want to delete the current version of a review, or all versions of a review. Pagination of versions helps the user to view a subset of versions at a time. Considering the huge number of versions in the system, it is very useful to have a pagination mechanism and a filtering mechanism which can be applied on the whole set of versions. The idea is to display the versions in an ordered, comprehensible and logical manner. In Expertiza the gem ‘will_paginate’ is used to achieve pagination. 1. Any user irrespective of his/ her privileges can view all the versions. The versions which a particular user can view should be restricted based on the privileges of the user. For instance, only a user with Administrator privileges should be able to view all the versions in the system. However, that is not the case now. Every user can view all the versions irrespective of whether the user is a student or an administrator. 1. Any user can delete any version The versions which a particular user can delete should be restricted based on the privileges of the user. For instance, a student should not be allowed to delete any version. According to the current implementation any user can delete any version in the system. 1. Filtering of versions were restricted to the current user The filtering options on versions were restricted to the current user. Sometimes a user might want to view versions associated with other users. For instance, an instructor might want to view the list of versions created by a particular student. This is not possible with the current implementation. 1. Problem 1 : The method paginate_list is doing more than one thing. The method paginate_list was building a complex search criteria based on the input params, getting the list of versions from the Database matching this search criteria and then calling the Page API. All these tasks in a single method made it difficult to understand. <code> 1. Solution : The implementation has been changed in such a way that the versions which a user is allowed to see depends on the privileges of the user. The approach we have taken is as follows: 1.1. An administrator can see all the versions 1.2. An instructor can see all the versions created by him and other users who are in his course or are participants in the assignments he creates. 1.3. A TA can see all the versions created by him and other users who are in the course for which he/ she assists. 1.4. A Student can see all the versions created by him/ her. 2. Problem 2 : The search criteria created in the method paginate_list was difficult to comprehend. The code which builds the search criteria in the method paginate_list uses many string literals and conditions and is hardly intuitive. The programmer will have to spend some time to understand what the code is really doing. 1. Solution : The implementation has been changed. A student is not allowed to delete any versions now. Other types of users, for instance administrators, instructors and TAs are allowed to delete only the versions they are authorized to view. 2. Problem 3 : The paginate method can be moved to a helper class. VersionsController is not the only component which require to paginate items. There are other components too. For instance, the UsersController has to paginate the list of users. Hence the Paginate method can be moved to a helper class which can be accessed by other components as well. 1. Solution : The filtering options has also been enhanced. The current user can now choose as part of the version search filter any user from a list of users if the current user is authorized to see the versions created by that user. 1. The method paginate_list has been split into 2 methods now. 1.1. BuildSearchCriteria – as the name suggests the sole purpose of this method is to build a search criteria based on the input search filters when the current user initiates a search in versions. 1.2. paginate_list – this method will call the paginate API. First the search criteria is built, then the criteria is applied to versions in the database to get all versions which matches the criteria and then the retrieved versions are paginated. <code> 1. The string literals and conditions in the method paginate_list were replaced with methods with intuitive names so that the programmer can understand the code more easily. We also removed an empty if clause and a redundant statement. <code> 1. The paginate method has been moved to the helper class Pagination_Helper. This new method can be now reused by the different components like UsersController etc. The method receives two parameters, first the list to paginate and second the number of items to be displayed in a page. <code>. 1. Introduced a constant VERSIONS_PER_PAGE and assigned the value 25 to it. The pagination algorithm for VersionsController displays at most 25 versions in a page. The existing implementation uses the value 25 straight in the code and there are few problems associated with such an approach. 1.1. It is not easy to understand what 25 is unless the programmer takes a close look at the code. 1.2. In case if the value 25 is used at more than one places and in future a new requirement comes to show at most 30 versions in a page, all the values will have to be modified. It is not very DRY. 2. The VersionsController was overriding AccessHelper - action_allowed? method to return true in all the cases. This was violating the whole purpose of the method action_allowed?. The purpose of this method is to determine whether the user who is triggering a CRUD operation is allowed to do so. So when the current user invokes a CRUD operation, the action_allowed? method is invoked first and if the method returns true the CRUD operation is triggered or else the user is intimated with a message and gracefully exited. Hence, when the action_allowed? method is overridden to return true always, it results in providing unauthorized access to certain users. <code> With the new implementation the AccessHelper - action_allowed? method has been modified in such a way that unauthorized access is prevented. As per the new algorithm, 'new', 'create', 'edit', 'update' cannot be invoked by any user. These operations can be accessed only by ‘papertrail’ gem. Only an ‘Administrator’ or ‘Super-Administrator’ can call 'destroy_all' method. All the other methods are accessible to ‘Administrator’, ‘Super-Administrator’, ‘Instructor’, ‘Teaching Assistant’ and ‘Student’. <code>. The current version of expertiza did not have any test for VersionsController. Using the test driven development(TDD) approach, we have added an exhaustive set of RSPEC tests for VersionsController, to test all the modifications we have done to the code of the controller class. The tests use double and stub features of rspec-rails gem, to fake the log in by different users - Administrator, Instructor, Student etc. The tests can be executed ""rpec spec"" command as shown below. <code>. Following are a few testcases with respectto our code changes that can be tried from UI: 1. To go to versions index page, type in the following url after logging in: <code> 2. After logging in as student/instructor or admin : Try accessing the new, create, edit, update actions. These actions are not allowed to any of the users. <code> 3. Another feature that can be tested from UI is Pagination. Try searching for a user's versions and see if the results are paginated or not. Search here: <code> 4. Visit the same URL as step 3, you should see only the students under that instructor in the users dropdown. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. Clean Code: A handbook of agile software craftsmanship. Author: Robert C Martin.",Good job of explaining changes!,"Dear Student,

I really appreciate your detailed and thorough work on this assignment and the in-depth analysis on the Expertiza project. I can see you gave attention to improving clarity, enhancing functions for versions, and making sure your solutions align with user-privileges. It is impressive to see that you have mentioned and implemented some strong principles of coding such as DRY (Don’t Repeat Yourself) in your solutions. 

The problems identified around pagination, search criteria, and user privileges are accurate and your proposed solutions seem to address these issues effectively. The detailed explanations on the changes made in the code make the logic of your implementation clear and easy to follow. 

However, it would be helpful, in future submissions, if you could provide some more context or explanations for those who may not be familiar with some terms or processes mentioned. For example, explaining what CRUD is or what the role of the 'papertrail' gem is in this project would add a lot of context.

The testing ideas you brought up are excellent and it would be helpful if you could detail how the RSPEC tests are being implemented and what specific areas they are covering. Remember, it's important not only to write tests, but also to document them thoroughly.

When it comes to code segments, please make sure you display it properly in your write-up using proper Markdown syntax or another easily readable format, as the given ""<code>"" does not properly isolate or format the code.

The assignment cites its references and uses concepts learned from external sources, which is great. Always remember to continue giving credit where it’s due.

Overall, I’m very impressed by the quality of your work. Keep up the good work.

Best,
[Your Name]"
62,E1958,"Expertiza has Assignment objects, which represent an assignment that is done by some number of users. An instructor or a TA can perform several kinds of operations on assignments, such as, ”Add participants”, “Create teams”, and “View scores”. These operations can be seen: First, on the homepage, under the “Actions” column in assignment list when a user (instructor or TA or admin) logs in and navigates to Manage -> Assignments. Second, when editing an assignment (by clicking on edit logo above), on the tab called “Other stuff”. Contents 1.1. <link> 1.1.1. <link> 1.2. <link> 1.1.1. <link> 1.1.2. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.3. <link> 1.4. <link> 1.5. <link>. The following tasks were accomplished in this project: 1. Issue 1384: Implement a setting in the user’s (instructor/ TA) profile, from where the user can choose whether to see these actions on the homepage or in a tab associated with each assignment. 1. Issue 1430: Under the “General” tab of the assignment edit page, an instructor or a TA can change the course of an assignment. What is wrong: A TA or an instructor can assign any course to an assignment even when they don't have access to the course. TAs can unassign an assignment from the course, and if they do so, they lose access to the assignment. What needs to be done: Only those courses should be shown in the dropdown list of courses, the assignment is part of and the instructor or TA has access to. Instructors, but not TAs, would then be allowed to change an assignment to be part of no course. Also, change the name of the tab from “Other stuff” to “Etc.”. 1. Implement a setting in the user’s (instructor/ TA) profile, from where the user can choose whether to see these actions on the homepage or in a tab associated with each assignment. Two new flags in the user database namely preference_home_flag and preference_edit_flag were created which were initialized to be true and the user would see a checkbox for both of his preference in the profile page which would both be initially checked to be true. Now user can uncheck this to see where he/she wants to see the operations. We implemented them both on local. We tried to use one of the flags as a text box and tried to insert text values in the profile page and could not accomplish the expected output as the flag was not updating. app/controllers/users_controller.rb. <code>. <code>. app/views/users/_editpreference.html.erb <code> db/migrate/20191028210443_add_preference_edit_flag_to_users.rb <code> <code> app/views/profile/edit.html.erb <code>. 1. Under the “General” tab of the assignment edit page, an instructor or a TA can change the course of an assignment. Only those courses are shown in the dropdown list of courses, the assignment is part of and the instructor or TA has access to. Instructors, but not TAs, would be allowed to change an assignment to be part of no course. Also, changed the name of the tab from “Other stuff” to “Etc.”. app/helpers/assignment_helper.rb. <code>. <code> app/views/assignments/edit.html.erb <code>. Travis-CI Build Testing Travis-CI Build Test of the beta branch after a refactored function is merged in the beta branch. <image> <image>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link>.","In the problem statement, the first two paragraphs of prose apply to Issue 1430, but that is not clear from the formatting.  A heading needs to be added.  Actually, I just did that for you.  BTW, there should be a space between ""Issue"" and the issue number, e.g., ""Issue 1430"".  I added the space too.

I'm not sure what it means to say, ""We implemented them both on local.""

When you show before and after views of code, it would be much clearer to use the Github diff view.

No screen shot of either of the two issue fixes.
No instruction on how to manually test.
No detail about issue #1384 fix (just code changes)
No reference links for thier work.","Dear Student,

Great work on this assignment. It is clear that you have done a detailed analysis of the Expertiza's Assignment objects. You have correctly identified the issues related to the user profile settings and managing assignments and have proposed sensible solutions to handle the issues. 

However, there are some areas where you can expand and improve. It would have been beneficial if you explained the issues and tasks in more simple, non-technical language, for the ease of understanding the problems you are trying to resolve. It's always important to consider who the audience is for your writing.

Additionally, your use of link placeholders are confusing and unnecessary if there are no use of live links. I encourage you to replace them when you have appropriate references, or remove them altogether if not relevant. The description and purpose of each step should be provided in a more clear and concise manner.

Furthermore, in your code descriptions please ensure to offer insight into how each class and method contribute to solving the provided issues. Complete and understandable explanations of your code will make it easier for anyone to follow along.

In terms of the issues you faced, like the flag not updating, it would be beneficial if you describe the potential reasons for why it occurred and the measures you took to troubleshoot it.

Do ensure to include image placeholders only if you plan to provide corresponding images. Otherwise, they are quite distracting and take away from the overall flow of your content.

Stay positive and keep going! These are just minor issues and with some more work, your content will be excellent! Looking forward to seeing your revised assignment.

Best,
[Your Name]"
63,E1476,"According to the existing code workflow, the assignment of topics to teams are based on FCFS (first come first serve) basis, where a team which first signs up for a topic gets the topic while other teams are waitlisted on the same topic. Since ‘sign up time’ is the only factor considered for topic assignment this method causes problems such as: 1. The assignment of topics are FCFS, hence not completely fair. 2. Non-uniform distribution of topics among the teams in a class. 3. The current system fails to resolve the problem when many teams bid for handful of topics(among many topics) causing unnecessary additions to the waitlist. 4. The assignment of topics is more focused on individual selection and ‘sign up time’. Factors such as team size are not considered which are important while assigning a topic to the team and potentially can reduce many issues faced by the current system. To address the above mentioned issues, we have designed an ‘intelligent assignment of topics’ system which tries to address the issues faced by the current system. <link> <ref> <link> </ref> is a project developed using <link> <ref> <link> </ref> platform. It provides features like peer review, team assignments and submission of projects. This can be achieved by submitting code base, URL of hosted code on remote server and Wiki submissions. It is an open source application and the code can be cloned from <link> <ref> <link> </ref>. This application provides an efficient way to manage assignments, grades and reviews. This makes the process easier and faster when the class strength is large. Expertiza is supported by National Science Foundation under Grant No. 0536558. Additional funding from the NCSU <link> <ref> <link> </ref> program, the NCSU Faculty Center for Teaching and Learning, the NCSU STEM Initiative, and the Center for Advanced Computing and Communication. The sign up process for group projects is observed by most students to be a troublesome task in expertiza. The current sign up process for topics is based on <link> <ref> <link> </ref> basis, where a student who signs up for a topic of his/her choice first, gets it. We have discovered some pitfalls with the current ‘topic assignment’ system in Expertiza which arises due to the below mentioned factors. Due to these reasons, we now try to propose an intelligent system which can addresses many issues faced with the current Expertiza system. 1. One student can sign up only for a single topic. In cases where many topics are available, a student is forced to choose a single topic among many available topics which can be a difficult task. To select a single topic which best fits his/her choice among many available topics requires a pre-study of all topics prior to the sign up process. Such a pre-requirement is not fulfilled by most students, which results in a student signing up for a topic which he/she has randomly selected OR because it was among the only available topics. 2. If a student is not able to sign up for a topic of his choice, he can waitlist himself for all the remaining topics, which causes unnecessary traffic in the waitlist queue of a topic. 3. If all the teams choose a handful of topics among many topics, it would also result in unnecessary additions in the waitlist queue for those few topics resulting in a situation where all the topics are not uniformly distributed among all the teams 4. Before, signing up, if more than one student forms a team and if each student belonging to the same team tries to sign up for different topics, than those topics are allotted to individual students resulting in a situation where a team can hold more than one topic. Thus other teams are forced to choose from remaining topics which eventually results in longer waitlists. After observing the above problems with the existing method of ‘topic assignment’ in expertiza, we have proposed and implemented an ‘intelligent assignment of topics’ method to overcome all the shortcomings of the existing system in expertiza. Previously in 2012, to address this issue of expertiza, a team proposed a possible solution of <link> <ref> <link> </ref> algorithm. The algorithm works by considering every team as strength of 1, representing the student in the team. After sign up the topic would be allotted to the team based on a lottery system where a team is randomly selected for every topic. However this method failed to address the following issues: 1. It did not consider the case where a team could be of more than one member, hence it allowed every team member to bid for different topics resulting in the same problem as mentioned in point (4) of Pitfalls with the current system. 2. The topics were awarded randomly through an algorithm which assigns topics to teams randomly (Lottery System) and does not consider any other criteria which caused the existing system of topic assignment to be a game of luck factor rather than on individual’s choice. Developer Note The name lottery has been retained for most of the files. This is because Intelligent Assignment could be confused with actual assignments. Intelligent Assignment and the subsequent discussion refers to the latest approach used in LotteryController for assigning topics to teams. 1. The instructor should be able to create assignments which can utilize intelligent assignment of teams. (It is an optional feature) 2. The instructor should be able to set the maximum number of bids a team can make. Defaulted to 3. 3. The teams should be able place bids on different topics limited to the number set by the instructor for these assignments 4. The teams should be able to prioritize their bids. 5. The instructor should be able to kick off [what does that mean?] the intelligent assignment of teams. To address the issues faced by both, the current system and lottery based system, we propose a solution based on ""intelligent team assignment"" approach. <link> <ref> <link> </ref>. This approach is based on two important factors: 1. Team strength 2. Priority order of the topics submitted by the team. An added advantage of this approach is that, unlike the previous system, the intelligent team assignment system allows each team to bid for multiple topics which increases the chance of every team getting at least one topic that they placed their bid on. Each team can place their bids in priority order, the priority of the bids are also considered while assigning topics to the teams. For example: If TeamA is up to its maximum strength and bids for Topic1 , Topic2 , Topic3 where Topic1 has the maximum priority then TeamA has larger chance of being assigned Topic1 , but if Topic1 is already assigned (to a different team which had equal probability of getting the same topic based on team strength and bid priority) then Topic2 would be considered for assignment followed by Topic3 . Thus the priority mentioned by each team is also an important factor for assigning topics to teams. To give an example of how the system works, let's consider the following phases of topic assignment. 1. Initially, every student is a team of 1 member. Before the sign up process takes place, students can merge their teams to form a larger team. The person to whom they have merged becomes the team owner/captain. 2. It is preferred that the number of members in the team should be as close as maximum strength allowed for each team to increase the chance of winning a topic. 1. Every team is allowed x bids that they can use during the sign up process to select the topics of their choice. The number of bids allowed for each team is decided by the instructor which is entered into the system during assignment creation/updation. [The value of x is decided by the instructor using class strength, number of topics created for an assignment and maximum team strength allowed for that assignment.] 2. During the sign up process, the team can place x bids on x topics of their choice in a priority order. 1. As each team can place their bids on the available topics based on topic priority. Hence every team gets to choose more than one topic of their choice. 2. The teams are assigned topics based on modified <link> <ref> <link> </ref> algorithm which considers factors such as team size and priority ensuring that the topics are no longer assigned based on FCFS basis. This approach addresses the most important issue where a topic is not assigned to the team just because the team was late to sign up for the topic as compared to the other teams. This flow chart illustrates the ""modified stable matching"" algorithm used to assign topics to teams based on the strength of the teams(bidder) and the priority in which they bid for the topic. <image> Modified version of Stable Matching After the above mentioned ""modified stable matching"" algorithm is run, there might be a case where few teams (for simplicity consider TeamA ) might not get any topic due to reason that the topics that TeamA placed their bids on, had other competing team TeamB which were up to their maximum team strength (or greater than TeamA strength) and had higher priority for the same topics. Thus TeamB got the topic but TeamA didn't get it. In order to handle this edge case we, implemented the ‘auto team merge’ algorithm which is run immediately after the ‘modified stable matching’ algorithm to handle such edge cases. This algorithm takes two parameters as input 1. A list of teams which are un-assigned any topic 2. A hash of team and topics which were assigned Algorithm 1. Sort the list of teams in descending order of team size 2. For each team a.Get the team_size and topics that the team placed their bid on b.Arrange the topics according to the priority order mentioned by the team i. For each of the topic, check which team is assigned this topic and store its team strength in assigned_team_size ii. If the team which is assigned this topic is not up to maximum strength and if the ( team_size + assigned_team_size <= max_strength allowed for each team) then assign this team the topic. Otherwise go to i. and repeat the process for next priority topic. end end. <image> Fig 1. Sequence Diagram Fig 1. shows the sequence diagram for this feature. The diagram shows the sequences exclusive to this feature. Therefore, this assumes that the assignment/exercise has already been created. Once the assignment is created, the instructor can enable the 'intelligent assignment of teams' feature for the particular assignment. Enabling this feature would give the students(or teams) a view to place bids on the topics they like. They can associate each bid with a priority. Once the deadline has passed, the instructor can kickoff the process which performs the automatic assignment. This would in turn start assigning teams with topics based on their bid preferences. <image> Fig. Use Case Diagram <table> <table> <table> <table> <table>. In order to meet other solution requirement, the initial plan was to add new tables. The following diagram represents the new tables in <link> <ref> <link> </ref>. The user table mentioned is not new and is present only to explain the field - ownerId . Earlier, all the information in AssignmentTopic and AssignmentTopicMetadata tables were in a single table called sign_up_topics . There was lot of data redundancy observed and we also required to add an extra field in the table sign_up_topics . Therefore, we decided to store the topics related to an assignment according to the diagram. One caveat to this design is that all the topics for an assignment are considered equal in terms of category, maximum bids allowed and maximum bids in waiting list. The table bid is supposed to store all the bids on the topics with their priority. The owner of the bid will be recorded too. Current requirement is to have only one bid per topic by an owner. Therefore, we could have (ownerId, topicId) pair as the primary key. However, in order to support multiple bids in a future scenario, we have used a field id as the primary key. Implementation Changes: However, because of the way the current database dependencies were strongly coupled, we decided to go ahead by adding a column ""Max_Team_Bids"" to the Assignments table and a ""priority"" column to the Bids table. The above approach can be used as a reference for future developers. <image> Database Design. The intelligent assignment controller is dependent on the AssignmentTopicController and other models like - Assignment , AssignmentTopic and Team . When the instructor starts the intelligent assignment of topics to teams, IntelligentAssignmentController triggers the assignment algorithm. The students interact with AssignmentTopicView which lists down all the topics for the assignment and allows students to bid for topics with priority. AssignmentTopicController is responsible for recording all the bids and priorities correctly. Following is the UML diagram of the O-O design focusing only on the component related to intelligent assignment of topics to teams. Implementation Changes We have avoided separating out AssignmentTopicMetadata from Assignment as this would have caused a lot of dependency conflicts. <image> UML Design. The following principles and patterns are used: 1. DRY : Using DRY coding practices. The earlier code had a lot of redundant functions such as getTeamsFromId which was violating the DRY principle. We have used the methods provided by the ActiveRecord class making the code structure and easy to understand. 2. MVC Use of the Model View Controller for maintaining the Intelligent Assignment flow. 3. Separation of concerns : The IntelligentAssignmentTopicController is separated from AssignmentTopicController as the former's functionality is specific and hence should not be part of the general AssignmentTopic Controller. During our development process, we stumbled upon certain bugs in certain areas which slowed down our process. This is brief summary of those issues and their corresponding fixes. These changes are not the right resolution, however, we have listed it here so that future developers could benefit from these. 1. Error thrown while adding assignments/teams/teamusers The model nodes has a method acts_as_nested_sets which causes this issue. 1. Error thrown while loading the sign_up_sheet_controller Comment this line ""require 'graph/graphviz_dot'"" 1. Missing rgt or lft column in nodes table Probably because the db migration AddCategories has not been run. The code in that is commented. Uncomment that and run the migration. <references/>.","Generally good description of what is to be done.  However, the changes made to each review strategy could be enumerated more prominently  And the document ends pretty abruptly.  However, there are no mentions of principles or patterns to be used.","Dear Student,

Thank you for your comprehensive research and thoughtfulness in proposing improvements for the intelligent assignment of topics system! You have put in a great deal of effort to analyze the caveats of the current system and proposed robust solutions. Your assignment exhibits a robust understanding of the topic and clear communication of your thoughts.

Below are my comments:

1. Detailed Analysis: You have done an exceptional analysis of the current issues with the FCFS system, from understanding its limitations to considering its effects on users. 

2. Solution Design: The assignment highlights your problem-solving ability, evidenced by the design of the new system you are suggesting. By considering factors like team size and topic priority, the new system is more democratic whilst addressing key issues of the current system.

3. Use of Images and Diagrams: Your use of visuals like flow diagrams and UML design diagrams is commendable as it allows someone reading your work to understand your ideas more easily.

4. Code and Application Understanding: It is evident that you understand the platform, its code base, and its functionality. This is particularly shown in your developer notes, where you explain why you decided to retain certain file names.

However, here are a few suggestions for improvement:

1. Structure: While the detailed information is great, the structure could be improved for better readability. Breaking the text down into sections with headings would make it easier to navigate your paper.

2. Consistency: There were some inconsistencies in punctuation and formatting throughout your piece. Additionally, the <image>, <table>, and <link> placeholders should be replaced with the respective images, tables, and references to avoid confusion.

3. Terminology: Be cautious with the jargon you use. For instance, the term ""kick off"" might be unclear to some readers.

Overall, great job on your assignment! Your work demonstrates a strong grasp of the material, a keen sense of analysis and problem-solving, and excellent research skills. Keep up the wonderful work!

Best regards,
[Instructor's Name]"
64,E1828,"This page provides a description of the Expertiza based OSS project. Expertiza is an open source project based on Ruby on Rails framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. In Expertiza, students usually review several projects during a given time frame. We felt that since each reviewer would have multiple projects to review and some project may be updated without his/her knowledge it would be more convenient to the reviewer if he/she gets to know the status of the review without opening the project to be reviewed everytime. This helps the reviewer quickly identify submissions which need immediate attention. The reviewer should be able to know the status of any review he/she is doing. This can be done in UI of the reviewer’s page. The submissions can be color-coded using a scheme similar to the one used in the “Review Report” page for the instructor in expertiza. The color coding scheme implemented by us is: Red – If the review has not been started Orange – If the review was started, but not completed Brown – Submission has been reviewed Since the functionality for the links of “View”,”Begin”,”Update”,”Edit” are already present, the 'Begin' link is visible only when the review has not started, so the link is 'Red' to indicate review has not yet been started. Similarly the 'Edit' and 'Update' links are visible only after the reviewer has opened the project to be reviewed at least once. So both these links can be colored 'Orange' to indicate that the review was started but not yet completed. The 'View' link is visible only after the review was submitted, so the link can be coloured 'Brown' indicating that no further action is required on the reviewers behalf and the submission has been reviewed. Hence, by just colouring the links displayed to the reviewer, we are able to indicate the status of the review. The lines in bold in the below snippet are the colour codes we added which will add button colour in the review page. Changes: <code>. app/views/student_review/_responses.html.erb. 1. Open expertiza (link is provided) 2. Login as student: student5408/password 3. Go to 'Assignments' 4. Select any assignment 5. Select Other's work 6. You are in the reviews page where you can see the buttons and their respective colours. As discussed thoroughly with our mentor and professor, the implementation is a UI change with CSS styling and colour tags added. Hence, testing the buttons on review page is beyond the scope of our project. The colour change will not impact the functionality of the buttons in any way. Hence, unit tests are not required. Colour for View Buttons: <image> Colour for Begin Button: <image> Colour for Edit Button: <image>. <link>.",Problem statement does not clearly explain what the issue is. The document could have been broken down into sections more clearly - text and headings are not clearly distinguishable. Does not explain changes made to schema.rb,"Dear Student,

I must attest to the considerable effort you put into explaining the Expertiza open source project. The detailed, step by step grading mechanism and the color scheme you have proposed are innovative and pedagogically informed. Particularly, the ability for a reviewer to know the status of a review without having to open the project comes across as an intelligent design aspect, potentially saving the reviewer lots of time.

However, I have some suggestions that can help improve your work. Although you claim that testing the buttons on the review page is beyond the scope of your project, it would add more credibility to your work if you could provide some type of validation even if it's just visually showing how the colors change under different circumstances. This will solidify your argument that the color change will not impact the functionality of the buttons in any way. Plus, it would provide the instructor or any reader with tangible evidence to support your claims.

Furthermore, while incorporating images in your assignment is a good practice, it seems like the images are not correctly inserted or referenced. Make sure to reference and insert images correctly to enable the reader to clearly comprehend your points. 

You did a good job describing the color coding scheme, but it may be worth considering adding a legend or key of sorts on the reviewer page itself. In this way, the information would be readily available to anyone using the system, without needing to memorize the color scheme.

In conclusion, despite a few areas needing improvement, you have done a commendable job overall with this project. I can see the dedication and time you have committed to this work. Please consider my feedback and keep up the good work.

Best Regards,

[Instructor Name]"
65,E1501,"This page is about an open source project based on Expertiza OSS. This project aims to refactor assignment.rb which is the largest class in Expertiza. It also aims to refactor other snippets which does not follow the Ruby style guidelines. <ref> <link> </ref> Refactoring is a technique to alter the internal structure of the code without affecting the external behaviour. It is used for: 1. Programs that are difficult to read; 2. Programs that does not follow the language specific guidelines; 3. Programs that has high coupling;. <ref> <link> </ref>Expertiza is an open source project developed using the <link> platform. It provides features like team assignments, peer review, submission of projects, grading etc. The code can be cloned and modified from <link> . This application provides an efficient way to manage assignments, grades and reviews. Assignment.rb is the largest class in Expertiza, comprising 1105 lines of code which contains the assignment model and the related functionalities. It also contains the score module which is refactored to make the file more clean and easy to read. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.2. <link> 1.3. <link> 1.1.1. <link> 1.1.1.1. <link> 1.1.2. <link> 1.1.1.1. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.4. <link> 1.5. <link> 1.6. <link>. Classes involved: <code> What they do Assignment.rb along with the controller file is responsible for creating and editing the assignments. The file also contains methods which calculates the student scores. The assignment and scoring modules are very tightly bound which can be grouped into smaller, more manageable classes. What needs to be done: 1. The assignment model needs refactoring as it contains some modules which are responsible for generating assignment scores; 2. Moreover, the querying module is database dependent which should be made database independent; 3. There are many function names and code lines which does not follow the ruby guidelines. They should be changed to more ruby like coding style;. <ref> <link> </ref>ActiveRecord concern is a pattern introduced in Rails 4.1 to separate the heavy loading done by models. It is recommended that models should be fat and should contain the business logic. This is leads to models getting too coupled. ActiveRecord Concerns solves this problem. Methods which can be logically put together are added in a <ref> <link> </ref> module/mixin. This mixin is then included in the main model. The mixin can be reused by any other model if required. This makes the code align with Rails philosophy of DRY. In this case all methods related to 'scores' were collaborated together and put inside the mixin scorable. There are many methods which are not directly related to assignments. These methods are responsible for generating the scores and related functions. These methods are: 1. get_scores; 2. get_max_score_possible; 3. compute_reviews_hash; 4. get_average_score; All these methods are taken out of assignment.rb and pushed into a new file ""scorable.rb"". This made score generation a separate module and the dependency of scores on assignments reduced significantly. The pull request can be viewed <link> . There were many instances where the coding was not like ruby like. The ruby community believes in small and well readable code. The code was refactored to be more readable. Many changes were done to the structure of the code to make it more Ruby like. Changes such as removing the return statements, writing .each instead of ""for loop"", adding a ""?"" to name of methods if they return boolean values, indentations and naming conventions were improved. Few of the examples are shown below in raw form as well as Github screenshots: <image> This refactoring example makes the snippet small and easy to read. It also introduces more Ruby style terms like select and processes like piping instructions. Before Change <code> After Change <code> Before Change <code> After Change <code>. ActiveRecord provides a layer on top database. Hence if no MYSQL specific query is used in the code it very simple to change the database without changing the code. Using Ruby hash for query rather than raw SQL also helps in keeping the code clean. The queries where changed to function more like active record query. This made the queries database independent and more user friendly. Before Change <code> After Change <code>. <ref> <link> </ref>`Rubocop` was used to check the ruby style guide violations. Most of the Ruby style guide violations in assignment.rb class were fixed. <image>. 1. Version of gem ""EventMachine"" was updated as earlier version was incompatible with ruby version 2.2.0. The version was changed from 1.0.3 to 1.0.7.; 2. One more gem <ref> <link> </ref> ""quite_assets"" was added to avoid unnecessary log creation of the asset request. It mutes the asset pipeline log messages. This gem is very helpful during development.; 1. Clean up tests: Few of the controller tests were not in the correct order. We changed them to the right order. 1. Feature change was not in the scope of the project. The changes are checking bad code smells and fixing them. The way to verify the changes is to make sure that it works as it was previously. Also, please have a look at the pull request for all the refactor details. You can pull the code with refactored file <link> . 1. <link> 2. <link> 3. <link> 4. <link>. <references/>.","The introduction is not very useful, but after that, it seems to be a good description of changes made.  Writeup is rather short, though.
","Thank you for submitting your project on refactoring assignment.rb in Expertiza. You've provided a detailed and comprehensive write-up of your work. From describing the project aims to delving into the technical aspects of ActiveRecord concerns, your approach to decoupling the application's heavily loaded models is exemplary.

Here are a few suggestions for further improvement:

1. Ensure Serif Uniformity: While the content's overall structure is good, it appears that part of the text has not been formatted consistently. For a more professional presentation, I recommend adhering to a consistent text serif.

2. References: I noticed that you included number of empty <ref> <link> </ref> throughout your report. I assume you wanted to insert references or external links here. Make sure to include actual references or external links in these tags for proper citation and to aid further research.

3. Define Terminology: For clarity, I recommend providing a brief explanation of terms like ""coupling"", ""ActiveRecord concern"", and ""DRY"", which some readers may not be familiar with.

4. Use Correct Verb Forms: There were a few instances where incorrect verb forms were used, for example, ""Programs that does not follow..."" and ""function names and code lines which does not follow...""; the correct form would be ""programs that do not follow"" and ""function names and code lines which do not follow"".

5. Proofread your Write-up: Finally, take some time to proofread your document to correct minor spelling, grammar, or punctuation errors.

Overall, your work is quite impressive, showing deep understanding of Ruby, Rails, and software engineering principles. Great job!"
66,E1554,"Expertiza <ref> <link> . expertiza project </ref> is a project built with <link> <ref> <link> </ref>.It is mainly used by an instructor to provide a peer reviewing systems among the students it also supports team projects submissions wikis etc. This class handle the basic creation and modification of student teams. There are also some complicated actions. E.g., if a team get destroyed (this may be caused by instructor force this team to be destroyed, the students all leave the team), the topic held by this team should be transferred to next team which is on the waiting list, if there is any. These are the scenarios where topic transferring may happen: 1. when instructor destroys a team 2. when the last person leave this team 3. when this team wants to switch topic 4. when instructor wants to increase the available slots for a topic. The same code for handling topic transferring used 3 times at the following places: <code>. 1. Make topic_transfering a function call, and make sure all those 4 scenario works. 2. Write tests for all those 4 scenarios. 3. Record a video for those 4 scenarios, submit it to YouTube and submit the YouTube link to Expertiza. 4. Delete method in teams_controller.rb is complicated, “@team.destroy” should be called latest after all the records related to this team can be deleted. 5. write tests for delete method. Before: Code repeated in teams_controller.rb, student_teams_controller.rb, SignUpTopic.rb <code> After: The repeated code implemented as a function in SignUpTopic.rb <code>. Rspec tests can be performed by using the following commands from expertiza directory in the terminal: <code>. 1. Login as instructor. 2. Create a course. 3. Create a assignment using the above course. 4. Create topics (two topics are sufficient, though one will be used). 5. Create Users (at least 4 for better understanding : User21, User22. User23, User24). 6. Add users as participants to the assignment. 7. Create teams (TeamX -> User21 , User22) and (TeamY -> User23 , User24). 8. Impersonate as user and choose the topic first, invite other user. Impersonate as other user, accept the invite. 9. Revert to instructor role after creating teams. Make sure you have the same setup as above before every scenario. Scenario 1: 1. Go to Manage Content > the assignment you created > select 'Create Team' icon > delete the first team. 2. There will be only one team now. 3. Go to Manage Content > the assignment you created > select 'Edit' icon > Topics Tab 4. The second team will have the topic on which it was wait listed. 5. Check 'Number of slots' , 'Available Slots','Number on Wait list'. Scenario 2: 1. Impersonate as user of the team which has the topic. 2. Leave from the team. 3. Impersonate as second user of the team which has the topic. 4. Leave from the team. 5. Revert to instructor role after creating teams. 6. Go to Manage Content > the assignment you created > select 'Edit' icon > Topics Tab 7. The second team will have the topic on which it was wait listed. 8. Check 'Number of slots' , 'Available Slots','Number on Wait list'. Scenario 4: 1. Go to Manage Content > the assignment you created > select 'Edit' icon > Topics Tab 2. Select 'Edit' icon for that topic. 3. Increase the number of slots to 2 or more. 4. The second team will have the topic on which it was wait listed. <link> Youtube video will guide you test functionality manually. <references />.","The writeup is a bit short.  Some of the parts (e.g., on deleting a team) show the code that was changed, but do not explain how it was changed.  ","Your assignment demonstrates a good understanding of the Expertiza project, its purpose, and some of its intricate features. However, there are areas where your writing could be improved for better comprehension.

1. Citations and References: You have made commendable attempts to cite sources in your write-up, but they seem incorrectly placed and incomplete. Make sure to correctly hyperlink the text that needs to be referred, and complete your reference list accordingly. 

2. Clarity of Process: While you enumerated the steps for each scenario fairly, some steps seem to lack necessary details. For example, ""Check 'Number of slots', 'Available Slots', 'Number on Wait list'."" (in both Scenario 1 & 2). You haven't specified what to check in these fields or what to anticipate. 

3. Proper use of Code: I appreciate how you signpost sections of your code, but some of the coding practices are a bit unclear, especially where you refer to <code>. You need to be more explicit about the framework you are using, and how the snippets of codes tie into the overall narrative. 

4. Consistency: The fourth scenario is labelled as ""Scenario 4"" - however, Scenario 3 seems to be missing from your document. Please do rectify the numbering and include Scenario 3 if it has been inadvertently omitted.

5. Grammar and Sentence Structure: There are instances where sentences are not fluently structured and punctuation is misplaced. For example, ""This class handle the basic creation and modification of student teams."" should be ""This class handles the..."" 

6. Video Submission: The YouTube video you've mentioned should be properly linked, as it can provide visual guidance for testing, which is very beneficial. However, it is currently not linked correctly.

Overall, I commend your considerable efforts on reporting the functionality and scenarios of the Expertiza platform. However, please make efforts to improve clarity, grammatical precision and the format for source citations. Keep working hard!"
67,E1684,"<link> is an open-source project on GitHub used by students to view/submit assignments and review others' work. Expertiza also provides tools to visualize the scores and gauge the improvements made during the course semester. It also facilitates and monitors team projects. It is targeted at educational and non-profit organizations. <link> is a hosted, distributed continuous integration service used to build and test software projects hosted at GitHub. Configuration: Travis CI is configured by adding a file named .travis.yml, which is a YAML format text file, to the root directory of the repository. This file specifies the programming language used, the desired building and testing environment (including dependencies which must be installed before the software can be built and tested), and various other parameters. Operation: When Travis CI has been activated for a given repository, GitHub will notify it whenever new commits are pushed to that repository or a pull request is submitted. It can also be configured to only run for specific branches, or branches whose names match a specific pattern. Travis CI will then check out the relevant branch and run the commands specified in .travis.yml, which usually build the software and run any automated tests. When that process has completed, Travis notifies the developer(s) in the way it has been configured to do so—for example, by sending an email containing the test results (showing success or failure), or by posting a message on an IRC channel. In the case of pull requests, the pull request will be annotated with the outcome and a link to the build log, using a GitHub integration. <link> supports selenium-webdriver, which is mostly used in web-based automation frameworks. It supports JavaScript, can access HTTP resources outside the application, and can also be setup for testing in headless mode which is especially useful for CI scenarios. Using Capybara with <link> : Load RSpec 2.x support by adding the following line(typically to the spec_helper.rb file): <code>. There should be a feature test for submission of the assignment by the student. Once the assignment is created by the instructor the only call to action for the student is assignment submission. The purpose of this project is to test whether the submission function could work properly under different scenarios. We will design multiple test cases to simulate different scenarios which the system could encounter. For example, how system respond when a user uploads an invalid URL. The following part will provide more and detailed information on test cases. When a user is attempting to submit an assignment, there are some possible cases need to be considered. 1. Upload single valid link: upload a valid link, the system should properly render the page and add this link into the database. We will use the following statements to simulate the submit action. <code> 2. Upload invalid link: upload an invalid link (e.g. a non-existing link), the system should detect the invalid link, reject the submission and cast corresponding error message. 3. Upload multiple links: upload multiple links, the system should properly render the page and add the new link into the database. We will use the following statement to check if the current page has the uploaded URL. <code> 4. Upload duplicated links: upload an link which has already been uploaded before, the system should detect this duplicated link, reject the submission and cast error message. 5. Upload empty link: upload an empty link, the system should reject the submission and cast corresponding error message. 6. Upload a valid file: upload a valid file, the system should properly render the page and add this file into the directory. We will use the following statements to simulation the submit action. <code> 7. Upload multiple files: upload multiple files, the system should properly render the page and add the new file into the directory. 8. Upload duplicated files: upload a file which has already been uploaded before, the system should update the existed file with new one. The test code will check whether the content of this specific file was successfully updated. 1. First, using <link> to create test data: create assignment, create topic, create participant. <code> 2. Mock the workflow of Assignment submission using Capybara. <image> 3. Check the result of the submission from both web page and database. In database level, the submission results are stored in the table: TEAMS. <image>.","The doc mentions the files that will be modified, but said little about the modifications that would be made.  Which methods will be modified?  What parameters will be passed?  Also, the testing plan is much too vague.","Overall, your assignment on testing the assignment submission functionalities of the open-source software has been done very thoroughly. I appreciate your usage of Github, Travis CI, Selenium-webdriver, and Capybara to approach the multiple scenarios that a user might encounter during assignment submission. By considering valid and invalid links, single and multiple file uploading as well as duplicate detection, you've covered most of the primary use cases of the system.

However, there are a few areas where improvement is needed:

1. The formatting and presentation of your test cases and code could do with a little more clarity. Be sure to format and comment your code for better readability. Especially when showcasing code snippets, they should be well-documented to clearly highlight the purpose of each code block.

2. It seems as if you attempted to include links and images to further explain your process, but they are not present in the assignment. For future assignments, please make sure that all your links and images are working correctly. They could be instrumental in understanding your workflow.

3. As you've quite rightly highlighted that printed errors for invalid or duplicate entries are important, it would be beneficial if you included what form these error messages might take and how they would guide the user towards correct submission. Additionally, please provide more explanation on how the system handles file updates, because the information provided was a bit unclear.

4. Your explanation about testing the database level needs further clarifications. How does the testing confirm the successful submission of an assignment?

Keep up your analytical approach to problem-solving, but remember that clarity is equally important when presenting your solutions. Don't take for granted that the person reading your work will understand everything you're doing. Explain each point thoroughly. You have the right idea, but polishing your presentation will take your work to the next level."
68,E17A0,"Traditionally, only individuals have been able to perform assignment reviews in Expertiza. Over the years, it has been observed that it would be more desirable if assignment setters could define how a specific assignment could be reviewed. One of the ways will be by an individual, and a new way of reviews will be by teams. The same teams formed for the assignment would be able to participate in reviewing peer assignments. The benefits of peers review are numerous, and there is an additional benefit of reviews by teams. In general, we may be getting to a point where traditional individual reviews are becoming ineffective, often missing nuances in an assignments details and concepts. It is a general belief that team-based reviews will address this, often pooling together resources from multiple reviewers working as a team to form a one cohesive and often comprehensive review. On the flip-side, it may be difficult sometimes for all team members to meet to perform reviews, and this may either delay reviews or curtail them. Ultimately, it is felt that the advantages of team-based reviews far outweigh any inherent shortcomings. 1. A new button to select Reviewers as a team will be provided at the Assignments Edit page in the Review Strategy tab for the instructors 2. Any member of a team should be able to select a review to be done by their team. 3. Team members should not be allowed to edit a review simultaneously. 4. The responses as well as the response_maps in the database should be deleted when the instructor decides to the change the 'Review Strategy' after the reviews have already started. In summary, functionality should be provided to allow Team reviews by connecting everything as mentioned above. Other than the changes required to be done by us, during the course of the project we have implemented extra changes as suggested by the professor. These changes include: 1. Providing the delete review logic in case the instructor decides to change the review strategy. 2. To track 20 mins of inactivity to auto-save the review in case when the user starts the review and forgets to save it. A message will flash every 30 secs in the last 5 mins to inform the user that the review will be saved if there is no activity. 3. Initially, the e-mail to the reviewee, for the review was sent when a response was created (i.e when a response is saved). Because of this there is a chance that the reviewee won't find any review since the review has not been submitted only saved. Thus, we changed this so that the e-mail is sent only when a review is submitted. We will add the following fields in existing models of the Expertiza. 1. To assign team based reviewing attribute to the assignemnts a new boolean field reviewer_is_team was added to the with the default set to false. 2. To create a common response for all the team members we added a team_id field to the ResponseMap model. This identifies the reviewer team. 3. To prevent concurrent editing of the reviews by the team members we lock the response in the ResponseMap. This is check is based on the new is_locked field. 4. To identify the user who has locked the review we have also added a locked_by field in the ResponseMap which carries the current_user.id. <image>. 1. The first change is a simple view change. The checkbox will added in ""assignments/edit/_review_strategy.html.erb"". The checkbox value will be passed to the response_controller and depending on the value of the checkbox, the response_map will be created. The default value for the checkbox is ""false"". Thus, it will not break any existing functionality. <code> 2. For this feature to work we must create correct mappings. In Expertiza, all reviewees are AssignmentTeams, even in a non-team assignment where each team consists of a single participant. However, with this project, reviewers can be either participants or teams. In our design we are creating only one ResponseMap per team, i.e if the ""reviewer_is_team"" is set by the instructor, the ResponseMap created will have the reviewer_id as the participant_id of the requesting student and the team_id as the id of requesting students team in that assignment. Now to map this single response to all students in a team, we changed the strategy which returns response_mappings, in the ""student_review_controller"", for a particular reviewer. If the assignment has team_reviewers, then we find the responses by ""team_id"", and if there are no team reviewers for the assignment then we return responses by matching the ""reviewer_id"". Thus, if our mappings are created correctly, then the entire team will be directed to a single response_map and thus a single response irrespective of who requests the review. Thus, any of the team members will be able to request reviews as as the mappings will created with the team_id. The reason for us to not set the ""reviewer_id"" null or 0 for team reviewers is that, some of the functionalities like number of reviews, scores are all mapped to a single participant. Thus, if that is set that to any value, we will have to define all new methods for team reviewers. But, now we can use all those functions on our response and then make that same response object available to all members of the team. By doing this, we are neither creating redundant maps and nor are we defining new methods for the same functions. The code snippet below shows our new strategy to find the responses for a particular reviewer. <code> 3. This is an important feature since if we allow teammates to edit reviews concurrently, each of them will overwrite each other's changes. We have handled this by using the is_locked and locked_by field in the response_map table. Using these fields, we will lock the response for the current_user. Thus, when one teammate is editing, the response is locked and that members id is stored in the locked_by field. Now for other users we will check locked_by field. If it does not match their id and they click on the edit button, then a error message will be displayed which will inform the user that his/her teammate is already editing the same review. This response is then unlocked when the current_user saves the response. The methods for locking and unlocking the response are defined in the <code> 4/5. Changes 4 and 5 are both database migrations. Thus, we just add these fields in their respective tables. 6. This feature is provided to handle a rare edge case. Say that the instructor decides to change the review strategy after the reviews have already started. Now, the format of the response_maps already created will not match the response_maps that will be created after the strategy change. Thus, if the instructor wants to change the strategy, s/he can delete all reviews already done, and then instruct students to start over. The delete_reviews method is defined in the assignment model. Our method deletes all the response_maps as well as all the response objects created. <code>. <table>. 1. MVC - The project is implemented in Ruby on Rails that uses MVC architecture. It separates an application’s data model, user interface, and control logic into three distinct components (model, view, and controller, respectively). 2. DRY Principle - We are trying to reuse the existing functionalities in Expertiza, thus avoiding code duplication. Whenever possible, code modification based on the existing classes, controllers, or tables will be done instead of creating the new one. 3. Polymorphism - We will use polymorphism to provide a single interface to entities of different types. In Expertiza, individual and team-based reviewers will share one single interface. <image> 1. Name: Teams submitting reviews for assignment or topic 2. Actor: Student (as member of a team) 3. Other Participants: Team Members 4. Precondition: Instructor has set up an assignment with review strategy as ""Team Reviews"". This assignment also has only teams. No students can participate as an individual. Thus, when a participant is added to the assignment, s/he will be added as a single member team. Thus, in the diagram above, the participant is a single member team. 5. Primary Sequence: Log in to Expertiza. Select an assignment. Select ""other's work"". The student can request a review for the team from here. Depending on the number of reviews allowed and the number of reviews already performed by the team, they will be allotted a new review Begin the review. Only one member of the team can edit the review at an given time. All restrictions that apply to individual reviewers, also apply to teams (e.g. like a individual reviewer, a team also cannot have more than 2 outstanding incomplete reviews). Complete the review and Click Submit. Edge Cases Apart from the case explained above we have handled two edge cases. These cases are as explained below: Case 1: Scenario: We are not allowing concurrent editing of reviews for teams. We are doing this by locking the response_map. Thus, when a team member is editing a review we lock the response using that team member's id. It can only be unlocked when the review has been saved. When locked the other team members can only view the review. Case 2: Scenario: The beginning of a review is a special case since when the begin button is clicked a review form is only rendered. Nothing is saved. Since there is no response object linked to the review, we cannot lock anything. Thus, if this case is not handled all the teammates will be able to begin the review concurrently and the person who saves last will overwrite changes of all teammates. Thus, we lock the respnse_map. Now when one of the teammate begins the review ,and the other teammates try to begin too, they will get an error saying that the review is already being edited by someone else. Case 3: Scenario: If a team member forgets to save or submit a review and has not closed the browser window, then we automatically save the review after an inactivity timeout of 20 mins thus unlocking it for the other team members to edit. After 15 mins of inactivity a message will be flashed every 30 secs, on the users screen informing him/her that after 5 more mins of inactivity the review will be auto-saved. The progress will not be lost. If the user wishes to continue editing, the counter can be reset with a simple movement of the cursor. Case 4: Scenario: At a critical time, if a team is unable to contact the team member who has locked the review by closing the browser window without saving the review, the other team members can contact the instructor who has been provided an unlock button for such emergency situations. The instructor can now unlock that review and then the other team members can edit it. This button was added since, in the case when a user directly closes the window without saving, we cannot track inactivity. Thus, the 20 mins auto-save condition will not function. For this condition to work there is a prerequisite that the browser window must be open. Thus, to handle the case when the aforementioned prerequisite fails, we have provided the unlock button to the instructor. Case 5: Scenario: An instructor can delete completed review if he/she decides to change the review strategy for an assignment between team reviews and individual reviews. When the instructor changes the strategy and clicks on the save button, there will be a pop-up confirming if the instructor wants to delete all the reviews. If a user is editing a review at the instant when instructor is deleting the reviews, upon pressing the save review or submit review button, the user is redirected to the student_review/list.html.erb page UI Changes 1. Currently there is no team reviewing in Expertiza. Thus, we will provide a check-box, in the review strategy tab of edit assignments, for the instructor. Checking this box will set the reviewers to teams, rather than individual participants. As seen in the new implementation, the delete button has been removed from the review_strategy tab. Instead, now when the instructor decides to change the review policy, s/he will get a pop-up. Current Implementation is as follows: <image> New Implementation will be as shown below: <image> 2. By default, the reviewers will be individual students. When they request reviews, they request reviews for themselves. If the instructor changes the reviewers to teams, then each participant (who is member of some team), will request reviews on behalf of the entire team. If the assignment has individual reviews: <image> If the assignment has team reviews: <image> When Instructor assigns reviews: <image> Test Plan The Assignments functions; including creation, updating, saving and modifying methods have already been tested, and our test plan includes testing for the new team-based reviewing functionality that we have added. Our test plan includes the following test methods: 1. Test the delete_reviews method to check whether it displays a flash message when there are no reviews to be delete. 2. Test the delete_reviews method to check whether it displays the success flash message on deletion of reviews. 3. Test the action_allowed? method to check whether it denies certain action when the review is locked by a user other than current user. 4. Test the action_allowed? method to check whether it allows certain action when the review is locked by current user. 5. Test the reviewer_is_team_member method to check whether the current user is a member of the assignment review team. Additional Links <link> <link> <link> Team Information <link> <link> <link> <link>. Apart from the case explained above we have handled two edge cases. These cases are as explained below: Case 1: Scenario: We are not allowing concurrent editing of reviews for teams. We are doing this by locking the response_map. Thus, when a team member is editing a review we lock the response using that team member's id. It can only be unlocked when the review has been saved. When locked the other team members can only view the review. Case 2: Scenario: The beginning of a review is a special case since when the begin button is clicked a review form is only rendered. Nothing is saved. Since there is no response object linked to the review, we cannot lock anything. Thus, if this case is not handled all the teammates will be able to begin the review concurrently and the person who saves last will overwrite changes of all teammates. Thus, we lock the respnse_map. Now when one of the teammate begins the review ,and the other teammates try to begin too, they will get an error saying that the review is already being edited by someone else. Case 3: Scenario: If a team member forgets to save or submit a review and has not closed the browser window, then we automatically save the review after an inactivity timeout of 20 mins thus unlocking it for the other team members to edit. After 15 mins of inactivity a message will be flashed every 30 secs, on the users screen informing him/her that after 5 more mins of inactivity the review will be auto-saved. The progress will not be lost. If the user wishes to continue editing, the counter can be reset with a simple movement of the cursor. Case 4: Scenario: At a critical time, if a team is unable to contact the team member who has locked the review by closing the browser window without saving the review, the other team members can contact the instructor who has been provided an unlock button for such emergency situations. The instructor can now unlock that review and then the other team members can edit it. This button was added since, in the case when a user directly closes the window without saving, we cannot track inactivity. Thus, the 20 mins auto-save condition will not function. For this condition to work there is a prerequisite that the browser window must be open. Thus, to handle the case when the aforementioned prerequisite fails, we have provided the unlock button to the instructor. Case 5: Scenario: An instructor can delete completed review if he/she decides to change the review strategy for an assignment between team reviews and individual reviews. When the instructor changes the strategy and clicks on the save button, there will be a pop-up confirming if the instructor wants to delete all the reviews. If a user is editing a review at the instant when instructor is deleting the reviews, upon pressing the save review or submit review button, the user is redirected to the student_review/list.html.erb page. 1. Currently there is no team reviewing in Expertiza. Thus, we will provide a check-box, in the review strategy tab of edit assignments, for the instructor. Checking this box will set the reviewers to teams, rather than individual participants. As seen in the new implementation, the delete button has been removed from the review_strategy tab. Instead, now when the instructor decides to change the review policy, s/he will get a pop-up. Current Implementation is as follows: <image>. The Assignments functions; including creation, updating, saving and modifying methods have already been tested, and our test plan includes testing for the new team-based reviewing functionality that we have added. Our test plan includes the following test methods: 1. Test the delete_reviews method to check whether it displays a flash message when there are no reviews to be delete. 2. Test the delete_reviews method to check whether it displays the success flash message on deletion of reviews. 3. Test the action_allowed? method to check whether it denies certain action when the review is locked by a user other than current user. 4. Test the action_allowed? method to check whether it allows certain action when the review is locked by current user. 5. Test the reviewer_is_team_member method to check whether the current user is a member of the assignment review team. <link> <link> <link>.","This is quite readable, except for the long paragraph in Step 2 of Approach, which should be broken up.  Some reviewers denigrated the test plan, but it seems reasonable now.  I would encourage you to make more use of Mediawiki markup instead of just putting numbers at the start of paragraphs.","This was quite an insightful, thorough and well-structured assignment with detailed descriptions of your proposed changes to the Expertiza system. It was impressive how you provided intricate strategies and planned for potential complications. You also planned for a great deal of contingencies by outlining ""Edge Cases"" and how these would be handled.

Your explanation of the motivations behind the change are very well versed, showing understanding of the benefits and potential drawbacks of the proposed innovation. You've also gone into some depth about the technical specifications which demonstrate a good level of comprehension.

However, some elements of your assignment were repetitive in nature, like for instance the repeated mention of edge cases at the end of the assignment, which felt unnecessary. Furthermore, the test plan is missing concrete tests with expected outcomes and defined inputs. Without those, it could become harder to understand what exactly is being tested and what the expected results should be.

Finally, the paper could benefit from focusing more on the user experience and the potential impact on users. For instance, how does the proposed changes benefit the instructors, and how well does it mesh with their existing workflow, or does it require them to adopt a new workflow.

The assignment might also benefit if you discuss more about the potential challenges and how to overcome them not only technically but also from a user perspective. It would also be beneficial to see a risk evaluation - what might be the knock-on effect if these changes caused issues?

Despite these areas for improvement, this is overall a thoughtful and well-researched paper. Keep up the good work!"
69,E1759,"Expertiza is an open source project based on Ruby on Rails framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. One of several ways to set up the environment and the one we adopted is:- Ubuntu-Expertiza image (.OVA) [Recommended] This is the link for the image. ( <link> ) And you can install VirtualBox (free) and import this image into VirtualBox. Some machine may require you to enable virtualization and then run the following commands. <code> <code> <code> <code> 1. For logging in as an instructor:- Username: instructor6 Password: password. Expertiza should be able to distribute surveys to the users. The survey can be one of the following: 1. Course survey (all the participants of the course can take it). 2. Global survey (all the users in Expertiza can take it). The survey can also be targeted (the admin can specify a group of people who will receive this survey). The three kinds of surveys in this project are: 1. Assignment Survey questionnaire 2. Global survey questionnaire 3. Course evaluation questionnaire <image>. The following tasks were performed by us as part of our project: 1. Understood the flow of the survey creation and deployment function. 2. Updated the RSpec file in /spec/features/ folder. 3. Used fixtures to create the student record in test DB. 4. Used Capybara to write functional tests for: 1.1. Creating a new survey. 1.2. Creating different types of questions. 1.3. Editing different types of questions. 1.4. Deleting different types of questions. 1.5. Deploying survey. 5. Created multiple tests to check valid and invalid cases. For example, to test valid_start_end_time? by checking that if the start time is later than the end time, the test returns false. 1. spec/features/survey_spec.rb 2. spec/features/assignment_survey_spec.rb 3. spec/features/global_survey_spec.rb 4. spec/features/course_survey_spec.rb 5. spec/features/helpers/instructor_interface_helper.rb. Login as an instructor: 1. Use credentials username: instructor6, password: password. 2. Click on Manage -> Questionnaires-> Survey / Global Survey/ Course evaluation. 3. Create a new Survey/ Global Survey/ Course evaluation filling in the parameters asked for. 4. Test if the survey is created and deployed and the questions can be added, deleted and modified. <image>. The following test spec has been written to create an assignment survey. <code> The following test spec has been written to deploy an assignment survey. <code> The following test spec has been written to create a course survey. <code> The following test spec has been written to deploy a course survey. <code>. After completion of this project, the creation, deployment, and deletion of surveys will be fully tested.","The wiki is well organized, but is also quite short.  The class hierarchy diagram and screenshot are useful.  Each test is described with just one line of code.  It would be much more helpful to have the various steps in the tests described in prose.","Dear Student,

Your understanding of Expertiza software along with its specific features including assignment creation and management, topic creation, team formations, survey deployment and peer review process is impressive.

The descriptive workflow of setting up the environment for Expertiza with the specific mention of various steps and necessary commands proves your understanding of the practical use of the software. The detail about the login process and its utilities is also covered well. 

Moreover, you have very nicely outlined your tasks within the project, including understanding the survey creation and deployment function, RSpec file updation, usage of fixtures for student record creation in test database and the use of Capybara for writing functional tests for various functionalities. 

You have thoroughly elaborated on creating different types of surveys like Assignment, Global, and Course Evaluation Surveys. Utilizing various test specifications to check the validity of different cases shows commitment to thoroughness and accuracy in your work. Your explanation of the methods you created to test various scenarios ensures that you have a solid understanding of the concepts involved.

Where the assignment could use improvement is in the organization of your points. There's a bit of repetition in terms of the RSpec examples and explanations - maintaining a clear, logical flow can make the assignment easier to read and understand. In particular, I would suggest consolidating all the details and examples related to test specs in one segment of your assignment instead of distributing it throughout. 

Overall, you did a good job on this assignment. Keep it up!

Best,
[Instructor Name]"
70,E17A7,"Expertiza is an open source project created using Ruby on Rails. This project is a software primarily to create reusable learning objects through peer review and also supports team projects. Expertiza allows the creation of instructors and student accounts. This allows the instructors to post projects (student learning objects) which can be viewed and worked upon by students. These can also be peer reviewed by students later. In the existing Expertiza functionality, the functionality for bidding for topics is present though only for specific situations. The bidding ability is only for bidding for a topic for (teams of) students in a course. This involves the instructor posting a list of project topics, and each student (or all students together as a team, if some students have already formed a team) then post a preference list, listing topics (s)he wants to work on. Then the bidding algorithm assigns the topics, particularly with the following features: 1. Students (not in a team) with close preferences are assigned to a project team, and the common preference is the project topic assigned to the team. Alternatively, for existing teams, the project topic is assigned as per the common project topic preference list 2. Each team is assigned only one topic 3. Each topic (if assigned) is assigned to a maximum of one team. This project is responsible for the bidding algorithm used in the conference, which is significantly different from the project bidding algorithm as explained above. For the purposes of the project, we assume that there are several reviewers in a conference who review papers which are proposed to be presented in the conference. Also, the entire list of papers proposed to be presented in the conference is also available. Then the basic working of the project assumes: 1. Before the bidding close deadline, reviewers submit a list of papers they wish to review. 2. After the bidding deadline, the algorithm assigns papers to reviewers to review, such that: 1.1. Each paper (if assigned) is assigned to a maximum of R reviewers (here R represents some constant) 1.2. Each reviewer is assigned a maximum of P papers to review (here P represents some constant) 1.3. Assignment of papers can be individual or team based. In this section, we discuss the problem statement, then discuss the existing code and possible changes required. 1. To take the existing bidding code in Expertiza (which is meant for students bidding for project topics) and make it callable either for bidding for topics or bidding for submissions to review. 2. The matching algorithm is currently not very sophisticated. Top trading cycles is implemented in the web service (though it is currently not used by bidding assignment) and could be adapted to this use. In the subsequent discussion with the mentor, it was concluded that the two bidding situations are very different hence it was decided to keep the two separate, at least initially. Also, the second requirement was modified to first make the bidding for a conference using any algorithm and if time permits, to use a better algorithm like top trading cycles. 1. To develop code such that both applications (bidding for project teams and bidding for conference paper reviews) use the same code 2. To improve the algorithm for calculating the score for a particular project topic/conference paper review assigned to a project team/conference reviewer 3. To ensure that the topic assignment algorithm assigns topics in a balanced manner in the case no reviewer has bid for any topic 4. To develop a variable name in the database so as to distinguish between a project topic and a reviewer topic We want to state here that we are not responsible for developing any conference features. Specifically, this means that we are not changing any UI features. We will be primarily relying on UI changes done by E17A5. The existing algorithm solves the following problem: To form teams of students of Maximum size M and then assign topics (there are N topics) based on preference lists submitted either by individual students or teams (complete or otherwise). Preference Lists can have minimum 0 topic and a maximum of L topics. Then the topics are allocated to teams such that each team gets a unique topic and each topic is assigned only to one team. The topics are assigned to project teams in 2 steps: 1. Making teams: This is done using a k-means clustering and a weighting formula that favours increasing overall student satisfaction and adding members until the maximum allowable team size is reached. You can read about it in detail <link> . 1.1. The basic cost function used in the algorithm is: D(i,j) = 1/N * ∑ [ M -U(i) ] where i varies from 1 to N 1.2. The Algorithm calculates the weights for every user, not a team or part of an incomplete team. It then assigns teams using the weights, by plotting graphs for each topic. It is as follows: 1.1.1. Draw a graph for every topic j with X-axis as the priority position i and the Y axis as the Weights. 1.1.2. Hierarchical K means to select teams such that all students in a team are close to each other in the graph above, hopefully, more towards the left of the graph, and also such that there are a minimum of 1 and a maximum of M students per team; 1.3. The Algorithm is as follows: <code> 1. Assigning topics to teams: This is implemented as a one line, comparing bid preferences to allot topics. In the following subsections, we discuss the problem, proposed design and code. We are trying to combine the code so that it can be used for both the project topic bidding as well as the conference paper review bidding. The combined problem statement is as follows: Given a list of people (students or reviewers) and also a list of N items to bid on (project topics or conference paper reviews), we require the following: 1. To form teams of Maximum size M (M is a positive number) 2. Based on preference lists submitted by people/teams having a minimum of 0 items and a maximum of L items, to allot items to teams such that each team gets at most P items and each item (to be bid on) is assigned to at most R teams. We note the differences: 1. For Bidding for Assignment Topics, M is generally greater then 1, but P = 1 and R = 1. The item to be bid on is the project topics. 2. For Bidding for Conference Paper Reviews, M >= 1 but P and R are generally greater then 1. The item to be bid on is the conference paper reviews. We note that a team of 1 person makes little sense, but we still implement it to be so that the code is compatible for both the applications. Keeping the existing algorithm and the project requirements in mind, we decided to divide the code into 2 parts: 1. Part A: Make teams for people not in a team (and if applicable, complete incomplete teams) 2. Part B: Assign topics to teams We note that Part A has been implemented on a web service independent of Expertiza. We also note that the algorithm explained above applies only to Part A, and that it is pretty sophisticated. Hence we choose to keep the existing code as is for this part. We will simply call the web service, provide the list of people, their bidding preference and also the max_team_size. Part B is implemented as one line. It is pretty simple. We also note that it simply cannot be used for conference paper review assignment. Hence we completely change this section and implement it using a new algorithm. In the 2 part design proposed in the above section, there were major changes in part B. These are discussed below: Let N = Number of topics <code> For every topic i: <code> Now find_den = ∑ [ N + 1 ] - ∑ [k] where the iterating variable k varies from 1 to t. 1. As we can see, each user gets a separate score for each topic there is to bid for. The scores are assigned on the basis of the preference list submitted. 2. Two users can get identical scores only when their preference list is identical. Even if user 2 has all topics of user 1 except the last one in the same order as user 1, still all topics of both users get different scores. 1. All scores are arranged in ascending order. 2. For the following values: <code> 1. Then calculate m1 = floor (n1 * n3 / n2) 2. Calculate m2 = floor (n2 * n4 / n1) 3. The topics are assigned on the basis of this order of scores, with the restriction that one topic should not be assigned to more then R reviewers, and each reviewer should not get more then the minimum of (P , m1) topics, provided that the score of the bid is lesser then the base score 4. The topics are assigned on the basis of this order of scores, with the restriction that one reviewer should not be assigned more then P topics, and each topic should not get more then the minimum of (R , m2) reviewers, provided that the score of the bid is lesser then the base score 5. When the bid score is greater then the base score, then the normal test conditions apply 6. This last modification is done for the balancing of assignment of topics in the case no team has submitted a preference list. In this case, this change tries to ensure that every topic is assigned in such a way that there are more or less equal number of reviewers reviewing each topic. The design methodologies that we will use while writing the code is discussed here. 1. We will implement this new algorithm such that the code is DRY 2. Use of naming conventions: To define the new variable to differentiate between project and conference topics as is_conference? 3. Re factoring the methods: The method that we are working on was very long. We will re factor it into several smaller methods of around 20 lines (altogether, these new smaller methods should be visible on a screen as a whole) 4. No hard coding of the data assignments 5. Use of new database objects if required 6. To understand and to use existing database column values, even in the case they are not used in the situation as of now. We have to implement this with the entry conference_slots. Actors: 1. Conference Reviewer: Submits a preference list of papers and reviews assigned papers 2. Conference Administrator: Responsible for the assignment of topics to the reviewers Scenario The case of reviewers submitting a list of preferred topics and the administrator running the assignment process. For our project, the main modification would be concentrating on Use Case 4 and 5. <image>. 1. Use Case Id: 1 2. Use Case Description: Participants choose the preference for conference review topics and submit it 3. Actors: Participants 4. Pre Conditions: Conference papers are presented and submitted, and the participants are eligible for reviewing 5. Post Conditions: Conference committee members can view participants preference and run bidding algorithm on it. 1. Use Case Id: 2 2. Use Case Description: bidding preferences and related participants information are processed and saved to database 3. Actors: None 4. Triggered by Use Case 1 5. Pre Conditions: participants preferences are submitted 6. Post Conditions: information can be retrieved and used by bidding algorithm. 1. Use Case Id: 3 2. Use Case Description: participants can view list of topic available for conference paper topic 3. Actors: Participants. 1. Use Case Id: 4 2. Use Case Description: Committee members can run bidding algorithm on application to help assigning the conference paper topics to participants 3. Actors: Conference Committee 4. Pre Conditions: preferences must be submitted by participants 5. Post Conditions: the bidding result can be used for paper assignment. 1. Use Case Id: 5 2. Use Case Description: System assigns participants to conference paper topics according to bidding result 3. Actors: None 4. Triggered by Use Case 4 5. Pre Conditions: bidding algorithm has run and result has been returned 6. Post Conditions: Participants can view topics been assigned to them. 1. Use Case Id: 6 2. Use Case Description: Conference committee members can change assignment result manually 3. Actors: Conference Committee 4. Pre Conditions: topic assignment has been done 5. Post Conditions: changes in bidding result is visible to participants and other committee members. Below is the Data Flow Diagram for process flows of the project. The diagram shows the process of bidding algorithm that we proposed to use for conference paper review assignment. <image> We explain in the terms of the actors: Reviewer and Administrator 1. Before the deadline, all the reviewers have to submit preference list of papers. They can save, modify list as many times as they want, but they can submit once 2. This information is saved in the database 3. When the deadline is passed, stop accepting preference lists 4. The administrator runs the paper assignment algorithm 1.1. For every topic, calculate the score for each user 1.2. Make a common score list, which keeps score assigned to every topic of every user. There should be a way to find out the topic and user a particular element of the score list belongs to 1.3. Now start assigning topics according to highest score 1.4. Keep track of the number of topics assigned to each user and the number of users assigned to each topic 1.5. If the number of topics assigned to one user reaches the maximum value, remove that user from consideration (remove all scores corresponding to that user from score list) 1.6. If the number of users assigned to one topic reaches the maximum value, remove that topic from consideration (remove all scores corresponding to that topic from score list) 1.7. Continue the above process until the score list is empty 5. Save the bidding into the database 6. Inform users about the results of the bidding. We extended the code for bidding in the lottery controller, made a separate type of assignment in the database using a new column ""is_conference?"". In addition, a new bid object model was also defined. We discuss these changes in the following sub sections: 1. Files Changed: lottery_controller.rb 2. Description of Change: Earlier the lottery_controller.rb consisted of one method of 50 lines, which is not readable. We divided it into several methods. 1. We realize that we must create the conference ""assignment"" to be compatible with the whole of Expertiza, and it must be different from a course assignment. To do this, we create a new column ""is_conference?"" in the assignment table 2. This variable is boolean, and if true, then it means the assignment is a conference assignment 3. We created a migration for the same 4. Code: <code>. Following the design methodology, we defined a new model to store the ""scorelist"" of bids along with the topics and the team ids. 1. Files created: bid_score.rb 2. Code: <code>. While we defined some of our own variables when creating the new functionality, we also have used the conference_slots option to control the assignment of topics to reviewers. 1. Code Changes : Given in the next sub section. 1. This was discussed above 2. Basically, in the case none/some of the teams have no preferences, then these teams should be assigned topics such that each topic has more or less the same number of reviewers assigned. 3. There can be two cases in which this does not happen: more number of teams via-a-vis topics or vice versa. 4. File Changed: lottery_controller.rb 5. Code Changes: <code>. In the latest revision, we have used the latest expertiza code base for our project. 1. UI testing of the implemented functionality to be done. 2. No UI has been created been created for the conference paper review bidding. Hence assignment bidding controller is used to manually test the code on a local host to determine the feasibility of code. 1. 1.1. Log in as an instructor 1.2. Go to an Assignment 1.3. Go to topics section, add few topics for the assignment. Later check the enable bidding checkbox button. 1.4. Go to add participants page, add few student to the assignment. 1.5. Now save the assignment. 1.6. Login as student (who is a participant of the assignment) 1.7. Go to the assignment page, then go to sign up sheet and bid for topics. 1.8. Do the above the step for the participants. 1.9. Login back to an instructor, go to manage assignments page, click on the run intelligent assignment button. 1.10. Go to the topics tab in the assignment, here you will be able to view all the team's assignments to their topics. 1. TDD and Feature Test cases to be written. For instance, we will do Rspec test in cases below: 1.1. When all the reviewers submit their preferences. 1.2. When there are no preferences from any user. 1.3. When few have their preferences and few don't. 1. Case 1: No reviewer submits a list of preferred topics to review : In this case all topics are assigned same bid score. Topics are assigned to users on the basis of ""balanced assignment"", first come first serve. 1. Case 2: All reviewers submit exactly the same list of topics to review: It will be first come, first serve. 1. Case 3: Number of topics exceed the number of teams: Some topics may not be reviewed,depending on the limits put by the conference. It is responsibility of administrator to add more teams in such a situation.","The description of what needs to be done is very clear.  The description of the current bidding code is not.  Some kind of itemized list would have helped.  In the new code, I don't understand what score calculation is about.  Is that perhaps bid priority?  The description of the test cases is very short and not specific; it would have to be elaborated considerably to be used as  blueprint for implementation.","This assignment is very well written and offers a detailed explanation of the project. I appreciate your effort and dedication to make this work, especially with the level of detail you provided about the proposed changes, use cases and data flow. 

Before we go forward, here are a few suggestions:

1. Clearer definitions: Though you've detailed the functionalities, it feels a bit overwhelming due to the usage of specific jargon without clear definitions. I suggest providing a brief explanation for the terms and the abbreviations used throughout the paper.

2. Organize: Organize your document better. Perhaps consider using headers and sub headers extensively to break down the information into digestible parts. This will also help make your document look cleaner.

3. Graphics: If you could use some graphics to illustrate how your proposed algorithm works and how the system will look post-implementation, it would be easier to visualize the changes proposed.

4. Proofread: Proofread your assignment for grammatical errors to ensure that it is easy to understand.

Overall, excellent work and this complex project demands this level of attention to detail. Keep it up!"
71,E1629,"The purpose of this project is to improve the performance of the Course and Assignment listing page. When an instructor or TA logs in to the system they are redirected to the course/assignment/questionnaire list page. This page lists all the courses that are created by the logged in user and also the public courses that are created by other users. The current implementation of the page is in ReactJS and takes a long time to load. The purpose of this project is to improve the performance of this functionality so that it takes lesser time to display the relevant data. The course assignment listing page has three tabs. These tabs are Courses , Assignments and Questionnaires . The courses tab lists all all the courses that the instructor/TA might be interested in. This includes all the courses that they created and also the public courses. Additionally in the courses page all the assignments related to each course is also loaded when the page is loaded. All assignments belonging to a course can be viewed by clicking on that course. On the listing page there exists a check-box which allows the user to select whether or not to display public projects. By default this option is selected and as a result all public and private courses are displayed. Similarly for the assignments page all the public as well as private assignments created by the user are loaded. Because of this the page takes a long time to load. This project is concerned with coming up with solutions so that the page is loaded in a quicker manner. The individual work items identified are as follows: 1. Include others' items check-box should be unchecked by default for both courses and assignments page. By default, the public courses should not be loaded. 2. Current implementation of the Course page makes separate REST calls to the controller for fetching assignments for each course. This is a bad design and it takes a while to load the whole page. we plan to modify such that the assignments are loaded only when a particular course is clicked. 3. List the courses in two different sections. One section should be to list all the courses that are created by the user. The other section should be to display all the public courses. This section should be displayed only if the check-box is selected. Searching for courses in the current single list implementation is difficult. Partitioning the list into two sections would greatly improve the usability of the page. 4. Similarly the assignments tab should be divided into two sections. The first section should list all the assignments that are created by the user and the next should list all the public assignments. In order to better understand the problem consider the following scenario: When logged in as an instructor(instructor6) the course page loads a total of 103 courses. Hence it will make 103 REST calls to fetch assignments for all these courses. Out of these 103 courses the signed in instructor is concerned with 25 courses. Assuming he checks the assignments to all of these courses it would result in a total of 25 REST calls to fetch assignments. This is a considerable reduction in the number of REST calls. The table that displays the course listing is a ReactJS component. Currently it loads both private and public courses in the same section by means of a single REST call. We intend to split this such that one rest call is made for public courses and one call is made for private courses. Files modified: 1. app/controllers/tree_display_controller.rb 2. app/assets/javascripts/tree_display.jsx 3. app/views/tree_display/actions/_courses_folder_actions.html.erb View of the Private Courses Section <image> View of the Public Courses Section <image>. Adding to the changes made in previous work item, load only the private section on page load. The public section is loaded only when the check-box to load public courses is selected. Files modified: 1. app/controllers/tree_display_controller.rb 2. app/assets/javascripts/tree_display.jsx 3. app/views/tree_display/actions/_courses_folder_actions.html.erb. Each row in the course listing table represents a course. Each course has a sub section listing its assignment. Whenever a user clicks on a course a REST API call will be triggered and this will fetch the assignments, and a subsection will be added to the user interface. Files modified: 1. app/controllers/tree_display_controller.rb 2. app/assets/javascripts/tree_display.jsx 3. app/views/tree_display/actions/_courses_actions.html.erb. <image> <image>. This project is involved with improving the performance of the Course and Assignment Listing page. The work is majorly in reactJS and there is no necessity to change the current database design. In order to measure if the changes we made as part of the project leads to actual performance improvement, we are planning to use page load time as a metric. We will update this section with a comparison of the page load time on completion of the project. Since most of the changes that are required to implement this project are proposed in the user-interface using javascript we will be performing manual testing of the UI. Detailed steps are as follows: 1. Course listing is a view used by instructors & TAs to view courses. As the instructor & TAs login to expertiza, they would be directed to the course listing where they would see that checkbox (“include others’ items”) to include public courses by other members, in the listing is unchecked by default. Similar to course listing, there is an assignment listing as well to be tested. Also check to see that only private courses are loaded by default. 2. The logged in user’s courses and others’ public courses are listed in two different sections. One section for each type. Section listing others’ public courses are displayed only when user selects the checkbox “include others’ items. 3. Similarly, the logged in user’s assignments and others’ public assignments are listed in two different sections. Section listing public assignments are be displayed only when user selects the checkbox “include others’ items”. 4. Check that on clicking a particular course in the course-listing page, the assignments of that course are listed. Added the following new test cases to the tree_display_controller: <code>.","Limited tests done, but then, there wasn't much that could be easily tested.
Design doc is rather sparse, not including the screenshot of the different course types (which doesn't explain much about the project).","Dear Student,

You've produced a comprehensive project around the performance improvement of the Course and Assignment listing page. You've shown a clear understanding of the application and its underlying technology, identified critical bottlenecks, and proposed thoughtful solutions to tackle those problems. Your proposal to make separate REST calls only when necessary, as well as dividing the display into different sections for public and private assignments/courses, are excellent suggestions for reducing load times.

Your detailed step-by-step manual testing plan further demonstrates an understanding of QA processes. Please make sure to thoroughly document the results of these tests for a clear demonstration of the final improvements and for future reference. 

However, I would recommend not only relying on manual testing but also invest time in setting up automated integration tests, which would help ensure the integrity of the system in the long run by catching potential regression errors early. You've mentioned adding new test cases to the tree_display_controller but there's no detail on these. Could you provide more information on them or clarification if I misunderstood?

Also, directly measuring the decrease in page load time is a good way to quantify the improvements made, but considering factors such as the number of queries to the server and the amount of data processed could also provide additional insight.

Lastly, consider including figures, graphs or tables to visually show the improvements in performance before and after the modifications.

Overall, you've done a great job outlining your plan for this project. Looking forward to seeing your measurement results and the final project!

Best,
[Your Name]."
72,E1683,"In Expertiza, students can review others’ work. However, currently all reviews are done by individuals, regardless of whether the assignment is assigned as individuals or teams. In team assignments, when the team member reviews an assignment, his/her review is independent from his/her teammates’ reviews. To encourage students to discuss together and review carefully, it is sometimes reasonable for students to submit their reviews as a team. And apparently, team-based reviewing can reduce the workload of each student. In a word, the main purpose of this project is to achieve the function of team-based reviewing and ensure that Expertiza works well with the change. <image>. Based on the design documents, the basic project design is proposed below. In Expertiza, we have ResponseMap , which is the object that records who reviews whom. In ResponseMap , there are two attributes: reviewer_id and reviewee_id . The reviewee_id is the ID of the Team , which indicates which team is being reviewed. And the reviewer_id is the ID of Participant , which specifies a user who is participating in this assignment. <image> To achieve function of team-based reviewing, a boolean field reviewer_is_team needs to be added to ResponseMap to determines whether the reviewer is a AssignmentParticipant or an AssignmentTeam . If reviewer_is_team is true, then the reviewer_id would refer to a record in the teams table, not a record in the participants table. <image> And a field reviewer_is_team is also need to be added to the assignments table as well to indicate the review of assignment is an individual-based reviewing or team-based reviewing. <image>. Several parts of the system need to work regardless of whether the reviewer is an individual or a team, like “View my scores” and “Alternative view”. The scores are given as team if the reviewing type is team-based. <code> For an Instructor to specify whether the reviewing is team-based or individual-based, we are intended to provide a dropdown on the Review Strategy tab of assignment creation. <code> <code> We set a lock in editing review, so that other team member cannot start to edit a review at the same time that one team member is editing it. The error message is considered to be displayed by flash[:alert] . <code>. RSpec is a testing framework for Rails, and is a Behavioral-Driven Development tool. It is a domain specific language(DSL). All the tests can be executed by rspec spec command, or can also be executed individually using the command ""rspec spec/models/assignment_team_spec.rb. We intend to write unit tests using RSpec for all the methods which we modified/created. We intend to write unit tests using RSpec for all the methods which we modified/created. And also the basic test case is proposed for UI test. <table>.","The documentation has everything that we asked for. it's well structured, contains a workflow diagram (it's not behaviour diagram. behaviour diagrams are use case, interaction, collaboration, state chart, and activity see UML 2.0). so I can skim it quite fast. the design of the UI with the pie chart is also nice. DB table is also explained well (Actually you could get ""round"" from the response table).  Well done!","Thank you for your submission. I appreciate the thoughtfulness and depth of your proposal for adding team-based reviewing to Expertiza. This is clearly a relevant change that will be beneficial for team assignments. You've identified key components to modify, such as the ResponseMap and assignments table, and offering an instructor control over the type of reviewing being performed is a great consideration. 

There are however a few points I'd suggest you make adjustments on or give more thought:

▪️ I noticed you mentioned adding a Boolean field called reviewer_is_team. How will you handle situations when the field isn’t explicitly set? What would be your default behavior and why?

▪️ Your lock for editing reviews to avoid conflicts is a significant move, but consider detailing the behavior when multiple team members simultaneously access the review, not necessarily editing.

▪️ The testing approach seems sound, but it might be beneficial to also describe some specific test cases you anticipate using RSpec. Considering edge cases goes a long way in ensuring a robust application. 

▪️ Moving forward, it would be great to see more consideration given to the UX/UI changes, possibly with some wireframes or detailed descriptions of how this will integrate seamlessly with the existing interface and user workflow. 

With these points addressed, I believe the proposal would be more comprehensive. Keep up the good work!"
73,E2010,"This page provides a description of the Expertiza based OSS project. <link> is an open-source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. The criterion.rb model consists of functions that decide what to display while creating, editing and viewing the questionnaires depending on whether the user is an instructor, a teaching assistant or a student. So, this file consists of a lot of HTML code that is rendered to the final questionnaire view. The current version of this controller has four methods, but two methods are very long and would require refactoring. The primary problem with these functions is that it consists of many statements of string concatenation. The HTML code which is rendered to the final view is made up of concatenations. Another issue with the code is that the branch conditions size for the complete and the view_completed_question method is very high. Also, this controller has very few comments. They are specifically needed to differentiate between the purpose of numerous nested branches from each other. The criterion.rb model consists of functions that decide what to display while creating, editing and viewing the questionnaires depending on whether the user is an instructor, a teaching assistant or a student. So this file consists of a lot of HTML code that is rendered to the final questionnaire view. Criterion is a question in questionnaire. Other type question in questionnaire include Drop down (multiple choice), Text box (short question), Text area (long question). They can be add in questionnaire. For this project, we have to deal with the following two methods: 1. The complete method, which is 104 lines long. this method returns the display for the students when they are filling the questionnaire. It includes the advice given for different questions, dropdown options to rate a project based on the question, a textarea to enter comments and so on. <code> 1. The view_completed_question method, which is 47 lies long. Thismethod is responsible to return the display if a student is viewingan already filled-out questionnaire. <code>. Our goal is to refactor the complete and view_completed_question method mainly by reducing the number of lines code for each function and also by introducing new methods to make the code more modular. We will also try to reduce the branch condition size wherever possible and hence reduce the cyclomatic complexity for these two functions. We also plan to introduce comments wherever needed to make the code more understandable. The main aim is to reduce the number of lines and make the code more compact without affecting the readability of the code. 1. High branch condition size problem: extracting three methods from method "" complete "" 1.1. Method "" dropdown_criterion_question "" return html when choosing dropdown options 1.2. Method "" scale_criterion_question "" return html when choosing scale options 1.3. Method "" advices_criterion_question "" return html about showing advice for each criterion question 2. Too long code 1.1. Combining the short HTML strings into longer ones but not too long 1.2. Using one readable line of code instead of three or more lines of if-else statements 3. Fix incomplete condition problem 4. Change the language to more Ruby friendly. We tried to tackle the issues mentioned in the problem statement as described below: An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. We are running Rspec tests to make sure the coverage is the same and manually checking the pages to make sure there are not any issues and the code is not breaking. The origin test about method ""complete"" didn't include the situation when the parameter ""answer"" isn't nil and the parameter ""dropdown_or_scale"" is ""dropdown"" or ""scale"". We added the test examples from 4 to 16 including the multiple for method ""complete"", ""dropdown_criterion_question"", ""scale_criterion_question"". 1. Test for method ""complete"" with or without answer and dorpdown_or_scale Origin test <code> New test <code> 1. Test for method ""dropdown_criterion_question"" with or without answer <code> 1. Test for method ""scale_criterion_question"" with or without answer <code> 1. All existing tests passed <image>. Test Log in Website url: <link> Log in: instructor6 Password: password Log in: student2064 Password: password Test criterion works well in questionnaire 1. After logging in as a student, click the ""Assignments"" 2. Choose an assignment, like ""Backchannel application review"" 3. You can choose ""Your scores"" to see the review results 4. Click Criterion 1, you can see all the reviews for this criterion. 5. Click ""toggle question list"", you can see all criterion questions. 6. After logging in as an instructor, choose ""Questionnaires"" tag 7. Click on the name Review: This should show a drop-down showing different reviews made. 8. Choose a review, select the edit icon to the right. 8. Change dropbox of question type to Criterion, select Add ""2"" more. Press the add button. 9. Edit question content: ""Test question Textarea"", ""Test question Criterion1"", and ""Test question Criterion2"" in that order. 10. You can also change the question content for exited criterion question These manual tests show criterion works well. Feel free to try your own test cases.","There are two kinds of changes described: changes to individual statements, or compound statements, and changes to methods. The changes to individual statements are described very clearly, but for changes to methods, usually the authors just dump the old code out, followed by the new code. That does not help the reader much. There are formatting glitches due to hundreds of single quotes throughout the document. One of them is not closed properly, and that causes the whole document, except for part of the table of contents, to be in italics. The overall impression is that this document is clearer than most.. The testing plan is very elaborate. Good Rspec tests are included.","Dear Student,

Great job on the assignment! Your report is very comprehensive and shows a deep understanding of your project. I appreciate the progress and details you have provided. Here are my comments and suggestions:

1. Clarity: Your report is clear and straightforward. You’ve thoroughly explained terminology and functionalities, which is quite helpful. You could, however, shorten some passages for conciseness without losing any of the salient points.

2. Problem Statement: You've excellently identified the issues concerning the criteria.rb model. Your explanations about the problems faced, like high branch condition size and lack of comments, are satisfactory.

3. Programming Practice: Your plans to refactor and simplify the methods show good understanding of programming best practices, such as reducing cyclomatic complexity and improving readability. 

Minor Issues and Suggestions:

1. Duplication: Be wary of repeated information. I noticed some passages in the report were repetitive. Try to keep your points succinct and unique.

2. Grammar: There are few grammatical errors and typos such as ""47 lies long"", ""Thismethod"", and ""dorpdown_or_scale"". Always proofread your work or use grammar checking tools to maintain work quality.

3. Method Descriptions: If possible, try to give a bit more detail about how new methods work. It's good you've explained their purpose, but a little insight on their function will be useful.

4. Images: I’m unable to see the images mentioned. Please make sure you provide proper links and they are accessible for future reference.

5. Tests: The comprehensive list of test cases covers many scenarios, which demonstrates your diligence in perfecting your version of the controller. Keep up the solid work!

One last suggestion, rather than just stating that you did solve the problems, it would be helpful to see a comparison between the initial and refactored code chunks. This will give a visual indication of how much the complexity and readability of the program has improved.

Overall, well done on your project, and keep in mind the few suggestions that I have given as it will assist you in your future endeavors.

Best,
[Your Name]"
74,E1463,"Expertiza<ref name=""expertiza> Expertiza <link> </ref> is an open source web portal for the use of both students and professors. Expertiza allows us to create reusable learning objects through peer review. It allows project submission, team creation and the submission of almost any document type, including URLs and wiki pages. Students can access their pending and finished assignments, they can do peer reviews on several topics and projects. It is developed on Ruby on Rails platform. More information on Expertiza can be found <link> . The source code has been forked and cloned for making modifications to the to survey responses controller. This wiki provides an insight into our contributions to the OSS Expertiza application, focusing on Refactoring the SurveyResponses Controller. <image> <table> Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.1.4. <link> 1.1.1.5. <link> 1.1.1.6. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link>. Refactoring helps to<ref> <link> </ref> 1. Understand what led to poor code design 2. Fix code which is difficult to understand 3. Express each idea “once and only once” 4. Recognize missing or inadequately formed classes 5. Simplify overly complex relationships between classes 6. Achieve the right balance of responsibilities among objects 7. Make code easier to test and more maintainable. We identified the following categories of code smells in the helper module: 1. Fat Classes : No class should be fat. Ever. There is no need for your controllers, models or views to be fat; this shows laziness, as there's been no thought given to the application's design outside of deciding to use a particular framework. 1. Bad Class names : A good class name is expected to adhere to the Ruby style and design style guidelines. It is expected to convey a reasonable amount of functionality handled. 1. Lengthy Definitions : These are the methods that have too many responsibilities and collaborators. As a result of which, their overall length has grown too long reducing the maintainability and readability. 1. Duplicated Code : These are those pieces of code that does almost the same functionality of some other piece of code leading to a bad design style. They are usually too error prone since not everyone identifies all the code responsible for the same task and does the changes whenever the need arises. There are many documented refactoring techniques, and a few common ones are below.<ref> <link> </ref> 1. Rename Class : Controllers as per Ruby conventions should be plural. 2. Using Helper classes : No class should be containing lot of code, a better practice is to have all active record queries with in the model and in order to keep as much as Ruby code out of the views, helpers are used. Helpers are the only methods you can access, other than instance methods for an instance you have access to. 3. Extract Method : It consists of breaking up long methods by shifting overly complex chunks of code into new methods which have very descriptive identifiers. This class creates surveys and records the responses which can be viewed. On submitting the responses, the scores and comments are posted. Classes : SurveyResponsesController.rb What it does : Creates surveys, submitting surveys, views responses, posts scores and comments. What has to be changed : 1. Pluralize the class SurveyResponseController to SurveyResponsesController 2. Changing declarations of Arrays and Hashes,removing commented out code 3. Use of routing helpers instead of hardcoded URLs 4. Move active record queries to the model or another class 5. Reducing the number of instance variables per action to one. 1. A new survey_responses_controller.rb file is added : As per Ruby on Rails convention, controller names get pluralized while model names are singular. So, the controller name becomes survey_responses_controller instead of survey_response_controller for SurveyResponse modelclass. 1. Modified declarations of Arrays and Hashes Before Refactoring : survey_responses_controller.rb <code> After Refactoring : <code>. Controllers are best at parsing the inputs, they call the appropriate models, and then format the outputs. It is desirable to have a skinny controller responsible for parsing inputs and models doing actual validation. A bunch of Active Record queries that existed in survey_responses_controller have been moved to SurveyResponse model. Before Refactoring: survey_responses_controller.rb <code> After Refactoring: survey_responses_controller.rb SurveyResponse.get_survey_list and SurveyResponse.get_survey_list_with_deploy_id methods have been created in SurveyResponse model for active record operations. <code>. It desirable not to have more than one instance variables in a controller action as it indicates increased coupling. Our goal should be reducing coupling as much as possible and view should have direct access to as few instance variables as possible. Here persist_survey method has been created in the SurveyResponseHelper to minimize instance variables. Before Refactoring: survey_responses_controller.rb <code> After Refactoring: survey_responses_controller.rb <code>. Creation of a resourceful route will also expose a number of helpers to the controllers in the application. We modified the routes.rb file to include all the actions in the controller. resources :survey_response do <code> The resourceful routes generated the helpers given below: <code> <code> <code>. Comments and extra spaces have been removed and conventions have been followed to enhance readability of the code. Testing was performed by running 2 different VCL instances one with the original code and the other with the re-factored code. While performing the manual testing we noticed that when new course evaluations are created, the survey participants are random users and participants selection is not based on the courses. However, while displaying the pending course evaluations in the course evaluation list view, the courses are taken into consideration. Because of this difference we were not able to submit survey responses and view them. In below images we have shown that the output after refactoring and output without re-factoring for all actions in the SurveyResponsesController. <table>. 1. <link> 2. <link>. <references/>.","Writeup doesn't clearly indicate what changes were made. There is a tendency to show ""before"" and ""after"" versions without saying what is different between them.  It doesn't mention design principles, nor list any design patterns.  Reviewers had trouble understanding code.","Your assignment on Expertiza and refactoring the SurveyResponses Controller shows great depth and understanding of the technical aspects involved. The understanding of Ruby on Rails platform and the identification of the challenges that you faced with the code are commendable. 

However, this report could greatly benefit from more structured organization. The usage of lists and sub-points disrupts the flow and could be rephrased into full sentences to create a cohesive narrative. Also, consider including more of an introduction to set up the context of your assignment, before delving into the technical details. 

The links, and reference markers (<link>, <ref>) should be replaced with actual references and hyperlinks to make the data more accessible for the reader. Further, use of placeholders such as <image> and <table> suggests that relevant images or tables have to be incorporated. 

The section about refactoring techniques and the reasons it's necessary is well explained and gives the reader a solid understanding of why this process is important. The problems you have identified are helpful to understand what kind of issues to look for, and your description of how each of them can be resolved is informative.

In your next assignment, also consider discussing more about the impact of these changes in a broader context—how does better code design affect the user experience or the scalability of the platform? A section discussing the results of your refactoring, along with lessons learned, might add value as well. 

In terms of grammar and syntax, there are a few places where sentences are awkwardly constructed or ambiguous. Be sure to proofread your assignment thoroughly before submitting it. 

Overall, you demonstrated a strong understanding of the platform and your role in modifying it, which is promising. Keep refining your communication skills and continue to consider both meticulous detail and overall big-picture impact."
75,E1868,"review_mapping_controller is the largest controller in Expertiza with 614 lines of code. The basic functionality of this controller is to assign reviewers to review artefacts or submissions by other participants or teams. But this controller includes a major chunk of code for generating and rendering several reports to the instructors. As part of the project E1837 <link> , the review_mapping_controller.rb file has been significantly modified to improve maintainability, code quality and code readability. To summarize, the review_mapping_controller was modified by separating the report generation functionality into a new helper named report_formatter_helper. This helper serves the logic for rendering different reports as per the instructor's request, thus segregating the controller specific code from the code for rendering the reports. Refactoring from E1837 served as one of the primary design improvements to achieve scalability with different reports. But, this improvement contradicts with the single responsibility Object-Oriented Design Principles. The aim of this project is to extrapolate the report_formatter_helper code into a reports_controller. - Separation of concerns - Generalize code to render reports - Modify the UI to list reports - Testing the newly introduced reports_controller. The reports and reviews are two different functionalities which should not be clubbed. As part of this refactoring, the existing design of review_mapping_controller handles the following two different functionalities: 1. Manage various reviewers 2. Display and manage different reports This violates the single responsibility principle <link> by handling two different functionalities. This project aims to segregate these functionalities into the following two controllers: 1. review_mapping_controller to manage the functionalities of reviewers 2. reports_controller to handle the reports functionalities. The reports provide functionality such as presenting reviews for grading, showing author feedback (rejoinders), showing a table of all teammate reviews, showing a calibration report in an assignment where students rate the same work that has been previously rated by an instructor, and showing how many answers students have tagged. Every report boils down to one single idea i.e. loop through either participants or teams. This loop can be generalized so that the layout (includes headers, footers etc) can be consistent across reports while delivering the desired content. In the current implementation, the reports are accessed by clicking on the “view review report” button in the buttons tray of an assignment, which leads into the review report page. This page contains a drop-down menu listing various reports to navigate to. This always forces the user to initially view the review report and only then choose the required report. We intend to modify this implementation such that the user is not forced to view the review report but can directly select the required report. Since the logic for report generation has been abstracted into a new controller, existing tests for report generation must be verified for regression and also check for improving the code coverage statistics. In order to follow good design practices, the logic to differentiate reports will be implemented using Strategy Pattern <link> . Currently, there are ten different reports 1. Review report 2. Author feedback report 3. Teammate review report 4. Aggregated comments by rubric question 5. Comment summary by reviewee (team) 6. Potential collusion report 7. Answer tagging report 8. Calibration report 9. Plagiarism checker report 10. Self review report The new implementation will have ReportFormatter module with following methods - ReviewReport - AuthorFeedbackReport - TeammateReviewReport - RubricQuestionReport - RevieweeCommentReport - CollusionReport - AnswerTagReport - CalibrationReport - PlagiarismCheckerReport - SelfReviewReport UML representation of the new module is provided below <image>. In order to avoid the user to be redirected to review reports page every time the user wants to view a specific report, the following changes have been made to the implementation: 1. The icon in view assignments page has been renamed from ""view review report"" to ""view reports"" to generalize. <image> 2. On clicking the ""view reports"" icon, the user is directed to a new page that has the drop-down to select the required report. <image>. The use case of reports gives a broad overview of the functionality. It also provides the preliminary tests to be written to ensure the proper working of the feature. Below use case diagram represents the intent of reports functionality. <image> RSpec is the preferred testing framework in the project. The first set of test cases deal with the retrieval of different reports for assignments and validating the fields returned by the reports. The details are as follows(sample reports screenshot included) 1. When the requested report type is ""SummaryByRevieweeAndCriteria"", we check that the corresponding data is rendered. This report should contain a summary, reviewers, average scores by reviewee, average score by round and average score by criterion. <image> 2. When the requested report type is ""SummaryByCriteria"", we check that the corresponding data is rendered. This report should include a summary, reviewers, average scores by reviewee, average score by round and average score by criterion. <image> 3. When the requested report type is ""ReviewResponseMap"", we check the corresponding report data is rendered. This reports participants, average and range. <image> 4A. When the requested report type is ""FeedbackResponseMap"" and assignment has varying rubrics by round feature, we check the corresponding participants' data related to feedback i.e. number of feedbacks done, last feedback status. 4B. When the requested report type is ""FeedbackResponseMap"" and when the assignment does not have varying rubrics by round feature, we check the corresponding participants' data related to feedback i.e. number of feedbacks done, last feedback status. <image> 5. When the requested report type is ""TeammateReviewResponseMap"", we check that there is a correct mapping between the participant and its response. The report must return participant information, the number of reviews completed, teammates reviewed, the last review status. <image> 6. When the requested report type is ""Calibration"" and participant is not empty we check if the correct report is rendered or not. The report must return the calibrated values of the participants' response to the given assignment. <image> 7. When the requested report type is ""AnswerTaggingReport"", we check if the correct report page is rendered or not. The report must render the participants' details, the number of taggable answers, the number of answers tagged, the number of answers not tagged and the percentage of answers tagged. <image> 8. When the requested report type is ""PlagiarismCheckerReport"", we check if the correct report page is rendered or not. 9. When the requested report type is ""CollusionReport"", we check if the correct report page is rendered or not. 10. When the requested report type is ""SelfReviewReport"", we check if the correct report page is rendered or not. Since this refactoring project includes a new controller, the idea from the test perspective is to cover the basic scenarios of the feature. Complete feature coverage including corner case scenarios shall be committed based on the schedule for the project.","The work to be done is described well, and so is the test plan.  However the Implementation specfics contain only a list of reports to be created, and nothing about the structure of the code that creates them.  Reviewers gave this design doc high marks.","Your work on this assignment is comprehensive and well-explained. The detailed process of separating the functionalities of review_mapping_controller and report_formatter_helper into different controllers for adjusting to single responsibility principle is expressed in an orderly manner. 

Your application of Object-Oriented Design Principles and the mentioned Strategy Pattern supports your code design and enhances maintainability. The details about the new implementation of ReportFormatter module and the outlined methods are a commendable effort. 

However, the assignment would be more readable if you could divide it into clear sections, possibly with subheadings such as ""Purpose,"" ""Current Issues,"" ""Proposed Changes,"" ""Design and Implementation,"" and ""Testing."" This structure could make your writing easier to follow. 

Your proposed changes in the user interface are practical and user-friendly. Your effort to create a direct, intuitive path for users to access reports of interest is appreciated. 

Your test plan seems systematic and thorough. Using RSpec to write your test cases is a great choice. It is admirable that you have broadly included expected outcomes of the various report types. However, don't forget to also mention and implement corner case or negative test scenarios in your tests. 

Lastly, your assignment lacks actual code sections or pieces that could be helpful to fully comprehend your work. To make your work more concrete, try to incorporate pseudo-code or small code snippets to illustrate your processes. 

Great job overall! Please make these adjustments for your final submission."
76,E17A6.2,"Expertiza is a educational website that allows school users to submit peer reviews on assignments. To register to use this website, one needs to be either a course TA or Instructor and send a request to expertiza administrator to get approved. The request function only serves TAs and Instructors, so students won't be able to register. A student account is created by instructors or TAs. The whole purpose of this approval process is because students have no point of using this website without enrolling to an instructors course first, so they shouldn't request accounts from expertiza but from their instructors and TAs. A pending request page that displays all the requests should also be able to perform actions like approve or reject with an note. However, currently, all of these are done manually, which means no pending request page currently exists, no simple approve or reject action, and no user experience, and all users are added into the database through command line operations in the database(only instructor and TA roles which is acceptable currently but not when more other institutions try to user Expertiza). In addition, we also want users be able to add their institution if it does not show under the list provided by us. Overall Introduction Request account function is currently not working properly. A new user who tries to request an expertiza account can do so, but the instructor can see yet has no power to approve any request. The approval process is currently done manually, which is cumbersome. Our mission is to fix the request account functionality so that whoever requests for a new accounts can be approved by instructor clicking a button, and secondly, optimize the functionality to improve user experience. 1. Add institution <br\> -A registering user should be able to choose their institution from a drop-down menu, but they should also be able to add an institution if they couldn't find one. <br\> -The new institution should be saved as a new record into the institution table <br\> -New account request should be saved to requested_users table with correct institution id.<br\> 2.superadmin, admin should be able to approve/decline requests <br\> -add a new drop-down item under “Administration > Show…” so requests can be visually displayed and handled<br\> -enable the ""approve"" function for admin and superadmin<br\> -make clickable user email address so a conversation is possible<br\> 3. The record retain after admin's approval/rejection and an email will be sent to remind <br\> -an email should be sent when a request is approved or declined<br\> -all record should be kept on the page even it has been handled<br\>. The following is the use case diagram for the feature that we are going to implement. <image>. - redesign the view shown in the previous section to include a field named institution in the current form to allow user to submit their institution if they couldn't find one in the list, and save it into the table corresponding to the form it submits to. - design a requested_user table to save all account requests. - to create an new view that can show all pending account requests and include actions like approve and reject to allow instructors to process requests on the same page - create corresponding new controller with methods corresponding to actions like reject, approve and index. <image>. - redesign the view and model to retain the request record after super-admin or admin approves the request. - add an email tag in the corresponding view, so there will be an email send to email address offered by requester after approval/rejection. 1. First of all, a new user need to click 'REQUEST ACCOUNT' to create a new account. <image> 2. In the 'request new' page, in the original version, the user can only choose an institution from the drop-down menu. After our modification, the user can choose the 'Not List' choice in the drop-down menu and type in an institution when (s)he is not able to find his(her) institution in the drop-down menu. <image> 3. After log in as an admin/super admin, the user can see a drop-down item under 'Administration->Show->Pending Users' to see all account requests. <image> ‎ 4. After clicking the 'Pending Users', the admin can see a list of new account requests and the emails are clickable to send email to the requesting user. Also, after the admin accepts the request, the record should retain in the view and an email informing the requestor will be sent to the requestors' given email address. <image> 5. After clicking the email address, the sending email page will pop up and admin can converse requestors. <image>. The project is implemented in Ruby on Rails that uses MVC architecture. It separates an application’s data model, user interface, and control logic into three distinct components (model, view and controller, respectively). We are trying to reuse the existing functionalities in Expertiza, thus avoiding code duplication. Whenever possible, code modification based on the existing classes, controllers, or tables will be done instead of creating the new one. Both manual and RSpec test will be performed on the following items. 1. a proper error message for improper information filled in, such as wrong email address format or existing account. 2. When a pending account gets approved or rejected, an email will be sent to the submitted email address. 3. A new item ""show"" should be added under administration and direct instructor to pending requests page when clicked 4. pending requests will have an email column that is clickable which allows instructor to send emails to applicants before a decision is made. 5. when a request is processed, its record is still kept with the status of processed.","The document is reasonably readable.  It explains the changes in functionality. The UI changes are described, but the code changes are not.  The test plan is not adequately described.  It should say what tests are to be performed, not just which functionality is to be tested.  It is reasonable to test the UI manually, but model and controller tests should be automated.","This is a comprehensive and well-thought-out assignment. You’ve done a great job outlining how the registration and approval process can be improved in Expertiza. Your proposed solution seems both user-friendly and efficient, which are crucial factors in website design.

Here are my suggestions to further improve your work:

1. When discussing the need for a system change, be careful with phrases like ""not currently working properly"". This can be interpreted as negative criticism, which is not constructive. Instead, focus on the need for enhancements and optimizations to improve user experience.

2. Be careful with your wording. There are a few instances where the phrasing is not quite clear, which can make it difficult for readers to understand your point. For example, ""This is because students have no point of using this website without enrolling to an instructors course first"", this sentence could be restructured for more clarity -- consider rephrasing it to: ""This is because students do not need to use this website unless they have enrolled in a course first"".

3. The use of <image> placeholders suggests that diagrams are a component of your plan. Make sure to create those diagrams at your earliest opportunity as they will clarify your process and design much more effectively than text alone.

4. I noticed you aim to implement email communication within the website’s interface. While this can be useful, it may also extend the scope of your work significantly, as email communication involves different technological aspects from web development. Please reconsider this or ensure that the workload is feasible.

5. I would recommend that you also consider talking about user roles in more detail. For example, how will the system differentiate between an admin, super admin, and a regular user?

6. Lastly, consider discussing how to handle errors or unexpected user behaviour. For example, how might the system handle a user attempting to register with an email that has already been used?

Overall, this is a very solid piece of work! All these suggestions are meant to help you refine your ideas and further improve your assignment. Keep up with the good work!"
77,E1852.3,"<link> is an open source web-based peer review system developed and maintained by students and faculty members at North Carolina State University. Features of Expertiza enable students to work collaboratively in teams on course projects and assignments. The purpose and goal behind this project is to allow students the opportunity to refactor, implement, and test <link> - open source software. Our team chose to work on unit testing existing functionalities within Expertiza, as a way to identify possible pitfalls or possible improvements that could be applied to the existing code. Unit Tests are implemented to ensure proper independence and desired functionality of methods in a model. Unit Testing is an essential component for the following strategies: 1.1. Test Driven Development(TDD), where unit tests are used to drive the development of a product. 1.2. Behavior Driven Development(BDD), which augments test driven development through the application of principles such as ""Five Why's"" and ""Outside In"" to identify and implement behaviors that are directly beneficial to the outcome of the product. In this project, RSpec testing models were used to satisfy the testing requirements of behavior driven development. The Participant model is used to prepare data for participants enrolled in each course or specific assignment. Participants have many relational dependencies such as having associated reviews, responses, and assignment teams. Participants are also assigned to various topics and assignments depending on the involvement of the participant's user. Functionality of the model allows the return of the participant's current team, his or her current responses, identifying attributes such as name and user handle, as well as the participant's role permissions and authorizations. Additional components allow for the generation of notification emails and the calculation of a participant's grade on an assignment. There are not enough unit tests for the Participant model of Expertiza. Current path coverage of participant.rb is only 36.08%. 1.1. spec/models/particpant_spec.rb 1.2. spec/factories/factories.rb. 1.1. Write unit tests using Rspec 1.2. Achieve a path coverage of more than 90% 1.3. Achieve a high branch coverage. To achieve a goal of more than 90% test coverage, our team completed the following test plan: 1.1. Obtain the appropriate testing environment via a provided virtual box image and RSPEC testing framework. 1.2. Acquire a deeper understanding of the Participant model, its functionalities and dependencies. 1.3. Create factories and doubles to assist in the testing of model methods. 1.4. Mock message passing and expected outcomes. 1.5. Apply generated helper objects and mocks to achieve high test coverage of each method within the Participant model. Our approach to testing the Participant model involved simplistic use of helper objects and mocked message passing. Because functions proved independent, it was unnecessary to include any common test case setup in a before block. Due to the nature of testing the successful send of a user notification email, it was necessary, however, to include an after block that would reset any system notification. Thus, accurately reflecting the expected outcome when testing the email function. The design approach associated with the scores function required a more involved development of object relations such as assignment questions having answers that could be scored according to the scoring policies associated with the questionnaire type. Further association of scoring rounds was simulated to achieve full coverage. The Participant model is a super class that encompasses various types of participants. The current factory file contains a default participant build that is associated with a subclass ""Assignment Participant"". In order to ensure the testing of the super class functions, we created a participant factory that is derived directly from the Participant model. <code>. The following variables were generated using the provided factory class to assist in the testing of the Participant model. <code>. 1. team : Returns the team associated with a participant. - mock simulates the find_by method in TeamsUser object and returns team_user <code> 1. response : Returns the response associated with a participant. - mock used to simulate the return of a response from the participant's response_map <code> 1. name : Returns the name of a participant. <code> 1. fullname : Returns the full name of a participant. <code> 1. handle : Returns the handle of a participant. <code> 1. delete : Deletes a participant according to the participant's current associations and the value passed to the variable 'force'. - mock to simulate the return of the participant team when asked - mock used in the testing of a forceful delete of a participant with a team association consisting of a single team user by simulating the return of team length to be one when asked <code> 1. force_delete : Method called inside #delete to remove the participant and all necessary associations. Testing of this method is covered through the testing of #delete. Therefore, there are not explicit test cases written. 2. topic_name : Returns the topic name associated with a participant. - mock used in the testing of an existing topic name by simulating the return of a participant's topic when asked <code> 1. able_to_review : Checks and returns the review rights of a participant. <code> 1. email : Sends an email to a participant, verifying an assignment registration. <code> 1. scores : Returns a hash of values that are applicable to a participant's assignment scores (i.e. { participant information, assignment question information, total scores }) - We mock participant.assignment to assign value to list of questionnaire , and for each questionnare we get assessment. For each questionnaire mock compute_score there by getting the score value. Here we have covered the case where assignments having both one and two rounds of rubrics. <code> 1. get_permissions : Returns the permissions association with a participant based on participant type (i.e. participant, reader, reviewer, submitter). <code> 1. get_authorization : Returns the participant's authorization role based on its access rights (can_submit,can_review,can_take_quiz). <code> 1. sort_by_name : Returns the sorted array of participants by name. <code>. Run all Rspec tests from the terminal : <code> Run a specific Rspec test from the terminal : <code> Run Rspec tests from terminal with mutations to test quality of test cases : <code> 1.1. more information about mutation testing can be found in the link provided in the External Links section of this wiki. Through the implementation of quality unit tests, 100.00% path coverage was achieved. 1.1. <link> 1.1. <link>. Expertiza Github with implemented tests for Participant model : 1.1. <link> - tests can be found within rspec/models/participant_spec.rb Mutant gem description and use : 1.1. <link> Demo video can be found here: 1.1. <link> -This demo video involves an in depth walk through of the testing code 1.1. <link> -This demo video involves a short capture of the RSpec test run.","Excellent motivation of the tests, and good descriptions of what they return.  However, you did miss one place:  The Variables section contains a long list of objects.  It should be explained why those objects are needed.","Thank you for submitting this exhaustive project on Unit Testing the Participant model within Expertiza. Your report indicates that you thoroughly grasped the purpose, aim and strategies of test driven development and behavior driven development. Your commitment to achieving a higher branch coverage and path coverage is commendable. Here are my comments:

1. Overall approach: You have clearly outlined the approach you took in learning the model's functionalities and dependencies, creating factories and doubles, mocking and applying helper objects. There is evidence of considerable attention to detail.
   
2. Testing Strategy: The choice to implement unit tests and the way you used RSpec testing models is properly articulated. Your understanding of how to fully exploit testing structures to achieve maximum coverage is impressive.

3. Method Testing: Your explanation on how you tested each functional method such as 'team', 'response' etc., of the Participant model is well illustrated. Your use of simulation and mocking to ascertain method behaviors is praiseworthy.

4. Code clarity: Your description of the code, although thorough, could potentially be harder for someone not familiar with the project to follow. Including some examples or snippets of code might be useful to illustrate how you created factors, mocked responses, and performed tests.

5. Path coverage: The significant increase in path coverage is significant. This indicates the effective implementation of your planned strategies to achieve optimal coverage.

6. Consider including reflection in your report that considers what your team learned, what strategies ended up being more successful than others, and what you might do differently if you were to approach this project again.

7. Finally, it would be interesting to see more discussion about any particular challenges you faced during this project and how you overcame them.

Your strong analysis and diligent work is thoroughly appreciated. Your dedication to ensure thorough testing and improved coverage of the Participant model will greatly contribute to the stability and reliability of Expertiza. I would strongly recommend that you continue exploring this area of software development.
"
78,E1464,"The requirements provided for the Open Source System project of Expertiza were as follows : The file refactored in this project is user.rb (295 lines) which is User Model class for expertiza project. This model helps the user log in and checks whether the user is a student, admin or a super admin. It helps reset passwords and assign instrcutors to the user. 1. Writing proper getters/setters if necessary, otherwise remove getters/setters 2. Replacing inefficient boolean logic (`if true` is not conditional) 3. Replacing old-style ActiveRecord queries 4. Using {} and [] instead of Hash.new and Array.new 5. Not instantiating more than 1 instance variable per action. <link> is a project developed using <link> platform. It provides features like peer review, team assignments and submission of projects. This can be achieved by submitting code base, URL of hosted code on remote server and Wiki submissions. It is an open source application and the code can be cloned from <link> . This application provides an efficient way to manage assignments, grades and reviews. This makes the process easier and faster when the class strength is large. Expertiza is supported by National Science Foundation under Grant No. 0536558. Additional funding from the NCSU Learning in a Technology-Rich Environment (LITRE) program, the NCSU Faculty Center for Teaching and Learning, the NCSU STEM Initiative, and the Center for Advanced Computing and Communication. 1. <link> 2. <link> 3. <link>. Any website that wants to provide content or features based on user preferences/roles needs to handle users. A website can do this by authenticating its users by a login/verification process. Expertiza does this with the help of the User Model(user.rb). Expertiza has multiple user roles like Student, Instructor, Admin, Super Admin and TA. User Model helps the user login and verify to access privileges for each user. The User Model(user.rb) also handles various other features like user access management (for example, Setting Instructors, TAs for a set of Students), user password management (for example, forgot password feature, generating random password) etc. We have identified quite a few issues in the User Model of the Expertiza project. Given below are the issues that we have identified (and fixed thereafter): 1. Inefficient boolean logic present at multiple lines in the code 2. Not using [ ] & { } instead of Array.new & Hash.new (for reasons like code hygiene and efficiency) 3. Using “key => value” instead of “key: value” 4. Not using in-built array functions such as one?, any?, zero?, first & last 5. Methods that were not being used 6. Methods that were just delegating their implementations to other functions in other classes. For each of the above stated issues, we have made the following changes to improve the code: Before Changes <code> After Changes <code>. For reasons like code hygiene and efficiency, we did the following changes: Before Changes <code> After Changes <code> Before Changes <code> After Changes <code>. Before Changes <code> After Changes <code> Before Changes <code> After Changes <code> Before Changes <code> After Changes <code> Before Changes <code> After Changes <code> Before Changes <code> Before Changes <code> After Changes <code> Before Changes <code> After Changes <code>. Before Changes <code> After Changes <code>. Before Changes <code> After Changes The function was commented out. <code>. Before Changes <code> After Changes The code was commented out and delegated using the code <code>. We have refactored the code for user.rb file (User Model File) for Expertiza project without changing the functionality of the expertiza project. As such there would be no changes in the functionality of the project, but inorder to verfiy the changes made please follow the below mentioned steps: 1. Go to <link> <image> 2. Enter Username as 'user2' OR 'user3' OR 'user4' and Password as 'password' where user2 is ADMIN and user3, user4 are STUDENT. Now click on 'Login' button. 3. You should now be able to view the landing page(given below) after successful login <image> 4. Now logout and try logging in with incorrect credentials. For Example: Username: 'user3' and Password: 'user3' 5. You should be able to view the forgotten password page with message saying ""Incorrect Name/Password"" <image> 6. Moreover, the forgotten password page can also be accessed directly, by clicking on ""Forgotten your password?"" link in the <link> page <image>. The project had redundant code, multiple functionalities in a method and extra conditional statements in User Model file. We analyzed each occurrence of these issues, thus creating a list which needed to be refactored. Thus we refactored the User Model file according to global rules for Model class file and Rails 4.0 standard. It's very difficult to explain the sequential and detailed procedure, but it has been explained in the sections above within the capacity of the Wiki. <references/>.","Report tends to be a listing of code changes, w/no description.  Except for style, there is no application of design principles.","The report submitted is thorough, detailed and demonstrates a deep understanding of the assignment. You have done a good job addressing the project requirements and explaining the role of the User Model in the Expertiza system. The identification of issues in the User Model, as well as your proposed solutions, are concise yet comprehensive.

Sharing ""Before Changes"" and ""After Changes"" was useful to understand the scope of the refactoring done. However, those parts were missing the actual code snippets which could have further enhanced the understanding. Please remember to include them in your future assignments.

The procedure you provided for verifying the implemented changes is appreciated. In future, consider including technical processes such as setting up the project environment or accessing the refactored User Model in the Expertiza project to ensure complete understanding for the user checking your report.

The concluding section does a good job summarizing the impact of your changes to the Expertiza codebase. Please also note down any challenges faced or strategies used during the process; this could prove useful for future development works.

Lastly, it's always a good practice to also include a list of potential improvements for the future. This shows foresight, and will be beneficial to anyone who takes up this project down the line.

Overall, good work on this project and looking forward to seeing more of such diligent work in future assignments."
79,E2104,"<link> is an open-source project developed using the Ruby on Rails framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. The application allows students to submit and peer-review learning objects (articles, code, websites, etc)[1]. Expertiza supports submission across various document types, including the URLs and wiki pages. When an assignment or review approaches its deadline on Expertiza, students initially should receive deadline reminder emails at a specific time before the deadline that the instructor has preconfigured. Lack of this functionality sometimes results in students missing their assignment submission deadlines and thus losing marks. Students should receive this type of deadline reminder email. So this amendment to the project involves adding an asynchronous deadline reminder mailer to the application. Modified Files 1.1. app/models/due_date.rb 1.2. test/models/due_date.rb 1.3. db/migrate/20210319212323_create_delayed_jobs.rb Implementation approach 1) Reminder email sent when assignment or review is approaching deadline: In the due_date.rb file, whenever a new due date is created or an existing due date is updated, the 'start_reminder' method will be fired which will eventually be added to the delayed_job queue. This job will be executed at a preconfigured time before deadline, where it will fire the method 'reminder' which will be added to the delayed job queue by the handle_asynchronously method of gem 'delayed_job_active_record'. Inside the reminder method, we will fetch three attributes - assignment_id, deadline_type, due_at. These three attributes will be used to decide the deadline type ( submission or review or teammate review ), fetch the participant email for that assignment, fetch the deadline threshold and at the end send the email reminder at a specified threshold time before the deadline which will contain all the details such as assignment names link to assignment and assignment type ( submission or review or teammate review). Testing We have used Rspec for testing the delayed_job functionalities. Using the test-driven development (TDD) approach, we have added a Rspec test which checks whether the mail is enqueued upon the firing of the reminder method. We have used Rspec for testing the delayed_job functionalities. Using the test-driven development (TDD) approach, we have added a Rspec test which checks whether the call for reminder method is enqueued upon the firing of the start_reminder method, with the proper scheduled execution time. NOTE: All the reminder mails except the ones for the reviewer are sent to expertiza.development@gmail.com ,as this is already set in the development environment. Additional Links 1.1. Git pull link: <link> 1.2. VCL deployment: <link> References 1.1. <link> 1.2. <link> 1.3. <link> 1.4. <link> Team <link> <link> <link>. 1. app/models/due_date.rb 2. test/models/due_date.rb 3. db/migrate/20210319212323_create_delayed_jobs.rb. 1) Reminder email sent when assignment or review is approaching deadline: In the due_date.rb file, whenever a new due date is created or an existing due date is updated, the 'start_reminder' method will be fired which will eventually be added to the delayed_job queue. This job will be executed at a preconfigured time before deadline, where it will fire the method 'reminder' which will be added to the delayed job queue by the handle_asynchronously method of gem 'delayed_job_active_record'. Inside the reminder method, we will fetch three attributes - assignment_id, deadline_type, due_at. These three attributes will be used to decide the deadline type ( submission or review or teammate review ), fetch the participant email for that assignment, fetch the deadline threshold and at the end send the email reminder at a specified threshold time before the deadline which will contain all the details such as assignment names link to assignment and assignment type ( submission or review or teammate review). We have used Rspec for testing the delayed_job functionalities. Using the test-driven development (TDD) approach, we have added a Rspec test which checks whether the mail is enqueued upon the firing of the reminder method. We have used Rspec for testing the delayed_job functionalities. Using the test-driven development (TDD) approach, we have added a Rspec test which checks whether the call for reminder method is enqueued upon the firing of the start_reminder method, with the proper scheduled execution time. NOTE: All the reminder mails except the ones for the reviewer are sent to expertiza.development@gmail.com ,as this is already set in the development environment. 1. Git pull link: <link> 2. VCL deployment: <link>. 1. <link> 2. <link> 3. <link> 4. <link>.","This page is very rudimentary.  It just gives the implementation approach, and does not show what changes have been made.  The Testing section has one paragraph repeated twice.","Dear Student,

Thank you for your thoughtful and detailed assignment on the addition of an asynchronous deadline reminder mailer to the open-source project on Expertiza. You adequately described the modifications made to various files in achieving this goal and how it will support students in adhering to their submission deadlines.

You’ve done commendable work in explaining the implementation approach, indicating every single step performed during the process. Your decision to run methods in the delayed_job queue when a new due date is created or updated is very clever and it seems you've considered all the parameters. The use of `handle_asynchronously` method of the 'delayed_job_active_record' is also interesting and it appears that it's apt for this application’s needs.

The explanation on how you fetch the attributes and then use them to decide the type of deadline, fetch participant emails, etc., shows good data interpretation skills. The inclusion of the link, along with the assignment type, in the email reminders offers a comprehensive solution for students. 

One area I am interested to hear more about is the testing phase. While it's good that you have used RSpec for testing the delayed_jobs functionalities, it would be beneficial to elaborate more about the specific tests conducted (beyond checking if the call for the reminder method is enqueued). Additionally, are there any particular challenges or observations noted during the testing and how have you handled them?

Your clear notation of reminder emails being sent to a designated development email for all but the reviewer's mail is an insightful touch.

Finally, it would have been even more enlightening if you made a summary about how this new feature will improve the Expertiza environment not only from the student’s perspective, but also including the perspective of instructors and administrators.

Please also be more precise about your links to mentions, as you did not replace the placeholders with actual links. As part of your standard assignments, it would be helpful to replace placeholder texts such as `<link>` with actual URLs or documents.

Overall, you demonstrated thorough understandings and considerable skills in developing this feature. I look forward to your continuing improvement in future assignments. Keep up the good work!

Best regards,
[Your Name]"
80,E2026,"In CSC/ECE 517, there are Expertiza-based course projects, Mozilla-based course projects, etc. However, currently, we can only specify one kind of rubric for all kinds of course projects. This means that refactoring projects, testing projects, and Mozilla projects need to use the same rubric. We hope we could specify different rubrics to be used with different kinds of course projects. This project was implemented by another team in Spring 2019. We will be implementing our project on top of what was implemented by the previous team, and fix the issues that were found in their implementation. Information on what the previous team had worked on is described in the Previous Implementation section. All aspects of previous implementation were good, and their design was well appreciated. Their changes were also merged to expertiza:beta branch, but were later reverted since the specialized rubrics weren’t saved in the database. This <link> provides a detailed explanation to the problem. For us to get started, we were provided with following links from previous implementation: 1. <link> 2. <link> 3. <link> 4. <link>. This feature was previously implemented and was detailed <link> . The feature concluded with allowing 4 rubric scenarios for an assignment: 1. Rubric does not vary by round or by topic. 2. Rubric varies by round, but not by topic. 3. Rubric varies by topic, but not by round. 4. Rubric varies by both round and topic. However, there were two issues with the implementation: 1. Rubrics in the dropdown were only those created by the logged-in instructor, so the TA wouldn’t be able to see them 2. Rubrics would not be saved after selecting them and saving. In light of these issues, <link> to expertiza were made as follows: 1. Two additional columns are added into the Assignment table that determines whether Rubrics varies by either Round or Topic with default values False 2. update_assignment_questionnaires method is re-implemented 1.1. Having extra column in the assignment questionnaire table topic_id, no need for deleting all the data and re-writing it again every single time in the DB (this caused the previous implementation to have a delay when selecting **rubrics) 1.2. The only varying value is questionnaire_id, the rest values may not change from Topics or Rubrics tabs, but can be added 3. There are 4 (four) possible cases for saving and updating data: 1.1. used_in_round = null and topic_id = null 1.2. used_in_round = integer and topic_id = null 1.3. used_in_round = null and topic_id = integer 1.4. used_in_round = integer and topic_id = integer This solved the issue of having rubrics save. The feature we have to implement was not fully committed due to the previously mentioned problems, so we have to reincorporate the missing code. However, a resulting issue is the inability for an instructor or TA to use rubrics that they did not create. The current problem can be broken down into the following parts: 1. Integrate the changes made from the original implementation into the current version of Expertiza 2. Allow an instructor/TA to chose rubrics that aren’t only theirs 3. Create and update tests to reflect the changes as needed. Our proposed solution keeps the previous implementation, but changes rubric filtering to allow instructors/TAs to use filters that are not theirs. Alongside the changes in the original implementation we propose: 1. Allow an instructor to choose different rubrics for different topics 1.1. PROBLEM: The drop-downs for selecting rubrics show only those rubrics created by the currently-logged in instructor (per project mentor). 1.1.1. SOLUTION: Change the filtering in the questionnaire_options method to reflect the desired filtering. 1.1.2. FILE: app/helpers/assignment_helper.rb. Following the <link> footsteps, this diagram depicts the interactions between an instructor and an assignment. The instructor may edit, delete, copy, and other stuff (already existing in Expertiza). Alongside editing topics and due dates, the instructor can edit what rubrics are assigned to an assignment. The highlighted portions are of interest. The topics tab allows instructors to specify which rubric associates with each topic while the rubrics tab lets the instructor determine if the assignment will vary by topic or not. <image>. Since our project is to improve upon a previous implementation that was slightly flawed, we will be modifying all of the same files that they previously modified (even if we don’t choose to alter their implementation in that file). The major modified files from the previous implementation include: 1. Controllers 1.1. assignments_controller.rb : To refresh the topics list when changing tabs 1.2. popup_controller.rb : To add a potential error message to the rubric view scores popup 1. Models 1.1. assignment.rb : Add methods to determine if an assignment varies by rubric/topic. (will be refactored as part of our change, however) 1.2. assignment_form.rb : Add topic ids to created assignment questionnaires 1.3. assignment_questionnaire.rb : Add topic id to assignment questionnaire model 1.4. review_response_map.rb : To allow finding review questionnaires by topic id 1.5. sign_up_topic.rb : To allow a topic to have many assignment questionnaires attach to it (via topic id) 1. Views 1.1. assignments/edit.html.erb : To move topic editing view to its own file that is rendered as part of assignment edit 1.2. edit/_rubrics.html.erb : Factor out common code into a function, update to use topic id 1.3. edit/_topics.html.erb : Topic editing view that was moved from assignment edit view 1.4. popup/view_review_scores_popup.html.erb : Assignments that vary by topic should not be displayed, instead getting error 1.5. sign_up_sheet/_table_line.html.erb : Add questionnaires to signup sheet table if assignment varies by topic 1. Helpers 1.1. assignment_helper.rb : To add a topic id to the searchable fields for a questionnaire 1. DB Migrate 1.1. XXXXXXXXXXX_add_topic_id_to_assignment_questionnaires.rb : Migration to add topic id to assignment questionnaire schema 1. All of the related test files to accommodate the above changes To address the issues brought up with the previous implementation, we will also make the following major modifications: 1. Controllers 1.1. assignments_controller.rb : Refactor to use the persisted assignment fields for varying by topic/round instead of using methods 1.2. grades_controller.rb : Refactor to use the persisted assignment fields for varying by topic/round instead of using methods 1.3. popup_controller.rb : Refactor to use the persisted assignment fields for varying by topic/round instead of using methods 1. Models 1.1. assignment.rb : Add persisted fields to the assignment for varying by topic/round instead of using methods to determine it 1.2. assignment_form.rb : No longer delete all existing questionnaires on update, update them instead. Now find questionnaire by assignment questionnaire and type rather than assignment/type/round_number/topic_id. 1.3. assignment_participant.rb : Refactor to use the persisted assignment fields for varying by topic/round instead of using methods 1.4. feedback_response_map.rb : Refactor to use the persisted assignment fields for varying by topic/round instead of using methods 1.5. on_the_fly_calc.rb : Refactor to use the persisted assignment fields for varying by topic/round instead of using methods 1.6. self_review_response_map.rb : Refactor to use the persisted assignment fields for varying by topic/round instead of using methods 1.7. tag_prompt_deployment.rb : Refactor to use the persisted assignment fields for varying by topic/round instead of using methods 1. Views 1.1. edit/_rubrics.html.erb : Modify to set assignment vary by round/topic fields instead of non persisted flags 1. Helpers 1.1. assignment_helper.rb : Refactor by moving function to find questionnaire / assignment questionnaire to assignment_form.rb. Remove filters that only allow instructors to see rubrics. 1.2. grades_helper.rb : Refactor to use the persisted assignment fields for varying by topic/round instead of using methods 1.3. summary_helper.rb : Refactor to use the persisted assignment fields for varying by topic/round instead of using methods 1. DB Migrate 1.1. XXXXXXXXX_add_vary_by_topic_to_assignments.rb : Migration to add “vary by topic” field to assignment 1.2. XXXXXXXXX_add_vary_by_round_to_assignments.rb : Migration to add “vary by round” field to assignment 1. All of the related test files to accommodate the above changes. We will be re-adding the database flow that was added in the previous implementation, linking sign_up_topic to assignment_questionnaire via a topic_id field. <image> In addition to that, we will be adding two additional boolean fields to the assignment schema: vary_by_round and vary_by_topic . As discussed earlier, in the previous implementation, these were methods that were called to determine if an assignment varied by round/topic rather than a persisted value. <image> Only a subset of the fields for each table is shown in the diagram because most of the fields are not relevant to these changes and would only serve to distract from the relevant changes. Additions are shown in bold. While trying to integrate the previous team's implementation of this feature, we discovered that their method for querying AssignmentQuestionnaires (AQs) was flawed. It would always query for the AQs by assignment id, current round number, and current topic id. However, if the assignment did not have reviews that vary by round or topic, these values would be nil on the AQ, and the previous query would fail. To fix this, we modified the assignment_questionnaire function in the AssignmentForm model to check the Assignment's vary_by_round and vary_by_topic flags, and then add the corresponding fields to the query. This means that: 1. If an assignment does not vary by round or by topic, the query for AQs will be by assignment id only. 2. If the assignment varies by round but not topic, the query for AQs will be by assignment id and round number. <image>. As part of our implementation, we modified existing code as well as added new code. To ensure that existing functionality was not broken, and new functionality worked as expected, we used the following Test Strategy (which was also used by previous team): 1. The following existing RSpec test files have been modified and they pass as part of testing: 1.1. spec/controllers/assignments_controller_spec.rb 1.2. spec/controllers/questionnaires_controller_spec.rb 1.3. spec/controllers/response_controller_spec.rb 1.4. spec/factories/factories.rb 1.5. spec/features/assignment_creation_spec.rb 1.6. spec/features/quiz_spec.rb 1.7. spec/features/staggered_deadline_spec.rb 1.8. spec/models/assignment_form_spec.rb 1.9. spec/models/assignment_spec.rb 1.10. spec/models/on_the_fly_calc_spec.rb 1.11. spec/models/response_spec.rb 1.12. spec/models/review_response_map_spec.rb. 1. As part of previous implementation, the team had introduced the following new RSpec test files. We have retained those file. 1.1. spec/helpers/assignment_helper_spec.rb 1.2. spec/models/self_review_response_map_spec.rb 2. All these rspec tests passed. Here we describe manual UI Testing steps to edit an existing assignment to allow it have to specialized rubrics for different topic types. These steps are also shown in recorded demo video. 1. Login to Expertiza using instructor account (For testing, username: instructor6 , password: password ) 2. Click on Manage > Assignments 3. Click on Edit option for any assignment, you should get following view. Make sure Has topics? box is checked. <image> 1. Click on Rubrics tab. You will see 2 checkboxes ( Review rubric varies by round? , Review rubric varies by topic? ) 2. Check the box for Review rubric varies by topic? 3. Go to Topics tab and verify that there is dropdown menu beside each Topic. 4. Select a rubric from dropdown menu, and click Save <image> 1. Go back to Home, and select the same assignment to edit. When you click on Topics tab, you should see the rubric you had selected. All rspec tests part of <link> has passed. The <link> has increased by 10.9% to 41.425%. After merging the previous team's work with expertiza, several RSpec tests failed. 1. This was due to how questionnaires were retrieved/found for an assignment. Staggered deadlines also rely on finding questionnaires using topic id, which isn't handled until after an assignment is made. 2. Resolved However, undoing filtering results in even more errors across models, controllers, and forms. This feature, however is a quality of life improvement and is less of a priority. 1. Unresolved Another quality of life improvement is that staggered deadlines and topics cannot be added to an assignment until after the assignment has been created and saved. 1. This issue exists on expertiza's beta branch itself, separate from our changes. 2. Unresolved. 1. Github : <link> 2. Pull Request : <link> 3. Demo Recording : <link>.","The explanations are reasonable at first glance, but I think they depend too much on being familiar with the E1936 design.  One example is the Database Flow section.  The statement, ""We will be re-adding the database flow that was added in the previous implementation, linking sign_up_topic to assignment_questionnaire via a topic_id field."" is not clear, and the table below does not help to elucidate it.  Then it discusses the vary_by_round and vary_by_topic fields, referrring the reader to the previous design doc.  It would be much better if this document were self-contained.  That said, though, other aspects are well written.","Hello,

Firstly, thank you for the diligent and detailed work you have put into this project. It's clear that you have a good understanding of the task and the previous team's efforts, and I commend your well-structured approach to improving those original implementations.

Here are some points pertaining to your assignment:

1. Excellent Job: Your breakdown of the problems in the previous implementation was thorough and clear. This is apparent not only in your explanation of the issues but also in your proposed solutions.

2. Clarifications: While your project was well-documented, there were some instances where you mentioned ""the file"" or ""the link"", but didn't actually provide the file name or link. Going forward, please ensure all referenced resources are accurately included to avoid confusion.

3. Diagrams & Visuals: If there were any diagrams or images as part of your assignment, they are unfortunately not visible in the text. Please ensure to include any visuals as they can provide helpful context and illustrate your points conclusively.

4. Implementation: Your detailed breakdown of the files to be modified, and the rationale for each, shows great understanding of both the system's architecture and the task at hand.

5. Testing: I appreciate your deep dive into testing both automated (RSpec) and manual. This serves to illustrate that the functionality has been thoroughly checked.

6. Improvement Suggestions: I recommend that you further explain how these new features interact with existing components of the software. This insight could lead to better understanding of possible improvements or revisions in the future.

Overall, you’ve done an impressive job at identifying and addressing the problem, summarizing and improving upon previous work, and taking the steps to ensure a more successful implementation. Well done!"
81,E2073,"Expertiza is an open source web application in Ruby on Rails. Its purpose is to allow teachers and students an environment to enhance learning. For teachers, they can use this platform to create, edit, or grade assignments. Students are able to view assignments that teachers have posted, create teams for projects, and review other peers assignments. By having one platform for students and teachers to engage, students are able to stay on top of their tasks and teachers can monitor how well their students are learning the material. Courses are an essential part of Expertiza as students and teachers can be grouped together by a course. The course_controller has many important functionalities such as creating, modifying, and deleting courses. It also has other functionalities such as adding, removing, or viewing TA's. When the course_controller is called to create or modify a course, the course's name, institution ID, directory path, or info can be updated. Our task for this assignment is to refactor some of the code in the course_controller file. Why do we want to refactor course_controller? Refactoring is the process of restructuring existing code without changing its behavior. It is important to refactor to keep your code readable, understandable, and clean so that future developers can understand your code when they want to implement or change existing code. For the course_controller, we wanted to refactor it to courses_controller since the current convention of rails requires that controllers be plural. We also wanted to improve readability by removing redundant code in two functions and also fixing a warning message to be more understandable. Lastly we removed a function in course_controller that belonged in a model and not a controller. The following tasks were accomplished in this project: 1)The class should be named courses_controller.rb, to follow the current Rails convention that controllers should be named in the plural. 2)Edit the warning message in the copy function 3)Remove duplicate code in the create and update functions 4)Remove create_course_node function as it does not belong in a controller and move it to course_node.rb. Issue: The class should be named courses_controller.rb, to follow the current Rails convention that controllers should be named in the plural. Solution: By changing the name of the class from course_controller.rb to courses_controller.rb, we needed to go through all the files where Course was called and change it to Courses. <image> <image> <image> <image>. Issue: Edit the warning message in the copy function Solution: When a student submits a file it should be stored at the path that the teacher specifies. If a teacher specifies a path that already has a filed stored then we need to warn the student that the path is already in use and where they should go if they do not want to overwrite the current file. <image>. Issue: Remove duplicate code in the create and update functions Solution: In the first and second images below, we have removed the redundant code in the create and update functions. We replaced the redundant code with a function called set_courses_fields which we defined in the third image. <image> <image> <image>. Issue: Remove create_course_node function as it does not belong in a controller and move it to course_node.rb Solution: For the first image, we have removed the course_node function from the courses_controller.rb file. The second image we are in the models folder for course_node.rb and we have moved course_node from course_controller.rb into this file. <image> <image>. Our testing plan is to have a automated and manual testing to ensure that the application is still working after we did the refactoring. We will be using Rspec to do the automated testing and show you the steps we did to test the UI. In the subsections below we are testing the create and update methods. File: courses_controller_spec.rb Command to run rspec on file: rspec spec/controllers/courses_controller_spec.rb <image> <image> <image>. <link> In order to manually test some of the functionalities after refactoring course_controller: 1. Login as instructor. (Username: instructor6, Password: password) 2. On the navigation bar hover over Manage and a drop down menu will display 3. Choose Courses 4. You are now at the Courses page. 1. In order to create a course, there is a blue circle with a plus button on the right side of the page next to Actions 2. Click on the blue circle and it will lead you to the New Course Page 3. Fill in the information to create a new course 4. After filling in the course information, click create and it should take you back to tree_display/list page 5. The course you created should be listed at the top. 1. In order to update a course, go to a course that you want to modify 2. To the right of the course you have chosen there will be two rows of icons 3. On the first row there should be a pencil, red X, and a paper icon, if the pencil does not appear you may need to refresh the page 4. To edit click on the pencil icon, this will take you to the edit page 5. At the edit page you can edit whichever part of the course you want to change 6. After you make your edits, click update and it will take you back to tree_display/list page where the updates will display. config/routes.rb app/models/course_node.rb app/models/course_team.rb app/controllers/course_controller.rb app/views/course/_add_individual.html.erb app/views/course/_course.html.erb app/views/course/_ta.html.erb app/views/course/add_ta.js.erb app/views/course/edit.html.erb app/views/course/new.html.erb app/views/course/remove_ta.js.erb app/views/course/view_teaching_assistants.html.erb spec/controllers/course_controller_spec.rb spec/features/course_creation_spec.rb spec/features/instructor_interface_spec.rb. 1. <link> 2. <link> 3. <link> 4. <link>.","Very good description of what you needed to do, and how you accomplished it.  Would have been improved if the Refactorings (""Refactors"") section titles had included what changes were made (""Rename to courses_controller""), rather than just saying ""Issue 1"", etc.  The test plan could have had more prose description, like your refactorings had.","This is a detailed and comprehensive report of the task of refactoring the Expertiza web application's course_controller file. The explanation and justification for the code refactoring are well thought out, and the documentation is properly arranged. However, few points need to be taken into consideration:

1. Including the actual images or code snippets with your report would make the explanations more clear. I noticed a lot of placeholders for images in your text, but no actual images were linked.

2. For the testing part, be explicit about your success criteria for each test you perform. 

3. It's important to address any potential issues or system behaviors that can be affected due to the changes you've made. You didn't mention what impact, if any, these changes might have on other parts of the system. Also, it would be beneficial to note the potential ramifications of any changes you've made, should there be any negative side effects or unanticipated interactions with existing code. 

4. Also, consider discussing what future updates or maintenance could be beneficial for this part of the application.

Overall, this is a strong presentation that expertly conveys the work you've done. Please take care of these minor elements in your future assignments. Good work scanning through the entire application looking for areas of possible refactor and making the changes. Keep it up!"
82,E2103,"A response is the object that is created when someone fills out a review rubric, such as when one writes a review, gives feedback to a reviewer, or fills out a survey. Responses to the individual rubric items are kept in Answer objects; each Answer object has a response_id to say what Response it is part of. Since response_controller needs to work with many kinds of responses, its code is pretty general. It is not the worst controller in the system, but it would be much clearer if its method names were more descriptive of what they do. 1. def assign_instance_vars This name could be more specific. 2. def scores This should be a model method (in response.rb)! It is all calculation. 3. def new This method contains a complicated condition that determines whether the submission has been updated since the last time it was reviewed. If it has not, then the reviewer can edit his/her previous review. If there has been an update, then the reviewer gets a new review form to “update” the review. It would make sense to have a model method that tests whether there has been a review since the last file or link was submitted. Then the code here would just call that function. It would be a lot clearer what the new method is doing. set_content(new_response = false) also plays a role in this calculation. Perhaps this method should also be included in the refactoring, for the sake of clarity of the resulting code. 4. def set_questionnaire Badly named; what kind of questionnaire and why? The name should be a lot clearer. 5. def set_questionnaire_for_new_response Badly named, no comments, not at all clear. The logic is not like set_questionnaire. Rename, refactor for clarity, and add comments as appropriate. 6. def show_calibration_results_for_student This method makes about five db accesses. Can it be broken into 2 methods, with the business logic moved to response.rb?. Below is a list of code refactor tasks and issues addressed by this team in this project. We have also included any pertinent details, reasonings, comments, warnings, etc., corresponding to each task. This method was poorly named and commented. This method was called within the controller methods Edit and New, and is used to set any instance variable objects that the controller will need during these actions. Due to this functionality, it was renamed to assign_action_parameters to better clarify that it was assigning parameters for the controller actions. <image>. This method appears to have been created to replace the code at lines 71-74, however these particular lines of code are never repeated, and any calculation or business logic regarding scoresd should be (and is) in the model, the method scores is not necessary. The method scores was deleted as part of this refactor. <image>. Note: The current version of this refactor does work - however, there are plans to refactor this further to meet CodeClimate requirements. The reason this method was complicated and needed refactoring was due to the fact that when a response is being created, that particular Response object must be created when the User first begins a new Response (so do the Answer object(s)). A new response also has to be created when there have not been any reviews for a particular current round, and also when a reviewee has updated their submission after the most recent review in the current round. So far, this method was refactored by moving much of the logic to the Response model in the method populate_new_response. In this method, references to a response map and the current round (if any) of a response are used to determine whether a previously-created or a new response object is used in this new review. <image> <image>. The main issue with this method was the naming and poorly commented code, making the purpose and functionality of the method obscure. This method is called whenever a user is editing or viewing a response - in this case, the controller already has access to the particular Response object in question and thus this method is used to get a reference to the questionnaire corresponding to the Response object and question id. Due to the functionality and because it requires access to a Response object already, this method was renamed to get_questionnaire_from_response. Comments were added to clarify its functionality. <image>. Again, the main issue with this method was the name and poorly commented code. This method has similar, but not the same, functionality as the set_questionnaire (get_questionnaire_from_response) method, except this method is called when a user is creating a new Response object, thus the controller does not have access to the Response object in question. In this case, it is possible to get a reference to the appropriate questionnaire by using the ResponseMap object instead of the Response object. This method was subsequently renamed to get_questionnaire_from_response_map and the code was commented to clarify its functionality. <image>. In this method previously review_response_map_id and calibration_response_map_id were used to get the review_response_map and calibration_response_map rom ReviewResponseMap.rb model accessing its database table. Further using 0th index values from both the maps the function was getting a assignment object. After that the function was using calling AssignmentQuestionnaire.rb model to get the set of questionnaire for the responses. The function had too many database calls and logic which should not be implemented into a controller. Therefore we created a method calibration_results_info Response.rb which would calculate the the required review_response_map, calibration_response_map , question objects keeping the logic and entire database access into the model. <image> <image>. Due to the size and structure of Expertiza, we thought it would be appropriate to provide some guidance on how to manually test the main refactors in this project, the new method and the show_calibration_results_for_student method. 1. def new In order to make a new response, we suggest logging in as (or impersonating) one of the following students: 1. student7602 1. student7605 1. student7607 Once signed in or impersonating one of the student accounts listed above, navigate to the Program 1 assignment, and click on it. Now, click on Others work, and request a new submission to review. From here, click begin to see that a new response form is generated. The below pictures show these steps. <image> <image> 1. def show_calibration_results_for_student In order to show calibration results from the perspective of a student, we suggest signing (or impersonating) as the following student(s): student7605 Once signed in, navigate to the Program 1 assignment, and click on it. Again, click on Others work, and click on Show calibration results. Now, the calibration results for this review response will be visible to the user. In order to create more calibration results, it is required to log into the instructor account and complete more calibration reviews for the Program 1 assignment and subsequently log into the corresponding student account(s) and repeat the steps above. To run the tests : <code> Changes made to response_spec.rb: <image>.","Very good description of what was done.  The paragraphs about each change are easily understandable.  I find the dark-background screenshots less readable than the default light-background changed code snippets from Github, but this is a minor issue.  The instructions on manual testing assume that the tester is using the anonymized db, which might not be true.","Dear Student,

Great job on such a comprehensive response to the assignment and a well-rounded set of suggestions for code refactoring in the Expertiza application. You have addressed each component with a demonstrable understanding of the codebase, and the practical ways to improve it. 

Your suggestions, such as renaming ‘set_questionnaire’ and ‘set_questionnaire_for_new_response' methods for clarity, shifting business logic from controller to model, and reducing repeated database calls are valid and based on best practices in MVC design. Indeed, your focus on clarity and separating the logic from the model to make it more maintainable is greatly applauded.

The section recounting specific changes and the names the method were renamed to was also very helpful and it shows the rationale for each decision was well thought out. Similarly, your efforts on commenting the code to provide clarity on its functionality for future developers is commendable. 

You've clearly gone above and beyond in this assignment with explaining how to manually test the main refactors. It's clear you thought about not just the execution of the code but its end use – a key consideration in development work. 

In the next assignment, it'd be great to see you include brief summaries of what each method is intended to do within the program. This will help provide context to the changes suggested, especially for those not deeply familiar with the Expertiza program.

The inclusion of code used to rectify specific uses noted in the assignment, while beyond the assignment remit, would be a nice way to illustrate your understanding of potential solutions. 

Overall, this is a solid assignment submission showing great potential in code review and debugging efforts. Fantastic work!

Kind Regards,
[Your Name]"
83,E1790,"In this final project “Text Metric”, first, we will integrate a couple of external sources such as Github, Trello to fetch information. Second, we will introduce the idea of ""Readability."" To get the level of readability, we will import the content of write-ups written by students, split the sentences to get the number of sentences, the number of words, etc., and then we calculate the indices by using these numbers and formulas. Our primary task for the final project is to design tables which allow the Expertiza app to store data fetched from external sources, such as GitHub, Trello, and write-ups. For the next step, we would like to utilize this raw data for virtualized charts and grading metrics. Currently, there are three models created to store the raw data from metrics source. (Metrics, Metric_data_points, Metric_data_point_types). <image>. <image>. <image>. <image>. <image>. <image> The current framework only defined the schema, but the models are still empty, and the methods of the data parser have not been implemented yet. This schema is a clever design because it follows the ""Open to Extension and Closed to Modification"" principle. When new data is added to the database, developers don't have to change the metric_data_point_types and metric_data_points tables. The developers only need to add two methods to translate the data type to and from strings. By browsing the code, the most basic types already have those methods to meet our requirements. But it is not flawless, and we will talk about the problems in the next section. Besides, we only have GitHub to be our data source currently. As a result, we also need to find other data sources to be one of the grading metrics. In model metric_data_points, it is defined that each metric_data_point belongs to a metric and a metric_data_point_type. However, in both model metric_data_point and metric, they haven’t defined has_many metric_data_points. So we can’t query all the metric_data_points of a metric or a metric_data_point_type. In schema metric_data_points, value has been defined as a string to accommodate different data type. But this requires the program to translate data into strings when storing the data and translating the string back to data when accessing it. To make it worse, using strings to store data types, such as float type or Time class, would either lose the precision or incur more abundant storage space. More external sources are needed. Our first and current source for grading metrics is GitHub, and Zach and Tyler have implemented the integration with GitHub API for fetching the commit data. However, the integration looks that it is still in the first stage; the app can fetch the data and store into the database. We don't have actual implementations of getting the valid data and the usage of this data to be one of the grading metrics yet. From the API offered by GitHub, we can fetch the commit information that the number of additions and the number of deletions is made by each contributor in the repository. We can just use these numbers to calculate the contributions for the metrics, or we can put these numbers into some equations to get the impact factor to represent as contributions for each group member. Sometimes, students only have project write-ups to submit (for example, this stage of the final project). As a result, there might be no GitHub commits to check the number of additions or deletions of the working repository. Here, we introduce some formulas for calculating ""Readability"" of those write-ups to be one of grading metrics. The readability indices contain: Based on a 0-100 scale. A high score means the text is easier to read. Low scores suggest the text is complicated to understand. 206.835 - 1.015 x (words/sentences) - 84.6 x (syllables/words) A value between 60 and 80 should be easy for a 12 to 15 year old to understand. 0.39 x (words/sentences) + 11.8 x (syllables/words) - 15.59. 0.4 x ( (words/sentences) + 100 x (complexWords/words) ). 1.0430 x sqrt( 30 x complexWords/sentences ) + 3.1291. 5.89 x (characters/words) - 0.3 x (sentences/words) - 15.8. 4.71 x (characters/words) + 0.5 x (words/sentences) - 21.43 To calculate these indices, we need to fetch the article to get the number of sentences, the number of words and the number of complex words, and then we can use these numbers to calculate the indices mentioned above to get the readability level. Trello is a web-based project management application. It helps students to understand what tasks have been accomplished, what works are in progress and what jobs are waiting for being started by adding cards and writing down to-do lists inside, and it also helps instructors to keep track of how students work by looking into these cards and lists. It is useful for both coding projects and writing projects because we can fetch the information from the activities to calculate the percentages of the workloads for each group member, and this result can be one of the grading metrics. For example, a group of students has a to-do list, which contains eight tasks. Student A finishes two tasks, Student B finishes one, and Student finishes one as well. We can use the information fetched from the activity of project from Trello RESTful API to calculate the percentage of finished jobs (which is 50%) and the proportions of contributions for each student (which are 50%, 25%, 25%, respectively). Using this data from Trello might be a good idea for being one of the grading metrics because we cannot merely conclude contributions by observing the number of additions and the number of deletions. What if a student just adjusts the indentation for all files in the project for an hour and the other student thinks about a complicated algorithm to get a correct answer for days or even weeks? However, the data from Trello offers a different aspect of the grading rubric; it concludes the contributions by calculating how many tasks are done by each student. Also, it can be used as a grading metric for both coding projects and writing projects because we only care about the todo-lists. 1.Since each metric and metric_data_point_type could have many metric_data_points, we need to add has_many metric_data_points in those models. To make the database store different data types as they are, we can create a metric_data_value table for each data type. Then we can change the the value field in table metric_data_points to the value_id, which help us to find the value in the corresponding metric_data_value table. When storing data in the database, we can create the new data using the factory pattern as shown in the figure below, and the string parameter “type” could be used for specifying which type of data is created. Each metric_data_point_type and metric combination could only have one metric_data_point, so if it already exists, the new data will replace the old one. Here each metric_data_point_type row actually represent one field of a metric. If two or more metric_data_point_type rows have the same value_type, their name should be different. So each row of metric_data_point_type is like a column header of a table, which make the database more extensible. When querying data in the database, we can first utilize the has_many relationship between metric and metri_data_point to get all the metric_data_points. Then get the each metric_data_value table by the value_type field in the metric_data_point_type. Finally use the value_id in metric_data_points table to find the data. <image> This design could solve the problem discussed above. Each data would be stored as their original data type. Thus, we do not need to convert data type to/from strings which lead to precision loss or space problem. This design also follows ""Open to Extension and Closed to Modification"" principle. Each time when we need to add a new datatype, we don’t need to modify the previous schema, we only need to add a new model and schema. For example, even if the new data type is an array, we could use the dimension field in metric_data_point_type to specify the length of the array, then use the value_id field in metric_data_point to specify the start id of the array, finally in the corresponding metric_data_value table we can use the start id and the dimension to get all the elements in the array. But this design has drawbacks too. First of all, the logic becomes more complex, it would be more difficult for a programmer to understand. Secondly, the table of each data type would need to store the id, which costs extra space. However, this overhead should be less than the overhead caused by string storage or frequent type casting. 2. We also need to implement the data parser methods. The data parser methods will be implemented in the data source model class. We can utilize Ruby’s duck typing character to implement polymorphism, so when the application gets a data source object, it could invoke the parser method without knowing which type of data source it is. This ensures this program is closed to modification and the data source is open to extension. <image> To implement all the parsers, we planned to use a factory pattern as shown in the diagram above. It allows further extension on new metric sources. For each parser class, we implement duck typing by defining the parse method with the same signature, so we don’t really need a super class or interface. The caller code could execute the parese method without knowing exactly which parser is created by the factory. Thus the caller code is close to modification, and this design follows open/closed principle. <image> Each parser will parse the given data source and use the metric data factory to create model for each data then use these data to create the metric model. 1. Given a valid url of GitHub, the GitHub parser could correctly get all the data. 2. Given a valid url of Readability, the Readability parser could correctly get all the data. 3. Given a valid url of Trello, the Trello parser could correctly get all the data. 4. Test that the parser should correctly create metric_data_point_type if it doesn’t exist. 5. Test that the parser should be able to create the correct type of metric_data_value model according to the type specified by the metric_data_point_type. 6. Test that the parser should correctly create metric_data_value models if it doesn’t exist. 7. Test that the parser should correctly update metric_data_value models if it already exist. 8. Test that the metric_data_point_value could be correctly queried with the data from a given metric. 1. <link> 2. <link> 3. <link> 4. <link>.","Reviewers generally liked it in the second round, and I think you've done a good job of describing what you would do in narrative form, which is the main point.  However, as noted by one reviewer, you could have done a better job of explaining the differences between your readability metrics.  Also, the huge model code detracts from readability; you'd have to zoom out to see it all.  The test plan is very sparse.","Thank you for the detailed information on your final project “Text Metric”. Your explanation is thorough and it is clear that you have carefully considered each stage of the project. Your proposal to use the ""Open to Extension and Closed to Modification"" principle definitely demonstrates your understanding of good program design. 

However, I have a few recommendations for improving your project:
 
1. **Models and Data parsing:** I noticed that your models are currently empty. Developing these models and their methods should be a priority, as the functionality of your program relies heavily on the data collected from these models. 

2. **Integration with GitHub & Trello:** I would like to encourage your exploration of other data sources, as you have begun to do with Trello. Utilizing information from Trello would indeed provide an additional perspective for your grading metrics.

3. **Tables and storage issues:** You mentioned some flaws in how data is currently stored in your system. One of which is using strings to store data types such as float or Time class. This could indeed lead to complications with precision and storage space. Resolving these issues should be another priority. 

4. **Testing:** Please make sure to carefully test your project, particularly focusing on your parser methods and data integration with other platforms such as GitHub, Trello, etc.

Get started on the next steps, but do not rush yourself - ensuring high-quality work is more important than immediately progressing onto the next task. I am excited to see your progress on this project. Good work so far!"
84,E2021,"The reviews performed by the students right now are being assigned on a first-come-first-serve basis. The task at hand is to implement a procedure so that the students can bid on the reviews that they would like to review, similar to the procedure of the assignment of the topics. The difference between the two procedures is that the assignment of the topic is a one-one mapping, i.e. a team is assigned to a single topic, whereas the assignment of the reviews is many-many mapping with each review being assigned to different students and each student assigned to different reviews. The bidding process, when implemented for reviews of projects, will hold several advantages. 1. The users will be able to bid for reviewing the projects that would interest them. This will incentivize them to get a better understanding of the project requirements and provide the necessary feedback in a very informed manner. 2. With the help of color coding, the students will be able to decide on the probability of being assigned to a particular review, that could help them in bidding wisely. 3. It provides the team members working on the project, a very informed feedback on how to enhance their project. Because,the feedback is from people who really are interested on the project. 4. It also helps the instructor in receiving more well-written, useful and meaningful feedback on what projects are more in demand among the students, which would be further useful in crafting the academic projects. The following are the tasks that are to be done- 1. Implement Gale-Shapely version for many-to-many matching situations on a web service as mentioned in the paper <link> . The Gale-Shapely version for many-to-many matching is an intelligent algorithm that allows users to achieve the review they will need. For example, let us consider a situation where user 'A' wants the review assigned to user 'B' and user 'B' wants the review assigned to user 'A'. Considering that it will motivate the students if they get the project that they would like to review, this mutual exchange between them would be beneficial. This classical problem can be solved using the following algorithm. <image> Motivation From a set R of available review topics, the user u from set U have to be matched with a pre-configured number of topics r1,r2,r3.....rk. So,the idea is to record the user priority and time-stamp at which r is bid. This information can then be used to change the color of the review in real time, which could further let the users know that their bid for this particular bis cannot be given a top priority. Once the bidding timeline is past, the recorded information for each bis is then fed to the algorithm, which would then match user u to review r1,r2,r3...rk. How should the algorithm match students S to the Review set R ? The algorithm has to initially append additional reviews randomly in case, the user did not bid for the required number of reviews. Then based on the input data of the list for each student, which contains the topic,time-stamp and priority it has to allot the review to a student with earliest time stamp and highest priority. Algorithm Steps 1) Let the user bid, these bids will have time-stamps and priority(determined by the color of the bid at that time stamp). 2) There will be cycles links of length 1 between the person who owns every review currently,which generates a directed acyclic graph. 3) We the will need to break all the cycles in the graph and assign the reviews to which the user is pointing at. The top is represent as [ TOP(i) ] 4) We can repeat this order until we have exhausted our preference list where all the assigned reviews are constantly deleted. 5) We will repeat this process for all the slots of the bidding until the users gets all these review slots filled, making it many to many. <image> From the diagram we can see that the three users are represented as u1, u2, u3 and the the three reviews are r1,r2,r3. In phase 1 : All users want the review 1 so all of them point to r1 and we see r1 is owned by u1 and r2 is owned by u2 and r3 by u3. In phase 2 : u1 is assigned r1 and now u2 points to r3 which is now its highest priority because r1 is removed and similarly u3 points to r2. In phase 3 : r2 is assigned to u3 and and r3 is assigned to u2, thus satisfying all. 2. Add the front end code to allow the bidding on topics and call the appropriate web services from the lottery controller. This is similar to the already implemented bidding process on topics <link> . Flow chart for this us functionality would involve : <image>. The latest implementation of the problem was E1986 <link> <link> . We can see that they have figured out the issues with the bidding assignement being one to one and not many to one and have succesfully used the Gale-Shapely version for many-to-many matching algorithm to solve the issues. They have also fixed a few problems with the UI that were being faced with the buttons and writing proper test cases. From the previous implementations we can see that the following files were modified in order to get the required implementation they have modified the following files : Modified Files routes.rb app/views/student_task/view.html.erb app/views/assignments/edit.html.erb app/controllers/student_task_controller New Files app/controllers/review_bidding.rb app/models/review_bidding_controller.rb app/views/sign_up_sheet/review_bid.html.erb Source Code for the Web Service. The problems in the previous work were given- 1. The link to the run bidding assignment is on the Review Strategy tab instead of the actions associated with an assignment like the topic assignment. This is an inconsistency in the UI that needs to be remedied. 2. All of the implementation code was put in the controller which is inappropriate for a controller. The code should probably be in the corresponding model file. 3. The tests that they have written are not adequate. 4. It does not allow the Instructor, to decide to whether to allow the bidding for reviews or not. Change the location of the running bidding assignment to the appropriate location. This is because it is inconsistent with the UI and will require changes. The part of the code that requires modification is- app/views/assignments/edit.html.erb <image> As we can see from the code attached we need to move this code away from the Review Strategy tab. <image> <image> We have also added a checkbox to check if the algorithm is run or not based on the value of the checkbox that is ticked. <image> Webservice : The previous team had not set up the web service as internet-facing. It was only working on their local system because they were facing issues with the flask framework setup. We have successfully setup up the web service call and made it internet facing. The code can be found at the following repository: <link> which is hosted using Heroku and can be accessed from the expertiza application. Various refactors on the code were also performed the changes are shown below. Write the code where it is suitable, following the DRY principles. The first file where we want to apply the principle to is the: app/controllers/review_bidding_controller.rb The code is shown below: 1.1.Previous Implementation : <image> From this, we can see the entire method can be moved to the model to reduce the stress on the model. The assignment participant code is moved to the controller thereby making it easier to perform separations of the model, view, and controller. Also in the below code attached we try to move the entire assignment_bidding_data to the model as well. 1.2.Previous Implementation : <image> The implemented changes by moving the code to the model are shown in the code attached below. We can see that both the method has been successfully moved to the model and thereby reducing the stress on the controller. The assignment_reviewers function is the function that will return the participant ids of all the reviewers who have a topic that is assigned to them. It will run a for loop to get the details and return an array of reviewers with assigned topics. 1.3.Current Implementation : <image> 2.1.Previous Implementation : The other function that we choose to move to controller hence to make sure the computations are performed only the model side is first the reviewer_bidding_data. <image> 2.2.Previous Implementation : The function reviewer_self topic shown below was also moved. <image> 2.3.Current Implementation : The new code that is attached to the model is shown below The reviewer_bidding_data file creates a hash of all values tat is required for a bidding value its has will hold keys and values for {'priority' => [], 'time' => => [] , 'tid' => [] , 'otid' => self_topic} it runs through the bids and get the required cols to add to the hash. <image> 2.4.Current Implementation The reviewer_self_topic is used to get the necessary self topic that is been assigned to the reviewer and the values will be returned based on what is been assigned. <image> 3.1.Previous Implementation In the same file, we notice the method: get_quartiles(topic_id) which assigns colors to the topics based on how much in demand they are. <image> 3.2.Current Implementation This has been removed to assign the color directly in the view. Instead of assigning pre-defined bands, as done in the previous implementation, we have implemented the colors dynamically as a band that varies from green to red, where the green color used to indicate the less number of bids and the red color indicates more number of bids. It has been implemented as shown below. <image> This implementation has been modified after looking into the pull request <link> which involves a similar implementation for the bidding of the projects. Write suitable tests to ensure that the implementation is working. The previous implementation gave their try on implementing the required test but all of them are commented out. So, they are required to be redone during this implementation. Previous Implementation <image> Previous Implementation We can see that the previous implementation has all the tests removed, the changed test cases are shown in the testing subtopic. <image> Current Implementation The current testing implementation has been shown below, in the Plan for Testing section. Manual Testing : There are a few cases that need to be tested. 1. The first case would be to test for the scenario, where no reviewer bids i.e. no one has given a preference of any sort. Then the bidding algorithm should assign reviews randomly. 2. The other case would be when all reviewers have selected a different project as their preference, at different times. This is an ideal scenario given that the reviewer cannot bid for his own project. 3. The other scenario would be when everyone selects the same project at the same or different times and does not provide any other choice or preference. This can be the scenario if one project is relatively interesting or easy to review in comparison to the others in the roster. 4. Another scenario would be if some projects haven't been selected at all for reviewing, this case arises if the particular project may require additional effort on the part of the reviewing to successfully complete the review. 5. A usual scenario is that the reviewers select all or most of the projects, and each project is on at least one reviewer's biding list. Automatic testing : Few tests have been written for both the controller and the models : the file we can see that tests were written for the controller that checks if the web-service call is fine. The Call to the webservice is made and check if the response code returned is fine. It checks if the right status code is returned on processing. Also it eventually checks for the json data being returned succesffuly. <image> The screenshot of the passed tests are shown below : <image> The other tests that are written are for the model. It check if the model has validations of the priority, participant_id and topic_id to be the right values as set in the database also it checks if the values returned from participant_id and topic_id are integers. <image> The other tests written checks if the assignment id is assigned right and if its an integer. It also checks if the assignment_reviewers returns an array and if the assignment_bidding_data will return a hash value in return. The review_bidding_data is also checked for the right hash values. <image> The screenshot of the passed tests are shown below : <image> In all of the above cases, all the projects have to be assigned to at least one reviewer so that every project has been peer-reviewed. [1] <link> by Atila Abdulkadiroğlu and Tayfun Sönmez. [2] <link> . [3] <link> . [4] <link> .","This is a well written description, but unfortunately it assumes that the reader is familiar with bidding for topics, which is not necessarily true.  You show ""before"" and ""after"" code sequences, but it would be much clearer if the changes were shown in Github diff view.  However, the descriptions of the changes are quite understandable.  Ditto for the tests.","Dear Student,

You have done a commendable job in providing a comprehensive explanation for the task at hand. The bid for review concept which is being introduced is well-explained with relevant motivation points. The understanding and detail of the Gale-Shapely version for many-to-many matches approach used is evident in the step-by-step breakdown.

Your illustrations and diagrams made the concepts clear and easier to follow. The meticulous approach to tracking and addressing problems from previous work is appreciated. However, even if it is longer, you could provide more context to these problems before proposing solutions.

Your added feature allowing the instructor decision power over the review bidding process is an excellent touch. Make sure to involve users (instructors) at all stages of development, so the solution aligns with their needs and expectations. 

The 'DRY' (Don't Repeat Yourself) principle in handling your code refactoring is brilliant and signifies good programming practices. Also, your detailed testing plans on the modifications you have made, including consideration of several scenarios for manual testing, demonstrates an in-depth understanding of quality assurance concepts.

One recommendation would be to focus on simplifying your language and breaking down complex information. In future, try to summarize important sections and to use more bullet points or numbered lists for easy readability. Given the complexity of the material, it would be helpful to have a summary or a conclusion at the end to stress the key points. 

Otherwise, your attention to detail, especially how you emphasise the importance of the model-view-controller paradigm in coding is impressive. Above all, your commitment to addressing preceding errors and barriers such as the internet-facing capability, shows remarkable problem-solving skills.

Keep up with the solid work!
"
85,E1848.3,"Out of the 30 methods defined for the model AssignmentTeam.rb, test case was written for only one. Our contribution was to successfully add test cases for all remaining 29 methods. Hence, increasing the coverage from 5% to 100%. AssignmentTeam This class handles all functionalities for a team linked to an assignment. Some of the functionalities include, get a list of participants in the team, get the team name, team score for the given assignment, submissions for this team (files) and (hyperlinks) and topic picked by the team. Add/or remove participants from the team. It also checks for any reviews the team may have gotten for their work. Export all teams in a CSV file, import files from CSV to form teams. Our test plan was to test every method individually, i.e. write unit tests. We also tested multiple cases for each method. A description of all the methods in the AssignmentTeam model in assignment_team.rb and the RSpec unit tests we wrote for them is below. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. We used multiple RSpec-specific and general industry best practices for testing in our unit tests. A description of our use of some of these techniques follows. We exploited describe blocks in RSpec to give our unit tests a readable structure. We had describe blocks for each method of AssignmentTeam . In these blocks, we used RSpec context blocks where appropriate and examples to identify and test the different cases in the source code. In order to isolate the unit under test (UUT), i.e. the current method under test, we employed RSpec stubs. We stubbed out database calls and methods that triggered them in order to improve the run time of the unit tests, and we also stubbed out some outgoing command and query messages in order to test only the current method under test. We exploited factories and the RSpec helper method let to make our unit tests shorter, more readable, and more maintainable, or, in essence, DRYer. Using the FactoryBot factories in factories.rb allowed us to use real Expertiza objects in our unit tests. We used the FactoryBot.build method to make our objects in order to avoid the run time penalty of saving (and this later having to retrieve) objects from the database. We used the let method with the factory as in the example below to make lazy-allocated objects which are cached throughout each example, improving run time. <code> Whenever team is called in an example, it returns the same value, i.e. the same object, which essentially allows tests that need it to have access to the same object without the need for allocating it as a class variable or instance variable for all of the tests or some of the tests. We placed these statements outside the scope of our unit test examples so the same objects could be used throughout all of them, DRYing out the test code. <link> is a testing framework for Ruby for behavior-driven development (BDD) licensed under MIT. It is inspired by JBehave and contains fully integrated JMock based framework which has a very rich and powerful DSL (domain-specific language) which resembles a natural language specification. Composed of multiple libraries structured to work together, RSpec provides encapsulated testing via the describe block to specify the behavior of the class and the context for the unit test case. RSpec is easy to learn and implement and can be used with other testing tools like Cucumber and Minitest independently. It is extremely powerful for testing states with complicated setup and also helps in tearing down complex code to access the objects required for testing RSpec semantics encourage agile thinking and practice and it structures the tests in a more intuitive way. During testing of the AssignmentTeam model, we found two bugs, one in AssignmentTeam#submit_hyperlink and one in AssignmentTeam.import . In AssignmentTeam#submit_hyperlink , http:// was appended to hyperlink strings without this tag or https:// at the start of them, rather than prepended . We fixed this error in our pull request. In AssignmentTeam.import , id , an undefined parameter, was referenced while raising an exception, and we updated it to assignment_id , which was the actual name of the parameter passed to the method. The model has a total of 237 lines, out of which 127 were relevant lines. We achieved 100% coverage with avg hits per line at 2.3 (the number of times each specific line was run during the test suite) <image> <image>. DRY principle could be cleaned up a little more. Sometimes it became necessary to use the let or build helper methods in each unit test. They may all be consolidated at the beginning. Some more edge cases could be thought of for each method, and tests written for those. Although, we have tried to cover as many as possible. Additionally, in the future, the code may also be refactored with a more efficient tool. Test coverage through quality tests consistently added throughout the development of the Expertiza project should be the future work of the project. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.","Description of mosts tests is very good. However, it's still a long list, and it would have been good if the tests were grouped, to bring some order to the description.  The scores(questions) test could be described in more detail by saying what objects are being created and why.","I appreciate the effort that you've put into this assignment, and it is evident that a lot of work has gone into creating comprehensive unit tests for each method. However, there seems to have been an issue in the reporting of your work with multiple instances of ""An error occurred while attempting to extract the child content."" This leaves the report incomplete and doesn't give us any insights into what you did or what you discovered in the process of the testing. 

I found your discussion on the use of RSpec, the concept of DRY coding, and the process of stubbing very informative and well articulated. You have demonstrated a clear understanding of the principles of testing and I admire your dedication to achieving a 100% testing coverage. 

Reporting the errors you found and how it was corrected shows your attention to details. I also appreciate you pointing out possible areas for improvement, and your recommendations for future work.

Please ensure that all links, images and code include in your report are working properly and that the information they are supposed to convey is clear and accurate. Remember to always double check your work before submission to avoid such errors.

Overall you've done an impressive job and show a good understanding of software testing principles. Revise the parts with the error messages and present all the methods and their corresponding test case results."
86,E2074,"LIVE LINK: <link> DEMO: <link> Currently, teammate review is just an extension of the project review feature. Although the features the project review function provides is adequate for team-to-team evaluations, it has been requested that the feature be extended specifically for teammate reviews. Some of theses critical features could greatly improve user experience, such as: 1. The ability to set a deadline on teammate reviews 2. The ability to check/verify who has completed a teammate review 3. The ability to create an assignment only involving a teammate review Implementing the third feature would also give the possibility of auto-grading for peer-reviews, vastly improving the UX for instructors. Testing and adding the the auto-grading functionality will be a stretch goal after the first three have been completed. Backend changes: 1. Addition to deadline_types table 1.1. A new type, teammate_review would be added to the aforementioned table. This would allow for deadline-based functionality on teammates review, satisfying the first feature requirement. 1.2. This would be added to the deadline_type model 1. Addition to Assignment.rb 1.1. A new function, participants_completed_teammate_review will be added to grab a list of participants that completed teammate reviews for a particular assignment 1.2. This will involve an innerjoin op on the ReviewMap , Assignment , and Participant table Frontend changes: 1. Modify Due Date tab functionality 1.1. Assignments will be allowed to have 0 rounds of reviews. This would disable the table lines for submission and review deadlines, making them disappear 1.2. Other deadlines on the page will not be affected. 1.3. If there are no submission or review deadlines at all, ""Your Work"" and ""Others Work"" will not show on the participant's homepage for the assignment 1. Modify List Submissions page for assignments 1.1. In the Team members column, all the students who have not reviewed their teammates will show a red dot next to their name, indicating a missing review. 1.2. A footer to the page will show explaining the meaning of this red dot if there are any present on the page. [PLAN] : I propose a method that will achieve the following goals: 1. Add the ability on the front end to set a deadline on teammate reviews Below is a graphic showing the implementation on the website, under the due dates tab for an assignment. The new elements are seen in red. <image> A new button will be added, and after clicking the instructor can then add a deadline to the teammate review. 2. Ability to restrict when users do teammate reviews. Below is a graphic of the new behavior on the ""Your team"" page. When the deadline has passed for teammate reviews, the edit button will show inability to edit, as well as an informative graphic (the tooltip) <image> 3. Ability to quickly check which teammates have completed team reviews in the current UI. Below is a graphic of the changes to the instructor view for an assignment. It shows a red dot to signify the student has not finished a peer review. <image> 4. Ability to have a teammate review only assignment. Below is a graphic of the due dates tab for an assignment and the changes made. After setting the review rounds to ""0"" (previously was not allowed), then the other items in the table below disappear. After selecting the new teammate review deadline, then a new row will appear. This allows the instructor to have an assignment that only features a teammate review. <image> 5. Add tests for internal logic and features Manual tests are in progress and will be appended to this section once completed. The above UI changes have been implemented already and work on the backend is in progress. The extra color stylings were only temporarily added to demonstrate / highlight the additional features. PR: <link> All of the changes mentioned previously have been correctly implemented and tested. Below is a summary of the key differences in the changes that I have made: 1. A 'teammate_review' DeadlineType was added to the DB through a migration script. This allowed for differentiation between other deadline types. 2. Another checkbox was added to be conditionally displayed on the assignment edit page under the due-dates tab above the previous ""Team formation deadline"" checkbox. It is displayed when the current assignment allows for teams to be formed and is hidden when not enabled. After being clicked, another row is added to the due date table itself for the use to select a teammate review deadline. (shown below) <image> 3. The logic was updated in the assignment controller regarding parsing of the currently selected inputs. Previously, this was done in a for loop and ended up overwriting values, showing and hiding parts of the form erratically. This has been corrected to be done in one pass. This now will update the deadline checkboxes on page load to always match the current values in the DB. In the screenshot below, note how the change now does an individual check across all deadline types for the current assignment instead of just one deadline type. <image> 4. Addition of 0-round-review assignments. This allows for instructors to have a singular assignment when the only purpose is to peer review teammates. After setting the assignment to 0 review rounds, the user can then add the teammate review deadline (or any other deadline type) and create an assignment strictly for that purpose. <image> ^After setting to 0 reviews, the other rows related to submissions disappear 5. Teammate review date restriction. Now teammate reviews can have a set deadline and can restrict the users based on preconfigured settings. These new permissions have been appended in the DeadlineRight model as well. When the deadline has passed, students will no longer see a button to edit or modify a previous teammate review. (lines 59-60 show the controller changes) <image> Changes to controller^ <image> ^^ ""Review"" and ""Edit"" button links are hidden past the due date 6. Extra conditional hiding values on the student task pages. When assignments only feature teammate reviews, the ""Your Work"" and ""Others's Work"" tabs are hidden on the student task page. This prevents user confusion from submissions on assignments not associated with a deliverable. (shown below, notice how there is only one task named ""Teammate Review Deadline"" and the hidden ""Your Work/Other's Work"" fields) <image> 7. Rspec testing. There were a couple tests for the new deadline in the rspec folder to ensure its stability over time. <image> 8. Quick view to see who has performed teammate reviews. On the list submissions page, there is now a red dot that is shown to the left of a participant's name if he/she has not reviewed all of their teammates. If there are any red dots on the screen, then a message at the bottom displays a message to explain what it is. In the example below, student 8597 is the only one who has completed ALL their teammate review. <image>. Rspec tests for the due date deadline type addition was added to the previous 'due_date_spec.rb' file. This is outlined in the previous section. Many of the additions are to the UI of the application, and thus must be tested manually. All the changes above where verified to work without bugs or errors (including all test cases of deadline's passing/being before today's date, the ability to make a teammate-review-only assignment, etc.). Contributors: Noah Lozevski - nlozevs@ncsu.edu.","Good job of motivating the changes, and describing them.  Not all of the code changes, e.g., assignment_helper, are covered in the document.  There is no plan for automated testing.  But the document is very clear.","Hi,

Great job on your assignment! You've demonstrated a good understanding of the project's requirements and proposed effective solutions. Your methods for improving the teammate review feature, particularly by setting deadlines and auto-grading, will certainly enhance user experience.

Your addition of automated and manual testing is a professional step in ensuring that your code changes are robust. Moreover, your consideration for instructors' user experience is commendable. 

Nevertheless, few areas can be improved. I suggest working on developing concise points in your explanations, it will aid readers in comprehending quicker and easier. Also, make sure to rotate between different types of sentence structures to prevent monotony in your write-ups.

Lastly, consider including a brief introduction and conclusion in your assignment to provide clarity about what is being presented and summarised. 

Keep up the good work!

Best,
[Your Name]
"
87,E1525,"Expertiza is a web application where students can submit and peer-review learning objects (articles, code, web sites, etc). It is used in select courses at NC State and by professors at several other colleges and universities.<ref> <link> </ref>. Expertiza is a large project developed as a combined effort of students and faculty using the Ruby on Rails framework. The main advantage of using Expertiza, in an educational environment, is for the instructor to introduce peer reviewing among the students. Expertiza allows the instructor to create and customize assignments, create a list of topics the students can sign up for, have students work on teams and then review each other's assignments at the end. Expertiza supports submission of almost any document type, including the URLs and wiki pages. Currently the teaming information is only accessible from specific assignment. Sometimes a course may require a student to work with at least, for example 5 other students. To check teaming information for a course, It would be helpful for a student to have a way in Expertiza to see how many other students (s)he has teamed with during a course, and who those students are. An instructor might also want to see this information for grading purposes. Similarly, instructors and students want to see scores that teammates have given them for contributions to their team projects. New features that will be added to the system will 1. Allow a student to see how many other students (s)he has teamed with during a course, and who those students are. 2. Allow students to see the review score that teammates have given them for contributions to their team projects. 3. Allow the instructor to be able to see the teaming information of all the students. 4. Prevent students from seeing individual review scores when the number of team members who reviewed the student is < k, where k should be settable by the instructor when editing an assignment. All the documentation for the Expertiza system can be found in the following links: <link> <link> The following section discusses briefly about each file that has would be modified in the course of this project. 1. <link> This file implements methods to represent various scores obtained by the student in each individual assignment and all assignments together in various pictorial formats such as Pie Charts and Bar Charts. 1. <link> 2. <link> These files handle all the assignments related functions. These include showing all the assignments of all the courses, and displaying details about each assignment such as deadlines, team details, submission links, links to review others’ work, scores etc. 1. <link> This view file displays various statistics related to review scores obtained by the student in different assignments. 1. <link> The file contains all the methods related to students and the assignments objects. 1. Use Case 1: Allow a student to see how many other students (s)he has teamed with during a course, and who those students are. 1.1. Actor: Student 1.2. Actions: 1.1.1. Student logs in to Expertiza. 1.1.2. Open the “Teammates” link in the Home page to find the number of people the student has collaborated with till then. In order to achieve this, we plan to add a link, say “Teammates” in the Home page "" <link> "" (Need log in to see). Clicking on the Teammates link leads to a page consisting of all the courses the student is enrolled in and number of people (s)he has teamed up with till then. This goal can be achieved by adding additional methods to the app/views/student_task/list.html.erb file and app/controllers/student_task_controller.rb. 1. Use Case 2: Allow students to see the review score that teammates have given them for contributions to their team projects. 1.1. Actor: Student 1.2. Actions: 1.1.1. Student logs in to Expertiza. 1.1.2. Open any assignment on the “Assignments” page. 1.1.3. Open “Your Scores” to find the review scores given by teammates in the “Teammate review” column. We noticed there is already a field “Teammate review” available in the “Your scores” ( <link> <id>) page of each assignment, and as of now it seems to be unused. We plan to use this section for allowing the students to see their review scores given by the team mates. This can be achieved by making changes to the app/views/grades/_teammate_reviews.html.erb file. 1. Use Case 3: Allow the instructor to be able to see the teaming information of all the students. 1.1. Actor: Instructor 1.2. Actions: 1.1.1. Instructor logs in to Expertiza. 1.1.2. Open the “Teammates” link in the “Assignments” page to find the number of people the student has collaborated with till then. This would involve adding similar changes as allowing students to view their teammates in the Instructors views. 1. Use Case 4: Instructor decides whether a student would be able to view his teammate reviews for an assignment or not by checking an option while creating the assignment. 1.1. Actor: Instructor 1.2. Actions: 1.1.1. Instructor logs in to Expertiza. 1.1.2. Clicks on the ""Create Assignment"" button. 1.1.3. Checks or unchecks the ""Show Teammate reviews"" option. 1.3. Actor: Student 1.4. Actions: 1.1.1. Student logs in to Expertiza. 1.1.2. Students should be able to see individual review scores only when the instructor has checked the ""Show Teammate Reviews"" option. This can be achieved by adding an additional option to the ""Create Assignment"" page of the instructor. <image> Use Case Diagram. The instructor can look at the overview of the course by clicking on the ""360 assessment dashboard"" action of the particular course. The following image shows the Dashboard page. <image> The above page summarizes the details such as the Grade distribution and Review progress for each of the assignments. Further upon clicking each assignment (""New Assignment"") in this case, the individual scores for each student will be seen in a table as shown below. <image>. Similarly, the instructor can look at the review and metareview scores for each student by clicking on the ""View aggregated team mate and metareviews"" action of the particular course. The following image shows the resulting page. <image> Along with the aggregate scores for each student, this page also shows the class averages for each assignment as shown in the image below. <image>. A video demonstrating all the above functionality can be viewed at <link>. To see the new functionality for student: Login to the Expertiza application using any student account like ‘user5403’, then select assignment. 1. The student should be able to see all the teammates he has teamed with in specific courses on the left panel. 2. To see the teammate review, select “your score” in one assignment, there is one column named “teammate review” showing the teammate review you got from your teammates for this assignment. To see the new functionality for instructor: Login to Expertiza as an instructor using username “user6”. 1. To see the fixed dashboard, click on the ""360 assessment dashboard"" action of some particular course. 2. To see the review and metareview scores for each student in one course, click on the ""View aggregated team mate and metareviews"" action of that particular course. <references/>.","Good listing of use cases. Specs say that the # of teammates in the entire course should be shown.  Design doc says only the # of teammates in an assignment will be displayed. We changed the conditions under which teammates will see reviews.  This will be controlled by a checkbox on the General tab of assignment creation, not based on the number of teammates k.  This change is not reflected in the doc.","Dear Student,

Thank you for submitting your assignment on the Expertiza system. Your report is well detailed and it's clear that you understand the utility and the potential of this system. Your ideas for enhancements of the system including the implementation of the ""Teammate"" function and the ""Teammate Review"" function can contribute to a better utilization of Expertiza in an educational environment. The use cases you provided are well-structured and thorough, exhibiting a good grasp of the basic tenets of software development. The utilization process is also well documented with a clear delineation of the roles of the student and instructor. 

A few suggestions for improvement:

- Your references are not visible at the end of the assignment, kindly check again.

- Be sure to add references to any third-party materials you are using, you've mentioned a few links but it's unclear what these links are showing.

- Some sentences are long, try to make them shorter and more succinct, this will make your assignment easier to read. 

- Also, do pay attention to your numbering, sometimes you use the same number twice (1, 1.1, 1.1.1 etc.) – this can potentially make your work appear less organized than it actually is.

- Lastly, it appears like you've mixed instructor and student functionalities. You might want to consider clearly separating each functionality to avoid confusion.

On a positive note, the screenshots and detailed descriptions will significantly help users navigate more efficiently through the system. 

Keep up the good work! 

Best,

[Your Name]"
88,E1570,"Expertiza is a web application where students can submit and peer-review learning objects (articles, code, web sites, etc). The Expertiza project is supported by the National Science Foundation.<ref> <link> </ref><ref> <link> </ref>. Classes involved: <code> Controller Responsibilities: This controller deals with displaying “trees” of objects to the instructor. When an instructor logs in, (s)he is greeted with a homepage that lists questionnaires (rubrics, quizzes, surveys), courses, and assignments. These objects are displayed in a “tree,” allowing the user to click on the top-level object and see the objects beneath it. Bad practices followed: 1. Many Duplicate Methods. 2. Very Long Methods combining many Functionalities. 3. Redundant methods not being used anywhere. Refactoring to be done: 1. Split get_children_node_ng and get_children_node_2_ng into smaller methods and give reasonable names to them and make sure implement common code in a single method. 2. Merge all the repeating methods into a single method. 3. Write functional tests for the TreeDispayController. 4. Remove commented code in list method. We used the DRY principle while refactoring our code to remove duplicates in get_children_node_ng and get_children_node_2_ng methods. <table>. <table>. 1. Login in as an instructor or admin using credentials (admin with password: admin or instructor6 with password: password) 2. To check the changes made in go_to_menu_items method, hover over the Manage tab in the navigation bar on the top and click all the links and check whether they are being redirected to correct pages. For example, if Questionnaires is clicked, you should be | redirected directly to the page displaying all the questionnaires with its sub-categories like Reviews, Surveys etc. 3. To test the changes made in get_children_node_ng and get_children_node_2_ng methods, click on the sub categories under each of the parent tree displays (Courses, Assignments and Questionnaires) and all of them will further expand to show the details. (Click on the name of the Course/Asignment/Questionnaire to expand them). <image>. <image>. <image>. <table>. <table>. This is a new Common Method for both get_children_node_ng and get_children_node_2_ng that does the functionality of rendering a page with data from all nodes by calling another method populate_1_row(). There is another Method call that happens in this method which as a whole renders the List View. <code>. 'This is a new Method that is called from Method populate_row() and fetches all the child node names from respective Controller actions and then populates the tmpObject. <code>. This is also a common Method which integrates the rendering functionality of get_children_node_ng and get_children_node_2_ng making sure both levels are properly populated in the view.' <code>. There was a Method which dint have any Routes defined in the Routes.rb file and was not called in any of the Controller . After Careful analysis we descided to remove the method from the tree Display Controller. <code>. <table>. We have written Rspec tests for the tree_display_controller and have run the same with success. From the home directory of the application, run the test as ""rspec spec/controllers/tree_display_controller_spec.rb"" <code>. <references></references>.","Good description of the changes that have been made; however, for the tests, the code is just given, without any description of why they test what they test.","Dear Student,

Thank you for your thorough submission on explaining Expertiza and your approach to refactoring its codebase. Your explanation of the challenges existing in the code is very comprehensive, and it was especially enlightening to see how you proposed to address these issues. 

Your explanation of the refactoring processes such as splitting methods, merging repeat methods, writing functional tests, and removing redundant or commented code provides clear insight into your understanding of clean coding practices. The DRY (Don’t Repeat Yourself) principle is a crucial concept in software development, and I'm glad to see you apply it here.

Your inclusion of the testing process of your changes is highly encouraging as testing is a critical part of software development, especially when modifying an existing system.

Though your write-up is in-depth, it would be helpful to work on the presentation a bit. For your next assignment, I would encourage you to try and include a more organized structure to your write up. Introduce figures/tables in the body of the assignment and make sure references are mentioned properly. Some of the steps or methodologies could use a bit more explanation - avoid use of the term 'etc' where possible and provide concrete examples instead. 

The pseudo code or the actual code could be more detailed so that they properly reflect the work done. Moreover, when providing 'code', please clearly illustrate whether it's a pseudo code or the actual code done.

Good job overall and looking forward to your future assignments.

Best,
[Instructor's Name]"
89,E1984,"This page provides a description of the Expertiza-based Semester project. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.8. <link> 1.2. <link> 1.1.1. <link> 1.1.2. <link> 1.1.1.1. <link> 1.1.1.2. <link>. In Expertiza the Instructor can create assignments and check the 'Allow self-review' box for Students. When enabled, each member evaluates his/her submission with the same criteria as the peer review. Currently, these self-review scores are not used to compute the final scores for the assignment. The task here is to improve the self-review system pertaining to give it a weightage in the final scores for the submissions. <image> The objectives we achieved for this project are as follows: 1. Provide a formula that takes both the peer review score and self-review score into account for calculating the composite score . 2. The composite score should get higher as the self-review score gets closer to the peer-review score . 3. Make sure that the peer-review scores are not visible before the self-review submission. 4. Display the composite score on the “View Scores” page. 5. Display the self-review scores in the ""View Scores"" page and in the ""Alternate"" (heat-map) view of the peer-reviews, highlighting them as a different type of review. The need for the self-review section is to know how well the students can judge their work and understand how to evaluate their flaws and rectify them. Also, if they can score themselves close to their peers, then it means that they have good self-assessment skills and they are being honest about what they think of their work. According to self assessment rules: students get more points as their self-review get closer to the scores given by their peer reviewers. The following flowchart illustrates the proccess of how scores are retreived to implement the self-review score feature. <table> List of files changed: 1. app/controllers/grades_controller.rb 2. app/controllers/sign_up_sheet_controller.rb 3. app/models/assignment_participant.rb 4. app/models/author_feedback_questionnaire.rb 5. app/models/response_map.rb 6. app/models/review_questionnaire.rb 7. app/models/teammate_review_questionnaire.rb 8. app/models/vm_question_response.rb 9. app/models/vm_question_response_row.rb 10. app/views/assignments/edit.html.erb 11. app/views/assignments/edit/_general.html.erb 12. app/views/grades/_participant.html.erb 13. app/views/grades/_participant_charts.html.erb 14. app/views/grades/_participant_title.html.erb 15. app/views/grades/view_team.html.erb 16. app/views/reports/_self_review_report.html.erb 17. app/views/student_review/list.html.erb 18. config/routes.rb 19. db/schema.rb 20. spec/controllers/grades_controller_spec.rb 21. spec/controllers/sign_up_sheet_controller_spec.rb 22. spec/features/assignment_creation_spec.rb 23. spec/models/assignment_particpant_spec.rb Next we show the most relevant improvements performed in this project. Feel free to review all the code changes in Github by following the next link: <link> 1. grades_controller.rb <image> <image> 1. assignment_participant.rb <image> 1. response_map.rb <image> 1. vm_question_response.rb <image> <image>. The following diagrams illustrate how the Self Assessment feture is meant to be used in Expertiza. Basically, we have two actors: on one side we have the Instructor which will create an assignment, add students to it and enable the self-review option. On the other side, students will be able not only to review their peers' work, but also will be required to review their own work in order to view their final scores, if the self-review option is enabled by the instructor. <image> <image> 1. Actors: 1. Instructor: This actor is responsible for creating assignments and adding students to the assignment. 2. Student: This actor is responsible for submitting, self-reviewing and viewing the scores. 1. Actions 1. Instructor: Create Assignment, Enable Self-Review. 2. Student: Login, Add work and Submit, Submit Self-Review, View Scores. <image> Currently, Expertiza allows students to submit an assignment and provides a link to self-review their work. Once the self-reviewing is done, the self-review score gets stored in the database and it is not further used in calculating the overall score of the assignment. Thus, students can score themselves higher than what they should actually get when considering the peer-review scores. This helps students in no way. So, to make a productive use of the self-review score and to help students learn self-evaluating themselves, we will make changes in the review score calculation, explained in the section below. We derived a formula that takes into account the self-review score and calculates a composite score , which will be the student's final score for a given assignment: <image> More information regarding the derivation of this formula can be obtain from the following document: <link>. You are welcomed to watch our 5-min demo video where we briefly explain and test the project functionality. <image> [ <link> ]. If you wish to try the self-review feature in Expertiza as shown in the demo, then follow the next steps: 1. Go to the link of the deployed application: <link> 2. Log in as instructor. Use the credentials: instructor6 , password . 3. Go to Manage->Assigments and clik the '+' icon on the top right corner to create an new assignment. 3.1. In General tab: write the assignment title, select any course and type any submission directory. 3.2. In Rubrics tab: uncheck the tab Review rubric varies by round? and select Design Doc for the Review in the Questionnaire drop-down menu. Select any type of Author Feedback. 3.3. In Review Strategy tab: go to the bottom and check the Allow Self Reviews? box. 3.4. In Due dates tab: for Submission deadline, select a date and time greater than the current date and time when creating this assignment. For Review deadline select a date and time grater than the submission deadline. 3.5. Click on Create to save and create the assignment. 4. Go again to Manage->Assigments , find the assignment you created and click on Add participants (user icon) to add some students. 4.1. Add student3000 and student4000 to the assignment. 5. Sign in as student3000. Log out from the instructor6 account or access to the application from a different browser (incognito window or a different explorer). Use credentials: student3000 , password . 6. Go to test assignment and click on work . Submit any link or file. 7. Click on Review my own work button and then the begin link to start the self review. Grade yourself accordingly and make sure to submit the self review when finished. 8. Repeat steps 5 to 7 for student4000 . Use credentials student4000 , password . 9. Log in as instructor again. Go and edit the assignment you created. In the Due dates tab, choose a date and time in the past. e.g. yesterday. This will enable peer reviews. 10. Sign in again as student4000 Go back to the assignment and click on Others work . Click on Request a new submission to review and review the student3000' s work. Don't forget to submit the review when done. 11. Sign in again as student3000 . Go to the assignment and click on Your Scores . Here you can see the final average peer review score, which is computed by using the proposed formula in this project. In the scores table, you can see your peer review score and self review score (cyan color) side by side. <image> <image>. Note that in step 7 of the Manual Testing section, we are immediatly submitting our self review after our work has been submited. This is the ideal workflow, however imagine the situation where a student forgot to submit his/her self-review questionnarie. Then by requirement of this project, and to make sure that every student submit their self review, the Your scores link will be disabled for the assignment. So students will only be able to review their scores after submitting their self review. <image>. The following Test cases were developed to ensure a correct implementation: 1. Peer-reviews cannot be viewed before a self-review is completed. 2. Peer-reviews can be viewed immediately when self-reviews are not required. 3. The composite scores are saved to the database. 4. Self-review scores are displayed with peer-review scores. 5. Student can only see their own self-review. We overloaded the get_assessments_for method with a second parameter which decides wheather the peer-review scores are retreived (false) or only the student self-review (true). Modifications were made accordingly in the grades_controller_spec.rb and assignment_participant_spec.rb files. <image>. The work done in this project can be built upon by future groups. Several areas can be improved upon and new functionality can be added. 1. Refactoring of the ResponseMap features: accessing scores from reviews is difficult, and requires several method calls. 2. Implementing multiple score approaches. A small addition to the instructor UI may allow them to select from different self-review formulas. 3. Add scores from team evaluation (Your team -> Review) to the formula. True peer assesment involves the use of peer-review scores within the team, not only peer-review scores from other teams as currently implemented.","Very good job of describing the changes to be made.  Code changes are nicely diplayed.  One place for improvment: Along with the code changes, write a couple of sentences describing, for each file, the changes in that file.  ","This is an extensive and detailed assignment with lots of information to digest. You have clearly put a lot of effort and thought into your project, which is commendable.

The assignment is well-structured and the content flows well. The explanation of the project and the inclusion of schematics are useful for understanding its functionality and aim. The explanation of the self-review assessment system, and why such a system is important, is detailed and understandable. 

The list of files you've updated for this project is helpful for anyone who might want to reference your work later. It's also commendable that you've provided a list of areas that can be improved upon in the future. This shows that you're considering the ongoing evolution of your project.

Your language is generally clear and professional, although there are some minor grammatical errors. Please double-check your work for proper grammar, punctuation, and consistent use of terms to ensure effective and professional communication. 

Also, the numbering system (particularly under the section ""List of files changed"") seems to have a few issues and should be revised for clarity.

The section about the most relevant improvements could use a bit more detail. While you list the files that were changed, it would be nice to see some information about what exactly was changed within those files, and why those changes were critical to the project. Similarly, instead of just displaying an image of the flowchart, it would be beneficial if you explained the flowchart in words, especially for visually impaired individuals who might not be able to understand the image.

In your future submissions, I would advise a bit more focus on readability and accessibility. Also, take the time to review your work for minor errors. Overall, a strong assignment. Good job!"
90,E1797.1,"Expertiza is an open source project created using Ruby on Rails. Students can upload and submit their assignments and related work online for grading purposes. Through this project, we aim to provide an interactive and refreshing visual timeline for all the student submissions for each assignment. We provided dynamic functions such as zoom in/zoom out to move left/right and recenter to provide smooth user experience. Currently, there exist various types of submissions that a student can make for an assignment for which timestamps are generated. 1. When a student submits links or uploads files as submissions to an assignment in Expertiza, a timestamp is created for the date and time at which each of the submissions was done. 2. The student may also be able to give reviews to other works for a particular assignment. These reviews when submitted also have an associated timestamp. 3. There also exist timestamps for deadlines that have passed and that are upcoming for an assignment submission or a review to be done. 4. For the reviews that a student receives for his work, the student can give feedback to each of the reviews. The submitted feedbacks also get timestamps. Currently there exists no functionality to view all these submissions and their timestamps in a single, aggregated way. Our project was to solve this issue by creating a Visualization that helps the student view all the timestamps for his submissions. The goal is to create a Timeline that shows all the timestamps of submitted records and links to the submitted content wherever necessary. The default state of the timeline is a point on the x-axis set to the current date and time. The timeline is interactive and allows the user to zoom in and out to change the viewing scale of the timeline. The user can also scroll in the timeline to move the timeline forward or backward from the current time. After all of this is done, the user can reset the timeline to change his view to the default state. With this, the student is able to view his entire submission history for an assignment in a convenient way. In Expertiza, it is possible for the instructor to view the submission records of a particular student. However, there is no way for students to check the history of their submission records. In this project, we are required to keep track of students’ activities and visualize them on their end by using a timeline chart. What needs to be visualized on the timeline: 1. Hyperlink submission record with timestamps 2. File upload record with timestamps 3. Due dates 4. Visualization of Peer review of others works, which includes: 1.1. A Review hyperlink that redirects to the review by clicking on it 1.2. The Round number (To be displayed only if the assignment has multiple rounds) 1.3. Timestamps 5. Visualization of Author feedback on others review, which includes: 1.1. A Feedback hyperlink that redirects to the feedback by clicking on it 1.2. Timestamps. The problem statement states the following issues that had to be resolved. Issue-1: Submission records with timestamps: A student can submit their work for an assignment using ""Your work"" button in the respective assignment page. Students have two options to submit their work : 1. Giving a hyperlink. 2. Uploading a file. As soon as the user submits any one of these, we needed to show hyperlink or file with the time-stamp on our visualization graph. Also, we needed to provide the submitted hyperlink or a link to the file on the visualization so that it will be easy for the user to navigate from a single page. Issue-2: Due dates: There are different due dates for every assignment like Round-1 submission, Round-2 submission, Round-1 review and Round-2 review Due Dates. These are different from submission time stamps because a submission's timestamp depends upon the time at which the user had submitted the work whereas a due date is the deadline date fixed by an instructor. Visualizing them by adding them into the timeline, helps the student to track all due dates in a single graph. Issue-3: Peer Review other's work: A student needs to review work of different teams during the course of the assignment. As of now in order to view the review, Expertiza requires the user to go to the ""other's work"" page in the assignment. Instead of this, we want this data to be viewed in our visualization graph. This issue includes a timestamp, link to view review, review round number to be shown in the graph. Note: this review is the peer review given by this particular student to different teams as part of the assignment, not the reviews the student received. Issue-4: Author's feedback on other's Review A student can give feedback for the review he/she received for a specific assignment. So this information also needs to be included in the graph. We need to show the timestamp and hyperlink to the feedback. It must be noted that the feedback here is not the feedback he got for review given by him/her but the feedback he/she gave for the reviews the had received. To visualize the timeline graphically we decided to use the vis.js JavaScript library. This library provides various interactive visualization charts (like graphs, networks, timelines, etc) to visualize data in real time. We chose to work on this library because when compared to other popular visualization libraries, vis.js provides the best possible representation of a timeline, one that meets the requirements of our project. To know more about how to make a timeline using vis.js, click <link> . The timeline contains a single horizontal axis that is divided into time intervals equally separated from each other. Let us consider an example where a student makes several submissions to an assignment. The student uploads a hyperlink ""https ://www.facebook.com"" and an HTML file as submissions. The assignment has several deadlines or due dates. There are due dates for Round 1 and Round 2 submissions for this particular assignment. There are also review deadlines for each of the rounds for the assignment. The student can give a peer review to other students' work on the assignment. The student is able to give feedback to the peer reviews that he received. We have used color coding to differentiate between different kinds of things visualized on the timeline. We have used Orange color for a round's submission and review deadline and Green color for all hyperlink submissions, file submissions and Cream color for feedback, peer review, team review and self review submissions. So in summary, the following things have to be present on the timeline that are visualized as rectangular boxes on the timeline: 1. The submission hyperlink box with the hyperlink 2. The file upload box with a link to the uploaded file 3. The Round 1 peer review deadline 4. The Round 1 submission due date 5. The Round 2 peer review deadline 6. The Round 2 submission due date 7. The Peer Review that the student gave to other students 8. The feedback that the student gave to received reviews 9. A self-feedback that the student gave to himself 10. A team review that the student can give to his teammates 11. Additionally, all the rectangular boxed have timestamps that display when the submission was made or the due date of that task Apart from this, various buttons were also added to better interact with the timeline. These include: 1. Zoom in - To zoom in by magnifying the viewing scale of the timeline 2. Zoom out - To zoom out of the timeline 3. Move Left - To move along the timeline's x-axis. The user can move forward by pressing the button 4. Move Right - To move backward along the x-axis 5. Recenter - Pressing this button helps the user to reset the zoom scale and the position of the x-axis in a way that all the items appear sorted in a single window. A single vertical red line set to the current time on the x-axis indicates the current time at which the timeline is being viewed. The percentage of zoom, percentage of window to move right/left can be modified as per convenience as mentioned in <script> of zoom buttons mentioned in later section of wiki. We have added hyperlinks to enable quick access to all of the student submitted content . For example, the rectangular box that shows the submitted file has a hyperlink that links to the contents of the file. Similarly, the reviews submitted by the student is linked by the hyperlink in the Peer review rectangular box on the timeline. Finally, after obtaining all the data from the database and the inclusion of all the stated information above to visualizing it in the timeline, the result would be something like this: <image> When the user selects a particular rectangular box on the timeline by clicking on it, then the line that connects the box to the timeline's x-axis becomes thicker and the color of the box also changes to White to indicate to the user the current box that is selected. If the user selects the file submission rectangular box (sample.html file), then the timeline would look like this: <image>. 1. app/controllers/submission_records_controller.rb 2. app/models/submission_record.rb 3. app/views/student_task/list.html.erb. 1. submission_records 2. response_map 3. due_dates 4. participants 5. assignments 6. users 7. teams 8. teams_users 9. signed_up_teams 10. sign_up_topics. The code to embed the timeline into the webpage is as follows <code> There are several buttons that were inserted into the timeline to allow the user to interact with the timeline. The code for that is <code> The functionality of each button is explained in the Program Design section above. It is necessary to obtain data from the Expertiza database to JSON format so that it can be processed by the timeline for visualization. After collecting the data from the database, processing it and storing it into a ruby variable, we use the JSON.parse() function to convert that information into JSON objects. To maintain continuity, the process of obtaining data and preprocessing it is explained later in the wiki. The code to convert the variable contents into a JSON object is as follows: <code> The following code is used to display due dates in the timeline. The types of due dates included are Round submission or Round review due date. <code> Then we need to add submission hyperlinks and files in the timeline. The code for that is <code> Explanation: The following code fetches submission records of a student for a particular assignment from the submission_records table. Then after checking if the submission exists and when the type is a file, a hyperlink to the file's location path is obtained and pushed into the JSON. The same is done for a submission with the type Hyperlink. Then to get the peer reviews, self-reviews, feedback and team reviews, the following code is used. <code>. Resources - 1. <link> 2. <link> A new file with the name timestamps_for_students_submissions_spec.rb file was created in spec/features folder with various test cases to test the changes. Testing the project using the User Interface. 1. Login as an instructor, go to manage assignments-> select an assignment-> add students to assignment->update duedates. 2. Impersonate as one of student -> navigate to the particular assignment edited in above step. 3. You shall see a timeline with duedates 4. Click on your work, submit hyperlink/files, same will be displayed in that particular assignment home page(navigate to previous page) 5. Review teammates work/ give a peer review/ submit a self review/ submit feedback to review received, same will be reflected in respective assignment home page along with a hyperlink to the particular review given. 6. The submission along with the timestamps for each submission along with hyperlinks to each of student's work is displayed in timeline. 7. One can test for the Edge cases mentioned above too. We have written tests for 3 scenarios 1. Scenario 1: Testing whether deadlines are visible on the graph: We created a dummy assignment with associated deadline in “before” statement. The code for that is: <code> Then, in the test case we tested whether the deadline is present on the graph. The RSpec Feature testing code is : <code> 1. Scenario 2: Testing whether submitted linked is visible on the graph: Since we already created a assignment in the “before” statement In this particular test case, we submitted the work for an assignment in “Your Work” tab and checked whether this link is present in the graph. The RSpec code is as follows: <code> 1. Scenario 3: Testing whether submitted file is visible on the graph: In this particular test case a file as submission for an assignment was uploaded. After this. it is checked whether this file is present in the graph. <code>. Timeline behavior when the student opens the view page of a newly created assignment 1. When the user has not made any submissions, reviews or feedbacks to reviews to the assignment, the timeline must only display the due dates of the assignment. Timeline behavior when student has not joined any team and makes submissions 1. When a student who is not part of any team makes a submission, he is assigned a team_ID by Expertiza and all submissions made by him are linked to that ID. So only those submissions will be displayed on the timeline. Timeline behavior when the student joins a team, what happens to the submissions he made before joining the team 1. When he joins a team and he receives a new team_ID, any submissions made hereafter will be made under the new team_ID and all previous submissions made by the student will not be shown on the timeline(this is how Expertiza assigns team_IDs and submissions- the same is reflected in 'your work' section of a user's profile). Only the user submissions made after he joins the team is shown on the timeline. Timeline behavior when there is no topic name for a given assignment 1. Sometimes topics in assignment are not named(eg program 2 - car rental app). In the peer review submission rectangular box displayed on the timeline after the student submits a peer review, instead of showing the label ""Review for [topic name]"", the label says ""Review"". Timeline behavior when a submitted hyperlink is removed 1. When a submitted hyperlink is removed, the submission must not be displayed on the timeline any more. A submission must be made before a peer review can be given 1. This condition holds even if the deadline has already passed. We can also include icons that are embedded into the rectangles. They act as visual aids to help the user quickly recognize the category of the box. We propose a design that would look something like this: <image>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. <link>.","The reviewers complained about various diagrams being missing, but I liked the flow in general.  Except for the Program Design section, which had a lot of prose without any examples or diagrams to concretize what was being said, it was easy to read and easy to see what was meant.  The code snippets had narratives to explain what they were about, though a little more detail would have been helpful.","It’s clear that you’ve put a lot of thought and effort into this detailed analysis of the Expertiza project submission process. The thorough examination of the functionalities, scopes for improvement, and possible solutions to existing issues is commendably comprehensive. 

I appreciate the time you've taken to extend the scope of your presentation to cover visualizing different types of records and associated timestamps via an interactive timeline chart. The color-coding section and the visual aids idea add an extra layer of user-friendliness to the design.

Your clear breakdown of the various issues with timestamped submissions and your proposed solutions are particularly impressive. From hyperlink submissions and file uploads to the representation of due dates, your analysis is both thorough and thoughtful.

Additionally, the walkthrough of how you would use the vis.js JavaScript library for the visualization aspect is excellent. The example you've provided of how a typical student would interact with the system is a helpful addition.

Moving forward, do ensure that descriptions of code are concise and clear. For instance, consider breaking down code explanations into smaller, digestible parts, as the paragraphs tend to get a bit text-heavy. Do not hesitate to include visual aids such as diagrams or screenshots to help illustrate complicated points, scenarios or code components.

Please also pay more attention to typographical errors and keep an eye out for repetitiveness. This would enhance the readability and comprehensibility of your work. 

Overall, great job on a thoroughly researched and detailed assignment. Your emphasis on user experience and practical solutions is commendable. Keep it up."
91,E1452,"The AssignmentTeam and CourseTeam models, as sibling subclasses of the Team model, tended to share certain functionality. This assignment called for refactoring those classes to make them better conform to ruby convention and to support the DRY (""Don't Repeat Yourself"")<ref> <link> </ref> principle of avoiding duplicate code. A quick skim of the code turned up a few places where the AssignmentTeam and CourseTeam models had similar functionality, as well as multiple methods and variables that needed better names. Some preliminary suggestions were run past the point of contact for this section of the codebase. They are summarized as follows: 1. The 'participants' and 'get_participants' methods in AssignmentTeam appear to have the same functionality, so these should be refactored into a single method. 2. The 'create_team_and_node' method will be renamed to 'create' to better follow accepted Ruby conventions. 1.1. A few other methods that could also be named better. For example, 'remove_team_by_id(id)' could be 'delete(id)'. 3. The 'includes?' method will be renamed to 'has_participant?' 4. There are some common responsibilities in both AssignmentTeam and CourseTeam, so that code will be pushed up into the superclass Team. This project took a two-stage approach. The first stage involved renaming methods and variables, but largely avoiding invasive code changes that could have an impact on the functionality. The second stage separately made changes like merging or removing duplicate functions. Several main goals were kept in mind throughout this process: 1. DRY 2. Ruby naming conventions 3. Project style conventions 4. Good design cosiderations, such as high cohesion and low coupling. <image>. 1. The import/export functionality for different team participants could be combined and simplified. This responsibility could probably be broken out into separate classes so that this responsiblity is encapsulated better. 2. Rather than extending the Team class to create separate classes to capture related functionality when teams are associated with assignments or courses, it might be better to just associate teams with courses or assignments directly and then delegate related functionality (like importing/exporting data) to separate helper classes. 1. The renaming and refactoring was performed as suggested in the given requirements. These changes helped enforce consistency and common conventions. 2. Some common functionality was combined to adhere to the DRY principle. 3. Methods were grouped and organized within their model classes to make them easier to read and mentally consume, and to suggest groups of responsibilities for potential future work. <references/>. 1. OSS - E1452 project on GitHub: <link> 2. Expertiza Project Documentation: <link> 3. Working Expertiza Site: <link> 4. Expertiza on GitHub: <link>.",Very clear.,"Dear Student,

I appreciate the considerable thought and effort you put into the assignment. It is evident that you have given a meticulous attention to identify areas in the code that could be refactored to conform to Ruby conventions and reinforce the DRY principle.

Your identification of the instances where the AssignmentTeam and CourseTeam models had similar functionality was particularly commendable. I also appreciate your suggestion to push some of the common code up to the Team superclass, which is an excellent application of inheritance.

Your two-stage approach that involves renaming methods first and then merging or removing duplicate functions is logical and demonstrates a proactive strategy to code cleaning. The way you organized the methods within their model classes further indicates your understanding of the important code organization practices.

Additionally, your analysis of the import/export functionality and your insights on separating out these responsibilities into distinct classes shows your understanding of encapsulation.

However, I would like to point out a minor error in the numbering of your points. You have used '1.' and '2.' repeatedly. Make sure to check your listing points correctly in future. 

Lastly, while you've provided links to the Expertiza project and site, I encourage you to consider including specific code examples directly in the assignment next time to illustrate your points better.

Overall, great job and keep up the good work.

Best,
[Your Name]"
92,E1859,"Expertiza is an online assignment grading platform. Instructors can create assignments and implement peer reviews for submitted assignments. This project concerns the creation of a system for visualizing student performance on those assignments, primarily as graded in peer reviews. Graphs will be made to show various rubric criteria and the class' performance on the criteria. If the criteria are the same for multiple stages of review, an instructor should be able to compare performance over time or between reviews. Contents 1.1. <link> 1.2. <link> 1.3. <link> 1.4. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.5. <link> 1.1.1. <link> 1.6. <link> 1.7. <link> 1.8. <link> 1.9. <link> 1.1.1. <link> 1.1.2. <link> 1.10. <link>. Our task is to provide an interactive visualization or a table for instructors that shows how their class performed on selected rubric criteria. Such feature would be immensely helpful for instructors as it would assist them to identify what they need to focus more attention on. For example, creating a graph showing the average scores for all or a certain subset of main rubric criteria (questionnaire). If the average score of the class on selected criteria (question) is low means the instructor can emphasize more on the learning materials related to it. The visualizations will be implemented as either a single or stacked bar chart with a bar for each of the selected criteria to be observed. If a single bar, then the height of the bar will be the total class average, but a stacked bar chart may be better to show the percentage of the class that received each score. The changes made to the expertiza project will primarily include HTML/ERB changes to the view files to accommodate the added charts on the page and the necessary javascript to allow responsive design. Brief controller modifications will be made to facilitate database filtering to get the displayed data. 1. On clicking Manage and then on assignments, following page appears. <image> 2. Click on 'view score' icon of an assignment. The summary report page of the selected assignment comes up. <image> 3. Following are mockup screens which we wish to create: a) Instructor would select the round and rubric criteria of the assignment for which he/she wants to view the class performance. <image> b) The bar graph of the class performance for those criteria would be displayed. <image>. The flowchart representing graphical flow of an instructor visiting view scores under assignments is given below: <image>. We have used the lightweight <link> library for displaying the chart data on the page, with standard HTML for all of the options and dropdowns for option selection. Google Charts was chosen because of its high compatibility, full option set, and comparable graphical quality to the rest of expertiza while keeping a small JS footprint, which should help prevent slow page responsiveness. The following graph shows the view of the 'view scores' page after the modifications. The instructor selects a subset of rubric criteria for which he/she wants to know how a class performed for a particular round. A bar graph of the average score of the class for that subset of criteria is displayed. <image> The above graph shows an average score of the class for 10 rubric criteria in Round 1 for assignment ""OSS project/Writing assignment 2"" selected by the instructor. A live demo with randomly generated data can be found on <link>. We have implemented a new partial file criteria_charts to the team_chart that display the bar graph with existing data collected by the grades controller methods to the view page. Modified files: <code>. <code>. <code>. The specification of the project does not require us to use automated tests. However, we have tested the existing tests after the addition of new features to the grades_controller. We have approached <link> testing framework. The UI feature tests are conducted manually. To validate all functionality of the chart when adding new features or fixing old ones, the following criteria were tested manually for expected functionality: 1. Chart is displaying correctly 1.1. Bars are showing up where expected 1.2. Bar annotations are showing the expected value 1.3. Criteria labels are for the correct bar and displaying correct values 1.4. Hover text is displaying the correct values 1.5. Null values are not present on the chart 1.6. Correct colors are used for the multi-round view 2. Show Labels checkbox works as expected 3. Round Criteria is displaying correctly 1.1. Round dropdown menu shows all rounds for the assignment 1.2. Selecting a round changes the criteria checkboxes 1.3. All checkboxes are displayed with appropriate text 1.4. Checkboxes correctly remove or add criterion bars to the chart. We have modified one of the existing tests for grades controller because the addition of new functionality broke that particular test. The added test handles the chart functionality correctly. <code>.","The documentation seems to show an outdated version of the screen that selects criteria to be shown.  The code has just been pasted in; there should be a description, and it would've been much better to give a link to Github, where the changes could be seen.  Some reviewers said that tests were not covered, but that deficiency has been fixed in the final version.  Would've liked to have seen some description of what the test does, however.","The assignment outlines the development of a visualization tool for Expertiza, a online grading platform. Here is my feedback:

1. Technical Understanding: The assignment shows excellent understanding of the requirements, both in terms of the final user experience and underlying technology. The use of Expertiza, HTML/ERB, and JavaScript are clearly understood and addressed with suitable solutions.

2. Scope and Detail: The description of every step is quite detailed and follows a logical structure. The consideration for several possibilities (single or stacked bar chart) also demonstrates strategic planning. 

3. Functionality Verification: Automatic and manual testing approaches shows conscientiousness but please consider providing more detail about the testing scenarios and results. Also, I don't see any mention of potential errors or possible areas of improvement, which is important for a comprehensive project review.

4. Project Refinement: The addition of new files and modification of existing ones show a nuanced understanding of the platform. However, it would be beneficial to include some discussion on potential user feedback or real-world application of this project.

5. Documentation: The assignment is well-documented with references to links and images. However, the placement of the '<link>' and the indexed headings that don't seem to align with any content can be confusing. 

6. Flow: The flow of content is largely logical and clear. However, you might want to reorder some points to enhance comprehensibility. Also, the two parts of the chart functionality - showing average scores and round criteria, could be better highlighted for clearer understanding.

Overall, this is a very good effort and shows depth in understanding and execution. Remember to always take a step back to review your projects both in terms of details and the bigger picture. Keep up the good work!"
93,E1522,"The goal of this project is to present the the data in Expertiza in a more convenient way. Through the use of charts and graphs to enhance certain pages, such as the student's scores page and the instructor's scores page, and allow for the users to get an at-a-glance analysis of the data without having to dive into the tables. Our project video <link>. The purpose of this project is to add a visualization element to some of the data collected in expertiza. The aim of this is to provide a more intuitive “at-a-glance” idea of the data, some examples would be: how a student is doing on his/her assignments, or how their work compares to that of their classmates. On a less functional angle, it also enhances the aesthetics of the pages, taking the drab tables and giving them a more appealing look. There are quite a few gems available to visualize data in Ruby on Rails, like Goolgecharts <ref> <link> </ref> and GoogleVisualr <ref> <link> </ref>. These gems makes use of Google Visualization API and wrap it to let users write ruby codes to present nice charts in their web pages instead of using Javascript. GoogleVisualr is a a wrapper around the Google Chart Tools<ref> <link> </ref> which allows users to create beautiful charts with just Ruby, instead of writing JavaScript if using the Google Chart Tools directly. Installing GoogleVisualr is pretty simple. Just include the following gem in the Gemfile. <code> And in the Rails layout, load Google Ajax API in the head tag, at the very top. <code>. 1. In your model or controller, write Ruby code to create your chart (e.g. Area Chart, Bar Chart, even Spark Lines etc). <code> 1. Configure your chart with any of the options as listed in Google Chart Tools' API Docs. <code> 1. In your view, invoke a chart.to_js(div_id) method and that will magically generate and insert JavaScript into the final HTML output. <code>. The following code presents the example of area chart. <code>. The following code presents the example of area chart. <code>. The following code presents the example of area chart. <code> The resulting chart looks like below. <image>. Googlecharts is a ruby gem implements a wrapper for Google Chart API. It is fully tested using RSpec. gchartrb<ref> <link> </ref> is a Ruby wrapper around the Google chart API<ref> <link> </ref>. In our project, we use gchartrb to generate all the bar charts in the visualization. Installing gchartrb is simple, just include the gem in the Gemfile. <code>. The following example code would generate a bar chart. <code> The bar chart would look like below. <image>. The following example code would generate a line chart. <code> The bar chart would look like below. <image>. This section describes where in Expertiza we can use these visualizations to provide a better user experience. The 'Review Score' view of the assignments can be enhanced using these visualization. We can see by the image below that currently the scores views includes only a large table. From a user experience perspective having a more prioritized view of the scores would be beneficial. Having all the data available for the user to peruse in a table is informative, but when the user wants only to get a quick idea of how they did in an assignment, it would be helpful to have some sort of visualization. <image> The above scoring which is in tabular form can be enhanced with charts. The scores page was augmented with bar graphs displaying the distributions of each column, as well as a circle icon for the average score for that column. This will allow for easily determining what the reviewers thought of the work, as well as what the range of scores given. The circle graphs with the averages provide a visual for the quality of the work in each of the categories. <image>. We created a new view under the grades views, called participant_charts. This view is included as a partial in the grades/view_my_scores view. This allows us to not modify any of the existing views and keep the code modular. For the bar charts we constructed a method that, given the score and the type of bar chart, populates an instance variable that contains the charts. The code was included in the grades controller (grades_controller.rb file) and is shown below <code> The width of the bars is dependent on the number of scores to show. Assignments with many reviews to show, require smaller bars. This is accomplished by tying the bar_width parameter, to the size of the data. For the circle charts showing the averages of the columns we used a javascript library, circle.js. By simply passing the scores to the .js code in the grades view as shown in the code below. The circle is then rendered automatically in a div block elsewhere in the view named the same as the id: tag below <code>. The user might want to hide the stats, with that in mind we included a button to toggle the visibility of the charts. Making use of an existing function, toggleElement, we added a link above the charts table that when clicked hides/shows the charts. The code to accomplish this is shown below <code>. Based on the uniformity of the review scores, we compiled a reliability metric. This metric encapsulates the level of agreement between the reviews, and should provide a quick at a glance notion of whether reviewers agree on the scoring for the particular assignment, or whether there is a high variance in the scores given. A good reliability score indicates that the grade given to the assignment by the reviewers is to be trusted, whereas a poor reliability score indicates that there was a high level of disagreement in the reviewers and the instructors should perhaps take a closer look at the participant's assignment. This reliability score is computed from the standard deviation of the review scores. A standard deviation that's less than 10 will award a good reliability score. A standard deviation between 10 and 20 will award a medium reliability score, whereas a standard deviation greater than 20 will give a poor reliability score. <image> The color of the three bars Icon, and the number of filled bars is representative of the reliability of the reviews. Take the case of the green sample icon in the image above, the reviews mostly all agree. Whereas in the following two images, the icon is yellow and red respectively to signify increasingly worrying levels of disparity in review scores. <image> <image> A similar method to the one used for the bar charts was used. In this case, a horizontal bar chart was created, and the data was dictated by the qualitative score that was passed into the method. This score could be 'good', 'medium' or 'bad'. Based on this string argument the graph is created with the correct number of bars and the correct color. <code>. In the instructor view of the assignment scores we added similar charts to the one shown for students. In this case we include a class average in the form of a circle chart, and a class distribution in the form of a bar chart. An example of this is shown below <image>. <references/>.","Obvious that you invested some effort in thinking about how data was to be presented. Good visual design, and good mockups of the changes to be made. It's not clear what the three horizontal bars represent, nor is it clear how you are going to calculate reliability.","Dear Student,

Thanks for submitting your assignment. Your hard work and deep understanding of the subject matter are evident. 

I like your project's vision of enhancing the representation of data on the Expertiza platform. The essential description of GoogleVisualr and gchartrb supports the statistical tools you select for visualizations. The code snippets and images provided give a good understanding of the implementation process. Your idea of creating visualizations to enhance user experience is laudable. 

However, there are a few areas where your assignment can be improved:

1. The details regarding the application of various charting gems could have been organized and explained more systematically for better comprehension.

2. There are redundant repetitions where you mentioned ""The following code presents the example of area chart"" three times in a row.

3. In this sentence ""The bar chart would look like below. <image>."", remember to describe what the image illustrates, as this kind of description could greatly help the reader's understanding.

4. The introduction of new concepts, like 'reliability metric', could have been smoother. An explanatory paragraph about the importance of reliability of reviews and its quantitative interpretation would improve the narrative flow.

5. Please proofread to correct typographical errors like ""Goolgecharts"". These minor errors can detract from your overall presentation.

6. The citation style is not consistent. It would be better to standardize the citation format for a more professional presentation.

I strongly encourage you to take these points into consideration. Overall, your work shows significant potential. By being mindful of these suggestions in your future work, your assignments will no doubt improve greatly. Keep up the good work!

Best,
[Instructor's Name]"
94,E1577,"<link> is an open-source <link> based web application which allows for incremental learning. Students can submit learning objects such as articles, wiki pages, repository links and with the help of peer reviews, improve them. The project has been developed using the <link> framework and is supported by the <link>. The current version of The Expertiza Project has an automated meta-review system wherein the reviewer gets an e-mail containing various metrics of his review like relevance, plagiarism, number of words etc. , whenever a review is submitted. The purpose of this project is to give students some metrics on the content of the review when the automated meta reviews are disabled. This also includes the addition of new relevant metrics which can help the reviewers and instructors to gain insight into the reviews. The scope of the project is limited creating a system where the reviewer and the instructors can view metrics for the submitted reviews.The user or the instructor need to manually visit the link to view the metrics.The instructor can view the metrics for every assignment available whereas the user can view only the metrics of the assignments relating to himself.The scope doesn't include any automated viewing of reports for the metrics.Since the project is mainly related to giving reports about the existing data, we will not be modifying the results saved by the actual <link> mechanism.The scope also excludes any change of the actual peer review process i.e. submitting a review of an assignment or adding an assignment to a user profile. The project requires completion of the following tasks 1. create database table to record all the metrics 2. create code to calculate the values of the metrics and also ensure that the code runs fast enough (can give results within 5 seconds) as the current auto text metrics functionality is very slow and diminishes user experience. 3. create views for both students and instructors that show for each assignment: 1.1. Total no.of words 1.2. average no. of words for all the reviews for the particular assignment in a particular round 1.3. if there are suggestions in each reviewer's review 1.4. the percentage of peer reviews that offer any suggestions 1.5. if problems or errors are pointed out in the reviews 1.6. the percentage of the peer-reviews which point out problems in this assignment in this round 1.7. if any offensive language is used 1.8. the percentage of peer-reviews containing offensive language 1.9. No.of different words in a particular reviewer’s review 1.10. No. of questions responded to with complete sentences 4. make the code work for an assignment with and without the ""vary rubric by rounds"" feature 5. create tests to make sure the test coverage increases. <image>. Iterator Pattern<ref> <link> </ref>: The iterator design pattern uses an iterator to traverse a container and access its elements.In our implementation, we have iterated over the comments in each response(answers table) relating to a particular round to calculate the individual metrics. Also while calculating the aggregate metrics we have iterated through the review_metrics table to read the metric values for a particular user using all the responses for the particular response map corresponding to the submission of the review. <image> The image shows the schema for the new table which will be created to store the calculated values of the metrics. Its attributes are explained below: 1. response_id: This attribute is captured when a user submits a reviewer submits a review and passed on to the ReviewMetric model.This is used to link the metrics to a particular reviewer-response map. 2. total_word_count: This attribute contains the total number of words for a particular review(response_id). 3. diff_word_count: This attribute contains the total number of different words for a particular review(response_id). 4. suggestions_count: This column holds the number of suggestions given per review 5. error_count: Field containing the number of comments which point to errors in the code. 6. offensive_count: This attribute contains the number of comments containing offensive words. 7. complete_count: This contains the number of comments which have complete sentences in them. 1. View Reviews Text Metrics as Reviewer: As a reviewer, he/she can see the text metrics of individual reviews as well as aggregate metrics for all the reviews done for an assignment/project. 2. View Reviews Text Metrics as Instructor: As an instructor, he/she can see the text metrics of reviews received by any team for a particular project/assignment. The instructor can also see the text metrics of the reviews done by any reviewer. 1. For use case 1 , test whether the text metrics Db has entries populated for each type of metrics (no. of words, no. of offensive words, etc), once the reviewer submits any reviews. 2. For use case 2 , test if the instructor can see the text metrics of reviews received by each team for a project/assignment. Also, test if the instructor can see the text metrics done by any reviewer. <image>. The project requires completion of the following tasks 1. Create database table to record all the metrics 1.1. A new MVC by the name ReviewMetric has been added to the project. 1.2. A table review_metrics is used for the same. It has the following columns to record data with respect to each response, i.e. review submitted. 1.3. A new row is updated in the table when a new review is saved or submitted and the respective row gets updated when an existing review is re-edited or submitted. <image> 2. Create code to calculate the values of the metrics and also ensure that the code runs fast enough (can give results within 5 seconds) as the current auto text metrics functionality is very slow and diminishes user experience. 1.1. The code for evaluating the metrics value as per each review is saved in the function calculate_metric at the model review_metric.rb 1.2. This code is called from the function saving residing at response_controller.rb . The saving function gets called post necessary processing when a review is saved or submitted. The calculate_metric method is called at the end of the saving method to analyse the review and save respective information according to the requirement. 1.3. The calculation code uses the Answer table to pull out the saved review content using the response_id of the review. It incorporates a set each for offensive words list, suggestive words list, and a list of problem pointing words. The function then calculates the following: 1.1.1. Total number of words in the review 1.1.2. Different number of words in the review 1.1.3. Number of offensive words in the review - the method uses a set of offensive words as a dictionary and compares this with each word in the review 1.1.4. Number of words which signals a suggestion in the review - the method uses a set of suggestive words as a dictionary and compares this with each word in the review 1.1.5. Number of words which signal a problem being pointed out in the review - the method uses a set of problem pointing words as a dictionary and compares this with each word in the review 1.1.6. Number of questions responded to with complete sentences - each sentence which has more than seven words qualify for a complete sentence <image> 3. Create partials for both students and instructors: 1.1. Views are created for both students and instructors to display the text metrics calculated for each review and assignment. These views are accessible through links in the student report page and instructor _review_report.html.erb page 1.2. The following are screenshots where the links are included in the above mentioned pages <image> <image> <image> 1.3. The following is a screenshot when a student saves or submits a review <image> 1.4. The following is a screenshot when the student clicks the View Text Metrics link <image> 1.5. The following is a screenshot when an instructor uses the View Review Report link at the assignments page for a given assignment <image> 1.6. The following is a screenshot when the instructor clicks the text metrics summary link <image> 1.7. The following is a screenshot when the instructor clicks the individual text metrics link <image> 4. Make the code work for an assignment with and without the ""vary rubric by rounds"" feat 1.1. The calculate_metric code works for each review submission in a way where it uses the response_id of each review saved/submitted to find the review text saved in Answer table. The entire review text is then thoroughly checked to calculate the required metrics. Hence, any variation in the review rubrics does not affect this metric calculation. 1. Tested for a valid object, i.e. a valid ReviewMetric entry. 2. Tested the ReviewMetric model so that it only calculates the metrics for a ReviewMetric entry with a valid response_id. 3. Tested the ReviewMetric model so that it does not calculate the metrics for a ReviewMetric entry with an invalid response_id. <image>. 1. Computing Power: Same as the current Expertiza system. 1. Memory: Same as the current Expertiza system. 1. Disk Storage: Same as the current Expertiza system. 1. Peripherals: Same as the current Expertiza system. 1. Network: Same as the current Expertiza system. 1. Operating system environment : Windows/UNIX/OS X based OS 1. Networking environment: Same as it is used in the current Expertiza system 1. Tools: <link> , Interactive Ruby. <references/>. 1. <link>.",It said that Expertiza was started by NSF; otherwise fine.,"Dear student,

The assignment is well thought out and appears thoroughly explained. It covers a broad spectrum of aspects related to a specific project. Your detailed statements on the functionality of the project, from the creation of the database table to record all the metrics, the creation of the code to calculate the values for the metrics, to the viewing environments for both student and instructor are truly commendable.

The use of the Iterator Design Pattern is appropriate for this kind of application and it's excellent that you've explained how you've implemented it in your project. The schema design for your database table is well-structured and logically reasonable. I also commend your exemplary use of images to support your explanations, which make your points easier to grasp.

However, there are areas that could use improvement. First, there were multiple instances of repeated information which were unnecessary like a repeated list of tasks. Ensuring that your writing is clear and concise will improve the quality of your work. Furthermore, the broken segments in your submission (such as the ""<link>"", ""<ref>"", ""<image>"", and ""<references/>."" placeholders) suggest that some content is missing. Please replace these with the intended links, images, or references for the best reader comprehension. 

Also, your explanation on the operating system environment was quite generic. It would be better if you delved into specific systems used in your project and discussed reasons for why they were chosen and how they benefited your project overall.

Finally, the piece would benefit from a clearer structure – consider breaking it into clear sections with headings, and summarizing your central points in a conclusion.

Please proceed with these revisions, as they will ensure your future assignments are more effective and well understood. Keep up the good work!
"
95,E1983,"Expertiza provides teammate reviews to gauge how much each team member contributed, but we would like to augment this data with data from external tools like Github (for example, number of commits, number of lines of code modified, number of lines added, number of lines deleted.) from each group’s submitted repo link. This information should prove useful for differentiating the performance of team members for grading purposes. Overall data for the team, like the number of committers and number of commits may also help instructors to predict which projects are likely to be merged. Currently, Expertiza provides Teammate Reviews under View Scores functionality for each assignment. 1. Teammate Reviews functionality in the View Scores page gauges teammate views on how much other team members contributed to the project. We need to augment this data with data from external tools like GitHub in order to validate that feedback. New metrics will be appended under each student data under the same functionality. 2. Github Metrics under View Submissions page should include a bar chart that shows the number of commits by the team throughout the assignment timeline. This will help instructors to get a team overview, and aid grading process. While this data will not have marks associated directly, it will prove useful to the instructor in differentiating the performance of team members and hence awarding marks as per contribution. Overall data for the team, like the number of committers and number of commits may also help instructors to predict which projects are likely to be merged. We have forked the repository <link> currently doing work upon for an independent study project by Carl. We have extended his work and added upon that to show the metrices. The link for our project PR is <link>. Extract Github metadata of the submitted repos and pull requests. 1. The metadata should be stored in the local Expertiza DB. For each participant, record should include at least: 1.1. Committer id 1.2. Total number of commits 1.3. Number of files changed 1.4. Lines of code changed 1.5. Lines of code added 1.6. Lines of code removed 1.7. Lines of code added that survived until final submission [if available from Github] 2. The code should sync the data with Github whenever someone (student or instructor) looks at a view that shows Github data. 3. The data for teams should be shown in the instructor’s View Scores window, in a new tab, probably between Reviews and Author Feedback. 1.1. Design a good view for showing data on individuals. Please discuss this with the project mentor(s). 1.2. It seems to me that this should be on the Teammate Reviews tab, right below the grid for teammate reviews. The reason for this is that we’d like to see all the data on an individual in a single view. For teams, by contrast, there is already a pretty large grid, and potentially multiple grids for multiple rounds, so adding a new grid is more likely to clutter the display. 4. Create a bar chart for the # of lines changed for each assignment team on “view_submissions” page. The x-axis should be the time starting from the assignment creation time, till the last deadline of the assignment, or current time, whichever is earlier. This task has been partially implemented by another group for project E1858. Github Metrics Integration in 2018 Fall semester. Detailed document about project E1858 on framework design and implementation can be found in <link> and the PR for Project E1858 is shown in <link> . However, their work has been rejected with the feedback ""They have integrated the github metrics into expertiza to show the number of commits, pull requests status, etc against every project. They have also integrated it into the metrics. Looks like they covered the edge cases. The code looks good but needs comments as it is pretty complex. The documentation feels like it is flooded with code, if there was a description of the changes, it would have been better. Extensive tests, but it might be good to see if additions to existing tests really belong in those same tests"". The goal of our current project is to resolve issues existing in their previous work, refactor codes they created and modify their code following ""DRY"" principles. The ultimate goal is to have the Github Metric Integration work in Expertiza. 1. The current screen looks cluttered and needs to be changed to display the data in a more organized and easy to read way. The GitHub commit data can be shown on a weekly basis instead of the current day wise. Showing the data day-wise does not add much for the instructor grading. A bar graph needs to be added to display data like no of commits, no of lines added and number of lines deleted by each user. 1. Old Graph Representation <image> 1. New Graph Representation The data is shown as a horizontal stacked graph grouped by the time range for eg: weekly or daily. The bar will show the no of commits, lines of code in a stacked manner. Assignment policy contains variables for due date and start date which can be used to get the timeline to plot week-wise data, this way we'll have max around 3-4 weeks of bars. <image> Note: The colors chosen to represent weeks and students have been chosen such that colorblind people are able to differentiate between them as well. <image> 1. Use Case diagram of two approaches to append 'GitHub contribution metric' in teammate review. 2. Use Case diagram explaining approach to add new column 'GitHub contribution metric' in 'View submission. Actors: 1. Instructor: This actor is responsible for viewing GitHub metrics of teams and team members of an assignment. Pre-Conditions: 1. The Team should have submitted the assignment with a PR link or GitHub repository. Primary Sequence: 1. The instructor should login. 1. The instructor should browse teams for an assignment. Post Conditions: 1. Instructor will be able to see the team contribution done by each team member in 'View Submissions' page using graph diagrams, as shown in the figure. 2. Instructor will be able to see the work done by each student in 'Teammate Review Tab' with new metrics table appended at the end, as shown in the figure. Github Metrics Features can be accessed from manage content UI <image> Then click the 'view submissions' <image> Then we can see 'Github Metrics button' in each project submission <image> Below is the bar chart of the number of commits per week grouped by team members <image> Below is a drop-down menu that allows the instructor to change the graph to show either the number of commits, or the number of lines added or the number of lines deleted. <image> Below is a drop-down menu that allows the instructor to change the graph grouped by week or grouped by student <image> Below is view that shows overall Github metrics showing the whole team contribution. <image> Below is a pop-up preview of the Github metrics (number of lines added and deleted as well as the number of commits) of each member on each date. <image> Below is a pop-up preview of the Github metrics (number of lines added and deleted as well as the number of commits) of each member over the complete duration of the project. <image>. 1. MVC – The project is implemented in Ruby on Rails that uses MVC architecture. It separates an application’s data model, user interface, and control logic into three distinct components (model, view and controller, respectively). We intend to follow the same when implementing our end-point for pulling GitHub data. 1. Dry Principle – We are trying to reuse the existing functionalities in Expertiza, thus avoiding code duplication. Whenever possible, code modification based on the existing classes, controllers, or tables will be done instead of creating the new one. 1. Restful Api - Representational State Transfer REST web services helps in establishing the interoperability between different applications. RESTful API uses the HTTP requests for performing the actions GET, PUT, POST and DELETE. To get the data from Github we will use their query api. After understanding the project E1858, We found some issues in this project and give our solutions below. Problem: The related codes for Github related functionalities are most implemented under ""Grades_Controller"". This design obviously violates a good design pattern because Grade_Controller involves too many functions. Solution: To improve it, we should create a separate ""Github_Metrics_Controller"" which is specifically responsible for functions related to Github Metrics. Following the MVC architecture, we will also need to create corresponding Models and Views for the new controller. Problem: There are some JavaScript codes in inappropriate positions. We need to replace JavaScript codes to 'assets' fold. Problem: Lots of codes in their current implementation violate ruby's ""DRY"" principles, such as redundant codes, meaningless names, long coding block and so on. We will refactor their code and fix code smells with the help of the code climate platform. Also, there are many useless spaces make the code look less elegant. A bar graph needs to be added to display data like the number of commits, the number of lines of code added/removed per user basis. The current work consists of cluttered graphs for code frequency for the entire team which makes it difficult to gather user-level activities/submissions in different timelines. We intend to add horizontal bar charts that can be mapped to user-level contributions in different per week. The controller code contains auxiliary functions that make calls to Github for third party resources. These can be moved to a helper class. To make sure the refactor code can work correctly, we need to run the original rspec test code and add some new test. The test results are shown below. 1. Run and pass existing RSpec Tests after refactoring 2. Develop New RSpec Tests for the new features 3. UI testing on the deployed project. We tested all the existing functionality for the page where we are showing GitHub matrices. New Features which we tested are: Github Metrics By Week 1. Number Of Commits 2. Lines Added 3. Lines Deleted Github Metrics By Student 1. Number Of Commits 2. Lines Added 3. Lines Deleted ""get_chart_data"" function parses the input github data based on the type of the graph and timeline selected to the required data format required by the chartjs-ror ""horizontal_bar_chart"" function <code> Checking private method being called <code>. For this project, we will add an API from the GitHub, all we need to do is to test whether the API can work appropriately after changing codes to another controller, moving javascript code and after adding new UI changes. <link> <link> <link>.","I thought it would have been better to distill the reasons for rejection of last year's project, rather than just quote the feedback.  They did a very good job of showing the changes to the tables and graphs displayed in their reports.  However, there was hardly anything describing the code changes, and the tests were pasted in, with hardly any description of what they were doing.","The assignment shows a clear understanding of the integrative nature of Expertiza and Github. The inclusion of teammate reviews and additional data sets from Github is a creative approach to differentiating performance in team members for grading purposes. The outlining of the data to be recorded for each participant proves comprehensive and well-suited for the project aims.

You've vividly illustrated your ideas for visual data representation and how you plan to improve upon previous work done on this subject, considering feedback previously received. The reasoning given behind your suggested design changes, such as improving the view for data on individuals and proposed changes to the bar chart view is clear and solid.

The use case diagram and actors indicate an excellent grasp of the different roles and interactions in this project. Additionally, the detailed instructions for navigating UI show a good understanding of the user experience.

Your MVC architecture, DRY principle, and Restful API, show an adherence to best programming practices and should serve to ensure quality and maintainability of your code. 

However, as you continue, I would recommend you to be careful about restructuring other groups' designs, be respectful and justifiable in your decisions. Furthermore, consider your test plans carefully. Are you including edge cases, and unusual scenarios in conjunction with regular use? Consider having a detailed error handling system in place, as in many cases, it's instrumental in identifying issues early.

Lastly, the meticulous breakdown of problems encountered in project E1858, along with subsequent solutions for the same, is commendable. The steps you've outlined for refactoring and improving upon this work will surely serve to create a more efficient and cleaner codebase.

Keep up the exceptional work!"
96,E1929,"This <link> project, completed in the Spring of 2019, aimed to improve the charts instructors could view to see the grade statistics for a given assignment. Two charts already existed, one showing the grade distribution for all teams, and another simply showing the class average grade. Our goal for this project was to add a third chart, using <link> , which would show grade statistics for the various <link> grades within that assignment. The chart is interactive so the user (instructor) can toggle which rubric criteria, and which statistics, to display. Along with displaying the rubric criteria for a single assignment, we aimed to add a feature which would allow the comparison of compatible rubric grades from two different assignments. Again, this functionality is interactive, allowing the instructor to choose which statistics will be populated in the chart. By viewing our new visualization of rubric grades, an instructor can better judge which aspects of the course are well-understood, and which may need a bit more attention. Contents 1.1. <link> 1.2. <link> 1.1.1. <link> 1.3. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.4. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.5. <link> 1.6. <link> 1.7. <link> 1.8. <link>. E1929 - Visualizations for Instructors - Class performance on specific rubrics An interactive visualization or table that shows how a class performed on selected rubric criteria would be immensely helpful. It would show the instructor what he / she will need to focus more attention on. For example, could you create a graph showing the range and clustering of scores for the 5 main rubric criteria? And, if these same 5 criteria are used in the preliminary and final assignments, it would be nice to be able to compare performance between assignments in a visualization that showed the class results on 3 separate artifacts. Webpage: login as instructor -> Manage -> Assignments -> View scores. <image> Figure 1: Existing assignment grade charts - The existing assignment grade charts show the average grade for the assignment and the grade distribution. During this project, we aimed to add a third chart which shows the distribution for specific rubric criteria within the assignment. We successfully executed all of the ideas we had during the planning phase: 1. Add new feature to show mean and median data for rubric criteria in a given assignment 2. Add new feature to show comparison 3. Performed UI testing to ensure features were operational, including edge cases 4. Added and ran RSpec and Capybara automated tests. <image> Figure 2: New Rubric Statistic Visualization - Added in the center of the existing two charts is an interactive chart the instructor can use to see the mean or median scores for whichever criteria they select. This is done on the ""Analyze Assignment"" tab, which is selected by default when the ""View Scores"" page is loaded. <image> Figure 3: New Rubric Cross-Assignment Comparison Visualization - The instructor can see a comparison between selected criteria between the current assignment and the selected assignment. The rubric criteria must be compatible in order for it to even show up in the selection list. This comparison visualization is done on the ""Compare Assignments"" tab which must be selected after the ""View Scores"" page has been loaded. 1. Refactored <link> partial view to use partials for each graphic. Previously both charts were defined together in _team_charts.html.erb, but now each graphic has its own partial view ( <link> , <link> , <link> ). This allows more flexibility going forward, if it's decided one chart should move to a new place on the page, or to a new page. <link> Added: 10 + Modified: 11 = Total: 21 1. app/assets/javascripts/rubric_stats.js (new) 2. app/controllers/grades_controller.rb 3. app/helpers/assignment_stats_helper.rb (new) 4. app/models/assignment.rb 5. app/models/assignment_questionnaire.rb 6. app/models/assignment_stats.rb (new) 7. app/models/criterion_stats.rb (new) 8. app/models/question.rb 9. app/models/questionnaire.rb 10. app/models/review_round_stats.rb (new) 11. app/models/score_view.rb 12. app/views/grades/_team_charts.html.erb 13. app/views/grades/_team_charts_averages.html.erb (new) 14. app/views/grades/_team_charts_distribution.html.erb (new) 15. app/views/grades/_team_charts_rubric_stats.html.erb (new) 16. spec/controllers/grades_controller_spec.rb 17. spec/factories/factories.rb 18. spec/features/grade_interface_spec.rb (new) 19. spec/features/helpers/grade_interface_helper.rb (new) 20. spec/models/assignment_spec.rb 21. spec/models/questionnaire_spec.rb. We performed automated tests using RSpec Framework and Capybara. In addition, we performed manual tests of the user interface (UI), by using the app. The RSpec Testing Framework, automated testing, was used to verify the models of the Expertiza web application feature set. Since this feature is dealing with visualizations (charts) that are intimately tied with Active Record models, we seeded the testing database with known data via FactoryBot gem. These changes were automatically rolled-back once the testing was complete. RSpec was used to increase/maintain automated test coverage for the methods that we added into assignment and questionnaire models. Mocks and stubs were utilized in order to decouple the model under test from dependencies of other models. This will allow us to identify easily if our model updates are causing an issue. RSpec Capybara was used to provide integration testing of the charts. The Test Database was seeded with the appropriate information for executing the results of the charts. An additional GEM was needed, webdrivers, to utilize the predefined drivers of Selenium. The default web driver, Rack-Test, does not execute java scripts. Since the graphs that we are using require java script, thus soliciting the necessity of Selenium with its predefined web driver, selenium_chrome_headless. This provides the required functionality to process the java scripts and to automatically ensure that they exist in the DOM. In order to use the headless web driver with the seeded Test Database, a different database strategy was required. As a result, for this test only, the database strategy was changed to truncation. Ruby 2.2.7 is used in the current version of Expertiza. This version does not allow for sharing of the database thread, and thus requires the to be written to the database outside of a transaction block. This allows for the headless web driver to see that the data is persisted the Test Database and is able to run as normal. Once the test is completed, the database tables are truncated and all data is removed. In addition to the automated tests above we also performed manual testing of the newly added features to include: 1. The new feature properly initializes 1.1. Analyze Assignment tab is loaded by default 1.2. Chart is in between the other two existing charts 1.3. Round 1, all Criteria selected, and Mean are selected by default 2. Analyze Assignment tab operating correctly 1.1. Bars are showing up where expected 1.2. Bar annotations are showing the expected value 1.3. Criteria labels are for the correct bar and displaying correct values 1.4. Hover text is displaying the correct values 1.5. Null values are not present on the chart 1.6. Round dropdown menu shows all rounds for the assignment 1.7. Selecting a round changes the criteria checkboxes 1.8. All checkboxes are displayed with appropriate text 1.9. Checkboxes correctly remove or add criterion bars to the chart 3. Compare Assignments tab operating correctly 1.1. Compare Assignments tab is only displayed if compatible assignments exist 1.2. Clicking Compare Assignments tab loads that tab 1.3. (All tests from Analyze Assignment tab apply to this tab as well) 1.4. The two colors for assignment comparison are correct. Using the Ubuntu image, one issue was discovered was with the ScoreView view. The migration files is building the view out as a table instead of a view as required, this can be seen in the schema file. The Development database shows the ScoreView as a view, but the Test database shows it as an table. It appears that the Development database was altered outside of migrations to force the ScoreView to be a view instead of table. With this scenario, the automated integration testing was forced to seed the ScoreView as a table. Further gems are available to alleviate this issue. 1. We were unable to find two compatible assignments in the Expertiza test database to fully test our Compare Assignments feature. We did test all the functionality by seeding the database, but it technically wasn't using real data. 1. Put our new chart on the View Scores page, rather than on a new page 1. Since it was able to fit on the existing page while displaying all the necessary info, we figured it'd be beneficial to have all grade statistics charts together. 2. Use GoogleCharts for our new charts 1. The group who previously attempted this project chose GoogleCharts because it has a high compatibility and its charts look of similar quality to those already existing in Expertiza. We agreed with this, and determined GoogleCharts had all of the features we would need. 3. Added the AssignmentStats, CriterionStats, and ReviewRoundStats models 1. This was a logical, structured way to organize the various data and methods we needed. 4. Encapsulation of the data within the new models 1. Since the various statistics we needed to form our chart were stored in multiple models, there would be no good place to put the new methods we'd need. The way we did it promotes cohesion, since the new classes have the sole focus of computing statistics. This also allows for future refactoring of other sporadic statistics methods. 5. Placed AssignmentStats methods in assignment_stats_helper.rb rather than in the model or controller. 1. The methods of interest were really not business logic, but more like massaging of data. For that reason it belonged more in the controller than the model. However, to keep things neat and clean in the controller, the methods were moved out to the helper file. 6. The exposure of mean and median as the metric_names in grades_controller.rb 1. Since we are explicitly calling the avg_data and med_data methods in the controller, we thought it made sense to name the metric_names nearby, within the controller, rather than hidden off in the helper file. 7. Moved most of the javascript code in _team_charts_rubric_stats.html.erb into app/assets/javascripts/rubric_stats.js. We had to keep our dynamic references of Ruby code in the view. 1. This keeps the view more clean and concise. Also, in the previous semester, one of the reasons the team's pull request was rejected was because they had too much javascript code in their views. <link> <link> <link> <link>.","For design doc: You did quite a good job describing how your tests work; unfortunately you did not do the same for the code.  The ""Decisions"" section does that to some extent, but it would be more useful if it structured in terms of what code files were changed.  Simply listing the files to be changed is not very helpful; it asks the reader to figure out for himself (her) what has been done.","Dear Student,

First and foremost, thank you for the thorough and comprehensive effort you have put into this project.

I am glad to see you are reflecting on your project and are able to identify both areas of success and areas for improvement. This indicates a mature and analytical mindset, which is highly commendable.

Your work on enhancing the charting functionality for instructors to view grade statistics is notably well thought out. Adding interactivity and the ability to compare compatible rubric grades from different assignments, is a praiseworthy enhancement.

The combination of employing both automated and manual testing procedures works to enhance the robustness of your project. I appreciate the attention to detail you've shown in ensuring every feature is correctly initializing and operating as it should.

However, there are a few areas that require attention for future projects. While test-database seeding is a solid strategy for most applications, a more authentic test might have involved coordinating with the course administration to secure real anonymized data or developing a more realistic data model. This could help ensure your program works in the real-world conditions it is designed for.

Your documentation was quite detailed and provided excellent insight into your process and choices. However, I would recommend that you work on clarity and conciseness in the future. Remember, you can structure your write-up for clarity, using subheadings and bullet points to break up large pieces of text and make your content easily navigable.

Finally, I congratulate you on the successful completion of this project. The learning experience you gained from this project is invaluable and will surely be beneficial in your future endeavors.

Best,
[Your Name]"
97,E1785,"This page provides a description of the Expertiza based OSS project. <link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. 1. The following problems need to be handled in this project: Currently, when someone reviews a submission at the next review round (second or third review round), (s)he can't see when that submission was last updated. But a reviewer needs to know when a submission was last updated, because only submissions that are updated need to be re-reviewed.So, reviewers should be told the updated submissions and their latest submission time. 1. 1)app/controllers/student_review_controller.rb 2. 2)app/views/student_review/_responses.html.erb. In order to know whether someone's submission has been updated or not ,we need to acquire the last review time and the latest submission update time.If the submission time is later than the last review time ,it shows that the submission has been updated after previous review so we would show that submission time on the review page to notify reviewers about the update. In our case ,the submission update time includes link or file update time and Github update time. We found expertiza has a submission record which has the time of submitting and removing file or link so we could get link or file update time through submission record. Github update time is actually its latest commit time which can be acquired using OAuth token to access the github repository to get it.There's review timestamp in expertiza database ,every time you update (save or submit) a review, at that moment the time would be stored in database. We use updated_at method to get the latest review update time that is our last review time. 1. 1.get the last review time. (here sorted_reponse[0] is the last review ) <image> <image> 1. 2.Use OAuth token to access the github repositpry and get the latest commit time. <image> 1. 3.Compare Github update time with last review time <image> 1. 4.get link or file update time through submission record and compare the submission update time with last review time. <image> 1. 5.show update information on the reviewer page <image> 1. Screenshots Of The Implemented Features <image>. 1. <link> 2. <link>.","There is a prose description of one of the issues fixed.  It includes code. There's also a screenshot, but it shows only a line related to the Github functionality.  The role of Github could be more clearly explained.","Hello,

I appreciate the amount of effort you have demonstrated in your assignment on Expertiza. You have provided a detailed analysis of the problem and offered a comprehensive solution. Your pursuit of improving the user interface with added functionality certainly deserves commendation.

However, there are several points you should work on to improve the effectiveness of your assignments:

1. Formatting: Your numbering format is a bit disorganized. Remember, it's important to properly sequence your points for easy comprehension.

2. Paragraphs: Your body of work seems cluttered, largely due to the big blocks of text, making it hard to follow. Break your points into different paragraphs. This will enhance readability.

3. Images: It appears that you intended to include images but only placeholders (""<image>"") are visible in the document. Please make sure to properly insert your images to illustrate your points in a more functional manner.

4. Elucidation: Certain sections are quite technical and might be hard to grasp for someone unfamiliar with the topic. Furnish explanations in a more approachable manner by making your language more layman-friendly.

5. Hyperlinks: You left placeholders (""<link>"") instead of actual links in your assignment. It'd serve you well to proofread your work before submission to avoid such issues.

Work on the above points and you'll certainly present an excellent assignment. I'm looking forward to your revisions. Keep it up!
"
98,E1658,"Expertiza is an educational web application created and maintained by the joint efforts of the students and the faculty at NCSU. It’s an open source project developed on Ruby on Rails platform and it’s code is available on Github. It allows students to review each other’s work and improve their work upon this feedback. The following is an Expertiza based OSS project which deals primarily with the lottery_controller.rb file. It focusses on refactoring some of the more complex methods, modifying some of the language to make it more Ruby friendly, removing some redundant code. The goal of this project is to attempt to make this part of the application easier to read and maintain. The lottery_controller contains all of the logic for running the lottery. Code climate is used in this project to detect various issues such as high cyclomatic complexity, bad naming, etc. Fix following issues mentioned below: 1. Cyclomatic complexity for run_intelligent_bid is too high. 2. Perceived complexity for run_intelligent_bid is too high. 3. Use snake_case for variable names. 4. Avoid more than 3 levels of block nesting. The code was refactored and its Code Climate rating improved from F to A. Before Refractoring: <image> After Refractoring: <image> 1. Cyclomatic complexity for run_intelligent_bid and other methods is greatly reduced. 2. Perceived complexity for run_intelligent_bid is also reduced. 3. snake_case are used for variable names. 4. More than 3 levels of block nesting is avoided. Before: <code> After: <code> Assignment using if condition was changed to conditional operator Before: <code> After: <code> Changed to find_by from find_by_id Before: <code> After: <code> Changed to the latest ruby convention for HashMaps Before: <code> After: <code> Removed unused variables Before: <code> After: <code> Changed find_by_id to find_by Before: <code> After: <code> Used snake case naming convention. Removed and condition inside if and converted it to nested if condition check. Replaced inject with each_with_obj. Before: <code> After: <code> Split the function into smaller pieces to keep up with coding conventions. Initially, the lottery controller had only one test case: for the action run_intelligent_bid. We added one more test case for run_intelligent_bid and also added test cases for all the other actions in the controller. 1. For the action run_intelligent_assignmnent, we have two test cases: 1. webservice call should be successful This is to check if the web service is getting called. But the URL given in the code is currently is of a web service that is currently down. Hence for testing purposes we have used a dummy URL. This can be replaced with the correct URL to the web service when it becomes available in the future. 1. should return json response This test case checks if the response from the web service is in JSON format or not. 2. For the action run_intelligent_bid, we have the following test cases: 1. should do intelligent assignment This was an already existing test case. It tests whether the assignment received is intelligent or not. 1. should exit gracefully when assignment not intelligent This checks if the control redirects to main page in case the assignment received is not intelligent. 3. For the action create_new_teams_for_bidding_response, we have the following test cases: 1. should create team and return teamid This test checks if the method is creating the team for bidding by taking in the assignment as parameter. 4. For the action auto_merge_teams, we have written the following test cases: 1. sorts the unassigned teams This test case checks whether the method is able to sort teams which have not been assigned to any assignments yet. As a result of our work, the code quality of the controller lottery_controller.rb has improved a lot. Code Climate has given it the highest possible rating. The original code had a code climate rating of F. We worked on all the issues pointed out by code climate and and improved the rating to A. Initially, there was only one test case and only one of the methods in the controller was covered. We have also added RSpec test cases for all the methods in the the controller and hence the test coverage has increased. This was a very good learning experience. We learnt how to write test cases in RSpec and got a chance to contribute to Open Source Software. Another major take away from the project was the chance that we got to read and understand code written by other people. This is very important skill to have when you work in the industry and can be sometimes more difficult than writing code from scratch.","The writeup is locally very good; it describes every change and gives the reason for it; ditto for tests.  What I'd like to see is a narrative overview of what was done, rather than just a bulleted list.","Great job on this assignment! Overall, your work on refactoring and improving the code quality is commendable. You demonstrated a thorough understanding of Ruby and coding conventions in practice. Your efforts to reduce both cyclomatic complexity and perceived complexity of methods reveal that you not only wrote the code, but also understood its mechanics and its implication on readability and maintainability. Addressing these complex elements definitely makes the software more efficient.

Your initiative to transition to more modern Ruby conventions, remove unused variables, and use more efficient methods like 'find_by' instead of 'find_by_id', as well as converting to snake case naming convention, helps create cleaner, more readable code.

The extensive explanations you've provided showing your thought process in refactoring the code is excellent. I also appreciate the detailed list of changes and test cases that you've included. It's important to ensure that your new code is still properly performing the tasks that it was intended for, and testing different scenarios can help accomplish this.

The addition of new test cases is a nice touch and brings completeness to the project scope. It seems like you really ensured your changes did not just improve readability, but also preserved the functional integrity of the code.

One minor point of critique is to incorporate some comments in the code to make it more comprehensible, especially if someone else is going to be working on it in the future. Additionally, it would have been nice to include evaluation of the performance of both versions of the code to quantify the improvement.

You have done an outstanding job with the assignment. Your insights, diligence, and understanding of best practices in coding ensure that you have not only improved the quality of code, but also contributed to the Open Source community. Keep up the good work!"
99,E1728,"This wiki provides details on the refactoring tasks that were undertaken as part of the continuous improvement to the Expertiza project. <link> is a web application where students can submit and peer-review learning objects (articles, code, web sites, etc). The Expertiza project is supported by the National Science Foundation. The application provides a complete system through which students and instructors collaborate on the learning objects as well as submit, review and grade assignments for the courses. By participating in the overall refactoring effort as part of the continuous improvement of Expertiza, students get an opportunity to work on a open source software project. This helps them gain exposure on the technologies used in the project as well as much needed experience in collaborating with peers as part of the software development process. The tasks involved as part of this refactoring effort were geared towards cleaning up the grade view logic. The initial set of tasks were: 1. For files: _scores_author_feedback.html.erb, _scores_metareview.html.erb, _scores_submitted_work.html.erb 1. Move javascript code to assets 1. For files: _scores_header.html.erb 1. Move logical code (such as L43-96) to helper file and assign self-explanatory method name 1. For files: _participant.html.erb, view_team.html.erb 1. Move javascript code to assets 2. Move logical code to helper file and assign self-explanatory method name 3. Such as L8-22 in _participant.html.erb 1. Create test file named grades_helper_spec.rb in spec/helpers 2. Write test cases for all methods in grades_helper.rb. On working with files _scores_author_feedback.html.erb, _scores_metareview.html.erb, _scores_submitted_work.html.erb, _scores_header.html.erb, the team came to find out that these files were not being used anymore in the application and the overall tasks were updated to the following: 1. Remove useless partials from grades view, such as _scores_author_feedback.html.erb, _scores_metareview.html.erb, _scores_submitted_work.html.erb, _scores_header.html.erb, etc. 2. For files _participant.html.erb, view_team.html.erb to grades_helper.rb 1. Move javascript code to assets 2. Move logical code to helper file and assign self-explanatory method name such as L8-22 in _participant.html.erb 1. Create test file named grades_helper_spec.rb in spec/helpers 2. Write test cases for all methods in grades_helper.rb by using factories. The named files were removed from the project and the deletions were committed to the repository. A new test file was created and added to the project: spec/helpers/grades_helper_spec.rb. Prior to this project, none of the existing methods in grades_helper.rb were tested using unit tests. The following unit tests were written and used to exercise the methods. An examination of the specific test cases is given below in the Test Plan section. The final two methods in this file are functional tests used to ensure all discrete functions perform normally when combined together. <code>. The main goal of testing was to ensure functionality was maintained after refactoring was completed. The following test cases exercise the functionality of the code sections which were refactored. Automated versions of these tests were written using RSpec/FactoryGirl/Selenium and appear in on the Github repository associated with this project. The functional tests may also be run manually per the descriptions below. <table>. Unit tests were required per the project assignment for helper methods which previously had no associated unit tests. These tests verified that each discrete method returned the proper values. The tests were written using RSpec/FactoryGirl and are listed in the code above. A summary of the test cases is given below. <table>.","This description will be hard to read, because long sequences of code are included without any narration, and without showing what was changed.  It would be better to use Github's diff feature to show deleted code with a red background and added code in green.  Or, if this would be too verbose, at least the difference between new and old should be described.  Test plan looks good.","Dear student, 

It's clear that you have invested substantial effort into this assignment, which is a detailed documentation of your work on the Expertiza project. Your participations in refactoring the Expertiza project are very significant and, indeed, will be beneficial for your development as a software engineer.

However, there are several points that could be improved in your assignment:

1. **Numbering and Outline**: It seems there's an inconsistency in your numbering of tasks and subtasks. You might want to recheck and correct these to improve readability and comprehension for readers.

2. **Task Specification**: While you have detailed some files and indicated certain lines of code (L43-96, L8-22, etc.) for your tasks, elaborating on what exactly should be done or what logic/code was moved would improve understanding.

3. **Clarity on Code Deletion**: You have discussed the removal of some files but do clarify if these files were completely unnecessary or if their functions were incorporated elsewhere.

4. **Code Explanation**: Despite including some code in your assignment, you didn't provide adequate explanations for it, making it difficult for anyone who reads your assignment to fully understand your work. Be sure to include clear and concise context and explanation for the code.

5. **Test Plan Section**: You referred to a Test Plan section and a table summary of test cases, but these were not included in the assignment. Please either include these sections or delete the references to them. 

6. **Conclusion**: It would be beneficial to summarize your work at the end of the assignment, illustrating what was achieved, and any problems encountered, along with how it impacted the overall project.

Remember, the clarity and effective communication of your thoughts in your writing are just as important as the coding work you put into the project.

Looking forward to seeing the revised version. 

Best, 

[Your Name]"
100,E1782,"In Expertiza, students may submit links (which go into the Expertiza db) or files (which go into a directory in the Expertiza filespace). A persistent problem in Expertiza has been that instructors have created multiple assignments that had the same submission directory. In this case, the students’ submissions for one assignment went into the same directory as the submissions for another assignment, and reviewers who thought they were reviewing for one assignment were also presented with work submitted by a different student on another assignment. The basic problem has been fixed, but there are some special cases that need to be addressed, and tests need to be written. Issue #391: When an assignment is created, there needs to be a check that the submission directory is not the same as the submission directory for any other assignment. In Expertiza, the pathname for an assignment always has the instructor’s user-id (e.g., /efg) in the path, so it’s only necessary to check all assignments created by the current instructor to make sure that the specified directory path is not in use by another assignment. Make sure that the check is made correctly even if it is a TA who creates the assignment. There is a method for setting path of the submission in assignment.rb. Issue #404: When a previously created assignment is assigned to a course, any existing submissions need to be moved to a subdirectory of the course in the Expertiza filespace. (In Expertiza, an assignment can be created without being assigned to any course, and can later be assigned to a course.) Even the assigning the assignment to a course is implemented in assignment.rb. 1) assignment_controller.rb 2) assignment.rb 3) assignment/new.html.erb. -> When an instructor tries to create a new assignment with the storage directory similar to one of the other assignments or a sub-part of other pre-existing assignment the system would warn the instructor about this change and wouldn't save the assignment. -> The system once gets a create request compares the directory path to paths of all existing directories for similarity and sub-part check (sub part check is required because if not done a directory will have submission files of one assignment as well as a directory for some other assignment) and logs an error if similarity is found. -> If there errors they will be displayed in /assignment/new.html.erb Pseudo Code: <code>. When an instructor creates a new assignment, (s)he can do it without specifying the course to which assignment belongs. In this case, the directory path for the course is assigned as ""<instructor_username>/path/mentioned/while/creating/"" Eg. ""instructor6/assignment4/Java/"" However when later s(he) assigns a course to the assignment, the assignment directory path should change to ""<course_path>/>/path/mentioned/while/creating/"" Eg. ""CSC517/f17/assignment4/ruby"" Psuedo Code: Added the following logic in assignments_controller.rb update method <code>. Link to ScreenCast Bug #391 : <link> Link to ScreenCast Bug #404 : <link>. Steps to test Issue #391: 1) Login as Instructor 2) Click on Manage , select assignments. 3) New public assignment/ New private assignment 4) Fill in the details and remember the directory path 5) Save 6) Create New assignment 7) Fill in the details and keep the directory path same as the one before. 8) You will see an error displayed on top of the page. Steps to Test Issue #404: 1) Login as Instructor 2) Click on Manage , select assignments. 3) Find out an assignment which isn't assigned to a course. 4) Select assign to course badge 5) Select course from available radio button 6) Click Save 7) Now you will the updated path on assignment display list and instead of assign to course remove from course badge will be visible. Following RSPEC Code is added to assignment_spec.rb: 1) To check if the directory storage path specified by the user is a part of any other submissions directory we check if the assignment.directory_path is a part of any existing directory path: <code> 2) To check that an assignment object cannot be saved until a submission directory path is provided for that assignment: <code> 3) To check if after assigning course to an assignment is the directory path updated to contain the course path: <code> 1. 1.1. To test the changes clone the following repository <link> .","For Issue 391, a short explanation has been given along with pseudo-code.  Would be helpful to see how that relates to the actual code.  For Issue 404, no prose description has been given of the fix.","Hi,

You've done an excellent job describing the issues and solutions in detail. Here is my feedback based on your work:

1. **Understanding of the Problem**: Excellent. You've clearly defined the issues with submissions directories in the Expertiza system. The problem statement was articulated very well, which made the context easier to understand. 

2. **Solution Design**: Good. You've included the methods to fix the issues and the locations of these methods in assignment.rb and assignment_controller.rb, which is beneficial. However, it would be better to elaborate on these methods and explain how exactly they would be used to solve this problem.

3. **Pseudo Code**: It's commendable that you provided pseudo code for your solution. However, the pseudo code is not complete and not properly formatted making it hard to follow. 

4. **Testing: Strong**: The inclusion of steps for testing both issues is great, this adds validity to your solutions. Though, there could have been more explicit steps in certain areas. It's also a good practice to consider and document potential edge cases.

5. **Rspec Code**: Great. Addition of test cases to assignment_spec.rb shows your understanding of TDD. But, the actual code is missing in your assignment and should be included.

6. **Clarity and Organization**: Good. The paper is well organized with defined sections making it easy to follow. 

Going forward, ensure you elaborate on your solution design by stating why a particular approach was chosen, possible complementary or alternative methods, and any potential limitations of your approach. Also, make sure to complete the pseudo code and provide actual Rspec code next time.

Keep up the good work!
"
101,E2066,"The lottery controller assigns teams to topics based on the priorities the team gave to each signup topic during the bidding process. When the lottery controller is called to run its method run_intelligent_assignment, a web service is sent the bidding data from each team and returns a new list of teams, each of which is close to the maximum team size specified for the assignment. The web service coalesces teams that have similar bid data and then assigns those coalesced teams to topics, giving each team their top bid on a topic that hasn't been assigned yet. Teams with larger team sizes and more bids are assigned their topics first. This class contains logic to merge bids. It also contains code that creates teams, add and removes users from team. These methods are more suited to being model methods. The As much as possible, the controller should only contain standard crud actions. 1. Fix bug which created multiple bids with same topic, team and priority. 2. Call existing AssignmentTeam.rb method to create team and team node, instead of creating them separately. (DRY principle) 3. Call existing Team.rb method to add members in team. 4. Remove code that explicitly deletes dependents before deleting object and rely on dependent destroy instead. 5. Move logic to delete empty teams belonging to an assignment into assignment.rb. 6. Move logic for creation of team with members to Team.rb. 7. Move logic that merges bids of different users to Bid.rb. The parent objects being discussed here have association callbacks dependent destroy to correctly dispose dependents when it itself gets destroyed. We don't need to explicitly delete child objects before parent is deleted. <code> The function remove_user_from_previous_team explicitly deletes team_user_node before team_user is deleted. TeamUser contains code has_one :team_user_node, foreign_key: 'node_object_id', dependent: :destroy to destroy related node when team user is destroyed. <code>. <code> Team contains code has_one :team_node, foreign_key: :node_object_id, dependent: :destroy to destroy related node when team is destroyed. <code>. Controller should not contain code to generate new bids by calculate priorities of topics using previous individual bids of users. This kind of complex logic is suited to being a model method in Bid class. Create a class method merge_bids_from_different_users which accepts team id, signup topics and bids of users, and contains logic to create bids and get priorities for new bids. <link>. Expertiza already had well written test cases for lottery controller. While moving methods to model some of these test cases were moved as well. After refactoring the controller, it was tested manually and using previously written RSpec tests to ensure that no bugs were introduced. Note: Although there is a drop of 0.004% in coverage all the code that belongs to lottery_controller and which was moved to models has 100% test coverage. Overall coverage might have reduced because total lines have reduced. Test which belong to code that has been refactored have been refactored, most of the other test relating to lottery controller remain unchanged. The following commands can be run to test lottery controller and other functions that relate to E2066. <code>. <link> By following the steps below, you will be able to manually test Expertiza with E2066 fixes. 1. Login as instructor. (Username: instructor6, Password: password) 2. From the menu bar, hover on Manage and select Assignments . 3. Scroll till you reach assignment named lottery . <image> 4. Click on the orange Intelligent Assignment button. Note: 1. If there are no non signed up teams that have bids for topics, then a 500 Internal Server Error is displayed. 2. When intelligent assignment finishes it disables bidding on topics, bidding on topics needs to be enabled to run intelligent assignment. Steps to create an assignment with topics: 1. Create a new assignment with Has teams? selected. 2. Go back, and then edit assignment by clicking on the pencil icon. 3. Select Has topics? 4. Go to Topics tab and add a few of them. 5. Enable bidding for topics. 6. Go to Other stuff tab, select Add Participants and then Copy participants from course . Steps to signup students for topics: 1. Impersonate a participant. 2. Select assignment with topics. (for example lottery assignment) 3. Open Signup sheet . 4. Drag and drop topics under selection section. 1. app/controllers/lottery_controller.rb 2. app/models/assignment.rb 3. app/models/bid.rb 4. app/models/team.rb 5. spec/controllers/lottery_controller_spec.rb 6. spec/models/assignment_spec.rb 7. spec/models/assignment_team_spec.rb 8. spec/models/bid_spec.rb. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.","Very good description of changes.  Where you titled subparts ""Example 1"" and ""Example 2"", you could have used more descriptive names.  Code sequences are shown in an easy-to-understand format, with irrelevant details elided.","Dear student,

You've done a good job at identifying the issues in the current lottery controller process and providing a meticulous solution for every bug identified. Your focus on the DRY principle and moving most of the heavy logic from the controller to model methods aligns with best practices in Rails, and your efficient refactoring efforts are commendable. 

Your thorough testing strategy is appreciated, and your explicit explanation on the drop in coverage is thoughtful. Your problem-solving ability and debugging skills are clearly evident from this assignment.

The detailed steps on how to manually test the changes are a great addition and will be very useful. However, it would be beneficial to supplement these manual tests with additional automated test cases to ensure reliability and reduce time spent on testing. It's crucial to have robust automated tests complete with edge cases as they can quickly find issues in the future with minimal effort.

Furthermore, your assignment lacks sufficient evidence of your actual changes, e.g., screenshot demonstrations, spec outputs, etc. It would be beneficial to include these in your submitted work. Adding visuals demonstrating the process and results of your fixes can make your explanation clearer and more understandable.

Lastly, be cautious with the placeholders <link>, <code>, and <image>. It's important to replace them with accurate paths, code blocks, links, and diagrams.

Keep up the excellent work! I look forward to reviewing your revisions."
102,E2111,"Github repository and pull request links are submitted as part of programming projects in several NC State CSC courses. Instructors would like to compile statistics on these Github links on a per-project, per-team basis, and integrate display of these data within Expertiza (similar to Github Insights). Code was introduced to add this functionality in a <link> which was not merged, and another team re-visited <link> , which was also not merged. The project team will troubleshoot existing code to eliminate issues that prevented these projects from being merged. Additionally, the team will add new features based on design patterns and MVC principles, including a Metrics model, that will decouple the Github Metrics functionality from other areas of the application and allow for future extensibility. Finally, the team will investigate DRYing the code using existing graphing functionality, and complete an analysis of the automated testing for existing and new code. The team has synced the revised 2019 project code with the current status of the Expertiza/beta branch and begun analyzing the existing code. Prior customer feedback has advised the team to address inextensibility/coupling issues, documentation issues, and synchronization issues. We are performing our own end-to-end analysis of the code in addition to this feedback, and have so far found numerous action items. We have separated these action items into Primary and Secondary objectives: Primary objectives are ""must-haves"" that need to be addressed before the existing code is mergeable. Secondary objectives are ""nice-to-haves,"" or features that were either left out of the original project or would make the integration display more complete. In order to achieve the Primary Objectives while making the application more extensible, the team proposes using a more strict implementation of the Adapter design pattern to decouple the details of the Github API from the proposed Metrics model. Elements of the Observer design pattern will also come into play to ensure that once Github data is queried and stored, and an assignment has come to a close, the Metric for that Assignment is unsubscribed from the Github API. This will further decouple the dependency on API data while retaining the data for future statistical analysis and/or research studies. The 2018 project wrote numerous tests, several of which are deeply coupled into the grades_controller tests. The team proposes several changes to the testing strategy. Builds never passed for this project because, in the current code, a user must be logged in and authorized to Github to render grades#view, and this broke several (expected) test cases. As part of decoupling Github from the grades controller, we expect to decouple and revert tests for the grades controller such that the tests become independent, permitting the build to pass if our Github controller tests pass as expected. The previous team wrote numerous intricate tests for the new functionality. Our team intends to go through these tests line-by-line and ensure that having so many tests is necessary, and the most elegant way to address the issue. We believe that some of the Github refactoring should move methods to become private, which may mean that specific tests for that method shouldn't be used. Alternately, particularly for API authentication which can be tricky, it may be prudent to have discrete tests. Finally, we want to ensure that the tests are actually covering the code -- we are receiving a TravisCI warning about tests without expectations, which needs to be resolved before the code can be merged. Tests were heavily inspected and slimmed down from 30 controller tests to 20 at final submission. These controller tests cover the new and existing methods within the metrics_controller. There is some difficulty with reliably testing the actual production functionality, because the functionality is totally dependent on the Github API, and therefore, a valid Omniauth token. We tested as much functionality as possible using Factories and mocks, and although the tests are not as elegant as we'd prefer (if we could more easily run tests incorporating the API), we believe we have covered the individual methods within the metrics controller. Tests for this controller are available at: /spec/controllers/metrics_controller_spec.rb. The new model being created, along with associated database tables, will lead to new tests being required for this model. These tests will need to be written first in keeping with TDD principles. Also, some tests may need revision when code is moved from the Github Metrics controller into the new MVC architecture. These tests will include, but not be limited to, testing cases when Github Pull requests exist, and do not exist (for Expertiza and non-Expertiza projects), validation of all data types being stored in the Model / new database tables, appropriate coverage of new and existing graphing helpers, cases when multiple repos and/or pull requests are included in the assignment links, and edge cases when Repos or pull requests were submitted but access rights have not been granted. New tests have been written for the methods within the new Metric model. Tests are available at: /spec/models/metric_spec.rb. This is how a user will view List Submissions when they are not yet authenticated to Github. The Login link redirects to an omniauth login screen, which redirects back to this page. <image>. This view is where an Instructor can login to Github via omniauth, and trigger queries to the Github API for the assignment submissions. The ""Github metrics"" link is only displayed when Github metrics are available for a submission. <image>. The updated chart view, which can be found via the ""Github Metrics"" link in the List Submissions view, displays all of the latest metrics from Github as of the page load. The team added a GoogleCharts Piechart totaling each team members contribution to the project. <image>. Here in the student profile, we ask students to set their Github.com email address. <image>. We show the UML for the new classes and model we created and implemented in our final project for a overview. Other than these, we also modified some of the existing classes and method, we will give detailed introduction later. <image>. The Github API requires users to be authenticated to query the API. Authentication is handled using Omniauth and the omniauth-github gem. Omniauth uses a multi-step authentication process, where a client is redirected to the service provider(Github), and the request is routed based on a Client Key and a Client Secret (set in /config/github_auth.yml). A user logs in and authorizes the oauth app for their Github account, then Github redirects the client back to Expertiza with an authentication token piggybacked. The token is then used for communication between the Expertiza server and Github. An extremely important note: The callback URL (the URL of the Expertiza server) is set within Github.com, where the oauth app is configured (and Client Keys/Secrets are generated). Our code in the Expertiza E2111 repository uses Client Key/Secret pairs that are tied to a Github oauth app that is configured to callback to <link> . Naturally, when Expertiza is running in a production environment, or a deployment on a remote server where the client is not on the localhost, this callback will fail to redirect. Therefore, for a deployment environment, you must create a new oauth app using your Github.com account (or your organization's) that configures the callback URL to <link> . For example, a production callback URL could be: <link> . The reason ""github2021"" is used for new oauth apps is due to Github's 2021 updates to their security infrastructure -- our code handles ""github"" and ""github2021"" callbacks differently to match these security updates. Legacy oauth apps (like the one used in the Repository code that routes to localhost) are still permitted to use the old omniauth. Then, you will use the Client Key and Client Secret you have obtained from Github to update /config/github_auth.yml; these keys will be passed to Github.com and ensure the correct oauth app on Github.com is handling your request, and the associated callback route. For more information on setting up a Github.com oauth app and key pairs, please see: <link>. We have a helper model called MetricsHelper, which contain helper methods for graphing: This method take parsed Github metrics data, authors in a PR, and dates of all commits as parameter. It Creates the bar graph for the Github metrics data. Links the authors with their Github data and assigns them a color. Currently supports up to 6 different colors and will loop if it goes over. This method take parsed Github metrics data, authors in a PR, and dates of all commits as parameter. It Creates the pie chart for the Github metrics data. Links the authors with their Github data and assigns them a color. It is easy for an instructor to tell the ratio of contribution of each team member with a pie chart. This method does not take any parameters. It defines the general settings of the Github metrics chart. This method does not take any parameters. It defines the labels and display of the data on the Github metrics chart. This is a new model that saves user's Github email as the identifier of their Github account. With this information, we can connect Github metrics with each students. It also saves the team_id, the participant_id, and the cumulative total commits in the submitted PR for each user. We make this model in a way that it is easy for future team to extend. This method takes a submitted Github pull request URL and a cursor for pagination in Github GraphQL API as parameter. It Formulate and return the actual query message to send over HTTP request to do the GraphQL query for a Github pull request. For more detailed information, check Github GraphQL API. This method takes a submitted Github repository URL, the date of the project starting date, and a cursor for pagination in Github GraphQL API as parameter. It Formulate and return the actual query message to send over HTTP request to do the GraphQL query for a Github repository. For more detailed information, check Github GraphQL API. The Metrics controller contains all the logics for querying Github metrics and present these metrics with the default show method. This method does not take any parameters, it checks whether the current user has the required privilege to run certain method. This method does not take any parameters, it runs a query against all the link submissions for an entire assignment, populating the DB fields that are used by the view_team in grades heatgrid showing user contributions. The default show method, which renders the html page that shows all Github metrics with a bar chart and a pie chart. This method redirect the user to Github authorization endpoint to authorize the current user. An authorized user can use the Github API with 5000 rate limits per hour. Unauthorized user only has 60 rate limits per hour, which may not be enough. This method takes the participant id as parameter. It calls several helper methods to query Github metrics information from links that this team submitted and populate all related instance variable, which will be used in frontend presentation. This method call corresponding method to retrieve Github pull request metrics information or repository information base on different conditions. This method take all PR URLs that a team submitted and retrieve all Github metrics. This method takes all hyperlink_data includes pull request number, repository name, owner name of a single PR url as parameter and retrieve all Github metrics for a single PR. This method takes the Github metrics of a PR returned by the query as parameter, parse and store them into corresponding instance variable. This method saves each PR's statuses in a hash. This is done through Github REST API not GraphQL. This method take all repo URLs that a team submitted and retrieve all Github metrics. This method takes the Github metrics of a repo returned by the query as parameter, parse and store them into corresponding instance variable. This method does the accounting for each author in this PR. It calculates how many commits an author has on each date. This method sort the ruby array that saves the commit information base on date. This method takes the query message as parameter and makes the actual Github api HTTP request with GraphQL and query message. This method takes the global GraphQL id of a PR object as parameter and make the actual Github api HTTP request to query the PR's status info. In addition to the changes mentioned above, we also added one authentication method, called custom_github_login in auth_controller.rb, which catches the returned 3-way handshake from the Github API when a new Github App is configured and authorized. This is required due to changes in the Github API for 2021. We updated the view for synchronous charts in /app/views/metrics/show.html.rb to include the new GoogleCharts piechart. To support the heatgrid in view_team in grades, a method was added to the Grades helper. This method creates the code used to populate, and set the coloring of, the heatgrid metrics table. Not only does this code look up metrics, it also takes care of determining the min, max, and mean number of contributions to the project, and assigns colors to each contributor based on how valuable their contribution to the project was. This file is used to set environment variables for the lookup of whether a Github contributor is also a ""Collaborator."" Collaborators are members of the Expertiza organization, and their contributions should not be credited to student teams. While these collaborators can be queried using the API, this functionality requires push permissions on the Repository. Unfortunately, because the team doesn't have push permissions to the Expertiza repo, we were not able to test and include this functionality in the final submission. 1. Database migrations for new models 2. Omniauth configuration YML file with the Github API keys 3. ajax-loader.png: A simple animated GIF which is rendered using Javascript while the code is querying the Github API for a full assignment (Slow query). A bug was found where view_team, as an instructor, displays ""Reviews"" in the HeatGrid with the table heading, ""Review"" instead of the student name. This bug was introduced by recent changes implemented in the ""Time Travel Not Allowed"" Expertiza project, where TAs are treated with different access permissions. In the code that was merged from this project, the heatgrid table headers are handled in the same manner for both Instructors and TAs/Students. We added several lines of code in the new Partial that was introduced by this team, to render the student names in the table headers when the user is an Instructor. These changes may be found in: /app/views/grades/view_team.html.erb /app/views/grades/_add_icon_to_name.html.erb. <link> <link> <link> <link> <link> <link> Previous Project References <link> <link>.","This design doc begins beautifully, describing the background, the reasons for the changes, and the implementation strategy.  It would be much better if it showed the changes to the various classes and methods and described why they were made.  Also, there should be more information on the tests, such as a list describing each test. ","Your submission is detailed and comprehensive, demonstrating robust understanding of the project's requirements. The technical depth of your work is commendable, particularly the efforts made to decrypt the existing codebase and identify areas for improvement.

Here's some specific feedback on the various points:

1. It's great that you identified the challenges within the existing code and separated them into primary and secondary objectives. This categorization will lead to a more effective workflow.

2. Your use of design patterns such as the Adapter and Observer illustrate your clear understanding of software engineering principles. Your explanations are concise and clearly articulated.

3. Your detailed analysis of the existing tests was thoughtful. Identifying tests that could be made private or discrete is a good strategy for improving code coverage and efficiency.

4. Your explanation on how you addressed authentication issues and implemented secure communication with the GitHub API using Omniauth is quite thorough.

5. The modifications you've launched offers a potential for extension to other teams, which shows a forward-thinking approach.

6. I appreciate the clear and detailed documentation provided for each method. It will contribute to better code maintenance and understanding amongst different users or revisiting teams.

7. Your efforts in testing the new functionalities you've developed are commendable. 

However, there are a few improvements to be considered:

- The report might be too thorough which could cause difficulties for the reader to understand. Make sure to keep your documentation precise and to the point to avoid confusion.
  
- Remember to double-check and proofread your work. I noticed several minor errors in terms of spelling and grammar that could potentially hinder understanding.

- It would have been great to see screenshots or diagrams in applicable areas.

In general, this was a job well done with a comprehensive analysis and implementation of the project's requirements. Keep up the good work!"
103,E17A1.2,"<link> is an open source project based on <link> framework. The Expertiza project is software to create reusable learning objects through peer review. It is a web application where students can submit and peer-review learning objects (articles, code, web sites, etc). It is used in select courses at NC State and by professors at several other colleges and universities. It also supports team projects, and the submission of almost any document type, including URLs and wiki pages. Expertiza enables the instructor to create new and customize existing assignments. It also enables the instructor to create a list of topics the students can sign up for as part of a project. Students can form teams in Expertiza to work on various projects and assignments. Expertiza supports submission across various document types, including the URLs and wiki pages. 1. Currently, the functionality of calibration is limited. It does not support varying-rubric-by-round feature. 2. For student side, there is no way to notify for an author to tell that a particular review that they received was submitted by an expert. 3. Students are not able to see how an expert has rated the assignment, they can only see calibration results for calibrated assignments by clicking on the “Show calibration results” link. 1. Change in DB Schema 1.1. “is_calibrated” field in assignment table to “has_expert_review” 1.2. “calibrate_to” field in response_map table to “expert_review_to” 2. User interface changes 1.1. Original interface <image> <image> <image> 1. 1.1. Instructor side 1.1.1. In assignment setting page (“General” tab), change the checkbox title from “Calibrated peer-review for training?” to “Add expert peer review?” 1.1.2. When instructor clicks that checkbox, there will be a new tab named “Calibration”. Change the tab name from “Calibration” to “Expert review” on the assignment setting page <image> 1.2. Student side 1.1.1. Change the link title from “show calibration results” to “show expert peer-review results” <image> 1.1.2. Change the title in “response/show_calibration_results_for_student.html.erb” to start with “Expert review comparison report for” <image> 2. New features 1.1. Let expert review support the vary-rubric-by-round functionality 1.2. Support multiple expert reviews (Both TAs and instructors could do expert reviews) 3. Tests 1.1. Create expert_review_spec.rb file in spec/features folder 4. Additional minor changes 1.1. Reflect changes in DB schema at all places, including tests. 1.2. Change the partial file name from “_calibration.html.erb” to “_expert_review.html.erb” 1.3. Rename “response/show_calibration_results_for_student.html.erb” to “response/show_expert_review_results_for_student.html.erb” and also change other call sites 1.4. Change in database The following schema changes will be implemented using a new migration file: 1. “is_calibrated” field in assignment table to “has_expert_review” 2. “calibrate_to” field in response_map table to “expert_review_to” Change in User interface The following files will be edited to reflect the changes in user interface as mentioned in tasks: 1. #assignments/edit/_calibration.html.erb 2. #response/show_calibration_results_for_student.html.erb 3. #student_review/_responses.html.erb 4. #student_review/list.html.erb 5. #assignments/edit.html.erb. <image> 1. Instructor and TAs are the ""Experts"" that can review the assignment. 2. Multiple experts should be able to review the same assignment. 3. When a student views the review, student should understand whether the review was made by an expert or a student. 1. app/controllers/response_controller.rb: 1.1. Method: show_calibration_results_for_student 1.2. Fetching all expert reviews performed for the respective assignment and respective team instead of fetching only instructor's response. 2. app/assignments/edit/_expert_review.html.erb 1.1. Showing multiple rounds of View/Begin review as per the current round and number of reviews already done by the expert (as it happens for students). 3. app/views/response/show_expert_review_results_for_student.erb 1.1. Showing calibrated response to students who have reviewed the assignment with responses of multiple experts for a particular round. 4. app/views/student_review/_responses.html.erb 1.1. Showing links for calibrated result for each round. 1. Existing tests should be changed according to changes in database schema and user interface. 2. A new test file expert_review_spec.rb will be created to unit test the changes with the following steps: 3. Log in using instructor's or teaching assistant's credentials. 4. General tab should have the checkbox titled 'Add expert peer review?' 5. Click on the checkbox. 6. There should be a tab ""Expert review"" on the assignment setting page. 7. Log out and log in back using student's credentials. 8. There should be a link titled 'show expert peer-review results' 9. Test multiple expert reviews by submitting multiple reviews when logged in as an instructor or TA for the same assignment. 10. Also test the vary-rubric-by-round functionality. New tests will be written to test the new features added, like : 1. assignment should support multiple expert review. 2. current assignment should support vary-rubric-by-round. 1. Pull request - <link> 2.Video Link - <link>.","This document is rather short, but so are the requirements for this project.  As several reviewers note, the test plan is weak. The screenshots are too big and can't be seen without zooming out, but the same could be said of almost all other design docs.","As an instructor, I think you did a great job with this comprehensive assignment, but there are areas of improvement.

Clear and concise communication is the key to success in any field. Your text seems rather lengthy, which makes it a little difficult to follow. Breaking long sentences and paragraphs into shorter, simpler ones would greatly enhance communication.

Your work on Expertiza shows diligence and attention to detail. However, you can make your submission more user-friendly by clearly separating sections, using headings and subheadings effectively, and stating your points more succinctly. This would not just make it easier for a reader to understand the changes you propose and describe, but also give your assignment a more structured look.

Also, some parts of text contain numbered lists where each number is followed by '1.' instead of counting up (1, 2, 3, etc.). This makes it confusing to follow the steps and understand the order in which they should be executed. Plus, numbers are followed by subpoints with numbering like '1.1.', which are usually used to indicate a subsection of a point, but that's not the case here. It's essential to double-check such numbering before submission.

Moreover, while I appreciate the time you took to include such detailed technical descriptions, it could distract from the points that you are attempting to make. It would be beneficial to place the images into an appendix and refer to them in the text by figure numbers. This, coupled with concise descriptions, should make for a clearer and more polished assignment submission.

Lastly, when including hyperlinks, please make sure to write representative descriptions instead of just writing '<link>'. 

Keep working hard, and keep refining those writing skills for better communication. Looking forward to the updated version of your project proposal."
104,E1996,"When the staff grade reviews, we look at them in the review-grader interface. The staff assign the score and provide feedback using the textboxes in the right column. The user are also allowed to read the reviews in the summary view. Some sections on these two page don't show correctly and some sections are not good-looking enough. The space can be rearranged to use the space more effectively. Implementing these enhancements to review grader will greatly improve the user experience of expertiza. <image> 1. The ""Score awarded/average score"" column is supposed to report the score by the current student reviewer in the first round, the average score by all reviewers in the first round, and scores for the second round. If the number of rounds ≠ 2, then the number of scores should be adjusted appropriately. Fix this problem so that it is populated with the correct numbers. 2. The scores in the ""Team Reviewed"" column would also be displayed with bar graphs, like in the ""Metrics"" column. It should be modified without making the column much wider, since this page needs to display a lot of information horizontally. 3. Column width should be adjusted intelligently. In the view shown, ""Reviewer"", ""Reviews done"", and ""Team reviewed"" are too wide, whereas ""Assign grade and write comments"" is too narrow. 4. Number the rows of the table (e.g., ""2. Student 8370"") so it is easy to count the lines. This will help us assign each TA (and the instructor) an equal number of reviews to grade. 5. Replace the team names with an anonymized version of them. This will help the grader not be biased if (s)he recognizes the team name as belonging to specific students. 1. The score which user can see on the website is ""-----"", which is in the get_each_round_score_awarded_for_review_report function in the review_mapping helper file. The problem is that the review_scores[reviewer_ID] doesn't exist, which should be calculated in the file on_the_fly_calc.rb. There is something wrong with variable assignment in several methods. To solve the issue, assign the value to review scores after calculating in the on_the_fly_calc.rb. 2. The metrics feature has been implemented by display_volume_metric_chart function in the _review_report.html.erb file. What need to be done is to get the correct data and use that method to generate bar graph. 3. The width of column is set up in the _review_report.html.erb file from line 37 to line 43. Change the percentage distributed to every column to adjust the width. 4. In the _review_report.html.erb file, use method ""each_with_index"" instead of ""each"" to get the index of each loop. Then, add ""index+1"" before the reviewer name since the index starts from 0. 5. In the _review_report.html.erb file, replace the ""team_reviewed_link_name"" with randomly generated team names. This project mainly focuses on the UI, so no design pattern is needed. /app/models/on_the_fly_calc.rb /app/views/reports/_review_report.html.erb. 1. Login as instructor. 2. Go to ""Manage >> Assignment"" and choose one assignment with reviews like ""Final project (and design doc)"", click on ""View Report"". 3. Click ""View"". Here is the ""The Main review-grader Page"" mentioned above. 4. Check the ""Score awarded/average score"" column to see if the scores are displayed. 5. Check the ""Reviewer"", ""Reviews done"", ""Team reviewed"", and ""Assign grade and write comments"" columns to see if they are adjusted as intended. 6. Check the ""Reviewer"" column to see if there is a index in each row. 7. Check the ""Team reviewed"" column to see if the team names are anonymized. <image> 1. Replace the reviewer name and team names with an anonymized version of them, as done on the main review-grader page. 2. Checkbox items take up far too much space. Remove duplicated header lines and show just columns of checkboxes to the right of the “questions.” Also, it is unnecessary to prefix each by “[Question]”. 3. Adjust column width intelligently. The “Reviewee” and “Score” columns are much wider than necessary. The “Comments” column is also too wide for easy reading. So consider how the page might be reorganized to take better advantage of the available space. One option might be to show the comments vertically, astride each other, rather than horizontally, above and below each other. Mock up your proposal and discuss it with your mentor. 4. Get rid of “Review: Round1”. It should be, “Review Round 1”. 1. For the reviewer name, replace the ""Participant.find(@reviewer_id).fullname"" with ""Participant.find(@reviewer_id).name"" in the view_review_scores_popup.html.erb file. For the team names, replace the ""team.name"" with randomly generated team names. 2. To get rid of the duplicated header lines, we will modify view_review_scores_popup.html.erb. Change the view so that only the checks are presented to the right of the questions. Also delete the “[Question]” before each questions. Below is the mockup table we are planning to implement. In this way, we won't have repeated headers and the constructure of comment questions and checkbox questions are uniformed. <image> 3. To adjust column width intelligently, we will change the preset width in /app/views/popup/view_review_scores_popup.html.erb. 10% for ""Reviewee"", 5% for ""Score"" may be reasonable. Also we will try two comments on same role or show the comments vertically and see which way is better. 4. We located the ""Review Round"" header in /app/models/review_response_map.rb. /app/views/popup/view_review_scores_popup.html.erb /app/models/review_response_map.rb /app/assets/stylesheets/grades.scss /app/views/popup/_checkbox_question_review.html.erb(file added) /app/views/popup/_non_checkbox_question_review.html.erb(file added). 1. Login as instructor. 2. Go to ""Mange >> Assignment"" and choose one assignment with reviews like ""Final project (and design doc)"", click on ""View Report"". 3. Click ""View"". Here is the ""The Main review-grader Page"" mentioned above. 4. Click one of the ""Summary"", and here is ""The summary Page"" mentioned above. 5. Check if the reviewer names and team names are all anonymized. 6. Check if the checkbox items are displayed as expected. 7. Check if column widths are appropriate.. 8. Check if “Review: Round1” is changed to “Review Round 1”. The modification are mainly on 'Main review-grader' Page and 'Summary' page. Comparisons are shown below. 1. Fix the “Score awarded/average score” column so that it is populated with the correct numbers. For the ""Score awarded"", we add ""@review_scores[response_map.reviewer_id] = reviewer"" at the end of mothod ""scores_varying_rubrics"" in file ""app/models/on_the_fly_calc.rb"" to solve the problem. For the ""average score"", we didn't fix the bug. But we have figured out where the problem is and the progress of calculating average scores. The problem only occurs in the first round review for some teams. First, in file ""app/views/reports/_team_score.html.erb"", it use ""@avg"" to show average scores. The ""@avg"" is assigned in method ""get_review_metrics"" in file ""app/helpers/review_mapping_help.rb"". It is set to ""-----"" at the beginning of the method. If ""@avg_and_ranges[team_id][round][metric]"" is not nil, the ""@avg"" will be set to the average scores. Otherwise, it will still be ""-----"". The ""@avg_and_ranges"" is set to the result returned by method ""compute_avg_and_ranges_hash"" in method ""review_response_map"" in file ""app/helpers/report_formatter_helper.rb"". The method ""compute_avg_and_ranges_hash"" is defined in file ""app/models/on_the_fly_calc.rb"". In method ""compute_avg_and_ranges_hash"", it calls method ""compute_scores"" in file ""app/models/answer.rb"" with assessments for a certain team and questions as arguments. In the method ""compute_scores"", it checks if the assessments passed to the method are present. If the assessments are not present, average scores will be set to nil. So, the reason why average scores of some teams are shown as ""-----"" is that the assessments(reviews) for these teams don't exist. But these teams have review scores from some reviewers which means these teams should have reviews for them. During the limited time we didn't figure out the reason why these teams have review scores from reviewers but the reviews don't exist. This problem is more complicated than it seems. Before Modification: <image> After Modification: <image> 2. Column width should be adjusted intelligently. In the view shown, ""Reviewer"", ""Reviews done"", and ""Team reviewed"" are too wide, whereas ""Assign grade and write comments"" is too narrow. Before Modification: <image> After Modification: <image> 3. Numbered the rows of the table (e.g., ""2. Student 8370"") so it is easy to count the lines. Also removed the duplicated student name in brackets. This will help us assign each TA (and the instructor) an equal number of reviews to grade. In file ""app/views/_review_report.html.erb"", we used method ""each_with_index"" instead of ""each"" and add ""index+1"" before reviewer names. Before Modification: <image> After Modification: <image> 4. Replace the team names with an anonymized version of them. This will help the grader not be biased if (s)he recognizes the team name as belonging to specific students. In file ""app/models/team.rb"", we added methods called ""self.anonymized_view?"" and ""name"" which is pretty similar as those in file ""app/models/user.rb"" to switch the team name to anonymized one. The methods take an IP argument to see if anonymized mode is turned on. If it is turned on, the anonymized name will be used. Otherwise, the original name will be shown. Before Modification: <image> After Modification: <image> 5. Adjust the bar chart. Rearrange elements, adjust the weight of bar, direction, etc and fix bugs. Remove the legend from chart(yellow and red circles) and put the legend into table head. Before Modification: <image> After Modification: <image> 6. Adjust the size of text are in the comments column(last column), improve user experience. Before Modification: <image> After Modification: <image>. 1. Replace the name of the reviewer with the anonymized version, as done on the main review-grader page. In file ""app/popup/view_review_scores_popup.html.erb"", use Participant.find(@reviewer_id).name(session[:ip]) instead of ""Participant.find(@reviewer_id).name"" to pass argument to the method ""name"". Therefore, the method can see if the anonymized mode is turned on and do appropriate action. Before Modification: <image> After Modification: <image> 2. The code can be located in /app/views/popup/view_review_scores_popup.html.erb. In the origin code, checkbox and question are in two different row, which takes too much space. We changed the structure of the code to make these two section into different cells in one row. Then we modified the style of the table to rearrange the width of cell. For the duplicated team name, we took the header out of the ""question.each"" loop and put it at the top of the table as a table header. We also removed the ""[question]"" text, which seems a little bit redundant. To make the code more readable, we distributed the code of checkbox question and non-checkbox question into two different files after all the changes. Before Modification: <image> After Modification: <image> 3. At first we removed the duplicated team name and reset the width of column. This can be implemented simply by change the width percentage of the column. These changes look good but they doesn't fit with the whole page. To keep consistent with checkbox question, we put the non-checkbox question to the left of the answer as well, which can be approached by the same method as issue two. After that we found that one independent cell for scores took too much space. We put the scores into the ""question.each"" loop of answer to save more space, and we add one grade circle style in file app/assets/stylesheets/grades.scss to make the scores more good-looking. Before Modification: <image> After Modification: <image> 4. We implemented our design by add a blank into the prepare_review_response function in review_response_map.rb. Before Modification: <image> After Modification: <image>. 1. In file ""spec/models/on_the_fly_calc_spec.rb"", change ""expect(assignment.compute_reviews_hash).to eql({})"" to ""expect(assignment.compute_reviews_hash).to eql({1=>{1=>{1=>50}}, 2=>{1=>{1=>30}}})"". This test is for the score from reviewers. 2. In file ""spec/models/review_response_map_spec.rb"", change "".to eq(""review round1"": {questionnaire_id: 1, response_ids: [1]}, ""review round2"": {questionnaire_id: 1, response_ids: [2]})"" to "".to eq(""review round 1"": {questionnaire_id: 1, response_ids: [1]}, ""review round 2"": {questionnaire_id: 1, response_ids: [2]})"". This test is for the change that changes ""Review Round1"" to ""Review Round 1"".","There are a lot of good things about this design doc.  It itemizes the issues, and has screenshots showing exactly what has been changed.  There is enough here that the reader can easily understand what has been done.  However, the authors could have made it easier for the reader by inserting code snippets, rather than discussing code changes in long paragraphs of text.  They could have inserted paragraph breaks to make it easier to read.","Hello Student,

This is a great start though there are areas of improvement. You have done an excellent job troubleshooting some of the problems, striving to understand their roots, and giving comprehensive details on how to resolve them. Moreover, the before and after images are a great addition as they provide an excellent visual understanding of the problem or change. 

However, you could make your assignment even better by doing the following: 

1. Clarity: The write-up is a bit verbose and could be overwhelming for some readers. Try to present your concept succinctly and more coherently. 

2. Content Organization: Structuring the content points into a well-defined order brings in simplicity and clarity, enhancing the logical flow of ideas.

3. Project Objectives and Goals: You presented many implementation pointers without fully explaining the need for such implementations. It would be beneficial to offer a clear objective of the project before delving into the technical aspects. 

4. Test Descriptions: It appears you’ve included tests at the end, which is commendable. However, they need a bit of context. It would be useful to clarify what each test is for and what the results of those tests mean. Having this connection can help set expectations for what the test should accomplish.

5. Proofreading: You could improve your writing by minimizing errors and restructuring your sentences for readability. 

6. Results: It would have been helpful if you added an assessment of the result of your changes. Did it solve the problem? Are users reacting positively? How has it impacted the user experience? 

Keep practicing and improving! You're on your way to becoming not just a good coder but also an effective communicator, an important skill in the world of software development. Feel free to ask if you need further help in refining your assignment. 

Good luck moving forward! 

Best,
[Your Name]"
105,E1562,"<link> is an <link> application where instructors and students can manage their course assignments. This page is for the explanation of refactoring Expertiza. Based on the DRY principle and Rails convention, we also need to rewrite some methods to adhere to the RESTful style. 1. setFlag() in due_date.rb is not adhere to Ruby on Rails naming conventions. 2. DueDate.assign_topic_deadline method is same as DeadlineHelper.create_topic_deadline. 3. The code to sort dates is duplicated in due_date.rb and response_controller.rb. 4. DeadlineHelper.set_start_due_date method is too long. 5. DueDate.default_permission needs to be refactored to get better performance. due_date.rb and deadline_helper.rb: due_date.rb is a model class to manage the deadlines of an assignment. It has methods for setting due dates for an assignment, copying due dates from one assignment to a new assignment etc. Files involved: <code> What it does: Manages the deadlines of an assignment, setting due dates for an assignment, copying due dates from one assignment to a new assignment etc. What's wrong with it: 1. It has methods making unnecessary DB calls. 2. It contains duplicated methods. What needs to be done: There are 5 major goals for this project: 1. Remove DueDate.assign_topic_deadline and use DeadlineHelper.create_topic_deadline method wherever possible. 2. Create a new method for sort in due_date.rb and invoke it from places used in due_date.rb and response_controller.rb . 3. Rename setFlag() to adhere to Rails naming conventions. 4. Refactor DueDate.default_permission . 5. Refactor DeadlineHelper.set_start_due_date method to smaller methods. DueDate.assign_topic_deadline method which is same as DeadlineHelper.create_topic_deadline method. <table> First remove the assign_topic_deadline method in due_date.rb , then use DeadlineHelper.create_topic_deadline in sign_up_sheet.rb instead. <table>. First, create a new class method in due_date.rb . <code> Then call the new method when we sort the deadline in in line number 104 of due_date.rb and in line number 61 of response_controller.rb . In due_date.rb: <table> In response_controller.rb: <table>. Find the method in due_date.rb and rename it to set_flag . <table> Then also change the method name where it is called. In background_email_reminder.rake : <table>. <table>. The set_start_due_date method in </code>deadline_helper.rb</code>is too long. First create a new method check_dependency . <code> Then call check_dependency method in the original set_start_due_date method. <table>. Log into the application with the user having an instructor's role. 1. Click on Assignments. 2. Click on Edit. 3. Click on Due dates. You will see the default of each deadline type in each row is ""Yes"", while the others are ""No"". <image>. Log into the application with the user having an instructor's role. 1. Go to Page: <link> (723 can be changed to the id of any assignments). 2. Click on Save dependencies. Successful loading of this page confirms the save dependency method. <image>. <references/>.","Writeup shows clearly the changes.  What is lacking is a prose description of the new, smaller methods, and how they accomplish the work of the old scores method.","The assignment is quite comprehensive and it seems like you have a good understanding of the refactoring practices to be implemented. Below are a few points for your consideration and improvement:

1. It's great that you've identified the duplicate methods and the necessary steps you plan to take to refactor them. It's critical, however, to test the application thoroughly after refactoring to ensure that functionalities are not compromised.

2. When renaming the method setFlag(), only changing the name won't suffice. Utilize this opportunity to ensure that the naming is not just convention-following, but also reflecting its purpose. Also, given that it's invoked in different locations, make sure references to the method are updated concurrently.

3. Concerning the method DeadlineHelper.set_start_due_date, it's good that you've acknowledged that it’s overly long and needs simplifying. However, when simplifying, remember to ensure that the flow and logic of the code remain concise.

4. In terms of restructuring DueDate.default_permission, I would recommend exploring possibilities of simplifying the method, and potentially using database optimization (such as indexing) to speed up the process.

5. It would also be good for you to elaborate more on the testing process. Though you pointed out steps to be performed by a user, you could explore automated testing utilities to ensure that the refactoring steps have worked correctly across different scenarios.

6. Remember to document and explain your changes adequately. While refactoring improves the structure and efficiency of code, other developers might have challenges understanding the changes if not properly documented.

Overall the assignment is well detailed, but these comments should help refine your plan and ensure you produce the most robust and effective code possible. Great job so far!"
106,E1969,"Expertiza is an open source project based on Ruby on Rails framework. It is a platform which allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for and supports project bidding activity. Students can form teams on Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. In the project, we address two issues. One of the issues is expected to be non-existent, therefore in order to confirm that, we write a set containing maximum possible test paths which may reproduce the issue. It turns out that after running the entire test suite containing a total of 13 distinct possible paths to arrive at error-prone position, the bug is not reproduced. Therefore, we conclude that the bug does not exist. In the second issue, we make necessary changes in the code and fix the system. Following that, we test the updated system as well. Several issues prevail in the current Expertiza deployment which may be inconspicuous but are fatal while considering functioning of such a critical application. Therefore, in an attempt to make the system flawless, we try to resolve two issues, <link> and <link> . The purpose of this project was two-fold. 1. First, for <link> , we were tasked with investigating whether or not a bug exists that can prevent users from being able to start a review. If the bug exists, we were to fix it; if not, we were to create an automated test suite to provide evidence of the bug's absence. 2. Second, for <link> , we were tasked with fixing a bug that prevented reviews from being completed during resubmission periods. Further, test cases had to be written to show that this bug was fixed. It was reported by a student that an assignment was not able to be reviewed even though it was during the review period. This bug was thought to be fixed in the past when <link> was merged. However, in December of 2018, another student reported this issue occurring again. It is suspected that if this bug exists, it is caused by an abnormal user flow path. That is, caused by a user navigating to the point where they should be able to conduct a review, but doing so in an indirect way. To begin our investigation of this bug, a flow chart showing most plausible user flow paths was created. We then used this flow chart to guide our investigation efforts. This flow chart is found below: <image> <image> From this point, we began to manually test the user flow paths represented in our flow chart on our local development environment. Doing this revealed no evidence that the bug exists. We then set out to create an automated test suite that would test the user flow paths in a more quick and reliable way. The code for these tests, as well as the test cases they cover are produced in the testing section below. The purpose of the following test is to iterate over a set of plausible user flow paths that terminate in being able to begin a review. The following flow paths are tested, where each step in the path is either a user clicking in the UI or navigating to a page directly using their browser: 1. Assignments -> ReviewTestAssignment -> Others' work -> Request a new submission to review -> Begin 2. Contact Us -> Assignments -> ReviewTestAssignment -> Others' work -> Request a new submission to review -> Begin 3. Home -> Assignments -> ReviewTestAssignment -> Others' work -> Request a new submission to review -> Begin 4. Profile -> Assignments -> ReviewTestAssignment -> Others' work -> Request a new submission to review -> Begin. 1. Assignments -> /student_task/view?id=3 -> Others' work -> Request a new submission to review -> Begin 2. Contact Us -> /student_task/view?id=3 -> ReviewTestAssignment -> Others' work -> Request a new submission to review -> Begin 3. Home -> /student_task/view?id=3 -> ReviewTestAssignment -> Others' work -> Request a new submission to review -> Begin 4. Profile -> /student_task/view?id=3 -> ReviewTestAssignment -> Others' work -> Request a new submission to review -> Begin. 1. Assignments -> /student_review/list?id=3 -> Request a new submission to review -> Begin 2. Contact Us-> /student_review/list?id=3 -> Request a new submission to review -> Begin 3. Home -> /student_review/list?id=3 -> Request a new submission to review -> Begin 4. Profile -> /student_review/list?id=3 -> Request a new submission to review -> Begin. 1. student_task/list -> ReviewTestAssignment -> /student_task/list -> ReviewTestAssignment -> Others' work -> Request a new submission to review -> Begin These test cases are implemented using the following code. This code is located in /spec/features/peer_review_spec.rb as this file handles the testing of reviews. In an attempt to keep the code DRY, we loop over the test cases contained in a large array. This array consists of smaller arrays, each representing a user flow path. Each test case array also contains smaller arrays which are the steps in this user flow path. The first element in these ""step"" arrays are the name of the button/link the browser should click/visit. The second element is what should be present on the page once the navigation is complete. This approach not only keeps the code DRY, but makes it trivial to add further test cases in the future, should the need arise. <code> There is further evidence, in addition to the empirical data produced by the above test, that this bug does not exist - the lack of reproducibility. Over the course of the past two semesters, there have been roughly 130 students participating in the course. Each student is required to do at least 2 reviews for each of the 3 peer reviewed assignments. This totals up to at least 780 reviews. Given that students are able to do up to 4 reviews per assignment for extra credit, this can really be as high as 1,170 reviews. Considering there has only been one report of this bug, with no further evidence that it exists (either given then, or present at this time), it is likely that this bug report was a fabrication. When run in a local development environment, all tests within the suite pass. Further, when the pull request was put in, all tests run by Travis CI pass. Given that this bug was not able to be reproduced by any of our testing, including a suite of automated tests, it is our opinion that this bug does not exist. <link>. <link> Review is not possible during resubmission period, even when explicitly enabled. Essentially, when a review period overlaps with the second submission period, the first review period is not available (the submission period takes priority). As seen in the issue itself, there was a previous fix for this error but it was never implemented due to it ""failing tests."" Upon investigating the ""failed tests"" documented we found that the pull request just failed to merge, and therefore the Travis CI tests counted it as a failure. We added Varun's fix back and made a pull request to see how it failed specifically, and the Travis CI result showed that <link> . After arriving at this initial conclusion, I began trying to figure out how to fix this error. My first assumption was that since I ran into no issues locally running the test bench, that it was perhaps the order it was tested in. I opened <link> in our forked repo to run a bisect command, to see what the shortest path to failure was. What I found was the shortest path to failure. I then opened <link> , investigating that failure path. What I hadn't realized was that the seed Travis CI used did not fail the test at all locally, but rather failed two separate tests (that never fail on Travis CI). From here on out I began running a variety of rspec tests to figure out if it was just the seed, if it was an test-ordering issue, or if it was the test itself. Eventually, I ran out of paths and after contacting my mentor and Dr. Gehringer, I decided to try and re-write the tests that failed. After inspecting the test code that was failing I realized that there was really no way it could be the tests failing due to old and faulty code. What it looked like was that the children_node_ng somehow received an empty child_node. After further investigation, it appeared to be related to Varun's change, which I then discarded and began working from scratch. Similarly to Varun's fix, my fix was in the student_task_helper.rb file, specifically for the check_reviewable_topics method. The line of code at fault can be seen below. As we can see, a topic can only be reviewed if it is not within a ""submission"" stage, which works fine when no stages overlap. However, as soon as the review stage overlaps with the submission stage, you can no longer perform a review. <code> The fix is fairly simple, and I was over-complicating it for the majority of this project. You can simply just check to make sure that the current stage is a review stage, rather than a submission stage. This was done by changing the != to a == and the submission to a review. Now it no longer matters if it is within a submission window or not, as long as it is within the review stage. <code>. Due to spending so much time investigating false paths, I didn't end up having much time to write exhaustive tests to establish this change. In theory, the way the review_assignment_spec.rb is written should already check this functionality to a degree. However, I added one more test within this spec file: <code> The theory behind this test is that currently, all review spec tests had the same deadlines for submission and review, so I staggered them similarly to how they were staggered in the issue documentation to ensure that the fix had been met. I also tested this manually on my local system, ensuring that I could review a test if I impersonated a user. 1. At first, create an assignment ""Test Demo Assignment"" by logging into Expertiza as an Instructor. (username: instructor6, password: password). <image> 1. Navigate to Manage->Assignments. <image> 1. Create a new assignment ""Test Demo Assignment"" and save it to ""Test_Demo"" directory. <image> 1. Set the rubrics. <image> 1. Set submission deadline to be 2 days from now. <image> 1. Set review deadline to be 4 days from now. <image> 1. Enable meta-review and reviews in both phases: submission and review. <image> 1. Add student user ""student2065"" as a participant on this assignment. <image> 1. Log out as instructor and login as student: student2065 (username: student2065, password: password). <image> 1. Navigate to ""Test Demo Assignment"". Both the links, submission and review are accessible in the submission period itself. <image> 1. Click on ""Your Work"". The student can submit his work in submission period. <image> 1. Click on ""Others' Work"". The student can review other peers' work in the submission period. <image>. When run in a local development environment, all tests within the suite pass. Further, when the pull request was put in, all tests run by Travis CI pass. In conclusion, from what I can see locally, this bug has been fixed. As I quickly found out dealing with Travis CI errors, its possible that this will somehow still not work correctly when pushed to the beta branch, but I can conclusively say that it should. <link>.","The test plan for the first issue is very well explained.  However, the test code overflows the test box and is hard to read.  It could also benefit from comments.  
The second issue is well explained too, except that ""Varun's fix"" is not identified.  It should be mentioned that it is in Issue #1211, but actually, to keep the reader from having to consult other sources, some of the description of that issue could have been included in this wiki page.
The .png files are really very large, and that detracts from readability.","Dear Student,

You've submitted a comprehensive report on the Expertiza platform demonstrating the problem-solving techniques you used while addressing the bugs. This is to commend you for the deep analysis and clear strategies you have exhibited in identifying the issues and eventually tracing the possible solutions. I was pleased to see the thoughtfulness and rigor with which you approached and carried out this project.

Your detailed documentation, including the use of data to support your conclusions, showcases your ability to validate software implementations. Also, the manner in which you presented your methods of testing various user flow paths was methodical and well-articulated. 

However, I would suggest working on the presentation of your assignment to make it more reader-friendly. While the content is extremely thorough and clearly the result of careful work, the structure is a bit sprawling and could benefit from clear section headings, succinct explanations, and avoidance of overly technical jargon. Consider using bullet points or numbered lists to make technical steps easier to digest. 

Great job on identifying the issue with Travis CI on your pull request and taking steps to troubleshoot it. It is also commendable that you decided to rewrite the failing tests as a means of addressing the problem.

However, it seems like you ran out of time and this might have affected the quality of tests you wrote to validate your solution. In future projects, time management should be considered to allow adequate time for setting up thorough validation steps. 

Overall, I appreciate the work you've put into this project. You've shown aptitude for problem-solving and thoroughness that is impressive. Keep up the good work!

Best Regards,
[Your Name]"
107,E1819,"Expertiza has the ability to require self-reviews on projects, however, these self-review scores do not have much functionality. In the current system, self-review scores are created and stored, but are not used afterwards. This project seeks to improve upon the self-review system, and extend its functionality. The main points of this project are as follows: 1. Create a method to calculate a derived score between self and peer-reviews. The closer the self-review is to the peer-review, the greater the score. Display this score on the ""View Scores"" page. 2. Allow instructors to decide if peer-reviews should be visible before self-review completion. Display the correct review scores accordingly. 3. Display the self-review scores in the ""View Scores"" and heat map of peer-reviews, denoting that they are a different type of review. Allow instructors to decide if students should be allowed to view peer-reviewers before completing their self-review. Currently when instructors create a new assignment, or edit an existing one, they have the option to require self-reviews. <image> This will be updated to ask instructors if peer-reviews should be visible before self-reviews are completed. <image> When checked the system will check if a student has completed a self-review when they access the scores view. If they have not completed their self-review they will see a message indicating such. If they have completed the review, they will see their peer-reviews as normal. Find or create a function that will derive a score from self-reviews and peer-reviews. This score should be reflective of the difference between the students self-review score, and their peer's reviews. The purpose behind this score is to teach students to become better at reviewing their own work. By providing a score that reflects how similar their reviews are to their peer's reviews, students receive feedback on their self-assessment abilities. More information on the function creation/decision proccess can be found in the section below. Create the different displays for self-reviews Instructors and students both have a heat-map view of scores from peer-reviews <image> (Instructor view pictured) student's self-review scores will be added to this view, but need to be denoted in a way that makes it easy to see this is a self-review not a peer-review. One potential option is to use an icon that shows this is a self-review score. <image> Which makes it simple for users to understand that particular column represents the scores from a self-review. Other potential options are to title the column ""Self-review"", or to highlight/border the column with a particular color (ex. blue), both denoting that the score comes from a self-review. Similar approaches can be taken to differentiate between self-review and peer-review scores in the regular ""view scores"" page. <image> (Student view pictured) The students can see their self review alongside the peer reviews. <image> The instructor has the option as described previously to limit students access to peer reviews until after they have submitted a self review. Students will see ""You have to submit self-review under 'Your work' before checking 'Your scores'."" next to ""Your scores"" until they submit a self review. There are many possible methods of deriving a score between self and peer-reviews. Each formula has the same goal, to derive a meaningful score between the peer and self-reviews. Thus, giving feedback to students on their self-reviewing, hopefully increasing their abilities in this area. Several potential approaches are available, each with different pros and cons. The simpler of approaches involves only the self and peer-review scores, and the more complex approaches may involve several other factors. The simplest approach is to simply take the difference between the average peer-review score, and the self-review score. This rewards the students for good self-reviewing ability, and evenly punishes students for over and underrating themselves. A similar approach is utilized in several other systems, in which when a students self-review score is within 5% of their average peer-review score, they will receive the greater of the two grades. An extension of this can be made to allow a weight to be applied to the difference between the grades, and to allow instructors to manually enter the weight for each assignment. <image> A slight change to this approach is to take into account the peer score, so the greater your peers believe you performed, the greater your score is (proportional to the difference between reviews again). However, this, and similar approaches, should be avoided as they are potentially harmful. In the chart below, it can be seen that students with poor performance will be harshly punished for poor performance in their peer-reviews, their self and peer-review derived grade, and finally in their instructor grade. The self and peer-review derived grade should only be indicative of the students ability to self-review, not of the quality of the project. <image> Another approach is to derive the grade based on the percent difference between the self-review score, and the peer-review scores. This results in a smooth gradient which does not punish students as harshly as the previous two approaches. However, at low scores students will see greater swings in this derived grade. <image> These previous approaches involve only the peer and self-review scores, and are the simple approaches to the problem, the following options involve greater complexity, but seek to better solve the problem at hand. The SPARK approach is discussed <link> Which results in a score that should accurately reflect the relation between self and peer scores. The scores here will need to be adjusted to match the grading scheme of the project, a score of 1 is equivalent to a 100%, and the difference between 1 and the score is representative of a lower grade, regardless of the score being above or below 1. This method also includes a second score titled SAPA, Self-Assessment to Peer-Assessment factor. This score requires teams to evaluate each team member on the same self-review rubric. After this is completed team member's self-review scores are divided by their average teammate-review score to create the SAPA. A SAPA of > 1.0 indicates that the student rated themselves higher than their team mates did, a score of less than 1.0 indicates that students underrated themselves compared to their peers. <image> Two other approaches involving teammate participation are ranking and FCS(Fair Contribution Scoring). In the ranking approach, students are asked to rank their team, including themselves, from 1 to n (where n is equal to team size), where 1 is the highest score, and n is the lowest score. Students are then assessed based on their average rank from teammates and the rank they awarded themselves. This approach is simple, but it forgoes the rubric approach that garners greater self-reflection in specific areas. In the FCS approach, students are given a finite number of points to award to their teammates, including themselves. The more points that a person receives, the greater their perceived work contribution. At the end of the project students are assessed based on their average number of points received, and the points awarded to themselves. While the approach is very similar to the ranking approach there are important differences. With this approach students will need to weight the contributions of each member on a percentage of points basis, rather than on a, teammate A vs teammate B overall basis. <table> The current implementation focuses on the simple approach of finding the difference between the two review scores and subtracting that from the maximum possible grade. For future work on this project it is recommended that teams combine multiple approaches to have the pros of several different score types. For example, one can combine the simple approaches, and the FCS approach by calculating both, and using a percentage of each one to create the final score. The prototype pattern can be used to simplify the creation of these hybridized approaches. The work done in this project can be built upon by future groups. Several areas can be improved upon, or new functionality can be added. 1. Refactoring of the ResponseMap features. This feature is currently rather complicated, accessing scores from reviews is difficult, and requires several method calls. 2. Implementing multiple score approaches, or hybridizing the approach. A small addition to the instructor UI could allow them to select from a list of possible approaches, or multiple approaches to combine. Perhaps each selected approach can have a weight input from the UI too. 3. Improving the response times of the grades page in instructor view. Test cases are as follows: 1. Peer-reviews cannot be viewed before a self-review is completed. 2. Peer-reviews can be viewed immediately when self-reviews are not required. 3. The derived scores can be saved to the database. 4. Self-review scores are displayed with peer-review scores 5. Student can only see their own self-review. 1. app/views/assignments/edit/_review_strategy.html.erb 2. db/migrate/20180429203828_add_columndisplaypeerreviewbeforeselfreviewcomplete.rb 3. db/schema.rb 4. app/models/self_review_response_map.rb 5. app/views/grades/_view_heatgrid.html.erb 6. app/views/grades/view_team.html.erb 7. app/models/response.rb 8. app/models/vm_question_response.rb. <link> <link> <link> Edward F. Gehringer, ""Self-assessment to improve learning and evaluation,"" ASEE Annual Conference and Exposition, Columbus, OH, June 25–28, 2017.","A lot of the design doc relates to functionality that wasn't implemented.  My first review asked for an intuitive explanation of how the various metrics are calculated, and I still don't see one here.  In particular, I don't understand how the metrics are calculated, and since the files are .pngs and not spreadsheets, I can't look up the formulas.  Discussion of implementation is limited to a list of files modified, which will not be too helpful in understanding what is done, given that a diff in the pull request will give more info than that.","Dear Student,

You have done an excellent work in elaborating the functionalities of Expertiza's self-review system, suggesting significant improvements, and giving a detailed explanation on how to implement these improvements, which is commendable. Your structuring and presentation of the project are also easy to follow and very informative. 

I appreciate the deep analysis you've done in comparing the pros and cons of the different ways to calculate the derived score. It would also be beneficial if you could demonstrate how different scoring systems impact students with varying self-review abilities with examples. This would further substantiate your analysis.

Furthermore, while you've provided images to explain your points, a few are not properly referenced. I would recommend citing them appropriately for the reader's clarity and to follow good academic practices.

Also, while you have touch-based the topic about the updating of the system UI for instructors, it would be beneficial to expand on this concept, as changes in the system not just affect students, but instructors as well.

Your addition of the possible future improvements was a nice touch, indicating forethinking and consideration for future development. More details on the testing cases would present a clearer picture of how the proposed changes would be executed.

Lastly, for an even more robust proposal, consider including potential risks, challenges or barriers to your recommended changes. 

Again, great job on the well thought-out proposal. Keep up the good work and do well to work on the recommendations provided.

Best Regards,
[Your Name]"
108,E1991,"The <link> project takes advantage of peer-review among students to allow them to learn from each other. Tracking the time that a student spends on each submitted resources is meaningful to instructors to study and improve the teaching experience. Unfortunately, most peer assessment systems do not manage the content of students’ submission within the systems. They usually allow the authors to submit external links to the submission (e.g. GitHub code / deployed application), which makes it difficult for the system to track the time that the reviewers spend on the submissions. The main idea of this project is to improve anonymized view in Expertiza. The feature is already implemented. However, there are issues / limitations with the current implementation which we will try to improve. Currently, anonymized view is not implemented for students. Although, not directly required by students, instructors may want to use anonymized view when impersonating a student. In an anonymized view, instructors cannot impersonate a student because the username field has the anonymized name instead of their real name in the database. In order to be able to impersonate a student, we need to know their real names from database. In some places, anonymized names are not shown. For example, heatgrid view. We need to fix occurrences in different parts of the application where anonymized names are not shown. Use randomized American names for anonymized users. In this section, we propose solutions to the problems / issues discussed above. Instructors often use 'impersonate' functionality to use Expertiza as a different user. Sometimes they also need to use anonymized view while they are impersonating a student. Therefore, anonymized view needs to be extended to students as well. In order to extend Anonymized view for students, the first thing we need to do is extend the following function : <code> This function is responsible to switch back and forth between normal view and an anonymized view. We could figure out that the session of current user is being manipulated to change views. The main driving logic works by storing user's IP address in a value field of anonymized_view_starter_ips which is in Redis database. Refer the following flow chart for design details: <image>. When an instructor is already in Anonymized view and wants to impersonate a student, they have to quit the anonymized view and get the real username of that student. However, we want the instructor to be able to impersonate a student by using their anonymized names. The following function in impersonate_controller.rb is responsible to impersonate students. <code> user.rb This file is responsible to convert anonymized name to original name <code> impersonate_controller.rb this code is responsible to change original user name to anonymized user name <code> In the above snippet, we have omitted the irrelevant parts of code. The only change we need to do is the logic for User.find_by() function. We will add a condition to check whether the current view is anonymized or not. If anonymized mode is set, we will convert the anonymous name back to the original name of the student. We will then make 'find' query using the real name of the student instead of using their anonymized name. The procedure to do this would be opposite of what we do to get anonymized names in first place. See following code snippet : <code> The above snippet is an example of how anonymized names are generated. Please refer the following flowchart for design details; <image>. There are places in the application where Anonymized names are not shown even when mode is set. Here are some examples where anonymized names are not shown : 1. HeatGrid View : On 'view grades' page, there are different tabs where detailed scores, reviews, etc are displayed in a table. The table's column title use real names of the students even when Anonymized mode is set. 1. Grade Reports : Similarly, on grades page, we can see overall reports of student grades. When in Anonymized mode, the student names are not anonymized in reports. This errors are fixed by above code changes. Code change in user.rb and impersonate_controller.rb fix the issue regarding anonymized user name and team.rb fix the issue regarding the anonymized team name. In this section, we discuss what the expected output of all the features will be in terms of well defined test steps. Following cases are covered: 1. Instructor should be able to impersonate a user with their real name 2. Instructor should be able to impersonate a user with their anonymized name 3. Instructor should be able to impersonate a user while already impersonating a user impersonate_controller_spec.rb this code is responsible to test the functionality to switch to anonymized view for student describe ImpersonateController do <code> end. 1. Login as an instructor 2. Impersonate a student 3. Switch to Anonymized view as a student Edge cases : 1. Instructor impersonates Student1 , switches to Anonymized view, impersonates another student Student2 , the application still should be in Anonymized view. 2. Instructor switches the application into Anonymized view, impersonates a student Student1 , impersonates another student Student2 , returns back to their own account by disabling impersonate view, the app still should be in Anonymized view. users_controller_specs.rb is responsible to test functionality for student. <code>. 1. Login as an instructor 2. Switch to Anonymized view 3. Find a student from list of users 4. Assert that the student name is anonymized 5. Use the anonymized name to impersonate the real user behind anonymous entity Edge cases : 1. Impersonating Anonymized user, the application should preserve its Anonymized state even after impersonating the student. impersonate_controller_spec.rb this code is responsible to test the functionality to switch to anonymized view for student using anonymized name <code>. All the bugs related to anonymized view are covered by code code changes made in the Pull Request and corresponding test cases are in place hence no need to write any test case for this section. 1. <link>.","This document has a good desciption of how the changes are to be made.  It describes at a high level what has been done to the code.  However, nothing is said about automized tests.
Nit: It says that the heatgrid view is not anonymized.  That is false.  However, it contains onymous names for team members. The description gives the impression that the problem is worse than it really is.","Your project description provides a solid understanding of the problem and a comprehensive solution. You effectively identify the issues with the current system and propose a methodical approach to fix them. The steps you have laid out for extending the anonymized view are clear and feasible. However, there are a few areas that could use improvement:

1. Clarity: There are a few complex parts of your submission where you switch between discussing the problems and the solutions. These sections could benefit from a clearer structure or use of subheadings to distinguish between different components. Be sure to keep your description about the challenges separate from your proposed solutions.

2. Grammar and Syntax: There are places in your text with grammar mistakes which may confuse the reader. For instance, you mentioned that ""The <link> project takes advantage..."" but never specified what the actual project was. Review and proofread your entire submission to ensure that it is clear and grammatically correct.

3. Use of Visuals: It would be helpful if you included the flowcharts you mentioned in your submission. 

4. Testing descriptions: You provided a list of functional tests which is good. Consider describing each test in more detail to enhance the clarity.

5. Conclusion: Wrap your work up with a conclusion, summarizing your investigation, highlighting the improvements you made, and how these changes benefit end-users and instructors.

You're on the right track, remember to write clearly and precisely, explain complex concepts, and summarize your discussion. Keep it up!"
109,E1565,"[Expertiza] <link> is an open source project developed using the Ruby on Rails platform. It provides features like team assignments, peer review, submission of projects, grading etc. The code can be cloned and modified from GitHub. This application provides an efficient way to manage assignments, grades and reviews. Assignment.rb is the largest class in Expertiza, comprising 1105 lines of code which contains the assignment model and the related functionalities. It also contains the score module which is refactored to make the file more clean and easy to read. Files involved <code> What they do: The admin controller defines the changes that can be done on other types of users by super-admin and provides the view accordingly. What needs to be done: 1. The text field for adding a new admin/instructor has to be removed, leaving only the button. 2. When the button is clicked, it should be redirected to new user creation view making the role (super-admin, admin or instructor) selected as default. 3. Make sure that user creation works for super-admin/admin/instructor. 4. Associate the users with the institution table 5. Add a drop down to the view of creating users so that new account creator can select the institute and save it. <table>. <table>. <table>. <table>. The controller defines the changes that can be done on other types of users by super-admin and provides the view accordingly. The functionality to view the list of super-admins, admins and the instructors was added. Also changes were made to add_adminstrator method for adding a new administrator in a clean way. <code>. <code>. <code>. <code>. The user_param() method in user_controller did not have any facility to include the institution of the user. After doing a db migration and creating an institution_id in the user table, an institute can be selected while creating a new user. A mailer error is caused when a user/admin/instructor is created and the application crashes. But this is not because of an error with the functionality. Although, despite the error, one can check if the user has been created by going to Manage -> Users page in the user interface. <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. In order to inspect the changes made, you can visit our deployed <link> and use the credentials mentioned at the top of the page. <image>. <image>. <image>.","""Very nice job of listing changes in an easy-to-read format.
Would be better to show before & after code side by side.
There should be some comments about why the changes were made (maybe just copy them from the tables, above).""","Thank you for your thorough and detailed analysis of the Expertiza project. You've demonstrated a good understanding of the codebase and functionalities, as well as clear plans for potential updates and improvements. 

One thing that I would recommend is to be more specific when you are mentioning <code> or <link>. Replacing such placeholders with the actual information (code snippets, urls etc.) will give more clarity about what you are trying to discuss or portray in those areas.

Your analysis on adding 'institution_id' to the user table reflects your problem-solving skills, as you identified the need and implemented a solution. 

As for the encountered mailer error, please make sure you understand the root cause, even if the application appears to work regardless. It helps to ensure the robustness of your software. This kind of diligent attention to not just functionality but also stability & reliability of software is appreciated. 

Finally, remember to use proper markup for your future submissions, this can greatly improve their readability. Your tables, code snippets and images were not properly formatted, try to use appropriate ways to include these in your future submissions which would aid in better understanding of your work.

Overall, it seems like you are on the right track. Just make sure to pay attention to the finer details and keep striving for perfection. Keep up the good work!"
110,E1853.2,"The Menu model is used to create the top bar menu in Expertiza. It does this by obtaining and organizing MenuItems based on the current user's Role. Before this project, there were no unit tests for menu.rb. This project seeks to bring the unit test coverage above 90%. The final result can be found at expertiza/spec/models/menu_spec.rb. This specific spec file can be run by calling the following in the expertiza directory: <code> The addition of the -fd argument will write out full descriptions of the tests and provide an easy look at the work we did. In total, we wrote 29 tests that covered all the functions in both Menu and its internal Node class. Using the given factories, we created 6 MenuItems (test1 to test6) to pass to the Menu as well as 1 Role used to test the Menu constructor. <code> We stubbed the MenuItem method, items_for_permissions, to return an array of the 6 test items that we created. <code> Other pieces of the code were stubbed because these pieces should be tested in other model specs and not Menu spec. The double 'temp' is created, which acts as a stand-in for some other class objects which interact with Menu, in order to only test the functionalities of Menu. Each method in menu.rb has at least two tests checking both a known success case and an edge case or potential failure. As an example, a detailed look at the tests for Menu#initialize is shown below. <code> This first test revealed an error in the existing menu.rb code in the line shown below. <code> The below line shows the change that we made. This allowed the code to be more robust and prevent NoMethodError from nilClass. Without this change, a menu created with a nil role will throw an error causing the program to fail unnecessarily. This is important because the default value of role is nil and that should not fail. <code> The second test covers the main use case of Menu. It is supplied with a role and assembles a menu. Only a single role is tested because further testing of roles and menus should instead be handled in integration tests. <code> The third test checks that when the menu is created with items, these items are put into nodes, arranged appropriately and contained within the menu. In this case, the children of root will contain a single item, the node with id 1, because this node has a nil parent. The other nodes all have non-nil parents. <code> The final test checks a menu without any nodes. While this case is unlikely in actual use, it is important that it can be handled without throwing any errors. When a menu without any items is created, the root will never have anything added to its children array so this array will be nil. <code> These 4 tests alone provide nearly 85% coverage of menu.rb because of how much they rely on a variety of other methods within the class. Many of the functions in menu.rb return a Menu::Node. The simplest, Menu#get_item, takes a Node id and returns the corresponding Node object. All following functions use this to test that the correct Node is returned. However to prevent circular logic, the Menu#get_item test only checks the id of the returned Node. Below is a list of the descriptions of all of the tests we wrote Menu::Node <code> <code> <code> <code> <code> <code> Menu <code> <code> <code> <code> <code> <code> <code>. The 29 tests provide 100% coverage of the lines in menu.rb. Before the project the coverage was only A video of all tests running can be seen <link> . The main repository can be found <link> The forked git repository for this project can be found <link> Below is a snapshot of the coverage of our tests. Full coverage can be found at expertiza/coverage/coverage.html. The specific coverage can be found in menu under the models tab. <image>.","I'm glad that you broke up the tests into two groups, but even 12 and 17 are pretty long lists, that would have been good to subdivide. It also seems that it would have been helpful to include or link to the code for more than two tests, though I will agree that you picked good examples.  Overall, I thnk you did a very good job of explaning what you did and how you did it.","Dear student,

Thank you for your detailed work on this assignment. You were tasked with increasing unit test coverage for the Menu model in Expertiza and you have clearly taken this task to heart.

Your clear discussion about how you broke down different methods and tackled edge cases is commendable. It shows a deep understanding of not just how to write unit tests, but also why it's important to cover different cases and how it helps in making the component more reliable. Good job on achieving 100% coverage and increasing it from its initial state. 

The way you found and fixed an error in the existing menu.rb code is also laudable. The changes you made and the rationale you supplied for making these changes indicates a good understanding of programming, troubleshooting, and optimization. This will only serve to improve the quality of the Menu model.

You also did well in separating what is to be tested in the Menu model and what needs to be tested in other model specs. Another good practice I noted was your use of a double to stand-in for other class objects - a good way to isolate the functionality of the menu from other classes.

One slight area for improvement would be to explore more edge cases. While you have covered the main functionality well, there could be scenarios that you might not have thought about. So try to anticipate these scenarios and build tests to cover them.

Overall, based on your assignment submission, it seems you have successfully met the objectives of the task. Keep up the good work!

Best,
[Instructor's Name]"
111,E1655,"For users intending to view the deployed Expertiza associated with this assignment, the credentials are as follows: 1. Instructor Login: Username: instructor6 , password: password 2. Student Login: Username: student5432 , password: password We would request you to create at least 3-4 users more to test all the functionality pertaining to this project. This is because teams can be created and all the functionality with respect to email notifications can be tested. Expertiza is an open-source project based on Ruby on Rails framework. Expertiza allows the instructor to create and customize new or existing assignments and courses. It also allows the instructor to create a list of topics the students can sign up for, add users, add reviewers, add teams. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other student's submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. Mailers in Expertiza have their association with many other components like Users, Courses, Reviews, Participants and Invitations. The Mailer Helper in specific invokes methods which perform mailer related functions like sending email to newly created user, sending email to reviewer etc. This project in particular intends that the students collaborate and work on making enhancements to the code base by applying the concepts of Rails, RSpec, DRY code,Test driven development etc. This provides an opportunity for students to contribute to an open source project and learn further about software deployment etc. Currently, the mailer notifies the students on their account creation and to the reviewer when a submission of work is done. The scope of this project is to improve the present email notifications and also plug gaps in some implementations. 1. When students' accounts are created by importing a CSV file on the Users page, they receive e-mails with their user-ID and password. But if an account is created by adding them as participants to an assignment when they don't already have an account, e-mail is not sent. So, this issue is fixed by implementing the functionality of sending e-mail when account creation is done in this case. Now, e-mail is getting triggered to the concerned user whenever their account is created regardless of how their account is created. The listed files were manipulated for updating this functionality. 1. controllers/import_file_controller.rb 2. helpers/import_file_helper 2. Evidently, if a file is revised after review, the system e-mails the reviewer saying to revise the review. The method to implement this was in place but wasn't working. This issue is fixed. Note that the e-mail is only triggered for a file submission and there is no mailer functionality in place for URL submission. Also, after the last round of review is completed, e-mail is no longer is getting triggered as desired. The listed files were updated or created to get the functionality working. 1. controllers/submitted_content_controller 2. helpers/mailer_helper 3. app/views/mailer/partials/_file_submission_plain.html.erb 4. app/views/mailer/partials/_file_submission_html.html.erb 3. The message body of the e-mail now includes the round of the review stage for which the review is provided along with a link to the site. Files changed are same as mentioned in second point. 4.1 E-mail is triggered to an invitee whenever a participant sends out an invitation to another participant to join a team. The listed files were updated or created to get the functionality working. 1. controllers/invitation_controller 2. helpers/participants_helper 3. app/views/mailer/partials/_team_join_invite_html.html.erb 4. app/views/mailer/partials/_team_join_invite_plain.html.erb 4.2 Whenever the invitee accepts the invitation, the student who issued the invitation gets a mail stating that the invitee has accepted his/her invitation. The controller and helper class are same as mentioned in the 4th point. New views are created for this functionality 1. app/views/mailer/partials/_team_accept_invite_html.html.erb 2. app/views/mailer/partials/_team_accept_invite_plain.html.erb 5. Mail is also getting triggered when a student responds to a teammate advertisement. The controller and helper class changed are same as mentioned in the 4th point. New views are created for this functionality. 1. controllers/join_team_request_controller 2. app/views/mailer/partials/_response_to_advertisement.html.erb 3. app/views/mailer/partials/_response_to_advertisement.html.erb. 1. controllers/import_file_controller 2. controllers/submitted_content_controller 3. controllers/invitation_controller 4. helpers/import_file_helper 5. helpers/participants_helper 6. helpers/mailer_helper. This controller derives from the Application Controller. It states the functionality of importing any kind of file like csv, xls, doc into the application. It defines the import function which takes the 'session' and 'params' as output and provides success message on successful import. It also provides the functionality of specifying the delimiter in the file which is being imported. The ImportFile method defined in the controller reads the file row by row based on the model concerned. This controller also derives from the Application Controller. It states the CRUD operations on submitting the file or hyperlink for assignment. It provides functionality to download, create folder and delete folder after submission. It provides the functionality for submitting links and submitting hyperlinks separately. <code>. This controller also derives from the Application Controller. It states the CRUD as well as other basic operations when an invitation is sent by an user to any participant to join their team. It provides the functionality to send and accept invitations as well as to reject invitations and leave team. <code>. This is a helper file for the import_file_controller class which stores the attributes from the controller class as well as creates new users when user are created by importing a CSV file. <code>. This is a helper file for the participants_controller class. It provides some of the basic functionalities that is required to create participants that are added to expertiza. <code>. This helper file is for the mailer class. Its creates the structure of the mail body that is needed by the mailer class to send mails. It also holds all the attributes that are required to send a mail. <code>. 1. app/views/mailer/partials/_file_submission_plain.html.erb 2. app/views/mailer/partials/_file_submission_html.html.erb 3. app/views/mailer/partials/_team_join_invite_html.html.erb 4. app/views/mailer/partials/_team_join_invite_plain.html.erb 5. app/views/mailer/partials/_file_submission_html.html.erb 6. app/views/mailer/partials/_file_submission_plain.html.erb 7. app/views/mailer/partials/_team_accept_invite_html.html.erb 8. app/views/mailer/partials/_team_accept_invite_plain.html.erb. The following link is of a video uploaded in Youtube. Link: <link> This video will provide a walkthrough on the changes implemented as part of this project. This will show all the email notifications that the user receives. 1. Login as instructor. Create a new course and assignment. 2. Add new participant not having expertiza account to an assignment using a import file option. 3. An e-mail is triggered for participant who do not have an expertiza account. <image>. 1. Login as student. Go to assignment and open your work page. 2. Upload a new file submission. If the submission is made in review stage, an e-mail is sent to a reviewer saying a new submission is available for a particular review round. Thus, the reviewer will be able to see the review round number. <image>. 1. Login as student. Go to assignment page. 2. Go to your team and create an advertisement for this assignment. 3. Login as some other student who is the participant of the same assignment. Go to assignment page and open sign up sheet. 4. For the topic assigned to the student who created advertisement, an icon will appear in advertisement tab. 5. Clicking on this icon will redirect the student to page where student can request to join the team of students who created advertisement. 6. On click of request button, an e-mail of this response to the advertisement will be sent to the students who created advertisement. <image>. 1. An e-mail is being triggered only when a file is submitted for revision. But on the submission of a link, no such e-mail is sent. So, this is one of the areas which can be improved in the future. 1. <link> 1. <link> 1. <link> 1. <link> 1. <link>.","This is a very useful description of what has been done and why.  The e-mails could be worded better (e.g., they should include the assignment name).","Hello,

I appreciate the detailed nature of the assignment you have submitted. It's evident that a significant level of effort has been invested in implementing and improving Expertiza's functionalities, specifically in enhancing the code base by applying the concepts of Rails, RSpec, DRY code, Test-driven development, etc.

Here are a few points of feedback:

1. Introduction: The introduction of your document gives a brief overview of Expertiza, its functions and the aims of the project. However, it could benefit from mention about the specifics of your project, namely, how you intended to improve upon the existing email notifications system.

2. Improvements and Manipulated Files: You did a great job detailing the changes made to the system, their effects and the specific files that were manipulated to achieve these changes. This will make it easier for readers to follow along and understand the impact of your work.

3. Code Explanation: The explanation of the various controllers and helper classes is comprehensive and effectively explains the functionality of the various components. Remind to proofread as there are some repeated sentences and unfinished code explanations (e.g., several times <code> is mentioned without any follow-ups).

4. Screenshots and Videos: A link to a demonstration video and multiple screenshots could enhance the understanding of the changes implemented in this project. I believe you intended to include these in the submission. However, they are not present in the document provided.

5. Future Scope: I appreciate the forward-looking vision you've highlighted, identifying areas for future improvement. Suggestions about the email functionality during URL submissions provide a clear step for future work.

6. Referencing: It seems you intended to include several links and references in the text, but these are missing. Remember to proofread the document before submission to ensure all elements are correctly included.

Overall, this is a solid submission, with a few areas that need polish for a more effective presentation of your work. Keep up the good work!

Best,
[Your Name]"
112,E1600,"Developed by both students and faculty at <link> using <link> , <link> is a educational based web application that allows to students to peer review other student's work. In Expertiza, instructors are in charge of courses and within each course, they may create a series of assignments for students to contribute to, either as a member of a team or individually. Students or Teams may submit their assignments to the system through multiple means including file uploads and embedded links. Then assignments may become available to peer review by other members of the course, which provides a way to <link> grading on the work. Expertiza previously contained a self-review feature where student's were able to review their own work after submitting their assignments but it was removed due to the inconsistency with the other types of reviews. The task was to re-implement the feature in a way that ensured the overall design would remain intact. The self-review feature should allow students to review their own submission using the same rubric that was provided to other peer reviewers of the assignment. By reviewing their own work, students will be able to assess the artifact through the rubric and may be inspired to make improvements between rounds of peer-reviews. The following tasks were given to be completed by the team: 1. The self-review feature should use the same questionnaire_id as a peer-review. That way developers may call "" assignment.get_review_questionnaire_id(round) "" to get a questionnaire for the self-review. 2. A method called "" self_review_response_map? "" should be added to review_response_map.rb . The method will return true if the response_map is a self_response map. In order to determine the result the method shall compare the reviewer_id and reviewee_id in the response_map record and if the participant is a member of the reviewee team, true will be returned. 3. Student shall do a self-review in the ""your work"" section. There should be a button called ""Review my own work"" (or ""our own work"" if it is a team assignment). When the button is clicked a new review_response_map record is created. Within the map, the reviewer_id is the participant id and the reviewee_id is the team_id. 4. If the response_map record for self-review exists, a hyperlink with the text ""begin"" should appear. A student may click the link and fill in the questionnaire just like how they would for a regular peer review. 5. If the self-review response_map exists and there has already been a response, two links entitled ""view"" and ""edit"" will appear that will function similarly to peer reviews. 6. If the self-review was completed in the last round and the current round uses a different questionnaire (using the vary_rubric_by_round feature), a link called ""update"" will appear, which brings students to a new page to fill in the new rubric for the new round. 7. In grades_controller.view_my_scores, self-review responses shall be excluded. 8. In grades_controller.view_team, self-review responses shall be excluded. 9. In grades_controller.view, self-review responses shall be excluded. 10. The method called "" add_self_reviewer"" in ReviewMappingController , shall allow instructors to create self-review response maps. This method needs to be made functional again. 11. Automated tests must be created. The following files were modified in creating the new self-review feature 1. review_response_map.rb 2. review_mapping_controller.rb 3. response_controller.rb 4. _set_dynamic_review.html.erb 5. _main.html.erb 6. _review_strategy.html.erb 7. response.html.erb 8. routes.rb 9. test_helper.rb 10. submitted_content_controller_test.rb 11. factories.rb 12. test_helper.rb The following files were created: 1. self_review_response_map.rb 2. _self_review.html.erb 3. 20160321221146_add_columnselfreviewenabled.rb The following test classes were created: 1. self_review_response_maps.rb 2. self_review_response_map_test.rb 3. response_map_test.rb The following fixtures were modified: 1. response_maps.yml 2. participants.yml 3. assignments.yml 4. questionnaires.yml 5. roles.yml 6. users.yml 7. assignment_questionnaires.yml 8. response_maps.yml 9. responses.yml 10. teams.yml 11. teams_users.yml. Below are instructions that will guide users through the new functionality included in the update in order to test it. A video walkthrough may also be seen <link>. When creating a new assignment, an instructor will have an option to enable self-reviews. In order to allow for self-reviews to be completed, the instructor must check the box while either creating or editing the assignment under the Review Strategy tab. If self-reviews are available on an assignment the following will be available for students to use. 1. During the beginning stages of an assignment under ""your work"" the User Interface will show a label called Self-Review and a button which reads ""Review my/our own work"" (depending on whether it is an individual or team assignment). 2. After selecting ""Review my/our own work"" the button will change to ""Begin"" (just like how a peer review works). 3. Once the user selects ""Begin"" they will be taken to a questionnaire to complete. The questionnaire is the same one that a peer reviewer would complete. 4. Similarly to a peer review, a user may either ""Save"" or ""Submit"" their self-review. 5. After a user saves a self-review, ""View"" and ""Edit"" links will appear. However, once a user submits their self-review, they will be unable to edit the peer review. 6. If there are multiple rounds of submissions and reviews, then in all following rounds an update link will appear to allow for students to update their self-review. 7. If late submissions are allowed (via Expertiza ""submission allowed"" flag) then a user may begin and submit self reviews even in other review stages. 8. If a self-review is not submitted throughout the duration of the assignment then ""Work yet to be submitted"" will be shown. 9. Scores from self-reviews will not be considered when calculating grades throughout the assignment. To test this application from UI, follow these steps: 1. First, for students to be able to do self-review, instructor must enable self-reviews for a given assignment. This can be done as follows: 1. Login as Instructor 2. Click 'Manage Assignments' and search for an existing assignment/create a new assignment. In 'Review Strategy' tab of assignment option, check the box associated with 'Allow self reviews?' and hit 'Save' Now, as a student (part of this assignment) one gets a chance to perform self-review of their work. 1. Performing Self Review: 1. Login as Student and select the assignment you wish to self-review 2. In 'Your work' tab of the assignment, at the very bottom of the page you'll find an option to 'Review your work'. On clicking this button, you'll get an option to 'Begin' self-review 3. Similar to peer-reviews, you'll have questionnaire and options to 'Save' and 'Submit' your responses 4. If you select to 'Save' your response, in the 'Your work' tab, you'll find 'View' and 'Edit' links which will allow you to view and edit your response respectively 5. If you click 'Submit' and submit your response (Hit 'Ok' in the prompt), in the 'Your work' tab, you'll find 'View' link which will allow you to view your submitted response. The links changes per round of submission (if there are multiple rounds) 1. In submission stage, you are allowed to submit self-review and thus you can see 'Review your work button'. Upon clicking it, you'll see a 'Begin' link. On successful submission of your response, you'll have 'View' option. On successfully saving a response, you'll have 'View' and 'Edit' 2. In review stage, you'll only have an option to 'View' your response 3. If there are multiple rounds of submissions, then you'll have a new 'Update' option to submit a new response for new/same questionnaire (similar to peer-reviews) for all upcoming rounds of submissions. 4. Finally, after the assignment is finished, you can 'View' your self-review. In order to implement the self-review feature a modification of the database was required to add the column, is_selfreview_enabled , to the assignments table. Below is the new database migration: <code>. The self-review feature was implemented using the Model View Controller (MVC) pattern. The MVC pattern was chosen due to its current existence in the design in addition to it being a rails standard. There were no other new design patterns used in this implementation. The largest change to the codebase to accommodate for the new self-review feature was the addition of a new type of Response Map called ""SelfReviewResponseMap."" The new model class is shown below: <code> In order to take full advantage of the new feature, instructors had to have the ability to turn it on or off as they see fit. As a result a checkbox to goggle the self-review feature was added to the assignment settings page in _general.html.erb . Below is some sample code demonstrating the addition of a checkbox to the assignment settings: <code> Changes were also made to review_mapping_controller.rb in order to accommodate the new self-review feature. The following method was added to handle the creation of new self-review for team members. <code>. Tests have been added to confirm all of the new functionality, below are some test samples that were implemented with the changes: <code> The tests may be run via the rake test command on the project download. A live version of Expertiza, running with the self-review improvement, may be found at <link>. 1. <link> 2. <link> 3. <link> 4. <link>.","A lot of the wiki is simply a copy of the requirements doc.
They mentioned that they didn't use design patterns other than MVC, but they also didn't describe any principles they used, e.g., how they added the new rubric type into the existing types.","This is a very comprehensive and detailed presentation of your task to implement the self-review feature in Expertiza. The step-by-step description of how the feature should work is clear and I commend you for taking the time to provide ample explanation for its function. 

The documentation on the changes made to the code, as well as the creation of different files and classes, is thorough. The section on how to test the feature from UI is nicely broken down and provides clear instructions on how to navigate the self-review feature.

Regarding your approach to this assignment, there are few points that can be improved:

1. It would be beneficial if you had included more insight into the challenges you faced while developing this feature and how you overcome them. This would not only showcase your problem-solving skills but also help other students who might face similar issues in future.

2. The document is very technical and might be difficult to grasp for someone without a technical background, so it might be better if you included an overview that describes the functionality of the feature in a simpler, more concise way.

3. Assignments above are in a list form, which can make it hard to follow when reading. Perhaps converting this to in paragraph form or categorizing them based on their attributes may enhance clarity and readability.

4. While the instructions for testing the self-review feature are well detailed, it would complement it to include some screenshots or a short demo video for better understanding.

Overall, you've done an excellent job in implementing the feature and writing a comprehensive document about the same!"
113,E1788,"Expertiza is a Ruby on Rails based Open Source project. It is a collaboration tool which lets users with different roles (student, instructor, teaching assistant) to collaborate on a course in an institution. A collaboration could be for an assignment where students teams up for an assignment and instructors grades them on the basis of their submission. Students could review other's works and give feedbacks as well. 1. <link>. 1. <link>. Heatgrid is the view which summarizes all the reviews given for the work of a participant (reviews, author feedbacks and meta reviews) on a singular web page so that an instructor can go through all the feedback given to a student and decide their grade. The columns are sortable by their score, criterion, average score for a criterion or a metric. (number of comments with more than 10 words) What’s wrong with it? app/views/grades/view_team.html.erb is a fairly complex for a view. It uses the concept of view models to generate the required tables. When multiple rounds of reviews are displayed on the heatgrid, a bug prevents the second round of the reviews from being sorted by their criteria, average score, or the metric mentioned above. Tables which shows each round's report were not getting sorted except the first. 1. Find out what’s preventing the reviews in the second round from being sorted by a criterion, average score or the metric even though same code is used for first and second round of the reviews. 1. Come up with a design that can be used for all the rounds of reviews and implement it. Previously, TA was also seeing instructor's course list in their home page. 1. TAs should only be able to view the heatgrid of students for the assignments in courses for which they’re TAs for. 1. Nor should a TA’s homepage list any courses (s)he is not a TA for. 1. Improve the Access Control and allow the TAs of that particular course to view the heatgrid for the participants of that particular course. 1. <link> 2. <link>. We found a discrepancy in the unique identifier property of HTML element which was causing a bug and other was related to adding a condition for populating items in the list to be returned. We identified the bug and found that there were no major changes required in terms of back-end services or UI. We did not try to modify any existing variable names and did not either try to refactor any existing code as it was beyond the scope of this task. For Problem 1 & Problem 2 . File 1 . 1. app/assets/javascripts/view_team_in_grades.js File 2 . 1. app/views/grades/view_team.html.erb For Problem 3 . File 1 . app/controllers/tree_display_controller.rb. For all the tables on the page which had each round's data, HTML component table was given same id which was only allowing only first table to have the sorting properties. We assigned a unique id to all tables based on the round number and included a class ""scoresTable"" for each table and initialised sorting features based on class. <code> <code> <image> <image>. We found that for a teaching assistant, if he/she is not a TA of a course, private field of tmp_object (already existing name) was assigned false value. So, by adding only true values in the resource object returned for the TA, ensured that only courses in which he/she is TA of will be sent back to the view. We did not change the variable name as it was out of scope of this change request. <code> <image>. We wrote tests to verify that the courses returned are only those which are specified in ta-mapping table. For that we considered 7 scenarios 1. When there is a mapping between the user and course but user is not a TA 2. When there is a mapping between TA and course - in this case the course mapped to TA should be returned 3. When there is no mapping - in this case, no course should be returned. 4. When TA is also a student of another course 5. When TA is also a student of the same course he is TA of 6. When there is mapping between TA and course - in this case TA should receive assignments which are for the mapped course 7. When there is mapping between TA and course and no assignments are linked to the course <image> Below is the test written: <code>. Based on the scenarios we added, code coverage increased by 0.2%. More report could be found from below link: 1. <link>. 1. Login as instructor/TA (who has the privilege to view summary of reviews for all rounds) 2. Choose an assignment and go to summary page You would see a page similar to below with sorting enabled on specific columns on the right side of name. <image>. Below are the screenshots displaying the fix : <image> <image> <image>. <image> <image> <image>. <image> <link> <image>. 1. Login as a TA. You would be directed to the hop page displaying all courses a TA has privilege to view. <image> Below is the db result which matches with the results displayed on the screen <image>. A video explaining the fix can be found at below location: <link>. Pull request link : 1. <link>.","The description is pretty readable, for the most part.  Toward the end, there are too few prose descriptions.  For example, about three screenfuls of code are displayed without any commentary (apart from comments in the code) describing what it does.  If you are just going to copy code, it would be more useful just to give a link to a file in the repo.  Also, below that, screenshots are juxtaposed without any indication of which screenshot shows what.  However, overall, the documentation will be helpful to future developers.","Dear Student, 

Good job on the submission, you have demonstrated a strong understanding of the problem and implemented a good solution for it. Your focus on maintaining readability and structure of the code when proposing solutions is commendable. 

Here are some points to take into consideration:

1. Clarity of Issues: You have successfully identified and explained the problem at hand which made it easier to understand how you arrived at the solution. Keep up the good work.

2. Code Implementation: Proper use of ID and class selectors in HTML to solve the issue of round reviews not being sortable. Also, your solution for ensuring only relevant courses appear for TAs is neatly done.

3. Testing: Excellent testing approach. Considering multiple scenarios to ensure foolproof solution shows your dedication towards the quality of code.

However, there are some areas of improvement that I would like to bring to your attention:

1. Presentation: Try to maintain a logical flow when explaining your solution. For instance, you can group the issues and their solutions respectively. 

2. Images and Links: Due to privacy settings, the images and links are inaccessible. It is crucial to always verify if they work. Remember to double-check your permissions before submitting next time. 

3. Explanation of Code: While you did explain your code to an extent, more in-depth explanations would be beneficial for the understanding of the assignment reader or grader. This will also develop your ability to explain your work to non-technical people.

4. Comments in the Code: Make sure to clean up all irrelevant placeholder tags. Your code should look neat and understandable, so those reading it can focus on the task at hand. 

In conclusion, this was a well done assignment, your analytical thought process and problem-solving skills reflect in the work done. Keep up the same effort for future assignments as well. Best of luck!"
114,E1777,"This page provides a description of the Expertiza based OSS project. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.1.1. <link> 1.2. <link> 1.3. <link> 1.1.1. <link>. <link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. The following tasks were accomplished in this project: 1. Information buttons to elaborate difference between the synonymous statements present in review strategy tab need to be included. 2. The punctuation, syntax and capitalization of statements in the review strategy tab requires improvement. 3. Message to a reviewer regarding how many reviews they are required to and allowed to perform is not clear enough. 4. Reviewers are assigned new reviews based on number of previous reviews assigned for that submission, which is incorrect. Issue #402 : To allow reviewers a larger set of topics to choose from, the instructor can set the threshold (on the Review Strategy tab of assignment creation/editing) to some integer k > 0. Then any submission that has within k reviews of the fewest number can be chosen by a new reviewer. Let’s say that all submissions have at least 1 review. If k = 3, then the reviewer can choose any topic where there is a submission that has 4 or fewer reviews so far. Suppose that the minimum number of reviews for any submission is 2, but that I have reviewed all the submissions that have only 2 reviews. Then I’m not allowed to review at all (unless k > 0). 1. Solution : This issue has been fixed previously. The reviewer will get assigned a submission even if it has fulfilled the required number of reviews, to ensure that the reviewer always receives a new submission to review as long as it is not his own. Issue #969 : 1. a.The two statements ""Set Allowed Number of Reviews per reviewer"" and ""Set Required Number of Reviews per reviewer."" are not well differentiated. It can very confusing for an instructor to give values for them. 1. Solution : Information buttons have been provided beside these statements in the review strategy tab to make sure that the instructor knows the difference between the two. This modification is made in the app/views/assignments/edit/_review_strategy.html.erb <code> <image> <image> 1. b) When the number of allowed or required reviews is not set on the Review Strategy tab, the system does not have a message to display to a reviewer about how many submissions of work they are required to and allowed to review depending on the values set by the instructor in the ""allowed number of reviewers per reviewer"" field and the ""Set Required Number of Reviews per reviewer."" field. 1. Solution : This view has been implemented in the app/views/student_review/list.html.erb <code> 1. c)The capitalization and punctuation of statements such as ""Set Allowed Number of Reviews per reviewer"" and ""Set Required Number of Reviews per reviewer."" in review strategy tab are incorrect. 2. Solution : This view has been fixed by making changes in the respective files. The changes were made in the file : app/views/assignments/edit/_review_strategy.html.erb <code> 1. Issue #965 : The assignment of work to review to a reviewer depends on the number of reviews it has previously received, if that work has been assigned to a reviewer previously and its review has not been submitted then the system will still consider it such that it would not assign the same work to another reviewer if it has enough number of reviewers previously assigned to review it. This might lead to a scenario where that work was assigned to enough number of reviewers, but it does not receive enough reviews and cannot be assigned to any new reviewers either. 1. Solution : This implementation has been fixed. The system now considers only the reviews that were submitted by the reviewers for that work so that every submission gets assigned to reviewers until it receives its allowed number of reviews. The modified file is app/models/review_assignment.rb and the modification is done in the method reject_by_max_reviews_per_submission <code>. Issue #402 :This is shown graphically with dummy topics and assignment. We create a dummy assignment with two different topics oss1 and oss2. oss1 has 2 slots and oss2 has 1 slot. So when a student who has submitted oss2 tries to review others work he will not be able to select oos2 at all because he cannot review his own submission. When a person who has oss1 as topic goes to this page and he asks to get a new submission for review it will give another slot’s oss1. If he does it again it says there are no more submissions available to review for this topic. So if he has already reviewed all the other submissions of his topic oss1 and he requests for one more submission of oss1 , he will not get any more submission to review because the only one left is his own submission. Issue #969 :Set allowed number and required number of reviews per submission as 3 and 3 respectively. Now it will display ""you should perform exactly 3 reviews."" Before: <image> After: <image> <image> Issue #965 :We created a dummy assignment with a team size of 2, 3 such teams are created. Maximum allowed reviews is 2 now. Previously for a submission after 2 people begin review its does not give any further submission to review to that user because it already reached the limit. <image> On changing the method, when we try to get a new submission we receive one. This is because the previous reviewers have only begun their reviews but have not submitted them yet. <image> Now when the previous two reviewers submit the reviews they began. Now the same new reviewer will not be able to submit his review <image>. 1. app/views/assignments/edit/_review_strategy.html.erb 2. app/models/review_assignment.rb 3. app/views/student_review/list.html.erb. 1. <link> 2. <link> 3. <link> 4. <link> 5. Clean Code: A handbook of agile software craftsmanship. Author: Robert C Martin.","Generally pretty readable, but the changes to instructor and student view are not well differentiated.  Secreenshots tend to be segued together without transitions. It would also have been better to explain the changes in terms of the functionality provided, rather than the issues addressed (e.g., ""Issue #969"" is not a heading that will mean anything to the reader).","Dear Student,

I appreciate the effort you've put into this assignment and the depth of your technical understanding. Your proposal for addressing the issues in the given project were well-reasoned and clearly explained. I also appreciate the examples used. This work shows a strong understanding of how to use Expertiza and provides practical solutions to existing issues.

In terms of structure and presentation, however, there are areas which can be improved:

1. The overall organization of the document could be clarified. I suggest using clear headings for each issue and solution to make them easy for the reader to find.

2. It might be helpful to add more explanation of the images you’re referencing. You've often stated ""Before: <image> After: <image>"". But without any context or description, it's difficult for someone reading to get a full understanding.

3. The numbering used throughout the assignment is inconsistent at times. I recommend doing a careful review of this and adjust to ensure clarity.

4. Citing the work of others properly is crucial. Your citation style could use some attention. Be sure to follow a standard citation style consistently throughout your assignment.

5. While mention of reviewed and submitted work is clear, at times the narrative can be improved by avoiding redundancies and enhancing the sentence formation.

Overall, your technical description and problem-solving are commendable. Revise your work with the mentioned suggestions to enhance the organization and presentation.

Good Job!
"
115,E1722,"<link> is an open source project maintained by the students and faculty of <link> . It is a web application based on <link> that facilitates the submission and peer-review of course work. <link> is a program designed to help with testing web applications. It is able to simulate regular user interactions like clicking buttons and filling in forms. It supports a number of testing drivers, including <link> and <link> . Expertiza's heat map display is an alternative way to view assignment review scores. Instead of the standard list of reviews that are expanded one at a time, the heat map displays all reviews together in a table with scores both color coded and displayed numerically. This allows the user to quickly view all scores received and see an easily understood representation of how high or low they are. Scores show as green when they are high, and shift through shades of yellow down to red as they approach the minimum possible. The purpose of this assignment was to write functional tests for the heat map display, which it previously lacked entirely. Functional tests are a kind of block-box testing and allow the user experience to be simulated and tested. This ensures that features work as expected and meet design goals. With active development, having these tests in place ensures that any features that break due to future changes won't go unnoticed. Since our assignment was simply to implement functional tests for a small part of the Expertiza project and we only changed a single method, there wasn't an opportunity to implement any particular design pattern. We created a single file and didn't modify any existing ones. 1. heat_map_spec.rb. To run these test locally, run the following commands on a linux system <code> This will run the tests we wrote and you will be able to see the results displayed in the command prompt. For testing the heat map functionality, we used factories to create test users, groups, and assignments that reset prior to each test. <code> A test user was used to fill in and submit a review using capybara. This review then displays for the other test users. This is called to setup the review before the test is run for every case that requires a review to be present. <code> To begin testing, the test user is logged in after the first user creates the review and logs out. First, a test to verify that when no reviews are present for a user, the page does not display scores. <code> Second, the ability to view existing review scores in a heat map was tested. <code> This test checks that the user can click through to a specific reviewer to view the detailed feedback. <code> A list of the questions on the review assignment should be at the top of the screen, and should be expandable by the user. <code>. Here is a link to the <link> request we submitted.","Wrtieup should have the project number in the title.  This is a very straightforward description of all the tests.  It would really help to add a paragraph listing and summarizing the tests, so the reader could see at a glance what you have done.","Overall, this submission demonstrates a complete understanding of the assignments objectives. The student clearly knows what functional testing is and its importance in a development environment. You implicate it properly and provide thorough explanations for each process involved in your assignment. 

The way you simplify the concept of a heat map and explain its function is commendable. It was very descriptive and gave a clear understanding of its purpose and how it works.

However, moving forward, it would be beneficial to explain the kind of considerations you have made while writing the tests, for instance, how have you ensured the coverage of edge cases or tough-to-replicate user scenarios? 

I noted that you did not include an opportunity to implement any design pattern, this is good to recognize. In future projects, consider anticipating such opportunities to better refine your development process and product design. 

Your explanation on test executions was clear and highlights how the designed tests work, and each step of code utilization is adequately explained. 

One minor significant detail is removing <link>. This was obviously a placeholder and I would encourage you to replace all instances of <link> with actual references, sources, or URLs, where needed as this could create confusion if not corrected.

Overall, I am pleased with your understanding and submission of this assignment, your explanation was in depth, logical and demonstrated a clear comprehension of the topic. Well done!"
116,E1652,"For users intending to view the deployed Expertiza associated with this assignment, the credentials are below: 1. Instructor login: username -> instructor6, password -> password 2. Student login: username -> student6420, password -> password 3. Student login: username -> student6361, password -> password. Expertiza is a peer review system where the students can submit their work and do reviews on fellow students’ work. Expertiza is an open source project and is based on “Ruby on Rails” framework. Expertiza facilitates easy creation of assignments and a list of topics for the same. It allows students to suggest a topic for an assignment as well. Students can form teams and invite other students to join their team for various assignments. Moreover, students can post team advertisements and describe the qualities they are looking for in their team members and other students can respond to the same. Expertiza overall gives a simple web interface for assignment management for both the students as well as instructors. In Expertiza, there are teammate advertisement, invitation and join team request features which facilitate students to form teams. Teammate advertisement works only for assignments with topics. The topic holders can create advertisement and a trumpet icon will show on the signup sheet page. If one respond to the advertisement, a join team request will be created and the topic holder can see it on “Your team” page. After a student get a team and the team is not full, (s)he should also be able to send invitations to others. All commits have been done from a single machine using id sndesai92 but all team members have worked on the project. Team members: 1. Saloni Desai 2. Shriyansh Yadav 3. Vaibhav Shinde. When a student gets accepted by a team, all the other join team requests/pending invitations should be removed. Current Scenario : When a student gets accepted by a team, all other join team requests/pending invitations are still shown on his page and their corresponding entries in the database. Fix: Files Changed app/controllers/invitation_controller.rb <image> If a student accepts an invite and that add was successful to the database, we call remove_pending_invitations() passing the student’s user_id and the current assignment_id to be deleted from the list of pending invitations. Similarly, we call remove_pending_join_team_requests() passing the participant_id as a parameter. Participant_id is fetched from the Participant table which gives data on which all students participate in a particular assignment. remove_pending_invitations() and remove_pending_join_team_requests() methods are defined in models/invitation.rb and models/join_team_request.rb as these methods are manipulating the database and it has to handled by the models while controller simply invokes these methods. app/models/invitation.rb <image> remove_pending_invitations() looks for all entries in the Invitation database that matches the student_id and an assignment_id and has a reply_status as waiting and destroys all of them. app/models/join_team_request.rb <image> remove_pending_join_team_requests() looks for all entries in the JoinTeamRequest database where a matching participant_id and the status is pending and deletes all those entries. When one respond to an advertisement, (s)he should only be able to respond once. Current scenario: A student can respond to an advertisement any number of times. Fix: Files Changed app/controllers/join_team_requests_controller.rb <image> We check if the join request initiated by a student is a firstRequest? . If it is a firstRequest? we allow the student to save the join request to the database else we flash a note saying the student has already responded to this particular advertisement once. app/models/join_team_request.rb <image> firstRequest? method fetches all entries from JoinTeamRequest table with a matching team_id and participant_id . If the number of entries returned by this query is less than 1 means the student is requesting a join team request for the first time. If user A got a topic and user B got no topic, then A join B’s team, A’s topic be be dropped and A and B end up with a new team with no topic. This issue should be handle carefully because we cannot simply add B to A’s team (imagine, if A has teammate X and B has teammate Y...). One of a potential fix is that, for assignment w/ topics, one cannot not post an ad unless (s)he holds a topic, similarly, one cannot sent invitations unless (s)he holds a topic. Current Scenario: A student cannot create a team advertisement without a topic but can invite other students to join his/her team without a topic. Fix: Files Changed app/views/student_teams/view.html.erb <image> Here we give access to the invite people link if and only if the team is not full and the student has a topic. If the last member leaves the team, all the records will be deleted (like sign_up_topics, reviews done on this teams work, etc). We have to respect the decision of the students when they leave. But the team record should not be deleted if this team’s work has already got reviewed. Current Scenario: If the last member leaves a team, the entire team is destroyed and a destroy on team creates a ripple effect thus destroying all the work done by this team. Fix: Files changed app/controllers/student_teams_controller.rb <image> app/models/response_map.rb <image>. The advertisement does not work properly when there are 2 teams posting advertisements on the same topic. Current Scenario: When 2 students post team advertisements for the same topic and a third student clicks on team advertisements, it shows both students' team advertisements. Step 1: Login as an instructor. Create a new assignment (Assignment1) and related sign up topics (Topic1, Topic2, Topic3) and add atleast 4 students as participants. (student1, student2, student3, student4) Step 2: Login as student1. Sign up for Topic1 for Assignment1. Create a team advertisement. Step 3: Login as student2. Sign up for Topic2 for Assignment1. Create a team advertisement. Step 4: Login as student3. Sign up for Topic3 for Assignment1. Invite student4 to join your team. Step 5: Login as student4 and respond to student1 and student2’s team advertisements. Step 6: Login as student1. Invite student4 from the response received to your team advertisement. Step 7: Login as student4. Accept student1 invitation. Outcome: This should delete pending team request send to student2 and delete the join team request sent by student3. Step 1: Login as an instructor and create a new assignment (Assignment1) and related sign up topics (Topic1,Topic2) and add students (student1,student2) as participants. Step 2: Login as student1 and sign up for Topic1 for Assignment1 and create a team advertisement for the same. Step 3: Login as student2 and respond to student1’s team advertisement for Assignment1. Step 4: Now as student2 again try to respond to student1’s team advertisement. Outcome: This should flash a message saying you have already responded to this team advertisement. Step 1: Login as an instructor and create a new assignment(Assignment1) and related sign up topics (Topic1,Topic2) and add students(student1,student2) as participants. Step 2: Login as student1 and before signing up for a topic go to your team’s page. Outcome: It shouldn’t allow you to invite other people to join your team or create advertisements unless you have a topic assigned to you. It cannot be tested from the UI as the team is not visible from the UI but still the entries in the databases are preserved if the team;s work is reviewed and the last member of the team leaves the team. 1. <link> 2. <link> 3. <link>.",Good job of describing the changes made and the manual testing process.,"Dear [Student's Name],

I appreciate the effort and detail you put into this assignment, explaining the Expertiza open-source project and the measures you've taken to address the issues you've identified.

Your conscious approach to propose updates is commendable, like removing pending invites once a person joins a team or limiting a student's ability to respond to an advertisement once. I also appreciate your insights regarding assignment topics and handling the process of team formations.

Your code modifications appear well thought out, however, it's difficult for me to evaluate them fully without the context of the actual code, since you've not provided it. Going forward, please submit actual code samples or snippets instead of denoting them as ""<image>"".

Regarding the assignment write-up, I have a few suggestions. It would help to break up different sections with clear subheadings to make the text easier to navigate. 

The test scenarios you described could benefit from being more concise, and results more explicitly defined, as clarity is vital when explaining testing procedures and outcomes. Do make sure you explain the outcomes in a manner that demonstrates the successful outcome of the test cases and the way they benefit the system.

Despite these minor areas for improvement, your submission demonstrates deep understanding of coursework topics and an ability to apply class learning to practical issues.

Good work, and I look forward to seeing your growth in future assignments.

Best Regards,
[Your Name]"
117,E1607,"This page outlines the use tests for assignment creation using the Expertiza system Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link> 1.1.8. <link>. Assignment creation in Expertiza provides a large number of options for users. Features come at the cost of complexity; this project is focused on creating testing methods to ensure that user interaction with the assignment interface remains stable and reliable. Assignment creation is available from the Manage -> Assignments drop down on the expertiza site. Once an assignment is created it has 5 tabs for form entry. The remainder of this document will cover testing for each tab in more detail, the tabs are: 1. General 2. Topics 3. Rubrics 4. Review Strategy Check the panxing01/expertiza repository for the current development files. Currently all tests are run in two files: 1. <link> 2. <link>. The Assignment class has many questionnaires throught the AssignmentQuestionnairs class. The Questionnaire class inherits from ActiveRecord::Base and has 8 fields plus primary key and date entries. The fields are: 1. name: The name of the questionnaire row 2. instructor_id: The instuctor key linked to the row 3. private: True if private questionnaire 4. min_question_score 5. max_question_score 6. type: field showing subclass 7. display_type 8. instruction_loc: stores URL for questionnaire instruction The Questionnaire class has 11 sub-classes. They are: 1. Rubric 2. CourseEvaluationQuestionnaire 3. SurveyQuestionnaire 4. BookmarkRatingQuestionnaire 5. AuthorFeedbackQuestionnaire 6. QuizQuestionnaire 7. GlobalSurveyQuestionnaire 8. Metasurvey 9. ReviewQuestionnaire 10. MetareviewQuestionnaire 11. TeammateReviewQuestionnaire. To set up functionality testing of assignment creation feature we did the following steps: 1. Created RSpec file in /spec/features/ folder of <link> 2. Wrote functional tests using <link>. In this section, the functional test includes assignment name, course, submission directory, description URL, ""Has team?"", ""Has quiz?"" and ""Calibrated peer-review for training"". 1. assignment name <code> 1. course <code> 1. submission directory <code> 1. description URL <code> 1. ""Has team?"" <code> 1. ""Has quiz?"" <code> 1. ""Calibrated peer-review for training"" <code>. In this section, functionality of ""Edit topics"" is thoroughly tested. Below are some of the code snippets of this testing module: 1. Edit topics content <code> 1. Show/hide teams <code>. Rubrics are arranged into 3 rows of data named ""Review"", ""Author Feedback"", and ""Teammate Review"". Each row is handled under separate descriptions in order to allow quick and comprehensive testing for the seperate functions. Each row updates using a subclass of the Questionnaire class for dropdown values. Classes used are the ReviewQuestionnaire, AuthorFeedbackQuestionnaire, and the TeammateReviewQuestionnaire respectively. Testing required creation of the three questionnaire subclasses in order to populate the dropdowns. Basic code layout for testing each value change: <code>. In this module we have tested the functionality of the ""Teammate Review"" module. Some of the tests are given below: 1. Teammate Review <code> 1. Notification limit <code>. The tests can be run on the terminal using the command: <code> We can check if the functionality of the system is implemented properly seeing if the corresponding tests pass or fail.","The class hierarchy didn't need to be included in this document.  Not sure why it was.
The wiki is supposed to explain why you've written what you wrote.  But you seem to have copied the code and inserted only a line or two, not much more than in the comments in the code file.","Your assignment presents a thorough outline on testing assignment creation on Expertiza, and highlighting the complex nature of this process is very important, good job on that. However, your assignment lacks examples of the actual test cases executed and screenshots of the output or error messages of failed tests. This could provide a more in-depth explanation and make the assignment more comprehensible.

Moreover, while you've included links for reference, they are currently placeholders and not clickable URLs. Providing actual URL links to the referred content would be helpful for anyone reviewing or learning from your work.

In your description of the tabs, it might be beneficial to provide more specific details about their functionalities and significance in the scenario rather than straight away jumping into code snippets and tests.

You've also gone into quite a few details about the questionnaire sub-classes but less so about their significance or the specific type of tests conducted on them. Include more context as to why they were designed in this way and how they affect the functional testing process.

Overall, the content of your assignment is well-researched, but requires more context and real-life application to be effective. Please revise this assignment taking into consideration the given points."
118,E1770,"<link> is a peer review based system which provides incremental learning from the class. This project has been developed together by faculty and students using <link> framework. Expertiza allows the instructor to create, edit and delete assignments, create new assignment topics, assign them to a particular class or selected students, have students work on teams and then review each other's assignments at the end. For the students, they can signup for topics, form teams, and submit their projects and assignments. Students then review the work done by other students and give suggestions to improve. Teams after reviews are allotted scores and they can refer to the peer comments to further improve their work. It also supports submission of different file types for assignments, including the URLs and wiki pages. Code Refactoring <ref>Refactoring <link> </ref> is the process of restructuring existing computer code—changing the factoring—without changing its external behavior. Refactoring improves nonfunctional attributes of the software. Advantages include improved code readability and reduced complexity; these can improve source-code maintainability and create a more expressive internal architecture or object model to improve extensibility. Typically, refactoring applies a series of standardised basic micro-refactorings, each of which is (usually) a tiny change in a computer program's source code that either preserves the behaviour of the software, or at least does not modify its conformance to functional requirements. Many development environments provide automated support for performing the mechanical aspects of these basic refactorings. If done extremely well, code refactoring may also resolve hidden, dormant, or undiscovered bugs or vulnerabilities in the system by simplifying the underlying logic and eliminating unnecessary levels of complexity. If done poorly it may fail the requirement that external functionality not be changed, introduce new bugs, or both. Test-driven development (TDD) <ref>Test-driven development (TDD) <link> </ref> is a software development process that relies on the repetition of a very short development cycle: Requirements are turned into very specific test cases, then the software is improved to pass the new tests, only. This is opposed to software development that allows software to be added that is not proven to meet requirements. The followings are several benefits of Test-driven development (TDD). 1. Maintainable, Flexible, Easily Extensible. 2. Unparalleled Test Coverage & Streamlined Codebase. 3. Clean Interface. 4. Refactoring Encourages Improvements. 5. Executable Documentation. RSpec <ref>RSpec <link> </ref> is a 'Domain Specific Language' (DSL) testing tool written in Ruby to test Ruby code. It is a behavior-driven development (BDD) framework which is extensively used in the production applications. The basic idea behind this concept is that of Test Driven Development(TDD) where the tests are written first and the development is based on writing just enough code that will fulfill those tests followed by refactoring. It contains its own mocking framework that is fully integrated into the framework based upon JMock. The simplicity in the RSpec syntax makes it one of the popular testing tools for Ruby applications. The RSpec tool can be used by installing the rspec gem which consists of 3 other gems namely rspec-core , rspec-expectation and rspec-mock. Refactor AssignmentParticipant model which is a subclass of Participant model. The following tasks have been performed as per the requirements. 1. Refactor scores method. 1.1. Write failing tests first. 1.2. Split into several simpler methods and assign reasonable names. 1.3. Extract duplicated code into separate methods. 1.4. Replace the conditional with the relevant method calls. 1. Method files is exactly the same as assignment_team.rb L103. 1.1. Write failing tests first. 1.2. Solve the duplication, extract method to a new file or delete useless one. 1. Method self.import is exact the same as course_participant.rb L21. 1.1. Write failing tests first. 1.2. Solve the duplication, extract method to a new file or delete useless one. 1. Use find_by instead of dynamic method. 1.1. Write failing tests first. 1. Use find_by instead of where.first. 1.1. Write failing tests first. Because the project is aimed at using TFD(Test First Development) to refactor the AssignmentParticipant model. We wrote 38 test cases for 24 methods in assignment_participant_spec.rb first, with the RSpec tool. The introduction video to our project<ref>Introduction video to our project <link> </ref> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code>. The method scores has been converted to smaller methods scores , assignment_questionnaires , merge_scores , topic_total_scores , calculate_scores . It is a good practice to keep the methods not extremely long as they tend to complicate the functionality and the readability. <table>. The files method of AssignmentParticipant model is exactly the same as assignment_team.rb, L103 , so we move it to a module named Instance_method in lib/TFD1770_refactor.rb . The below two lines are added to the AssignmentParticipant model and AssignmentTeam model. require 'TFD1770_refactor' include Instance_method 1. module Instance_method <code> <code>. The self.import method of AssignmentParticipant model is exactly the same as course_participant.rb, L21 , so we move it to a module named Class_method in lib/TFD1770_refactor.rb . The below two lines are added to the AssignmentParticipant model and CourseParticipant model. require 'TFD1770_refactor' include Class_method <code> 1. module Class_method <code>. Use find_by instead of dynamic method <table> Use find_by instead of where.first <table>. 1. Expertiza Github repository<ref>Expertiza Github repository <link> </ref> 2. Our Github repository<ref>Our Github repository <link> </ref> 3. Our pull request<ref>Our pull request <link> </ref>. <references/>.","You can assume that your readers know about Expertiza and RSpec.  You can launch right into the Project Description.  It's great that you wrote so many test cases, but just displaying them is not helpful.  It would be easier to read them in Github.  There should be a description of each test, and they should be organized in a way that is easy to comprehend.","Dear Student,

Thank you for your submission. This is an impressive piece of work and it shows a great understanding of the procedures involved in code refactoring and test-driven development. It's clear you took some time to analyze the code and have applied your knowledge to improve substantial parts of it. 

On the positive side, your step-by-step approach to the problem was excellent and it allows anyone to follow your logic and understand what you were aiming to achieve in this project. It's great that you first wrote failing tests before embarking on the refactoring process, this indicates a good understanding of TFD, which is an important foundation of developing solid, reliable code.

However, it would be helpful if you can provide more of your thoughts for each action – why did you decide to refactor certain methods and not others? This would be useful explanation for other developers and for your own reflection. In some places where you've written ""<code>"", I assume that's where code should have been included. A clearer presentation of your code and results would also be beneficial.

Regarding the test-driven development process, the advantages mentioned provide a clear justification for why this methodology is useful. However, the precise application of these principles to the given assignment could have been described more thoroughly. For instance, how did these benefits manifest in your project? 

On the overall, your understanding and execution of concepts like refactoring and TDD are commendable. For future projects, aim to tighten your explanations and justifications, and make sure every step is well-documented and easy to follow.

Looking forward to your future submissions. 

Best,
[Your Name]"
119,E1964,"This page provides a description of the <link> project undertaken for OSS component in Object Oriented Design and Development. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.2. <link> 1.3. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link>. <link> is an Open Source project based on Ruby on Rails framework. It is a software to create renewable learning projects through peer reviews and continuous assessments. It enables group projects and project submissions via URLs and wiki pages as well. It is supported by the National Science Foundation. This project aims to easily handle review score exporting for instructor and TAs, when they try to export scores from Expertiza to <link> . Currently, no such option exists to export scores so that it can be later uploaded to WebAssign efficiently. All tasks pertaining to the completion of the project have been listed out here as follows: 1. A new button has been added to export scores. 2. All functionality to be handled will be taken care of using VanillaJS in the view of Review Report. 3. Tests have been written for the UI and CSV creation. 4. Files modified: <code>. Diagrammatic representation of the workflow of the project is shown as follows: <code> Screenshot of the Review Report page with the option to export scores (marked in red): <code> Code snippet of the added button: <code>. 1. <link> is the link to a screen recording on how to access the functionality and export the CSV file. We have written two methods inside _review_report.html.erb named exportTableToCSV and downloadCSV which are as follows: <code> <code> The output file has ""name"", ""unity_id"", ""email_id"", ""grade"" and ""comment"" fields from the Review Scores Report table. <image>. The code has been designed such that all the reviews completed by reviewers for a particular assignment can be seen, graded collected and stored easily by the click of a button. Thus, a good test case would be to check whether the required headers and data are getting stored and to check whether junk data gets stored in the csv if there are no reviews by reviewers. Newly created test cases include: 1. Test cases to check for the UI elements in Review Report html page. 2. Test case to check whether added button (""Export Review Scores To CSV File"") is actually rendered in the html page. <code> 1. Test case to see whether a simple CSV with the correct headers (Name, Unity ID, Email ID, Grade and Comments) is being created. <code>. <code>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.","1) Concise and to the point wiki
2) Good architecture diagram and clear explanation of code changes
3) Tests are explained clearly
4) Only con is they have copy pasted the whole code, but since the code is well commented, it is still easy to understand.  Would have been much more readable if presented in Github diff view.","Dear Student,

First of all, I want to commend you on your thorough work on this project! I can see the effort you took not only to complete each task, but also to document each step you took thoroughly. I appreciate especially that you gave contextual details about the software you were working with and the specific aims of your project. This gave me a good sense of why your work was necessary and how it contributed to the overall functionality of the software.

In terms of improvement, I would suggest using headings and subheadings to organize your assignment better. This will make it easier for the reader to navigate through your report, particularly because you have included quite a large amount of information.

Furthermore, your report will benefit greatly from more explanations of the code snippets you provided. Instead of just presenting the code, explain what it does, how you came up with the solution, and any potential limitations or alternatives. This will demonstrate your understanding of the software in a more in-depth manner.

Also, I noticed you mentioned that you had written tests for the UI and the CSV creation. However, it was not very clear how these tests were implemented or what their results were. It's great you included the test cases created, but it also would be informative to add more explanation about what is being tested and why it is important to the overall project.

Lastly, there is a repetitive sequence of numbers for your links. Make sure each number reflects to specific content to avoid confusion. 

Overall, your assignment was very complete, just a bit disorganized that made it somewhat difficult to get through, try to take these points into consideration in your next project reports.

Best regards,
[Your name]"
120,E1931,"Current conflict notification sends an email to the instructor whenever two reviews for the same submission differ “significantly” on their scoring (the threshold is specified in the “Notification limit” on the Rubrics tab of assignment creation). Right now an email is sent at any such time one of these conflicts happen, and it links to the review or submission which initiated the notification. It gives the link in raw HTML, but it should give it as a link associated with text, such as the text “this new review” linking to the page that shows the review.The email send to the instructor should also link to page that shows data on each of the reviews done on this team. Currently, this feature works as follows: <image> Whenever a new review is submitted, it is compared with the average of the previously submitted reviews. If the difference between the new submission and existing average is more than the threshold limit set, then a mail is sent to the instructor.With every review submitted for an assignment of a particular student, the average is updated.The mail sent to the instructor contains the links to the conflicted review and a summary of the reviews. Currently whenever the conflict happens,a summary link is sent to the instructor which contains the score of all the reviews but there is no view where the instructor can see all the conflicts and analyze them. The existing email body uses hardcoded URLs mentioned in models/response.rb file in the method notify_instructor_on_difference. Being hardcoded, these links wouldn't work on other servers where Expertiza is running. For Example, if the setup is done on localhost, the links will not be functional. <image> 1. Conflicting Review which triggered the mail <image>. The scope of this project is to send an email notification to instructor which will contain links to the conflicting review, summary link, and a link to report which can be used for analyzing. The new report will have the information like the Team(having conflicts), the standard deviation for the team review score and pictorial representation of all the review scores. The email sent to the instructor should link to a page that shows the data on each of the reviews done on this team: 1. The name of the team. 2. The members (user-IDs and/or names) 3. One line for each review received.In this line would be 1. The name of the person (or team) that submitted the review, which would be hyperlinked to the review itself 2. The score given for the review 3. A bar chart showing pictorial view 1. The average score received from reviewers. 2. The standard deviation of the score received from reviewers. 3. Review scores that are outside some “tolerance” limit should be highlighted, e.g., boldfaced or shown in a different color.Probably the tolerance should be, perhaps, one or two standard deviations from the mean. 1. Feature 1: New page to show the conflict report A new view page of the report which will have the following information:- 1. The name of the team. 2. The members of the team. 3. The name of the reviewer which would be hyperlinked to the review itself. 4. The score given for the review. 5. A bar chart showing pictorial view of all the reviews for a particular team. 6. The average score received from reviewers. 7. The standard deviation of the score received from reviewers. 8. Conflicting reviewers are highlighted.These are those which are two standard deviations away from the mean. This view have a report of all the teams on one page.This report link is added to the mail that is already being sent whenever some conflict happens.This report page will be also accessible from the reports drop-down in the instructor view. 1. A new partial is created for this view - <code> 1. Partial for the display for reviewers,scores and metrics <code> 1. Sample view of the new report - <image> 1. Method to get all the answers(scores) for a reviewee on an assignment for a particular round <code> 1. Method to get the maximum score for an assignment and for a particular round <code> 1. Method to create the bar chart showing the review scores per round <code> 1. Method to get the team members <code> 1. Method to find the standard deviation <code> 1. Method to find the average score per round per team <code> 1. Method to get the review score for each round of particular team <code> 1. Method to create a response map for the reviewers and reviewee as well as the teams and the reviewee_id <code> 1. Method to get the reviewers of a particular assignment and particular reviewee <code> 1. Feature 2: No hardcoded URLs Hardcoded URLs are be managed by the config file in order to make these links functional on every server running Expertiza and raw URLs will be given some meaningful names. 1. Code changed for removing the hardcoded URLs <image>. To test code implementation and correctness of the modified feature, we had done the following tests:- 1. Run and pass existing RSpec Tests 2. UI testing for the new functionality 3. Develop New RSpec Tests for the new code. All the existing related rspec tests have tested and they all passed wit 0 failures. Majority of the new functionality concerns with the new view,so we have mainly done the UI testing shown below.Some of the Rspec test added are shown below: 1. Rspec Tests for Answer Model <code> 1. Rspec Tests for Report Formatter Helper methods <code>. We have created a <link> showing the new functionality. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. <link> 8. <link> 9. <link> (New Created) 10. <link> (New Created) 11. <link> 12. <link> 13. <link> 14. <link> 15. <link>. 1. <link> 2. <link>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.","It is good to show the code, but I would have preferred a full-color report from Github's diff function, like you did with Feature 2, No hardcoded URLs.  You could also have described the changes with more than a one-line bullet point.","Instructor feedback:

The level of detail and thoughtfulness you've put into this work is commendable. You have demonstrated a strong understanding of the concepts and have applied them effectively in this problem. 

I appreciate that you provided information about the existing setup of the feature, possible loopholes, and then provided your solution. This makes your approach comprehensive. 

Also, the descriptive, step-by-step presentation of methods is quite detailed which indicates thoroughness and order in your work. 

However, there are areas where the assignment could use some improvements:

1. I noticed that you've inserted placeholders for code blocks, test cases, and images. Please make sure to include all these pieces in your final submission for complete evaluation.

2. Similarly, I see many placeholders labelled `<link>`. Please ensure to replace these with actual useful resources or references for proper context.

3. Your assignment lacks a brief introduction and conclusion summarizing your approach, key findings, results, and future recommendations. 

4. Formatting and organization need some attention. Sub-headings for different sections in your assignment would increase readability.

5. For methodological considerations, consider explaining why you chose a particular approach over others. What are the advantages or disadvantages?

6. Lastly, it would have been beneficial to see a bit more critical analysis related to the implementation process, potential challenges, and ways to overcome them.

Looking forward to a more polished and complete version of this impressive work. Keep it up!"
121,E1846,"As part of the project we were given task to fix following two issues. 1. <link> : In the existing Expertiza setup, the database supports only UTF-8 characters. Hence, if a user enters a non UTF-8 character, the database throws an error. This further leads to loss of data while refreshing or going back to the input page as data wasn't saved in database, effectively leading to loss of entire review if there's even a single non UTF-8 character. We need to solve the problem by removing such unsupported characters. 2. <link> : The existing expertiza stores the HTML formatting tags (Like <b> for bold) as a string. However, while rendering the string these tags are not escaped, resulting in no formatting. We need to solve the issue and display proper formatting. These are important issues from usability point of view and need to be fixed. While trying to save utf8 chars the application was throwing up error as following <image>. If a user looks at the review score table, he/she can see html tags along with the review comments. There are other instances such as the self review page where the problem is repeated. <image>. One of the solutions proposed was filtering out the non-UTF8 characters before saving the input in the database. Since the non-UTF8 input can come from any view, we implemented a filter_non_UTF8 method in application controller to do just that and adhere to DRY principle. An alternative approach will be removing the problematic characters within individual functions, but this leads to repetitive code and a violation of DRY principle. However, while experimenting with the fix, we found out that not all tables support UTF8 formatting. For E.g., the versions table which has the latin charset. <code> We changed the charset with the command: <code> Output of show create table now is <code> This solved the problem. Therefore, we created the migration VersionTableSupportUTF8 to change version's characterset. <code> <code> If we want to fix this in all tables, we can do following for each database via script or add migration for each table. <code> Thus we see that after lot of exploration and careful debugging we were able to zero down on the root cause. This approach is the best possible outcome as it is not a point fix and solves the root cause. Fix also avoids any duplication of code / point fixes. The HTML template issue was caused due to a security feature of Ruby , which by default does not evaluate strings. To resolve the HTML template issue, we used the sanitize() function. This strips all the tags that aren't whitelisted, thus ruby now renders the standard HTML tags. We have sanitized required pages. <link> We had to carefully test all flows where the html tags were getting rendered. We discovered about more than 2 places where this could be done. However there were additional screens such as tooltip in grade scores which too were showing html tags. Therefore we added code to strip tags in html. For tooltip changes, sanitize does not work, therefore we escaped all html form the text. <code>. The following files were modified for this project namely: 1. Refactored application_controller 2. Refactored self_review_popup 3. Created a new migration - VersionTableSupportUTF8 4. Created Rspec file application_controller_spec.rb 5. Changed app/views/grades/view_team.html.erb 6. Changed db/schema.rb. To check if our fix for rendering html tags works we relied on manual setup and verification. We reran the steps that were causing the issue in first place and checked if it is fixed by inspection. Steps for verification : 1. Log in as instructor6 2. Create a copy of “Final Project (and design doc)” 3. Change all due dates to today’s dates. Enable “Use signup deadline” as well and set that date to day’s date 4. Save 5. Click on add participants, then import all participants from course (The following steps assume student7488 and student7489 were added to the course during this step. Double-check to make sure they were added, or use some other students that were added) 6. Login as student7488 – sign up for the first topic. 7. Login as student7489 – sign up for second topic. 8. Login as instructor6 – set signup date to yesterday’s date (so we are now past the sign up deadline) 9. Login as student7488, submit any example hyperlink for this assignment. Perform a self review under “Your scores” (Add bold, italics, lists etc.. in this review as well) 10. Do the same as student7489 11. Login as instructor6 – set submission date to yesterday’s date (so we are now past the submission deadline) 12. Login as student7488 – go to “Other’s work” and click “Request new submission for review”. Perform review. 13. Do the same as student7489. 14. Login as instructor6 – set review1 date to yesterday’s date 15. Navigate back to “Manage -> Assignments”. Click on “View review report”. On the top-left dropdown, select “Self-review report”. Click on “View”. Click on student7488 in the “Self Review” column. You will not see HTML tags if you had entered them in step 9 instead appropriate html will be rendered. Video of running output is available here: <link> -- As you can see in the later part of the video, HTML tags have been rendered correctly. 1. Repeat 1-8, create assignments and add reviewers 2. Login as student2 and give review that contains html tags, logout 3. Login as student1 and check reviews After the fix ( refer to section 3.2 ) Following is the output with html escaped. <image>. 1. Edit any text field and enter a supported UTF8 character. 2. Save. 3. Try to edit it again and try to save. Earlier, this step was failing as it tried entering UTF8 character to the versions table which did not support UTF8. After the fix, editing it works as seen here: <link>. We have added Rspec tests to test that the given non-UTF8 character is removed and a valid UTF-8 character is not removed. This ensures that the functionality is exhaustive. The video is available here: <link> Both the Rspec tests pass: <image>. 1. GitHub pull request: <link> 2. Video Issue 1: Non-UTF8 character removal test + Rspec runs: <link> 3. Video Issue 1: UTF-8 character support : <link> 4. Video Issue 2: Rendering HTML : <link>.","Most reviewers think the writeup was good.

The document is well-structured. The issues to be fixed, the approach and the test plan have all been clearly mentioned. Links to videos are also included.","Thank you for your thorough and detailed work on this assignment. Your approach to understanding the problem, finding root causes, and coming up with solutions is commendable. You have shown great skills in code troubleshooting and debugging. You have also written a thoughtful and comprehensive analysis of the approach you took to solve the specified issues, and have included all necessary information in your submission.

The decision to filter non-UTF8 characters in the application controller is well-reasoned, and your argument for a more generalized solution displays a good understanding of software maintenance and the DRY (Don't Repeat Yourself) principle.

You've also shown great practicality in your approach to deal with the HTML tag rendering issue, effectively utilizing Ruby's sanitize function to ensure safe rendering of the required HTML tags.

Your testing methodology is exhaustive - it is great that you executed manual verification and created detailed step-by-step test cases for future reference. Moreover, the inclusion of Rspec tests reinforces the reliability and maintains the quality of your fixes.

However, it would have been even more beneficial if you could have explored additional testing methodologies like unit tests or automated testing tools. It's also important to keep in mind that relying heavily on manual verification comes with its own set of risks, so considering more automated ways to test your fixes can lead to even more reliable results in the future.

The use of a version control system and providing the pull request link shows good organization and collaboration practices. In addition, the documentation through various videos is appreciated - it offers transparency to the work done and helps understand your solution approach better.

Overall, your solutions appear to be well thought out and thoroughly tested so great job on this assignment! Keep it up!"
122,E1963,"1. E1963 This project aims to enable the instructor to change the role of an assignment participant. There are two ways to add a new assignment participant, first being through the Add button on the assignment participant page. Another way is to import via a spreadsheet with the list of users that are to be added. The motivation of E1963 was to enable the instructors adding these users using either of the methods mentioned above to change these users' role. A user can have one of the following roles - participant, reader, reviewer, submitter. 1. The existing UI had the a dropdown that displayed the role of the user: submitter, reviewer, quiz-taker, or ""participant"" (a ""participant"" can perform all three roles). We have added a Submit button below each dropdown to enable the instructor to change the role of the user. On clicking the submit button, the role associated with that user is changed in the persistent storage. We have also added a flash message which confirms the change to the user. The following issues were targeted in this project: 1. #1: The instructor does not have the option to change the role of the user, once he/she has been added to the assignment. Thus, if the instructor wishes to change the role of a user from say a reviewer to a submitter, he/she is not able to save the changes. 2. #2: With the changes made for the issue mentioned above, the instructor will be able to save the changes manually. We would like to maintain the same behavior when the assignment participants are imported from excel. Upon creating a new user using an Excel import, the user should have the role of a participant by default. An instructor was then unable to change the role of the assignment participant. <code>. For each of the assignment participant record, there is a dropdown which contains the role of the participant. When the instructor attempts to change the value in the dropdown, it is not reflected in the backend, as there is no call associated with it, to submit the changes. Thus when the user revisits the page, the changes would he would have made are not retained. Authorization of the user is based on the flags can_submit, can_review and can_take_quiz flags, which are set to be true or false based on the role of the user. By default, the user is assigned the role of a participant in any assignment. Thus, the goal is to modify these flags and save them in the database when the role of the assignment participant is changed, so that it is a persistent change. Authorization of the users based on the flags can be deduced as follows: 1. Participant has can_submit=true, can_review=true and can_take_quiz=true 2. Reader has can_submit= false, can_review=true and can_take_quiz= true 3. Submitter has can_submit=true, can_review= false and can_take_quiz=false 4. Reviewer has can_submit=false, can_review= true and can_take_quiz=false Problems: 1. 1. There is no way to change the role of the user, once the user has been added to the assignment as a participant. (Submit button now resolves this issue.) 2. 2. Instructor is not given any confirmation that the role of the participant has been reverted to the original value once he/she navigates somewhere else. This is misleading for an instructor as the he/she might be under the impression that the changes he/she made have been saved. (Flash message now lets the user know about the change.). 1. As an Instructor, go to Manage Assignments <image> 1. Click on add participant <image> 1. Note that the user on the first record is currently a ""Reader"" <image> 1. Change the role of the ""Reader"" to say ""Submitter"" <image> 1. Refresh or re-navigate to this page and note that the changes are reverted <image>. Changes are made in the partial for participants ""_participant.rb"", so that the submit button is rendered on the view. Upon changing the selected value for the user role, 'update_authorizations' method is called from participants controller which passes the participant id as a parameter to the method to change its role in the database. The selected role is passed as a parameter 'authorization' to the update authorization method that updates the can_submit, can_take_quiz, and can_review flags appropriately for each role as described above for the selected participant id. Implementing the above mentioned changes, allows the instructor to change the value of role in the dropdown which retains the corresponding record on tap of the Submit button. We have verified that the changes in the above mentioned flags are reflected in the database. The instructor will be presented with a success message on changing the role of the selected participant, on clicking submit. The instructor can revisit the page and expect the updated value to be retained. Both the problems listed above are taken care of such as the instructor is facilitated with an option to change the participant, as well as knows that the change made will be durable. 1. Submit button has been added to each row of assignment participants <image> 1. Change the ""Reader"" to ""Submitter"", on the first record and click on submit. Changes have been persisted. Flash message confirmation is also provided to the Instructor to let him/her know of the change. <image>. (These changes were not part of the assigned issue E1963, these are additional issues that we encountered while fixing E1963) In addition to the above-mentioned issue, we fixed a few other issues that we observed , which were relevant to Assignment Participant and Course Participant Controllers, namely: 1. Export Details in Assignment Participants view: We noticed that a a blank csv file was getting generated on exporting detail button in Manage Assignments. We discovered that the reason for this issue is that in the import method, the model defined was that of AssignmentParticipant whereas all the parsing methods for export were present in Assignment model. We did the required changes, tested the functionality and note that this is working fine now. The changes for this are made in the common module - export_file_controller.rb following which the export and export_details methods are now called from the assignment.rb as opposed to assignment_participant.rb where there are no export methods and their corresponding implementations. Now, the Export Detail button generates a comma-seperated file with the following headers: 1. Assignment Name 2. Assignment Instructor 3. Team ID / Author ID 4. Reviewee (Team / Student Name) 5. Reviewer 6. Question / Criterion 7. Question ID 8. Answer / Comment ID 9. Answer / Comment 10. Score 2. Along with the previous issue, we found that since the partials were shared among Assignment Participant and Course Participant, Course Participant also had the Export Details section and the corresponding button. However, it is not required and we believe that it should be removed from the view. We consulted Dr. Gehringer and based on his feedback as well, we removed the semi-view consisting of ""Export Details"" from Course Participant. The changes are made in the file ""start.html.erb"" by using conditional rendering of the partial based on the model name. The view before change: <image> The view after change: <image> 3. Missing Handle: Assignment Participant on adding a new Assignment Participant: We observed that when a new assignment participant is created, if a user already exists with the username, the existing user is added to that Assignment and his existing handle attribute in Users table is mapped to the handle attribute in Participants table. However, if a new user is added not currently in the Users table, a new entry is created first in the Users table and is then replicated in the Participants table. Although, we noticed that the handle attribute in Participants table was coming as null. We fixed this issue by making change in the define_attributes method in ImportFileHelper.rb. 4. Import Assignment Participants was not working - It is expected that if a user does not exist in the system, on importing assignment participants, a user will be created and he/she will be added to the assignment as a participant. With the current implementation, the user was getting created, however corresponding AssignmentParticipant was not getting created due to a validation with respect to handle. We have fixed this issue by setting the handle in AssignmentParticipants to be the same as the name of the user created (in accordance with the current functionality - when a user is added as an AssignmentParticipant from the UI). This facilitates us to import AssignmentParticipants. The mandatory minimal attributes required to import an assignment participant are : 1. Username 2. Full name 3. Email id 4. Password. 5. The role in the Assignment Participant view doesn't have a header unlike all the other attributes on the view. We added a header for the role, thereby increasing the readability and consistency on the UI. The required changes are made in the partial ""_user_list.html"" The view before change: <image> The view after change: <image> 6. The role in the Course Participant view doesn't have a header unlike all the other attributes on the view. We added a header for the role, thereby increasing the readability and consistency on the UI. The required changes are made in the partial ""_user_list.html"" The view before change: <image> The view after change: <image>. Rspec test has been added to check the update authorizations functionality in the participants_controller_spec.rb. The test verifies the change of flags mentioned above as per the authorization of the user. The tests also checks whether the expected flash message is visible on the UI. Code coverage is 100% for all the code that we have added in the controllers, as part of this project. To make sure we covered all of our code (100%) with test cases we used Ruby Code Coverage plugin of RubyMine and SimpleCov gem. After manually running the test file, the SimpleCov gem highlights the lines of code which are covered by our test cases with green color, and with red color for lines for which are not covered by our test cases. The image below shows the output of SimpleCov gem for the file participants_controller_spec.rb with 100% code coverage (all green). Please see the coverage of the code as shown in the screenshot below: <image> Please find the tests added below: <code>. 1. <link> 2. <link> 3. <link> 4. <link>.","The documentation looks very good. The team has not only added the probelm statement but also identified few issues that existed in the system. 
The team has clearly explained the code changes.

The only suggestion I would make for improvement is that the team could have included the code changes, e.g., in Github's diff view.  Oh, and the tests in the test plan were not described as well as the other chnages.  Would be good to explain how they work.","Dear student,

Thank you for this detailed and comprehensive report on your project E1963. You have systematically identified and addressed problems and provided clear explanations for your changes. 

Your level of detail and your commitment to thoroughly resolving issues, as well as making additional necessary updates, is commendable. I appreciate the effort you put into fixing the issues that arose as you moved through the process, such as the CSV file, handle attribute, and role headers.

However, the report could be clearer in some instances. Some of the explanations were complex and difficult to follow. You might consider providing more practical examples or diagrams to illustrate these points in future reports.

Make sure you reference your screengrabs and code snippets more clearly in the future. You have some hanging phrases such as '<image>' which might indicate incomplete sentences or thoughts. 

You've done a good job with testing, ensuring a 100% coverage for all the code that you added. Keep up this rigor in your future projects.

In conclusion, you've done a great job in handling this project. Keep up the good work for your future assignments, and always strive for clarity in your explanations. Well done!

Best,
[Your Name]"
123,E1936,"This Wiki page is created per CSC/ECE 517: ""Object-Oriented Design and Development"", Expertiza Project requirements (Spring, 2019). Our <link> was assigned the project "" <link> "". This is an Expertiza project. In this wiki page we describe the problem to be solved, how we solve that problem, and how we test our solution. We also provide helpful links and contact information for our team. In this section, we discuss the problem we need to solve, the Expertiza feature this problem is related to, what needs to be done to solve the problem (at a high level), and the previous attempt to solve this problem. This problem statement summarizes the problem as described in the project description "" <link> "". In CSC/ECE 517, there are several types of topics that could be covered in a single class assignment. 1. Code base 1.1. Expertiza 1.2. Mozilla 1.3. etc. 2. Goal 1.1. Refactoring 1.2. Testing 1.3. etc. However, currently we can only specify one kind of rubric for an assignment. This means that teams working on different topics will be evaluated using the same rubric. With this setup, it's not possible to fine-tune rubrics for different topics - rubrics tend to be overly general. The Expertiza project already has a feature that allows rubrics to vary by project phase or ""round"". The feature we will add in this project is a feature to allow rubrics to vary not only by round, but also by topic. This allows more flexibility to the instructor when setting up an assignment, so that they can use rubrics better suited to the tasks that students are performing in an assignment. When this feature is complete, the following scenarios will be possible, and the instructor will be the judge of which scenario is the best fit to the assignment: 1. Rubric does not vary by round or by topic. 2. Rubric varies by round, but not by topic. 3. Rubric varies by topic, but not by round. 4. Rubric varies by both round and topic. This section summarizes the work as described in the project description "" <link> "". 1. In assignment#edit page ""Rubrics"" tab, add a checkbox to specify whether rubric should vary by topic. 2. In assignment#edit page ""Topics"" tab, add dropdown(s) next to each topic to specify which rubric(s) are associated with the topic. 1.1. The dropdown(s) should appear only if rubric should vary by topic, per the Rubrics tab. 1.2. The topic should have a multiple dropdowns (one for each round) only if rubrics vary by round, per the Rubrics tab. 1.3. By default, the rubric(s) for each course project will be the one(s) specified in “Rubrics” tab. 1.4. The dropdown value can overwrite the default rubric. 3. Be careful when making changes to the code 1.1. The signup_sheet_controller should have as little to do as possible with the selection of rubrics. 1.2. Anything not germane to selecting topics should be in another controller or (more probably) a helper. 4. Create a DB migration to allow rubric to vary by topic as well as by round. Before: (Rubrics tab for an Assignment) <image> Before: (Topics tab for an Assignment) <image> After: (Rubrics tab for an Assignment) <image> After: (Topics tab for an Assignment) <image>. There was previous attempt to implement this project in the Fall of 2018 semester by different team, but it was rejected due to several reasons. As a result our team was assigned to complete this project with the given implementation. However, after detailed investigation of the proposed design that team has made in the previous semester and review of the code changes, we proposed different architectural solution for the problem, which we believe is simpler, more efficient, and elegant solution. Our team was provided with all relevant information and materials about the design and implementation of the previously attempted project. We would like to acknowledge that we use previous implementation and design as reference and our starting point for our own implementation. The following is the list of links with the relevant materials that we have used for better project understanding, determining pros and cons of previously proposed changes, and establishing our design strategy and implementation: 1. <link> 2. <link> 3. <link> After reviewing all relevant materials above, we concluded that the project implementation was incomplete and proposed design had significant flaw. We identified main drawbacks and flaw as follows: 1. Establishing incorrect many-to-one relationship between sign_up_topics and questionnaires tables: 1.1. Creating a DB migration to add questionnaire_id in the sign_up_topics table to store the dropdown data presumes one-to-one or many-to-one relationship between sign_up_topics and questionnaires tables 1.2. Correct relationship between sign_up_topics and questionnaires tables is many-to-many . For example, each project topic may have various rubrics depending on the round it is used (e.g., for round 1, topic may have one rubric; but for round 2, the same topic may have different rubric) 1.3. Proposed previous migration changes would break DB design and would not allow to store correctly topic and its associated rubric per different round. 2. Per project requirement specifications, "" The dropdown box should appear only if 'Vary rubric by topic' is selected in the Rubrics tab. "" This requirement was not met and Vary rubric by topic checkbox in the Rubrics tab was not implemented. Therefore, dropdown box with the list of rubrics appears regardless of whether "" Vary rubric by topic "" is selected or not. 3. The dropdown box includes the list of all possible rubrics including default value. However, this condition can be improved. The dropdown box should list the rubrics that were created by the current user (professor who is logged in). This would allow to shorten the list of possible rubrics dramatically and help to avoid any misunderstanding and confusion while user selects desired rubric for the course project. We found no further issues with the rest implementation and in other project materials. Wiki page is very useful for understanding design of proposed changes, finding drawbacks and the flaw. Considering all the pros and cons, and taking into account drawbacks of the proposed changes, our team evolved different approach that should successfully solve the problem stated for the project without without creating additional issues. Please see our <link> for more details. The project requirements originally specified how to alter the databases to support varying rubrics by topic. Create a new table named topic_questionnaires with field: 1. id 2. topic_id 3. questionnaire_id 4. used_in_round However, the E1936 team successfully petitioned for this requirement to change to give us more freedom in the implementation. The original suggestion had a flaw. There is already an existing table in the Expertiza project called assignment_questionnaires , which has columns including assignment_id , questionnaire_id , and used_in_round . It is this table that maintains the knowledge of which rubric is used in which round of an assignment. If we were to add a new table to maintains the knowledge of which rubric is used in which topic of an assignment as originally suggested, then we would have a big problem. Knowledge of round-rubric relationship is duplicated. This would lead (best case scenario) to extra work, and (worst case scenario) to lots of bugs caused by inconsistencies in how these tables are handled with CRUD operations throughout the code. In other words, this is not a DRY solution. In this section, we propose our solution to the problem with the set of UML diagrams, discuss implementation techniques and details, and list the goals we achieved. We start by proposing our solution to the problem utilizing UML diagrams that include Use case, Entity Relationship, Class, and Sequence diagrams! Further, we discuss design strategy by breaking project problem into multiple staged sub-problems and provide solutions for each of these sub-problems. We also discuss some design strategies in the form of problem - solution, and provide the list of involved files. To illustrate implementation details for different tasks we decided to include selected (only) modified code where pseudocode-like solution is provided for each major task in this project. Finally, since we received some common questions and misunderstanding during first peer review period, we include Q/A section, where we provide an answer to each common question and concern we received. Our solution and implementation of the project can be easily shown by discussing Use Case, Entity Relationship, and Class diagrams. First, for simplicity we discuss in general possible sequence of interactions between a user (in this case instructor) and the system (Expertiza) via presenting Use Case Diagram. Then we plan to show proposed database modification via Entity Relationship Diagram. At this point the high-level design and proposed changes should be clear. To make our design more concrete and dive into implementation level, we decided to provide UML Class diagram. Finally, to demonstrate our achievements, we complete this section with the UML Sequence diagram to illustrate interactive behavior of a system with utilized specialized rubrics feature. <image> The above Use Case Diagram shows general sequence of interactions between an instructor and the system (Expertiza) that defines where and how the feature can be utilized. Note that highlighted use cases are objects of our interest and work. Also please note that all of the shown use cases already exist in the system and we simply added a new feature into the system with existing use cases. Particularly, the rubric for each assignment and newly added Review rubric varies by topic checkbox with which instructor may choose to vary assignment by topic or not, by checking and unchecking the checkbox is displayed in the Rubrics tab. Hence, we show how instructor can get to the Rubrics tab of the assignments. Similarly, Topics tab of assignments has additional Questionnaires column for each topic, where instructor may specify which rubric associates with which topic. To perform this sequence of interactions and utilize the new feature, instructor must choose Edit any assignment from the list of all assignments displayed to him/her in the Manage Assignments page, which can be navigated by instructor by selecting it from the header of the system. <image> The sections of the diagram highlighted in yellow show newly introduced items. That is, we are adding a new column called topic_id to assignment_questionnaires , in order to link assignment_questionnaires to sign_up_topics . Any assignment, topic, or questionnaire may be represented by multiple records within assignment_questionnaires , but each record within assignment_questionnaires refers to just one assignment, topic, or questionnaire. It is the ability to have an assignment represented by multiple records, and the new relationship to sign_up_topics , that allows us to support all of the required scenarios: 1. Rubric does not vary by round or by topic. 2. Rubric varies by round, but not by topic. 3. Rubric varies by topic, but not by round. 4. Rubric varies by both round and topic. <image> This table illustrates the possibilities that the system may have. 1. Assignment 1 does not vary by round or by topic. 2. Assignment 2 varies by round, but not by topic. 3. Assignment 3 varies by topic, but not by round. 4. Assignment 4 varies by both round and topic. This change is done via database migration by running the following commands: <code> Above command adds the topic_id column to the AssignmentQuestionnaires table and generates new migration file: <image> To see the details of the entire database change please check this <link> . <image> The above UML Class diagram describes the changes our team made in the Ruby classes, methods and attributes. Please note that all provided classes in the diagram had already existed in the system, and we only added new relationship, modified existing methods (and some method signatures) and utilized given attributes. All of the class's attributes and methods that are shown in the diagram are utilized (directly and indirectly) in our current implementation. Some of the methods and attributes provided within the classes in the diagram are newly developed. There is only one newly added aggregation relationship between the SingUpTopic class and AssignmentQuestionnaire class. Moreover, controllers and models for the certain classes were combined into a single class for simplicity to the design description. In reality, half of the methods shown in the Assignment class are implemented in the app/controllers/assignments_controller.rb file and other half is in the app/models/assignment.rb file. We decided to combine all of the functionalities of each relevant controller and model class into single class for the ease of design presentation and interpretation. We used Sequence diagram below to illustrate how MVC architectural pattern is used for a given classes. Below we provide UML Sequence diagram to illustrate the interactive behavior of a system utilizing the specialized rubric feature that we implemented. Note that the following UML Sequence Diagram still is considered to be a high-level diagram and it displays the behavior of the system that we observed while debugging and implementing our code. By presenting the following sequence diagram, we do not make a claim that this is how Expertiza works, we simply documented our observations and want to share it with the teaching staff and fellow students. It is possible that we could have missed something or incorrectly interpreted the source code, but this diagram is the best of our knowledge. We hope that this would be useful for the teams working on similar projects in the future! <image>. As we have concrete understanding of the problem and proposed solution, we would like break this problem into multiple more manageable sub-problems with specific tasks and well-defined solutions to these tasks. Generally, each sub-problem requires modification of one or more files. We would like to propose our Design Strategy as follows: 1. Clean up code that our implementation will use 1.1. PROBLEM: We need to add/change content to the edit assignment Topics tab, but unlike other tabs in the views, it does not have its own partial view to work with 1.1.1. SOLUTION: Refactor and move the code dealing with topics into separate app/views/assignments/edit/_topics.html.erb file 1.1.2. File: app/views/assignments/edit.html.erb 1.2. PROBLEM: In a section below, we discuss the need to modify existing methods to also accept an optional argument topic_id . In many cases these existing method use confusing variable names or lack sufficient comments. 1.1.1. SOLUTION: Clean up methods that we plan to modify 1.1.2. FILE: (many). 1. Allow an instructor to indicate that rubric should vary by topic 1.1. PROBLEM: There is no way for an instructor to indicate that an assignments' rubric should vary by topic 1.1.1. SOLUTION: Add a new checkbox in the edit assignment Rubrics tab to indicate this preference 1.1.2. FILE: app/views/assignments/edit/_rubrics.html.erb 1.2. PROBLEM: If the user changes the ""Review rubric varies by round?"" or ""Review rubric varies by topic?"" checkbox on the Rubrics tab, but leaves the page in an inappropriate state before leaving the tab (e.g. rubric weights that do not add up to 0% or 100%), then the user does not get feedback that they made a mistake. They only get such feedback when explicitly performing a ""Save"". Switching from tab to tab on the assignments edit page attempts to perform an implicit save, but there is no mechanism to update the flash messages onscreen if anything goes wrong. This becomes more problematic now that the Topics tab appearance depends on choices made on the Rubrics tab. 1.1.1. SOLUTION: Provide a route to an assignments controller method that can return a render of the flash messages. Add an AJAX call on the assignments edit view that can update the flash messages onscreen. 1.1.2. FILE: app/controllers/assignments_controller.rb 1.1.3. FILE: app/views/assignments/edit.html.erb 1. Allow an instructor to choose different rubrics for different topics 1.1. PROBLEM: There is no way for an instructor to choose different rubrics for different topics 1.1.1. SOLUTION: Add a new column in the edit assignment Topics tab for choosing rubric(s) 1.1.1.1. New column only visible if rubrics vary by topic, per Rubrics tab 1.1.1.2. New column has multiple rounds per topic only if rubrics vary by round, per Rubrics tab 1.1.1.3. Default value for any rubric is that rubric which is shown on Rubrics tab 1.1.1.4. Rubric(s) in the dropdown list is/are only those that were created by the currently logged in instructor 1.1.2. FILE: app/views/assignments/edit/_topics.html.erb 1.2. PROBLEM: The code in app/views/assignments/edit/_rubrics.html.erb includes dropdowns like the ones we need to add for topics, but that code is way too complex for its functionality (too heavy for a view, uses JavaScript) 1.1.1. SOLUTION: Use the code in app/views/assignments/edit/_rubrics.html.erb for inspiration only 1.1.1.1. Refactor and move as much actual work as possible out into helper methods that are simply called from this view 1.1.1.2. Views are not intended to do heavy lifting 1.1.1.3. Use as little JavaScript as possible, since this is a Ruby On Rails project, not a JS project 1.1.2. FILE: app/views/assignments/edit/_topics.html.erb 1.3. PROBLEM: The drop-downs for selecting rubrics should show only those rubrics created by the currently-logged in instructor (per project mentor). They currently include those created by the instructor of the relevant assignment. 1.1.1. SOLUTION: Change the filtering in the questionnaire_options method to reflect the desired filtering. 1.1.2. FILE: app/helpers/assignment_helper.rb 1. Support the ability of the database to link rubrics to topics 1.1. PROBLEM: There is no relationship in the database that can link together rubrics with topics 1.1.1. SOLUTION: Add a new migration that adds topic_id field to existing assignment_questionnaires table 1.1.1.1. This new field will reference the id field in the sign_up_topics table 1.1.2. FILE: db/migrate/[timestamp]_add_topic_id_to_assignment_questionnaires_table.rb 1.2. PROBLEM: The AssignmentQuestionnaire model does not have any knowledge of topics 1.1.1. SOLUTION: Add a new belongs_to reference in the model, to sign_up_topic 1.1.2. FILE: app/models/assignment_questionnaire.rb 1.3. PROBLEM: The SignUpTopic model does not have any knowledge of assignment_questionnaire records 1.1.1. SOLUTION: Add a new has_many reference in the model, to assignment_questionnaires 1.1.2. FILE: app/models/sign_up_topic.rb 1. React to an instructor saving an assignment after altering the rubrics-vary-by-topic checkbox 1.1. PROBLEM: There is nothing in place to remember when an instructor chooses to vary rubrics by topic, or chooses to not vary rubrics by topic 1.1.1. SOLUTION: Modify existing method update_assignment_questionnaires() . This method executes upon assignment save (explicit or via tab-change). This method deletes all AssignmentQuestionnaire records before creating new correct records reflecting the user's selections in the edit assignment form. Modify such that this method can create multiple records reflecting multiple topics, in the case where rubric should vary by topic. With this modification, the correct records (with default rubrics) are present when the user goes to the Topics tab, so that the Topics tab can display properly. 1.1.2. FILE: app\models\assignment_form.rb 1.2. PROBLEM: There is no way to refresh the Topics tab to show / hide drop-downs after the instructor changes checkbox on Rubrics tab 1.1.1. SOLUTION: Make use of existing ""Save""-like functionality when changing tabs on the edit assignment page. When updating due to tab-change, cause a fresh render of the Topics tab. When updating due to ""Save"" button, keep functionality as-is. 1.1.2. FILE: app/controllers/assignments_controller.rb 1.1.3. FILE: app/views/assignments/edit.html.erb 1. Support the ability to find the correct rubric for a particular topic 1.1. PROBLEM: The existing methods allow us to find the correct rubric for a particular round, but not a particular topic 1.1.1. SOLUTION: Modify the existing method questionnaire(assignment, type, round_number) to also accept an optional argument topic_id 1.1.2. FILE: app/helpers/assignment_helper.rb 1.1.3. SOLUTION: Modify the existing method assignment_questionnaire(assignment, type, number) to also accept an optional argument topic_id 1.1.4. FILE: app/helpers/assignment_helper.rb 1.1.5. SOLUTION: Modify the existing method questionnaire(round = nil) to also accept an optional argument topic_id 1.1.6. FILE: app/models/review_response_map.rb 1.1.7. SOLUTION: Modify the existing method questionnaire(round) to also accept an optional argument topic_id 1.1.8. FILE: app/models/self_review_response_map.rb 1.1.9. SOLUTION: Modify the existing method review_questionnaire_id(round = nil) to also accept an optional argument topic_id 1.1.10. FILE: app/models/assignment.rb 1. Use the correct rubric for a particular topic 1.1. PROBLEM: When finding rubrics to display, save results from, calculate scores from, etc. round may be used but topic is not 1.1.1. SOLUTION: Examine all callers of methods modified in the previous section and pass in topic_id where appropriate to grab the correct rubric 1.1.2. FILE: (many) 1. Support the ability to determine if an assignment has rubrics that vary by topic 1.1. PROBLEM: There is no handy method to call that can tell us if an assignment has rubrics that vary by topic 1.1.1. SOLUTION: Add a new method varying_rubrics_by_topic? based on the existing method varying_rubrics_by_round? 1.1.2. FILE: app/models/assignment.rb. Here we paraphrase some questions we received during round 1 of the documentation review. 1. Q: How will the new logic for varying rubric by topic tie in with the existing logic? 1.1. A: We will add a new field topic_id into the existing table assignment_questionnaires , as noted in the <link> . We will update methods that find questionnaires to allow these methods to also accept a topic_id argument, as noted in <link> . 2. Q: How will the ""Rubric varies by topic"" selection be stored? 1.1. A: Indirectly, by saving records in the assignment_questionnaires table which either reference a topic_id or leave this field nil. For more details please see the <link> discussion. 3. Q: What will happen if an instructor selects ""Rubric varies by topic"", makes selections on the ""Topics"" tab, and then deselects ""Rubric varies by topic""? 1.1. A: The Topics tab, when next visited, will no longer show dropdowns for selecting rubrics by topic. When the assignment is saved, the appropriate not-varying-by-topic records will be saved in the assignment_questionnaires table. For more details please see <link> . 4. Q: What will happen after an instructor selects ""Rubric varies by topic""? 1.1. A: The Topics tab, when next visited, will now show dropdowns for selecting rubrics by topic. These rubrics will default to those shown on the Rubrics tab. When the assignment is saved, the appropriate varying-by-topic records will be saved in the assignment_questionnaires table. For more details please see <link> . 5. Q: How will the appropriate list of questionnaires for the new dropdowns on the Topics tab be determined? 1.1. A: In the same way that the appropriate list of questionnaires for the existing dropdowns on the Rubrics tab is determined. Namely, by the questionnaire_options method in the file expertiza/app/helpers/assignment_helper.rb . In this section, we provide selected portions of modified code to illustrate how we implemented the new feature. Allow an instructor to indicate that rubric should vary by topic app\views\assignments\edit\_rubrics.html.erb <code> Allow an instructor to choose different rubrics for different topics app\views\sign_up_sheet\_table_line.html.erb <code> Support the ability of the database to link rubrics to topics app\models\sign_up_topic.rb <code> React to an instructor saving an assignment after altering the rubrics-vary-by-topic checkbox app/controllers/assignments_controller.rb <code> Support the ability to find the correct rubric for a particular topic app/helpers/assignment_helper.rb <code> Use the correct rubric for a particular topic app\controllers\response_controller.rb <code> Support the ability to determine if an assignment has rubrics that vary by topic app\models\assignment.rb <code>. In this section, we describe how to use the newly implemented feature. (Log in as an Instructor). 1. Navigate to Edit page for an Assignment. 2. Click the Rubrics tab. 3. Check the ""Review rubric varies by topic?"" checkbox. After checking the ""Review rubric varies by topic?"" checkbox, 1. Click the Topics tab. 2. Select the appropriate Rubric from the dropdown menu(s) beside each Topic. See also: <link>. To test code implementation, correctness of the added feature, verify that the team did not break any existing functionalities in the Expertiza, and ensure that no bugs were introduced in the code, we developed the following Test Strategy: 1. Code inspection 2. Run and pass existing RSpec Tests 3. Develop New RSpec Tests 4. Run through live UI to test a feature using Expertiza instance. Run all existing RSpec tests on any changed files, after our changes, to ensure that we have not introduced any failures. The commands and results are shown below. <code> The features tests were extremely time-consuming so we did not routinely run them during development. However TravisCI results on our <link> demonstrate the passing status of all tests. Write comprehensive RSpec tests, for all new or modified methods. 1. FILE: spec/helpers/assignment_helper_spec.rb 1.1. METHODS TO TEST: 1.1.1. questionnaire(assignment, type, round_number, topic_id) 1.1.2. assignment_questionnaire(assignment, type, number, topic_id) 2. FILE: spec/models/review_response_map_spec.rb 1.1. 1.1.1. METHODS TO TEST: 1.1.1.1. questionnaire(round, topic_id) 3. FILE: spec/models/self_review_response_map_spec.rb 1.1. 1.1.1. METHODS TO TEST: 1.1.1.1. questionnaire(round, topic_id) 4. FILE: spec/models/assignment_spec.rb 1.1. 1.1.1. METHODS TO TEST: 1.1.1.1. review_questionnaire_id(round, topic_id) 1.1.1.2. varying_rubrics_by_topic?() Run these tests, to ensure that the new code works as intended. The commands and results are shown below. <code> The test suite for a single new method is shown below. 1. There are many such suites added in expertiza/spec 2. This example illustrates our general strategy: 1.1. test missing input 1.2. test bad input 1.3. test various acceptable forms of input 1.4. test scenarios that lead to various return values <code>. Here we describe manual UI Testing that was performed. 1. Go to Rubrics tab and verify that both ""Review rubric varies by round?"" and ""Review rubric varies by topic?"" checkboxes are unchecked. 2. Go to Topics tab and verify that there are no dropdown menus beside each Topic. 1. Go to Rubrics tab and verify that ""Review rubric varies by round?"" is checked and ""Review rubric varies by topic?"" is unchecked. 2. Go to Topics tab and verify that there are no dropdown menus beside each Topic. 1. Go to Rubrics tab and verify that ""Review rubric varies by round?"" is unchecked and ""Review rubric varies by topic?"" is checked. 2. Go to Topics tab and verify that there is only 1 dropdown menu beside each Topic. 1. Go to Rubrics tab and verify that both ""Review rubric varies by round?"" and ""Review rubric varies by topic?"" checkboxes are checked. 2. Go to Topics tab and verify that there is 1 dropdown menu per round for each Topic. 1. Go to Rubrics tab and check the ""Review rubric varies by topic?"" checkbox. 2. Change weight values for the Rubrics so that they add up to 97%. 3. Go to Topics tab and verify that checking the ""Review rubric varies by topic?"" checkbox did not work. 4. Verify that there are no dropdown menus beside each Topic. 5. Verify that the proper error message is shown. In CSC/ECE 517, there are several types of topics that could be covered in a single class assignment. However, currently we can only specify one kind of rubric for an assignment. This means that teams working on different topics will be evaluated using the same rubric. With this setup, it's not possible to fine-tune rubrics for different topics - rubrics tend to be overly general. In this project, we have solved this issue, by allowing rubrics to vary not only by round, but also by topic. This allows more flexibility to the instructor when setting up an assignment, so that they can use rubrics better suited to the tasks that students are performing in an assignment. The following scenarios will be possible, and the instructor will be the judge of which scenario is the best fit to the assignment: 1. Rubric does not vary by round or by topic. 2. Rubric varies by round, but not by topic. 3. Rubric varies by topic, but not by round. 4. Rubric varies by both round and topic. The instructor may use the Rubrics tab of the assignments edit page to make changes to the ""Review rubric varies by round?"" and ""Review rubric varies by topic?"" checkboxes. The instructor may then use the Topics tab to select the appropriate rubric(s) for every topic in the assignment. Various other Expertiza code has been updated to retrieve the correct rubric depending on round and topic after the instructor has made these selections. This section discusses possible future work for another CSC 517 team to take on. Such a team can search the Expertiza codebase for ""TODO E1936 (future work)"" to find most of the places in the code that the notes below refer to. 1. Reduce the delay between changing the state of the ""Review rubric varies by topic?"" checkbox on the Rubrics tab, and the show / hide of rubric drop-downs on the Topics tab. 2. Redesign UI for tone analysis, heatmaps, and review scores pop-up. These areas are designed around the assumption that reviews do NOT vary by topic. For example, in the review scores pop-up, a reviewer can see the reviews they have given, arranged by question, across multiple reviewees. 3. Consider whether the questionnaire options available for selection in drop-downs on the Topics and Rubrics tabs should include only those questionnaires created by the currently-logged-in instructor. Our work in this project changed the filtering from instructor-owning-assignment to currently-logged-in instructor - but left in place all non-private questionnaires. Consider whether non-private questionnaires should be excluded. This may result in some drop-downs not having any available questionnaires. In this section we provide useful links related to the work that has been completed by our team. 1. <link> 2. <link> 3. <link>. 1. Expertiza Web <link> 2. Expertiza on GitHub <link> 3. Expertiza Wiki <link> 4. Rspec Documentation <link> 5. Wiki with Previous Work <link> 6. Pull Request of the Previous Work <link>.","This is an excellent design doc, especially in the way that it explains the rationale for change and why some design options were chosen over others.  The problem/solution format to the Implementation section and the Q&A are practically unique for this project, and they are very helpful.  I still have some suggestions: The Selected Modified Code section could have used a larger font and had more comments about what the code was doing.  I also find the Github diff display more readable, like your screenshot of adding topic_id to AssignmentsQuestionnaires.","Your assignment shows thorough understanding and analysis of the project requirements. The proposed solution for the problem presented in the assignment appears well-designed, and you have demonstrated a detailed understanding of using topic-separated rubrics.

The concise and thorough explanation of the problem statement was very helpful. Your systematic approach of dichotomizing the problem into sub-problems was a smart strategy. I appreciate the level of detail present in the solutions and implemented code — this ensures that anyone reviewing your work, or using the feature you created, will have a clear understanding of the modifications. 

Testing methodologies for the code are well articulated and the explanation of each step executed in UI Testing is commendable. Including potential future improvements highlights thoughtfulness about the project's future and it is good to see that you are thinking not just about the end product, but also about its potential growth. 

Your detailed, graphic approach to show the functionality of the new feature can make the project easily understandable by anyone. Illustrating the implemented feature with the help of diagrams is a nice touch. This will simplify the understanding process for implementers in the later stages.

The references provided seem to cover a broad array of resources and materials related to the project, the useful links will very helpful for future teams to understand your project or further develop upon it.

Overall, this assignment demonstrates a meticulous approach to problem-solving, paired with clear modulated solutions and thorough testing. Your research, design, and implementation are commendable. Nice job!"
124,E1568,"Expertiza is a web application where students can submit and peer-review learning objects (articles, code, web sites, etc). It is used in select courses at NC State and by professors at several other colleges and universities. This page provides a description of the Expertiza based on OSS project. As the project, our team members successfully removed the answer controller, split confusing methods and provided all unit test in the Answer model. Changes can be found in the Answer.rb file which locates in expertiza/app/models/. There is a answer.rb file which handle all methods related to answer calculations. But there is no related view file related to AnswerController. All methods in it are show,action_allowed? and calculate_all_penalties. It is obvious that calculate_all_penalties method has already been deployed in GradesController. So we can get rid of calculate_all_penalties in AnswersController. Action_allowed? method is used to set the access authorization for different users. Because there is not show view page related to show method. So we can remove AnswerController. This can be checked in the controllers folder. As described in OSS project, the self.compute_scores method is complex. Followed the principle that one method only do one thing, we split the the self.compute_scores by adding a method called self.compute_stat to take on some responsibilities from the self.compute_scores method, namely, computing the current score. Specific changes before and after are shown below: <code>. <code>. <code>. We found some parts of codes in the 'self.submission_valid?' method can be taken out as a individual method. To fulfill the function which calculates the latest review phase start time, we named this method as 'latest_review_deadline"". See the changes below: <code>. <code>. <code>. Line 89 SQL query uses 'find_by_sql' which is not in accord with Rails 4 format and we substituted it with 'where'; which can be reflected in Line 93 in our case. Since Line 89 SQL is too long, which violates the rule that code should be readable; thus we take the following measures: <code>. There are six methods in the new version of answer.rb; so we performed six unit tests. The test file for Answer model is answer_spec.rb which can be found in the directory: expertiza/spec/models/ . Below is the unit test code: <code>. To verify that our code did not break the original functions. Sign in as instructor6 with password of 'password' and go to 'Assignments' then pick an assignment; and check scores. The result remains same. 1. <link> 2. <link> 3. <link> 4. <link>.",Too little explanation; code sequences too long (test sequence is much too long),"Dear Student,

Firstly, your description of the actions you've taken in the Expertiza project is very detailed and clear. You've demonstrated a thorough understanding of the given task and shown adequate technical skills to improve the application. Your team has made commendable efforts in identifying redundant controllers and methods, thus improving the overall code base's efficiency.

Removing the Answer Controller based on the reasons listed shows a good understanding of MVC (Model-View-Controller) framework which forms the basis for applications like Expertiza. Your explanation for splitting the 'self.compute_scores' method into two, and introducing 'self.compute_stat' to handle some of the responsibilities, aligns well with the principle of Single Responsibility. This change makes your code cleaner and more understandable.

The conversion of 'find_by_sql' to 'where' and shortening the SQL query for better readability, indeed, shows your ability to enforce coding standards and your commitment towards best practices. Your adoption of unit testing is particularly impressive. Unit tests ensure that the individual methods or units of your code are working as expected, thereby improving the overall robustness of your application.

However, keep in mind for future assignments, you should include the actual code snippets in your submission, this would make it much easier for your peers and me to give comprehensive feedback. The placeholders <code> and <link> should contain your actual code and relevant links respectively.

Additionally, it would be useful if you could further elaborate on the test procedures, especially what functionalities or methods were tested, what kind of data was used, and the expected and actual results of these tests. Also, remember to use assertions in your tests, as they make your tests self-checking, removing the need for manual verification.

In conclusion, you've done an excellent job with your assignment. Your ability to grasp and implement the key principles of software design and testing is commendable. I encourage you to continue learning and enhance your software development skills. Keep up the good work!"
125,E1841,"Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.1.1. <link> 1.1.1.1.1. <link> 1.1.1.1.1.1. <link> 1.1.1.1.1.2. <link> 1.1.1.1.1.3. <link> 1.1.1.1.1.4. <link> 1.1.1.1.1.5. <link> 1.1.1.2. <link> 1.1.1.1.1. <link> 1.1.1.1.1.1. <link> 1.1.1.3. <link> 1.1.1.1.1. <link> 1.1.1.1.2. <link>. Expertiza is an Peer Review Web Application System. It allows multiple students to participate in various assignments posted by the Instructor and provides a platform to all the students to conduct a peer review on the work done by their peers. Expertiza is an opensource project written in Ruby on Rails and React.js. We as a team have targeted some specific issues related to this project and Have tried Our best to fix them. In Expertiza, instructors (also admin, super admin and TAs) can create rubrics (they are called questionnaires in DB, there are different types like review rubric, teammate review rubric, etc. Each rubric may have one or many criteria (called questions in DB). For each criterion, it may have 0 to many suggestions. If an instructor has created an assignment with specific review rubric and reviews have been performed using the same rubric. After that if an instructor changes the rubric to more reasonable one, the reviews performed earlier won’t work. You need to fix this issue. An instructor should be warned about changing the rubric if there are outstanding reviews. Maybe it would be better to ask the instructor whether to delete previous reviews, & if so, tell the students to redo those reviews because the rubric has changed. After an instructor has created an assignment and if an assignment is rubric-varying-by-round and then mistakenly changed to be not varying by round, and then corrected to be varying-by-round again, the formative rubric is applied to all rounds. Of course this is incorrect; the summative rubric should be re-enabled for the summative round. The problem is that when you make an assignment rubric-varying-by-round, the Javascript just assumes that the summative review is the same as the formative review. AJAX should be added to fetch the summative review ID from the db (it’s still there, because we assume the assignments_questionnaires table entry hasn’t been removed). You need to fix this issue. Log in as an instructor into the expertiza system. If you try to select ""Manage > Questionnaires > Review rubrics"", it should pull up a list of review rubrics. But actually, it just takes you to the main Questionnaires page. The exact same error is happening for ""Manage > Questionnaires > Author feedback"", etc. You need to figure out what causes the error and fix it. Current Functionality Instructor able to create an Assignment but once participants have started reviews, changing the rubrics doesn't update the score. Instructor able to populate an Assignment with multiple rubrics Display of the Main tabs Instructor able to navigate between tabs(Courses, Assignments and Questionnaires), but Manage menu selection doesn't work. Solutions Issue #1186 When one tries to select ""Manage > Questionnaires > Review rubrics"" , it just takes back to the Questionnaires Main page rather than displaying the Review rubrics page. Solution Description tree_display.jsx File Path to file: /app/assets/javascripts/tree_display.jsx A new React lifecycle function was added to the ContentTableRow class, viz. componentDidMount: function() . The function determines which sub-menu item was clicked in the Manage Instructor Content- Questionnaire menu and expands the corresponding rubric by updating the state of the table row. <code> tree_display_controller.rb File Path to file: /app/controllers/tree_display_controller.rb In this file, multiple functions were updated viz. goto_controller() and list() and goto_{rubric_name}, where rubric_name is one of the following: [questionnaires, review_rubrics, metareview_rubrics, teammatereview_rubrics, author_feedbacks, global_survey, surveys, course_surveys, bookmarkrating_rubrics, courses, assignments] The goto_controller function now takes in a new parameter names ""last_open_tab"", which indicates which tab ought to be selected after a refresh (due to list action). This value is stored in a session variable. The goto_{rubric_name} functions pass in the value for last_open_tab corresponding to the tab to which they belong. The list action was updated to store an instance variable that will be accessible in list.html.erb. goto_controller(): The modification in goto_controller enables the function to keep a track of which tab was last opened by adding a new parameter viz. last_open_tab and setting its values to the integer value corresponding to the position of the tab on the web page . For example , if the Questionnaires tab is opened then a value of 3 will be assigned to the last_opened_tab parameter as the position of the Questionnaires tab is 3 on the web page.This function also handles the direction of the control from Questionnaires tab to the Review Rubrics Tab when Review Rubrics tab is clicked. <code> list(): This function generates instance variable which contains the params variable current value and makes that value available to the list.html.erb file. <code> List.html.erb file Path to file: /app/views/tree_display/list.html.erb This file has been modified so that the tree_display.jsx file is able to access the sub-menu item which is was clicked. The change involves added a data property called data-menu-item to the root div element with id ""tree_display"". The value is set equal to the instance variable set in tree_display_controller.rb. <code> Issue #1096 Solution Description This fix for this issues involves determining which, if any, of the rubric values were changed during the modification of an assignment, retrieving the corresponding responses, deleting those responses and sending mail to those reviewers. We also alert the instructor about the above happening and they may choose not to update the rubric. assignments_controller.rb File Path to file: /app/controllers/assignments_controller.rb This file was updated to contain all the logic for handling review-response deletion and sending mails to appropriate reviewers. The following functions were updated: edit, update 1.1. The edit function was updated to- store the current(before edit) rubric values in session. store the current assignment in session. store the current action(edit) in a instance variable so that we can distinguish the creation and deletion views. <code> 1.1. The update function was updated to- call the private handle_rubric_modification function. <code> This following functions were added: (private)rubrics_before_edit, (private)handle_rubric_modification, private(rubric_modified_rounds), (private) get_responses_for_modified_rounds, (private) notify_reviewers_about_rubric_change, (private) reviewer_emails. 1.1. The rubrics_before_edit function is used to store the values of rubrics on an assignment before the users tries to update them. The values are retrieved from the instance variable @assignment_questionnaires. <code> 1.1. The handle_rubric_modification method is used to handle rubric changes by an instructor to an assignment. <code> 1.1. The rubric_modified_rounds method gets all rounds for which an instructor changed a rubric when updating an assignment. <code> 1.1. The get_responses_for_modified_rounds method retrieves all responses to reviews whose rubric was changed by an instructor when updating an assignment. <code> 1.1. The notify_reviewers_about_rubric_change method is used to notify(mail) reviewers that their review responses have been deleted. <code> 1.1. The reviewer_emails method retrieves reviewer emails from response objects. <code> Solution Screenshots Issue #1186 <image> ' Initial Page'- Assignments tab selected The Questionnaires tab gets selected and Review rubric is auto-loaded. <image> Review Rubric Page <image> Meta Rubric Page Issue #1186 <image> ' Initial Page'- Assignments tab selected - editing assignment <image> User alert <image> After Cancel in alert <image> After Ok in alert <image> Reviewer mailed <image> Review response deleted. When one tries to select ""Manage > Questionnaires > Review rubrics"" , it just takes back to the Questionnaires Main page rather than displaying the Review rubrics page. Path to file: /app/assets/javascripts/tree_display.jsx A new React lifecycle function was added to the ContentTableRow class, viz. componentDidMount: function() . The function determines which sub-menu item was clicked in the Manage Instructor Content- Questionnaire menu and expands the corresponding rubric by updating the state of the table row. <code>. Path to file: /app/controllers/tree_display_controller.rb In this file, multiple functions were updated viz. goto_controller() and list() and goto_{rubric_name}, where rubric_name is one of the following: [questionnaires, review_rubrics, metareview_rubrics, teammatereview_rubrics, author_feedbacks, global_survey, surveys, course_surveys, bookmarkrating_rubrics, courses, assignments] The goto_controller function now takes in a new parameter names ""last_open_tab"", which indicates which tab ought to be selected after a refresh (due to list action). This value is stored in a session variable. The goto_{rubric_name} functions pass in the value for last_open_tab corresponding to the tab to which they belong. The list action was updated to store an instance variable that will be accessible in list.html.erb. Path to file: /app/views/tree_display/list.html.erb This file has been modified so that the tree_display.jsx file is able to access the sub-menu item which is was clicked. The change involves added a data property called data-menu-item to the root div element with id ""tree_display"". The value is set equal to the instance variable set in tree_display_controller.rb. <code>. This fix for this issues involves determining which, if any, of the rubric values were changed during the modification of an assignment, retrieving the corresponding responses, deleting those responses and sending mail to those reviewers. We also alert the instructor about the above happening and they may choose not to update the rubric. Path to file: /app/controllers/assignments_controller.rb This file was updated to contain all the logic for handling review-response deletion and sending mails to appropriate reviewers. The following functions were updated: edit, update 1. The edit function was updated to- store the current(before edit) rubric values in session. store the current assignment in session. store the current action(edit) in a instance variable so that we can distinguish the creation and deletion views. <code> 1. The update function was updated to- call the private handle_rubric_modification function. <code> This following functions were added: (private)rubrics_before_edit, (private)handle_rubric_modification, private(rubric_modified_rounds), (private) get_responses_for_modified_rounds, (private) notify_reviewers_about_rubric_change, (private) reviewer_emails. 1. The rubrics_before_edit function is used to store the values of rubrics on an assignment before the users tries to update them. The values are retrieved from the instance variable @assignment_questionnaires. <code> 1. The handle_rubric_modification method is used to handle rubric changes by an instructor to an assignment. <code> 1. The rubric_modified_rounds method gets all rounds for which an instructor changed a rubric when updating an assignment. <code> 1. The get_responses_for_modified_rounds method retrieves all responses to reviews whose rubric was changed by an instructor when updating an assignment. <code> 1. The notify_reviewers_about_rubric_change method is used to notify(mail) reviewers that their review responses have been deleted. <code> 1. The reviewer_emails method retrieves reviewer emails from response objects. <code>. <image> ' Initial Page'- Assignments tab selected The Questionnaires tab gets selected and Review rubric is auto-loaded. <image> Review Rubric Page <image> Meta Rubric Page. <image> ' Initial Page'- Assignments tab selected - editing assignment <image> User alert <image> After Cancel in alert <image> After Ok in alert <image> Reviewer mailed <image> Review response deleted.","The description of changes is rather hard to follow, because descriptions of changes do not point out where in the code the change was made.  One has to read the prose, then study the code.  One way of showing the correspondence better would be to link to particular Github commits using the diff view where it would be easy to see what code was changed.  It could also be done by referring to methods and/or line numbers in the displayed code. They have added all screenshots at the end of the document. It would have been better if they would have added the screenshots while describing the particular issue.","Dear Student,

Thank you for your comprehensive and thorough work on this assignment. Your detailed breakdown and solutions to both issues #1186 and #1096 regarding the Expertiza application are duly noted and well articulated. I appreciate provision of the descriptions, file paths, code, and screenshots - this profound level of detail greatly enhances your explanations.

Here are some pointers for your future commitments:

1. Try to maintain a concise and direct to the point approach. Your assignment could have been more digestible if less verbose, and you could achieve this by compacting your explanations without omitting crucial details. 

2. Make sure to properly format your documents to increase readability. Section headings, bullet points, numbered lists and indentations are important to guide the reader into your thought process.

3. Ensure all your code inclusions are closed. In some instances, I noticed the '<code>' tag was opened but not closed. This interferes with the document format and overall readability of your work.

4. Finally, try keeping the visual content (screenshots) to a strict 'need to show' basis to prevent oversaturating your work. Also, understand that while screenshots provide clear evidence of your work, they are no substitute for a robust and compelling explanation of what was done or achieved.

Again, your assignment shows a promising depth of understanding, dedication to problem-solving and knowledge application, and I’m confident about your performance in future tasks. Keep it up!

Best wishes,
[Instructor's Name]"
126,E2081,"Expertiza rubrics are utilized to build questionnaires and these rubrics incorporate several kinds of items, including Criterion (dropdown + comment), Checkbox, MultipleChoice, and Scale. When we use these questionnaires for reviews, for example the teammate review assessment we encounter a few problems. One “problem” with all of these types is that there is nothing to stop a reviewer (say some student) from assigning the maximum score to all the reviewees (student's teammates). This is indeed a problem for teammate assessment, when the faculty asks for what fraction of the work each teammate did.So an alternative is needed, let’s call it a “Cake” item type, that allows a reviewer to divide a “cake” in any way between the reviewees, but does not allow him/her to divvy up more than 100% of the cake. 1. When the reviewer submits a score that would bring the total assigned for this item to > 100%, the system needs to warn. 2. The system must a reviewer to give him/herself a score 3. The proposed design needs to be compatible with existing self reviews code and teammates reviews 4. Design should be extensible to other kind of reviews apart from teammate reviews as well <image> For instance, the above figure consists of a team of 4 members, with self included as a team-member when reviewing every member's contribution. If A has reviewed his other 3 teammates B, C, D with contributions of 15%, 10%, and 45% respectively, he should only be allowed to review self with a contribution of 30% or lesser. The issue asks us to have a Cake type for the question taking in a participant’s contribution, whenever s/he is reviewing the other teammates. We add in a new Question type ‘Cake’, which will be extended from the Scored Question model [cake < scored question < choice question < question]. 1. Stars: Existing design for teammate reviews uses stars to symbolize the contribution provided by each student. We can implement the cake type using the same. Cons: Stars are not very versatile when there are a greater number of students per team and if the student wants to equally rate their contribution. 1. Drop Down: In order to give the student more flexibility, another way a student can pick the contribution of each team member is using a dropdown of the % values. Cons: Drop down values need to be restricted to intervals of 5 or more, as the drop down becomes too long to display all values from 0-100. 1. Text box with up-down arrows: Provides utmost flexibility and precision to the student while adding contribution of his team members, we can provide a text box with necessary validations which lets the student provide the contribution % for his teammates as any integral number within the limits. There will also be text to warn the user about how much contribution is remaining based on what is typed into the box and any previously completed teammate reviews. <image>. The amount of credit assigned to self will be the remaining amount of percentage not given to the other teammates for the reviews. This will eliminate the need to do a self-review to specifically assign the leftover percentage to oneself. The self percentages for the cake questions will only be assigned to a student once they have completed the reviews for all other teammates. This will ensure that the students are motivated to complete the teammate reviews and the self-review calculation is executed once (instead of needing to re-calculate after each review). In the current system workflow, we found that the teammate reviews are taken as instances of TeammateReviewResponses. The questionnaire for reviewing teammates includes the question asking the cake (contribution) factor. Ideally, the cake should include the reviewer as well. Currently, whenever a participant is reviewing their teammates they are shown a view where the names of their teammates are displayed with a 'Review' link next to them. The last line has the user name displayed with no link but reminder text to complete their reviews. We plan on updating this view once the reviews are complete for all teammates with a 'View' link in the user's line item that will show all of the self cake contributions. 1. Log in to expertiza to view the home page 2. Login as an Instructor, and then impersonate a student or login as a Student 3. Go to Assignments -> Your team 4. You will see a list of your teammates with a link: ‘Review’ 5. You will see yourself with no present link, this will become visible once you complete all reviews as: 'View' 6. You can see the questions for asking the contribution as a cake type 7. There will be a text description next to it denoting what part of the cake is taken (what contribution factor of the work is used) 8. For yourself the view will automatically be filled out with the leftover percentages for each cake contribution. We found that it was efficient to calculate a self contribution as the remaining percentage not assigned to all other teammates. This eliminates the need to create a specialized self-review to assign a contribution to oneself. We decided that it would be best to allow access to the self-review once all other teammate reviews are complete because it encourages users to do their reviews and the final calculation for self contribution needs to only be done once. A new class Cake has been newly introduced as a subclass of ScoredQuestion. The Cake class is a type of question that can be offered as part of any questionnaire, which keeps an account of all the answer values recorded for one specific question. The maximum value that can be given to a question of type cake is 100, and any value entered above 100 is automatically void, setting the answer entered to zero by default. The user is informed of the same and also can keep track of how much of the “cake” has already been taken, which helps him determine the value that he can enter. Upon entering a value greater than 100, a warning is displayed, informing the user that the value has exceeded 100, and setting the value back to 0. A textbox input with up-down arrows is being used, to help the user increment/decrement values as he pleases. 1. app/controllers/questionnaires_controller.rb Added cake type in editing the questionnaire. <code> 2. app/controllers/response_controller.rb A new method calculate_total_score was added. And it is called in methods new and edit to calculate and update the total contribution for a cake question when a student wants to create or edit a review. <code> 3. *app/models/cake.rb A new class Cake was added as a subclass of the ScoredQuestion class. A cake type question has a textbox that takes the percentage contribution assign to the reviewee for this specific question. Only positive integers under 100 are legal in this textbox, and illegal inputs will be prompted with corresponding error messages. <code> <image> 4. app/views/questionnaires/_questionnaire.html.erb Added cake to the dropdown list. Now the instructor can choose to add a cake type teammate review question to the questionnaire. <code> <image> 5. app/views/response/response.html.erb Added response showing how much of the total contribution has been assigned for a cake-type question. <code> <image> 6. app/views/student_teams/view.html.erb Added a new table intended to display the remaining score in each question the reviewer currently has. <code> <image>. There are several things we plan on testing in this project as follows: 1. Test the Cake question type to see that it properly renders and is editable 2. Test the view for 'Your team' to verify the table containing Review Questions and Self Contributions is present when reviews are enabled 3. Test the string reminder text for the cake questions that indicate the amount of contribution left to assign 4. Test the cake contribution text boxes for valid responses (no negative numbers, over-allocation, or non-numeric characters) <image>. The implementation that is done in this project adds the Cake type question for questionnaires and verifies that a total of 100% is not exceeded by all contributions given to team members. It also validates that non-numeric entities are not allowed to be saved as a contribution. For the future scope of this project, the next step would be to add to the table view in student_teams so that the cake questions included in the teammate review rubric display along with the self contribution percentages. This can be done by pulling the response map for the user id and team id they are assigned to and populating all cake questions in the list. By using the calculation functions that exist in cake.rb, it should be possible to find the total contribution at any given time that has been assigned to teammates and subtract that that value from 100 to receive a self contribution. This value can then be displayed next to each cake question and be assignable to a grade for that student when being evaluated by the instructor. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.","This is a very readable description of the changes made by this project.  Good descriptions are given of how the new methods work.  Would have liked to see you use subheadings, e.g., 3.1, 3.2, etc. to describe each of the files.","Dear student,

Thank you for the thorough and well-researched assignment on integrating the ""Cake"" item type into Expertiza rubrics. Your design and approach on solving the presented problem is detailed, feasible, and well-reasoned.

You have clearly explained the existing problems in the current system and have proposed an innovative solution to improve it. Your approach for a 'Cake' model assures no one gives more than a hundred percent, preventing over-assignment of contribution percentages, which is a common issue.

You have also done a commendable job in explaining some of the cons of using stars for allocation and the proposed solution using drop-down menus or text boxes. Your illustrations and figures add more clarity to your explanation. 

The step-by-step proposed software changes are particularly impressive. They show strong technical understanding and the ability to communicate complex concepts. Your attention to practical limitations and extensibility of your proposed design shows proper consideration for real-world application and future improvements.

Strengths of your assignment include your proposed system workflow, ViewController updates, Cake class concept, and more. Your end-to-end solution approach is laudable.

However, there's room for improvement in some areas as well. The explanation could be made simpler and more streamlined for the reader. It might be easier to grasp your design if you build up from simpler concepts to more complex aspects. 

It is also important to include more actual research findings. Employing real-world samples, conducting a literature review, or perhaps even conducting a user case study might substantively strengthen the conclusions being drawn.

Lastly, testing is mentioned briefly at the end but some greater detail here would be beneficial. This could include a test plan, potential obstacles you anticipate in the testing phase, or a comprehensive list of edge cases that needs to be considered.

Overall, this was well-executed work with thoughtful reasoning and clear attention to detail. Please incorporate the feedback provided to further improve your future assignments and continue the good work!

Best regards,
[Your Name]"
127,E1765,"This page provides a description of the Expertiza based OSS project. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.1.1. <link> 1.1.1.1.2. <link> 1.1.1.3. <link> 1.1.1.4. <link> 1.1.3. <link>. <link> is an open source project based on <link> framework. The Expertiza project is software to create reusable learning objects through peer review. It is a web application where students can submit and peer-review learning objects (articles, code, web sites, etc). It is used in select courses at NC State and by professors at several other colleges and universities. It also supports team projects, and the submission of almost any document type, including URLs and wiki pages. Expertiza enables the instructor to create new and customize existing assignments. It also enables the instructor to create a list of topics the students can sign up for as part of a project. Students can form teams in Expertiza to work on various projects and assignments. Expertiza supports submission across various document types, including the URLs and wiki pages. This class manages the questions attached to a questionnaire. It enables the creation of new questionnaires, and editing of existing questionnaires. The questions attached to the questionnaire can either be added/updated manually from the user interface or imported from an existing comma separated file. Once the questions are added/updated satisfactorily, they can be exported as a comma separated file. The controller currently has its own import and export methods to achieve this functionality. The following tasks were accomplished in this project: 1. Fixed Issue <link> : Instructors can make changes to each others' rubric, which should not happen 2. Updated action_allowed for access_control to prevent unauthorized access of methods.. 3. Implemented new feature <link> : Dumping and loading rubric criterion from CSV 4. Refactored Questionnaires Controller to use existing Import and Export controllers. 5. Added import method in Questions model to enable creation of questions from CSV. 1. Any user irrespective of his/ her privileges can edit the questionnaire. The questionnaire should be restricted to be editable only by an instructor, administrator, or a super administrator. Furthermore, an existing questionnaire should be restricted to be editable only by the instructor who created the questionnaire in the first place. 1. Import and Export functionality in the Questionnaires Controller The current implementation of the Questionnaires controller uses its own import and export methods. The Questionnaires controller should instead use the import and export implemented for the intended purpose. This promotes separation of concerns and code reuse. 1. Problem 1 : An instructor can change others' review rubrics. The method action_allowed in Questionnaires controller returns true for any user role for all actions. <code> 1. Solution : The implementation has been changed in such a way that the restriction on who is allowed to edit an existing rubric is as follows: 1.1. A super administrator can edit any existing rubric. 1.2. An administrator can edit any existing rubric. 1.3. An instructor can only edit an existing rubric if it was created by him or her. An instructor cannot edit a rubric created by another instructor. 1.4. The other functionalities have been left as it is, assuming that any user can create, view, etc. a new or existing rubric. 1. Problem 2 : Import / Export controller The feature to allow importing Questions from files and exporting the questions had been broken since the refactoring of Questionnaire controller in <link> . 1. Solution : Solution 1.1. The export file and import file views have to be enhanced to allow import/export of questions. 1.2. Questionnaire edit view will have to be enhanced to render the export_file/start and import_file/start views which would support importing questions from and importing questions to CSV files. 1. The action_allowed? method in Questionnaires controller has been modified to check for separate roles based on the action: 1.1. If the action is edit, it checks that the user is a super administrator, an administrator, or an instructor who created the questionnaire in the first place. 1.2. Else, all users are allowed to perform the action. (Assuming that even a student is allowed to add a questionnaire such as polls, surveys, etc) <code> 1. Integrating export_file and import_file section with the questionnaire view allows questions to be imported into system from file, example CSV file and also to export question entries from system into an external file. 2. The export_file and import_file views are now partial rendered as part of the edit questionnaire view. <code>. Following are a few testcases with respect to our code changes that can be tried from UI: 1. Log in as instructor 1 and create a new rubric. 2. Log in as another instructor. Go to [ Edit] page for the rubric and try to edit the questions. 3. Re log in as a student. Go to [ Edit] page for the rubric and try to edit the questions. 3. Re log in as instructor 1. Go to [ Edit] page for the rubric and try to edit the questions. 4. Re log in as a super administrator / admininstrator. Go to [ Edit] page for the rubric and try to edit the questionnaire. 5. ""Export"" button can be used to export all the questions and its associated details from the current questionnaire into a csv file that would named with the name of the questionnaire. 6. Choose the file that contains the questions to be imported into the questionnaire and press ""Import"" button to import the details into questionnaire. 1. The columns expected in the csv file would be displayed in the same page in the expected order. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. Clean Code: A handbook of agile software craftsmanship. Author: Robert C Martin.","In my opinion, this writeup is too short.  While it does describe the changes to the action_allowed? method in detail, there is very little description of how the dumping and loading of rubric criteria work.  Also, there is no indication of whether feature tests have been written.","I appreciate the thoroughness and detail of your write-up on the Expertiza-based OSS project. You give a clear and concise explanation of the project's aim, objective, and functionalities. You do an excellent job of describing the features, the issues you faced, the solutions and the functionalities of your codebase. I commend your problem-solving skills in addressing and resolving the issues.

However, please take note of the following areas that could benefit from some improvements.

1. Layout and Structure: There is an overuse of bullet points and numbering, which makes your project explanation lengthy and confusing, especially when it comes to the hierarchy of the bulleted points. Try to use paragraphs and headers to separate your points for improved readability. 

2. Content Formatting: Watch out for correct and logical sequencing, especially for enumerations. There seem to be two sets of numbering starting from 1 in your project. 

3. Proper Usage of Code Snippets: While you have integrated code snippets to explain your points, you have appeared to use the ""<code>"" tag without including any sample code. Please ensure to use the code snippet only when you are sharing a part of your code.

4. Hyperlinks: You frequently use ""<link>"" as placeholders for urls. For a more polished and final presentation, replace <link> with actual urls or descriptive text that links to the urls.

5. References: It's good that you provided some references at the end of the project. Make sure to uniformly style and format all of your references, ideally using a recognized citation style.

6. Technical Detail: Please ensure to explain specific terminologies and technologies for a broad set of readers who may not be familiar with them.

Remember, the goal of the assignment is not just to complete the project but also to effectively communicate your work. By tending to these areas, your work can improve greatly in clarity, coherence and neatness. Keep it up!"
128,E1730,"Please note that our problem statement has changed! The 'Problem Statement' section in this article describes the new one. <link>. Expertiza is an open source peer review system. It allows students to upload their work which can then be reviewed by other students using a rubric. Instructors and graders can view the reviews and they can then assign grades to the reviewers as well the reviewee. While grading students, a grader might want to organize reviews by sorting them by a particular metric. The only available metric was ‘Average Volume’ (number of words in the review). A new metric called ‘Overall Sentiment’ is added which is a gauge of the sentiment of the review, that is, whether the review was positive or negative. The task was to allow a grader to select a particular metric, and the view displays that metric for each review. In addition to that, the grader should be able to sort the reviews by that selected metric. 1) For each review, send a POST request to the Sentiment Analysis URL for sentiment analysis with the review as parameters. 2) Store the sentiment values in a list. 3) In the view, allow the grader to select the metric(average volume or overall sentiment) from the drop down menu. 4) The view is rendered accordingly to either show overall sentiment in the metric or the average volume 5) Using the tablesorter (jQuery) addParser method, the Metric column is sorted by the appropriate metric. Only a single metric for sorting reviews called ‘Average Volume’ was present. The table was sortable only by that metric. The ‘Overall Sentiment’ metric is added to the system. The grader can choose between two metrics (Average volume, Overall Sentiment) and sort reviews by that metric. A gem called HTTParty is added which facilitates the sending of HTTP requests (GET, POST, etc.) to the web service using Ruby code. app/controllers/review_mapping_controller.rb app/helpers/review_mapping_helper.rb app/views/review_mapping/_review_report.html.erb app/views/review_mapping/_searchbox.html.erb spec/helpers/review_mapping_helper_spec.rb. Method description: This method constructs the query to be sent to the sentiment generation service. It takes the review id and the text in the review and constructs the query in the format required by the sentiment generation server. Code: <code> Method description: This method retrieves the response from the sentiment generation service. It makes a JSON request and expects a JSON response. It takes two parameters, the review for which the sentiment is to be obtained and a boolean to check whether it's the first try in obtaining the sentiment value. In the cases where the Sentiment generation server fails to calculate a proper sentiment value, we will retry our request with only a single sentence of the review. It was decided after a meeting with professor to simply use the first sentence of the review text as the single sentence that would be used during the retry, to try and generate a sentiment value. Code: <code> Method description: This method creates a sentiment hash with the id of the review and the results from the sentiment generation service. Code: <code> Method description: This method handles the case when a sentiment generation query has been retried. This is the last effort to retrieve a sentiment from the server. If it succeeds and a 200 response code is received, we parse the JSON response to extract the sentiment value. If unsuccessful, we assign the sentiment a -500 value to represent an error condition where even the retry had failed to get a proper response from the server. This case could be due to a variety of reasons like an overloaded server, a malformed query, etc. Code: <code> Method description: This method generates the sentiment list for all the reviews. It gets the sentiments created from parsing the responses from Sentiment generation server and inserts them into a list. Code: <code> Method description: This method creates the correct format i.e. Metric Name: Metric Value, so that the view can easily render it. Code: <code>. Scenario 1: Testing Tool: RSpec Description: Check whether the sentiment query is constructed. <code> <code> Scenario 2: Testing Tool: RSpec Description: Test whether the webservice returns a response <code> Scenario 3: Testing tool: RSpec Description: Check whether the web service does not respond with a 404 error or a 500 error <code> Scenario 4: Testing tool: RSpec Description: Check whether the web service returns a response in JSON format <code> Scenario 5: Testing tool: RSpec Description: Check whether the retry returns a valid response. It may be a -500 which would denote that the retry failed, however it should never be nil. <code> Scenario 6: Testing tool: RSpec Description: Check whether the sentiment list does not return a nil value <code>. Steps to run the RSpec test plan mentioned above: 1) cd into the expertiza directory 2) Run the command: rspec spec/helpers/review_mapping_helper_spec.rb Steps to test the implemented feature: 1) Login to Expertiza as an instructor, with the username - instructor6 and the password - password 2) Under the Manage.. tab on the header, click Assignments. 3) Click the Assignments tab on the page, in case the Courses are loaded(which happens by default sometimes) 4) For any assignment, click View Review Report icon 5) That will take you to the review report page 6) To choose a metric (Average Volume (default), Sentiment), choose from the Metric dropdown and click Select 7) The page will reload with the appropriate metric 8) You can sort using the arrows in the column header. If you have any issue with testing the feature, check out the Youtube video: <link>.","It would be helpful to have some kind of intro and perhaps also a summary giving the big picture.  The writeup as it is is just a series of changes, with no explanation of why the change was made, or how it fits into the overall goal of the project.  To understand what you have done, the reader will likely have to read the text over and over again, trying to figure out how everything fits together.","Good job on your assignment. It looks like you have understood the problem statement well and developed a methodical solution. Your step-by-step explanation shows the thought process behind your decisions.

The code snippets and the method descriptions provide a clear understanding of what each function is aimed to do. The decision to use HTTParty gem to facilitate sending of HTTP requests is quite fitting to the required functionality.

In terms of improvements, it might be useful to add more comments within your code. While your explanations here are clear, comments within the code itself can be beneficial for someone else (or even your future self) who might go through your code at a later time. 

Also, the sentences in your document could be a bit more streamlined and concise. There's a lot of valuable information here, but it sometimes gets lost in the length and complexity of the sentences.

Your testing plan looks comprehensive. I particularly appreciated your detailed instructions for running the test and testing the implemented feature. The addition of a YouTube link for additional troubleshooting is a thoughtful touch.

Overall, great work! With a little cleanup and clarification, your code and documentation will be even better. I look forward to seeing your next assignment."
129,E2109,"Expertiza allows users to complete peer reviews on fellow students' work. However, not all peer reviews are helpful, and some are more useful than others. Therefore, the application allows for the project's authors to provide feedback on the peer review, this is called ""author feedback."" The instructors have no easy way to access the author feedback while grading peer reviews, which would be a useful feature to have since this shows how helpful the peer review actually was to the group that received it. Thus, making the author feedback more accessible is the aim of this project. However, a group in 2018 was tasked with this project as well, and most of the functionality appears to have been implemented already, but that is in an older version of Expertiza. Our primary task is then to follow their implementation, refactor any code that may require it, make the suggested improvements that were left in their project feedback and make the feature compatible with the latest beta branch of Expertiza. Secondary tasks are to make the author feedback column toggleable and to refactor the function that averages author feedbacks so that it reuses existing code that exists somewhere in Expertiza already. 1. Our primary goal is to take the author feedback column functionality from the 2018 branch and update it so that it merges successfully with the current beta branch. 2. In the 2018 branch, there is an author feedback column to the review report, but the previous team's submission added new code to calculate the average. However, this most likely already exists somewhere else in the system, and so we will identify where that functionality exists and refactor the code to reuse it to follow the DRY principle. 3. Part of the 2018 group's feedback said that the review report UI began to look somewhat crowded in its appearance. However, there is often no author feedback, and so the column for that should be made toggleable. So we will make it so that the column is dynamic and will only be present if there is author feedback to display. The user could then toggle the column to show or hide that information depending on their own preference. Below is the current implementation of the page we are going to edit on the beta branch. It can be seen that the ""author feedback"" column is not present in this view at all. <image> Here is the 2018 group's version of the page we are editing. It has the ""author feedback"" column as well as the necessary functionality. However, the user interface has clearly changed since 2018, and therefore, there will likely be merge conflicts between their branch and the current beta branch. Part of our task would then be to resolve those merge conflicts and port the functionality back over to the most recent beta branch. (Sourced from this <link> ) <image> Currently, in the 2018 group's branch, the entries in the ""Score awarded/Avg. score"" and ""Author Feedback Score"" columns contain a lot of missing entries. Though, this does not appear to be the case in the most recent beta branch available in 2021. Therefore, we would add this filter (i.e. code that removes the missing entries represented by the dashes) to the missing entries available in the beta branch to the 2018 group's branch code. In addition, the 2018 group's branch has the author feedback in its own column in-between ""AVG score"" and ""Metrics"". Instead, we will move it under the same header column ""Scores"" as seen in the current beta branch, just to the right of the ""AVG Score"" column. To accommodate for this additional column being introduced, the ""Team reviewed"" column width would be reduced a bit so that the ""Scores"" column renders approximately at the same location on the page. Below is the final product of our implementation. As can be seen, some columns that had unnecessarily large amounts of space given to their width e.g. reviewer and team reviewed, have been reduced to accommodate the new author feedback column. There is also still ample space for the assign grade and write comments column to be expanded. <image>. The below files were expected to be edited by our group to complete this project: 1. app/views/reports/_review_report.html.erb 2. app/controllers/review_mapping_controller.rb 3. app/models/on_the_fly_calc.rb 4. app/views/reports/response_report.html.haml 5. app/views/reports/_team_score.html.erb However, the below files had to be edited (or added) in order to implement the author feedback column: 1. app/helpers/report_formatter_helper.rb 2. app/helpers/review_mapping_helper.rb 3. app/models/on_the_fly_calc.rb 4. app/views/reports/_review_report.html.erb 5. app/views/reports/_team_score_author_feedback.html.erb In the report_formatter_helper.rb file, an attribute had to be added to the helper (that is later mixed in with the reports_controller). This attribute gives the controller access to the model's author feedback scores that have been calculated. The review_mapping_helper.rb file required an older method to be once again introduced, this method is called ""get_each_round_score_awarded_for_review_report"". It is required to properly read and display the computed author feedback scores from the hash they are stored in. Another method that is similar to it, ""get_awarded_review_score"", could not be used as it causes an exception to be thrown; this is due to the fact that the ""get_awarded_review_score"" method does not accommodate for when the hash does not contain the key it is trying to access (specifically, it is unable to handle when the ""reviewer_id"" does not exist in the hash's set of keys). The on_the_fly_calc.rb file only required the expected changes as introduced in our implementation plan. However, one additional method, called ""feedback_questionnaire_id"" had to be added in order for the ""calc_feedback_scores_sum"" method (that is also in the same file) to work. This method used to exist else where in an older version of Expertiza, located in the assignment.rb model, but it is not needed beyond the scope of ""calc_feedback_scores_sum"", so it exists with private access in the on_the_fly_calc.rb file. The _review_report.html.erb file had to be modified - the width of the other columns was reduced to make room for the author feedback column, the column header was added, and the necessary call to the author feedback column partial was also introduced. Finally, a new file called _team_score_author_feedback.html.erb, was added to the repository. This file is the partial required to render the author feedback column, and is a reintroduction of the 2018 group's _team_feedback_score.html.erb file. Like the 2018 group, we plan to add three methods to the on_the_fly_calc.rb file in Models. These methods are: 1. compute_author_feedback_scores 2. calc_avg_feedback_score(response) 3. calc_feedback_scores_sum The feedbacks are stored in the ResponseMaps table and are queried using the assignment_id/reviewer who gave the response/reviews (responses) in each round in the 'compute_author_feedback_scores' method. The method iterates through all the rounds done during the review process, and calls the 'calc_avg_feedback_score' method, providing a ""response"" argument. The response argument is the review a team provides for the author's work. Lastly, in order to obtain the final average score for a particular review (response) that the authors (team) have gotten, they obtain a sum of the feedback scores from each of the authors and divide it by the total number of feedbacks that were obtained. These methods have already been implemented by the 2018 group and are included here again for the reader's convenience. <code> <code> <code> However, they calculate the average with a custom implementation that most likely exists somewhere else in Expertiza already as suggested by the instructors. As part of our project, we will identify where that functionality exists, and either reuse it or extend it so that it can be reused here instead. Though, we will first implement the functionality as the previous group did, and then slowly perform our refactor to ensure functionality is not broken by the refactoring process. Since we will need to modify the user interface to introduce the author feedback column, we expect to add a column within the .erb files in the views folder that were identified above. These files were selected as they were the files necessary for the previous group to implement their UI changes. They also add a 'calculate_avg_score_by_feedback' method to the controller for the file 'app/controllers/review_mapping_controller.rb'. The following method was written by the previous team to calculate the average scores for the feedback given by authors for the reviews of their work. <code> Unfortunately, it exists in the controller level logic, and perhaps isn't required to exist there. It is likely better for this method to be moved to this controller's corresponding model, and we will do so during our project to make the code follow the principles of MVC. The 2018 group wrote a RSpec test when they wrote their function to calculate the author feedback scores. It was located in the on_the_fly_calc_spec.rb file and the method they wrote was called 'compute_author_feedback_scores'. Below is the snippet of the RSpec test that they wrote: <code>. The UI testing, isn't much of a functionality, but is rather the change in the view of the report page by the intructor. For anyone to test the UI, the following steps would be a suitable guide: 1. First login to the expertiza website with Username as instructor6 and password as password . 2. Next click on Manage and tab on top left of the screen and click Anonymized View . 3. Once we get into ananoymized view, click on Assignments . 4. After the assignment list loads up, on any given assignment, eg: Final Project Documentation, navigate to the right side and search for the icon with a person on it and says Review report. 5. Click on that icon. This will take you to another page where there is a button Report View . Click on that. 6. This will navigate you to the report page as seen above and you will be able to view the Author's Feedback column and score obtained for every student. 1. <link> 2. <link>.","The design document seems based on editing and debugging the 2018 project.  It has not been updated to incorporate many of the changes made in their project, though I do see that it was edited on April 30. The other issue I see is that the design doc treats the 2018 project almost as a black box ... code that should be modified to get it running, without describing the design of that code.  The changes that this team made are described better, but to know how the code works, it would still be necessary to understand the 2018 project.","Dear student,

Great job on your report on the Expertiza project! Your detail-oriented and thorough approach is highly commendable. 

Your problem identification, explanation of the tasks, and clear communication of your project goals and proposed solutions are solid. Good use of past projects and understanding of the Expertiza system to propose changes and improvements. Your detailed walkthrough of the system alterations for the codebase, from the front-end to server-side logic, is well structured and articulate.

Incorporating images in your report is a very helpful addition to visually clarify the changes made and enhances understanding. Your anticipated changes and additions to the software's code are comprehensive and capaciously explained. Using the DRY (Don't Repeat Yourself) principle in code refactoring shows your grasp of an important software development principle.

Here are few suggestions for improvement:

1. Use a more formal, academic language to ensure professionalism in your work as some sentences are a bit informal.
2. For YOUR project, always try to describe the methods YOUR team is going to implement, not what has been done by previous teams. Your project includes not only reuse and refactoring, but novel development as well. Do highlight your contribution more.
3. Try to cut down on repeating similar points, and focus on making each point clear and concise once.
4. Include more about testing or possible issues that could arise and how you could anticipate and handle them.
5. It would be useful to have a pre and post-implementation comparison or discussion section. 

Please revise and further develop your report with these suggestions. I am excited to see your final product. Keep up the good work!

Regards,
[Your Name]"
130,E2086,"1. Deployment Link: <code> 1. Github Repository: <code> 1. Github Pull Request: <code> 1. Youtube Video Link: <code>. 1. Expertiza Project - E2086 : Let course staff as well as students do reviews. Peer review is a great way for students to learn about how well they have developed their application. However, sometimes, the peer reviews may not be thorough and the team/person's work reviewed might not reflect the actual status of the development. By letting course staff perform reviews as well, the reviewer and the reviewee both benefit, improving the overall learning experience. Currently, there exists no method for the instructor/TA to perform reviews of assignments submitted by the students. Hence this is what this project aims at, allowing instructor/TA to perform reviews. This project aims to allow instructors to submit reviews of student work, using the same review form that students use to do reviews. Controller: <code> Model: <code> View: <code>. Our project aims at enabling the instructor/TA to review the submissions using the same form that a student uses while peer-reviewing. For this, our implementation has been divided into 3 parts, and can be described as follows: 1. The first part involves the primary functionality of letting the staff perform a review on students submission. 2. The second part involves allowing the students to identify from their end, which review has been performed by an instructor/TA. This will help students improve their project as the opinions presented by a staff member would be valid. 3. Third, we plan to enable the instructor/TA to do review instead of assign grade in the review round. After the review Round, the review review session will be closed and replaced with assigning grade interface. 1. Functions that were included <image>. 1. In the assignment page of the Expertiza, If an instructor or a TA is a participant in an assignment, then the instructor should be able to review any team that has submitted the assignment. 2. In order to see who is participating in the assignment, click on the “Add participants” icon (the one with the + sign and a picture of a person). That will bring up a list of participants and allow you to add more participants. 3. Make the instructor and/or TAs participants, and then they should be allowed to do reviews. <image> 1. Then, to perform reviews, the instructor/TA would click on the clipboard-like “View submissions” icon, as shown below. <image> 1. A list of submissions would be pulled up: <image> 1. If the last due date for the assignment has not passed, then the “Assign grade” link should be changed to “Perform review”, and when clicked on, it should pull up a review page for the team, showing their submitted work at the top, as a review page normally does. 2. We will add the review link in views/assignments/list_submissions.html.erb and once instructor/TA click that link. Controller response will be called. Once the get_current_stage() change to ""Finished"" it means the due day of the review round is over. The review link will be replaced by the grade link. 1. Also, it would be more clear if we could mark the instructor's review with something special on the reviews page, as shown below. 2. We will add an icon in views/grades/view_team.html.erb and app/views/response/view.html.erb if these review is made by instructor or TA. This function will be implemented in helpers/grades_helper.rb <image>. We create a link ""Begin review"" in list_submissions.html.erb in order to let staff(TA/Instructor) perform review before the review deadline. And if the current stage becomes ""Finished"", we show the ""Assign Grade"" link. We use function current_user_is_assignment_participant to check if the current user have access to perform review. If the current user does not have the access to this assignment. No link will be shown. <image> This is what it looks like. <image>. first, we found some code in the student_review/_responses should not show here. The purpose of the code from line 5 to line 12 is to find team members. This action relates to response_map. So we created a function called ""find_team_member"" and moved the code into response_map . <image> <image> Second, we found it is better to use unless instead of using if ! in ruby on rails. So we fixed this small issue. <image> Third, we found that the student review and the staff review have a lot of common code. So we refactor the student_review/_responses and let student review and staff review share one common template. We created a symbol variable :reviewer_role in order to identify the role of performing review. The shared template locates in app/view/shared/responses folder. <image>. In this file, student review and staff review share one template. We use reviewer_role to identify the role of the reviewer and render the different views for this reviewer. The page will show different review action base on the current stage and if the review did this review before (For example: if the current stage Finished and no previous review, the page will show ""Begin review""). <image>. Before modification, the normal review could only be done by students. When the student finished the review and clicked “Submit”, the page seemed to redirect from the students' review. Since we newly added staff to review, the location of redirect should also be modified accordingly. <image>. A simple check is made to determine if the reviewer is a TA or Instructor. app/assets/images/staff.png is displayed to make an instructor performed review stand out from other reviews. First, in order to determine if a review was completed by a staff participant (either a TA or an instructor), we create a function in app/models/review_response_map.rb. <image> If the mouse hovers over the icon a tooltip appears saying ""Icon indicates this review was done by course staff"" <image> <image>. The basic idea of this project is to change the 'Assign Grade' link to 'Perform review' if the deadline of a assignment has not passed. Thus, to test the functionality of this part, we plan to test it at the frontend. 1. Click 'Manage' -> 'Assignments' to go to assignment page. 2. Add a new assignment for a course that the current account has registered. Make sure the due date of the assignment is after the the time to perform the review as an instructor. 3. Click 'Add participants' icon in the new created assignment row, and 'Copy participants from course' to add all students registered to this course. Then add the current instructor account to this assignment through 'Enter a user login:' input space. 4. Impersonate as one of the students to simulate the submission of work. 1. Click 'Manage' -> 'Assignments' to go to assignment page as instructor. 2. Click 'View submission' icon in the new created assignment row. Now the 'Begin review' link show be under participants name if the due date has not passed. 3. Click one of the 'Begin review' link to do the review for a certain submission by using the same templet of student peer review. 4. Impersonate the student that was previously reviewed by instructor. Check score for the assignment, and the review from the instructor should be recognizable from other student reviews. <code>. <image> All Rspec tests are passing for this implementation as is evident by the Travis CI. <image>. The video <link> demonstrates the functionalities implemented in this project. This project was done by Team E1985 on Fall 2019 with the following work: Expertiza wiki: <link> Github Pull Request: <link> Github repository: <link> Youtube screencast: <link>.","The document is comprehensive and readable.  The list of team members is in the middle of the document, which is unusual.  The long partial _response_actions.html.erb should have been described in more detail (or divided into multiple partials).  Also, the rspec tests should have been described in more detail, by saying what is being tested.  However, these are minor points; overall, it is a very good job.","Dear Student,

Congratulations on your articulate and thorough submission. Your report was exhaustive. It had a good blend of coding and descriptive explanation which gave a comprehensive overview of your project. I appreciate the idea of your project, letting course staff, and students do reviews is indeed a great way to yield better results, and enhance the learning experience for all.

You have explained clearly the project aim, which is to enhance the review process of student work by letting instructors/TA participate as reviewers. The three-part implementation was also comprehensible. Your description on how instructors will be allowed to participate in the review process and how it will impact the students is thoroughly done.

Images provided to support your implementation were also quite effective. The part where you discussed the fixes you made and the refactoring of code was duly noted.

Ideally, the code snippets should be properly labeled and commented to give a clear understanding of their functionality within the project, unfortunately, I wasn't able to check it because of the missing codes. 

The testing portion was a good inclusion, it allowed for a step by step picture of how the project operates. However, the section was written in the second person which doesn't adhere to scholarly formality. Also, the material would've benefitted from having sample outputs of each test detailed for better clarity. 

Lastly, good job on passing the all Rspec test for your implementations. This is a good indication of the quality of your project. Also, you have provided the links for the Travis CI, and Expertiza wiki, but unfortunately, the actual hyperlink is missing which makes it unclickable, and the resources are not actually accessible.

Overall, your presentational skills were good, and the project shows a lot of commitment and understanding. Kindly pay attention to the missing parts in your submission, it will avoid detracting points unnecessarily in the future.

Keep up the good work!

Best,
[Your Name]"
131,E2079,"The <link> project takes advantage of peer-review among students to allow them to learn from each other. It is an open-source application running on Ruby on Rails. It is used for the management of courses and the assignments for respective courses, by the faculties and the students. The manage content section of the application has different views that display information about the users, courses, assignments, questionnaires, and reviews. The application should have a fully functional search functionality throughout the views, so that a user can search any type of data with ease, on the basis of any number of parameters depending on his requirements. Users should be searched on the basis of one more parameter which includes name, full name, email, etc. Similarly, assignments should be searched on the basis of name, created date, updated date, etc. However, the search functionality in the existing application is constrained to just a single parameter for users and assignments. Questionnaires management does not have a search functionality implemented as yet. This project works on improving the search functionality of Expertiza, by adding search bars if not present, introducing an advanced search feature where user can search on the basis of more than one parameters, and making the search functionality appear more elegant. 1. An instructor or administrator can search for a user by name, user-ID, or other characteristics. 2. An instructor should be able to search for assignments by name, due date, or other characteristics. 3. An instructor should be able to search for rubrics (or other questionnaires) by name, or by the courses or assignments they have been used in. 1.1. For the instructor, there also needs to be a way to quickly find rubrics (and other questionnaires) that have been used in a single course. It should be possible to search or click somewhere to bring up a list of questionnaires used in the course, expanding only the applicable questionnaires in the list of questionnaires. 1.2. One should also be able to search for questionnaires by words used in questions that belong to the questionnaires. 4. There should be a way to search all reviews of a particular team’s work for particular scores or text strings. Reviews should be able to be filtered by score, text comment length, reviewer, and reviewee. 5. An instructor or administrator should be able to search for all the assignments that a particular user has participated in. 6. If more than one criterion needs to be specified, there should be an 'Advanced Search' button. 1. <link> 2. <link> 1. <link> Previous implementation 1. <link> 2. <link>. The design proposed in this iteration of the project is not much different from a high level than the design proposed form last year in <link> . Below you will see a copy description of the solution previously proposed and some additional design choices added to improve upon the previous iteration of this issue. Changes from the previous design will be denoted by clear statements indicating the revision. Four main objects in this application are used as the basis for expanding search functionality. These are the user, assignment, questionnaire, and the review. Each of these points are searchable by the title of the object or not searchable at all. The remaining sections note the current situation and propose a tentative solution. Note the following is a copy of last year's proposal. Reference is listed at the bottom of the page. In the current system workflow, the user is unable to search in the Manage Users view. In the proposed workflow, we plan to enable the user to search by all the columns in the UI viz. Name, Full name, Email Address, Role, Parent by entering a partial or a complete text that matches the particular field. We will also allow searching for fields irrespective of the case of the searched string. The user will be able to apply multiple filters at a time and the output of the query will match all filters applied. If no results are found, an empty list will be returned. In the current system implementation, searching via the name of the assignment is supported with a partial or complete assignment name. However, the search is case sensitive. In the proposed system, the user will be able to search for an assignment using additional filters such as Creation Date and Updated Date along with Assignment Name. The user will also be able to apply multiple filters at a time and the output of the query will match all filters applied. If no results are found, an empty list will be returned. To search for an assignment by Creation Date, the user will be prompted with a calendar where he can select a date and all the assignments created on or before the selected date will be displayed. To apply multiple filters, the user can tap on the Advanced Search button available, adjacent to the Search button; a hidden div will then be rendered below-containing text boxes for all the columns. All assignments that were created before the selected date for Creation Date or Updated Date columns and the ones that match other filters will be returned. An empty list will be returned if the search criteria don't match any records in the database. The existing system does not have search functionality under Questionnaires. The proposed system will implement search functionality for searching via the name of the questionnaire, the text in the questions within a questionnaire, date of creation, and date updated by entering a partial or a complete text that matches the particular field. We will also allow searching for fields irrespective of the case of the searched string. The user will be able to apply multiple filters at a time and the output of the query will match all the filters applied. If no results are found, an empty list will be returned. To search for an assignment by Creation Date, the user will be prompted with a calendar where he can select a date and all the assignments created on or before the selected date will be displayed. To apply multiple filters, the user can tap on the Advanced Search button available, adjacent to the Search button; a hidden div will then be rendered below-containing text boxes for all the columns. All assignments that were created before the selected date for Creation Date or Updated Date columns and the ones that match other filters will be returned. An empty list will be returned if the search criteria don't match any records in the database. The questionnaires will be grouped on the basis of their courses and will be expanded when clicked. The existing system does not have search functionality under Reviews. The proposed system will implement search functionality for searching using the attributes like team name, score, reviewer, reviewee, comment, etc. by entering a partial or a complete text that matches the particular field. We will also allow searching for fields irrespective of the case of the searched string. The user will be able to apply multiple filters at a time and the output of the query will match all the filters applied. If no results are found, an empty list will be returned. The user will be able to apply multiple filters at a time and the output of the query will match all filters applied. If no results are found, an empty list will be returned. Below is a flow diagram from last year's iteration that we will aim to follow in our implementation. Reference is listed at the bottom of the page. <image>. This is the sequence diagram for the interaction between instructor and expertiza in the context of advanced search. <image>. The code changes will be in the following files In the <link> , some of the code changes in the diff of app/assets/javascripts/tree_display.jsx are unintentionally moved around,added and deleted in several places. This is likely caused due to code added in-between 2 other parts of code which makes it seem like it's been deleted and added at another place. Controllers app/controllers/ <link> Models app/models/ <link> app/models/ <link> app/models/ <link> app/models/ <link> Views app/views/reports/ <link> app/views/users/ <link> app/views/users/ <link> Helpers app/helpers/ <link> app/helpers/ <link> Rspec Tests spec/models/ <link> spec/models/ <link> spec/models/ <link>. 1. on_the_fly_calc.rb 2. summary_helper.rb 3. report_formatter_helper.rb (seen on branch review_adv_search_scores) 4. _searchbox.html.erb (seen on branch review_adv_search_scores) Since the last team had this code working, we decided not to reinvent the wheel but use their implementation for the feature. Thus, both helper files were updated to accept additional search criteria. This was accomplished by updating the summarize_reviews_by_reviewees(...) function to include the search attribute criteria. This includes getting teams, min and max score, and text from the search criteria. A Query object the collects the team object, leaving the rest of the logic to filter reviews from team reviewees based on all search criteria. The _searchbox.html.erb file was also updated to reflect the graphical changes for a user to enter additional search criteria if the SummaryByRevieweeAndCriteria tab is selected in view reports . However, bugs were found in the beta branch that hindered the required webpages to load. Therefore, a few bugs were fixed while others still remain. As a result, these changes are left in the review_adv_search_scores branch instead if being merged into beta. 1. tree_display.jsx 2. tree_display.scss 3. questionnaire_node.rb There are 2 main classes associated with the QuestionnairesSearchBar and QuestionnairesAdvancedSearchBar. QuestionnairesSearchBar is the main search bar containing the traditional search bar also with the advanced search bar which is QuestionnairesAdvancedSearchBar. We have the option to enable or disable this UI element in the code. For the model, we use the variables question_text, course and assignment which are bound to the model questionnaire_node.rb. The search parameters are also bound and will be updated automatically in the view and model. For example, when the user types text in the advanced search box, it can be accessed from the model and added to the query conditions. Changes to app/models/questionnaire_node.rb . Added the extra search fields to the query conditions. <image> Changes to app/assets/javascripts/tree_display.jsx . React code for advanced search. <image> Changes to app/assets/javascripts/tree_display.jsx . React code for advanced search. <image> Changes to app/assets/javascripts/tree_display.jsx . React code for advanced search. <image> Changes to app/assets/javascripts/tree_display.jsx . React code for advanced search. <image>. 1. tree_display.jsx 2. assignment_node.rb 3. tree_display.scss The functionality of assignment search filtration was implemented using react in javascript. This code was implemented in tree_display.jsx which directly impacts how the webpage functions based off of data in JQuery objects. React objects were added to implement search filtering functionality for assignments. The file, assignment_node.rb is updated to enable search parameters to interact with the table. The methods changeDateStart, changeDateEnd, changeAvailableToggle are relevant for the advanced search bar in assignments and courses. Changes to app/assets/javascripts/tree_display.jsx . React code for UI components in Advanced search for assignments and courses. <image> Changes to app/assets/javascripts/tree_display.jsx . React code for UI components in Advanced search for assignments and courses. <image> Changes to app/assets/javascripts/tree_display.jsx . React code for UI components in Advanced search for assignments and courses. <image> Changes to app/assets/javascripts/tree_display.jsx . React code for UI components in Advanced search for assignments and courses. <image>. 1. users_controller.rb 2. user.rb 3. _search.html.erb 4. list.html.erb 5. user_spec.rb The method ""get_user_list"" in user.rb and ""search_parameters"" in user_controller.erb from last team works perfectly doing the filtering work on this user page. These methods will accept 3 additional parameter that represent user name, full name and email of a user and return the filtered user list. The beta branch introduced a new paginate feature that divide the long user list on list.html.erb into multiple pages. We are using the ""paginate_list"" method to achieve this paginate function. The advanced searching box part is also from last team. The JS code works well on delivery our new searching parameters. The list.html.erb page takes a long time to load due to the large size of users in expertiza system. Please be patient for the loading and searching operations. <image> user_controller use the search_parameter method to filter user list by calling get_user_list method in user model class. <image> user model have new parameters on get_user_list method. It use these new parameters to filter list with regular expression. <image> The JS code for the advanced search box. Several bugs were found on beta before implementation took place. These bugs had to be dealt with before review summaries would be presented on the webpage. The following bugs were found in the following link: 1. /web_host/reports/response_report?class=form-inline&id=843 This link brings you to a page to view review statistics and graphics per assignment. Several optional views are listed but bugs have blocked pages from loading including the following: 1. Review Report (view) 2. Comment Summary by Review (view) The review report view contained a bug in on_the_fly_calc.rb on line 54 where the code was calling an undefined method to retrieve a review topic id. This function was refactored to successfully retrieve a topic id given a team id. After this bug was fixed, the page loaded review reports correctly. The comment summary by review contained multiple bugs. The first bug was found in summary_helper.rb when the code would try to split comments into sentences in function get_sentences(...) . Comments would exist but in the presence of only one sentence with no comments, the code would return a nil object. Therefore, this bug was fixed by returning the comment if it consisted of a single sentence, or a list of sentences of multiple sentences existed in the comment. Solving this bug led to another bug related to displaying the average score by criteria. Returning floats seems to break the program but we have been unable to find the root to this issue. Therefore, this bug still exists. Our code for searching through reviews cannot be tested as a result. The following screenshots show before and after an advanced search for courses, assignments, and users. <image> <image> <image> <image>. <image> <image> <image> <image>. <image> <image>. Following are from the master branch <image> <image>. Automated tests can be written to test the following functionalities: 1.1. Given an unfiltered search result still show 1.2. Given a filtered search, the result renders a list of objects containing the filtered search item 1.3. Given an invalid search, an empty list returns RSpec tests will be written to cover the depth of each test point above for all four search objects mentioned in the proposed solution. The one's shown below are not able to pass. This might be that the tests aren't written to test the exact functionality of our implementation. <image> This first set of rspec tests are written to demonstrate that the filtering logic is able to differentiate partial and incorrect search matches for first name and correct full name from an admin perspective. <image> This set of rspec tests is confirming that an incorrect full name renders 0 results, and a correct email will render the correct user. <image> This set of tests confirm that an incorrect email will render 0 results, while correct emails and correct first names will still render the correct user. <image> This set of tests confirms the functionality that full names and correct emails render correct users. It also tests first name and last name matches for all users. Additionally, a set of first name and full name combinations will render results for all matching users. <image> This set of tests confirms that narrowed first name, full name, and email render one specific result. UI tests will be performed to reproduce the behavior previously mentioned. These steps were reproduced from the previously proposed solution for this issue. 1.1. Log into expertiza to view the home page 1.2. Go to Manage > Users 1.3. Type the search string in the search box available on the UI and select the column to search for from the dropdown. 1.4. To perform a search based on multiple filters, the user can tap on the Advanced Search button adjacent to the Search button, the view renders a hidden div containing text boxes for all the columns, allowing the user to search based on multiple columns. 1.5. All the entries that match the specified criteria will be returned. 1.6. An empty list is returned if the search criteria don't match any valid records in the database. 1.1. Log into expertiza to view the home page 1.2. Go to Manage > Assignments 1.3. Type the search criteria in the available search criteria and select the appropriate field from the dropdown. 1.4. To perform a search based on multiple filters, the user can tap on the Advanced Search button adjacent to the Search button, the view renders a hidden div containing text boxes for all the columns, allowing the user to search based on multiple columns. 1.5. All the entries that match the given criteria will be returned. 1.6. An empty list is returned if the search criteria don't match any valid records in the database. 1.1. Log into expertiza to view the home page 1.2. Go to Manage > Questionnaires 1.3. Type the search criteria in the available search criteria and select the appropriate field from the dropdown. 1.4. To perform a search based on multiple filters, the user can tap on the Advanced Search button adjacent to the Search button, the view renders a hidden div containing text boxes for all the columns, allowing the user to search based on multiple columns. 1.5. All the entries that match the given criteria will be returned. 1.6. An empty list is returned if the search criteria don't match any valid records in the database. Link for Video Demo - <link>. Current issues exists in this PR for this issue, including build errors in the Travis CI build and various existing bugs within beta. Some of these bugs have been mitigated but others still remain. There needs to be more eyes and time on solving many of these bugs hidden within beta surrounding this issue. 1. <link> 2. <link> 3. <link>.","This document was not the easiest to read.  The changes for advanced review search should have been included.  Referring to the previous team's document makes it harder for the reader, who must flip back and forth.  Since the project was not merged, it is not useful to have future developers read about it.  For advanced questionnaire, assignment, and course search, the logic should have been described in more detail.  What are the various elements or methods in the views?  How do they fit together?  Many screenshots are segued together with no comments.  The reader would have to figure out what they are for.  I'm not sure why you said your automated tests could not pass.","Dear Student,

This is a comprehensive and very detailed assignment. Your effort and dedication are reflected in the quality of this work. You have identified the problem requirement clearly and proposed solutions quite considerably. It is impressive that you have provided step by step process flow for better understanding. Each phase of your assignment shows logical flow and rigorous analytical thought. 

However, there are a few things that could be improved. It would have been better if you could specify what bugs you encountered and how you resolved them, this would provide a more clear understanding of troubleshooting steps taken. Also, there's room for improvement in the testing section. Make sure to explain whether tests are passing or failing and specify your plan about what to do if they are failing.

On a general note, consider breaking up the longer paragraphs to make your report more readable. This is particularly important in the sections where you're outlining the solutions and in the automated testing section.

Keep working hard and never hesitate to seek help or clarifications if you need them. Your effort is commendable and I am looking forward to your next assignment. 

Best wishes,
[Your Name]"
132,E1762,"Expertiza is a web application where students can submit and peer-review learning objects (articles, codes, websites, etc). Instructors add and edit assignments to Expertiza. Students can be assigned in teams based on their selection of the topics. The Expertiza project is supported by the National Science Foundation. The Expertiza project is software to create reusable learning objects through peer review. It also supports team projects, and the submission of almost any document type, including URLs and wiki pages. In Expertiza, there are several types of response maps (model files in app/models). They basically map responses, the one who submitted the response and the one to whom it is directed to. The parent class is ResponseMap, and the subclasses are (from most used to least used) ReviewResponseMap, TeammateReviewResponseMap, FeedbackResponseMap, QuizResponseMap, AssignmentSurveyResponseMap, BookmarkRatingResponseMap, MetareviewResponseMap, SelfReviewResponseMap, CourseSurveyResponseMap, GlobalSurveyResponseMap. You can find the database structure for these response maps here. For each response map record, there is one reviewer_id and reviewee_id. However, you need to check the code to learn what are recorded as reviewer/reviewee ids (see the foreign key constraints at the beginning of each model, they could be participant_id, team_id, etc. as per that model). These models do not have any unit tests. • Create a factory for each response map models in factories.rb file (review_response_map factory has already existed). • Then create test files in spec/models (you can refer to answer_spec.rb, due_date_spec.rb for how to write specs); write model specs for methods (if you find any method has no caller, remove the method instead of write tests for it). Good tests means their coverage is maximum, so try to cover as much methods and conditions as possible. ---. To write the unit tests for the models, we need to define the spec files for the models. But before that, we need to understand the working of the methods. For this we use the following files (in app\models ) – • Response_map.rb • Review_response_map.rb • Teammate_review_response_map.rb • Feedback_response_map.rb • Quiz_response_map.rb • Assignment_survey_response_map.rb • Bookmark_rating_response_map.rb • Metareview_response_map.rb • Self_review_response_map.rb • Course_survey_response_map.rb • Global_survey_response_map.rb While writing our tests we will need a way to set up database records in a way to test against them in different scenarios. This is done by creating factories for each response map model in the spec/factories/factories.rb file. Now, we use RSpec to create the test cases for these models. These files are added in the spec/models/ folder. The convention of naming the files is MODELNAME_spec.rb , hence we get following files. • Response_map_spec.rb • Review_response_map_spec.rb • Teammate_review_response_map_spec.rb • Feedback_response_map_spec.rb • Quiz_response_map_spec.rb • Assignment_survey_response_map_spec.rb • Bookmark_rating_response_map_spec.rb • Metareview_response_map_spec.rb • Self_review_response_map_spec.rb • Course_survey_response_map_spec.rb • Global_survey_response_map_spec.rb After studying the given models to be tested, we realize that many of the models contained either a blank/unimplemented method or contained a standard ruby implemented method. Hence, the RSpec for these methods are not part of problem coverage.Consequently, no factories are created for the same. The following models did not contain any relevant method, hence the tests were not necessary for them: • Assignment_survey_response_map.rb • Teammate_review_response_map.rb • Bookmark_rating_review_response_map.rb • Self_review_response_map.rb • Course_survey_response_map.rb • Global_survey_response_map.rb Also, the ReviewResponseMap model has a few private methods which according to unit testing rules need not be tested. Hence, those methods are outside the scope of given problem statement. Each response map model needs its own factory for testing to create relevant mock objects to test the specs written. Hence here is a sample of a factory we created for the response_map.rb model. <code> Here, we create a mock object for the model ResponseMap to test its methods. We assign the necessary attributes with default values like reviewer ID, etc. in factory description. The values of these attributes can be set as per personal choice while creating the factories. The test cases implemented in the project can be observed in the respective spec files of the models. A sample test written for the some methods of response_map.rb is stated here for reference. <code> <code>. The test plan of this project involves running the newly made RSpec files for respective models and check if the expected output is attained or not. Testing the working of the files can be done as explained in the next section. To check the test cases of a particular model, run the given command in terminal: <code>. Condsider the given RSpec for export method in ReviewResponseMap model: <code> The export method is as follows: <code> The export method takes an empty array and the aassignment id as input. It returns a list containing mapping between the reviewee name and reviewer name and the mapping list is sorted according to the reviewee name. In the unit test, we need to check two conditions: 1)It should return the mapping between reviewee name and reviewer name. 2)The mapping must be sorted according to reviewee name. In the RSpec we have tested the two conditions as shown in the code. For the first condition, we created the mock objects for assignment, assignment_team(reviewee), review_response_map and reviewer and assigned their proper associations. When we run the export method, we get the expected mapping between the reviewee and the reviewer. For second condition, we created single mock object for assignment and reviewer and two mock objects for assignment_team and review_response_map. Now when the export method is executed, we get the mapping in sorted order based on reviewee name which can be seen in the RSpec code. For another example, condsider the given RSpec for feedback_report_response method in FeedbackResponseMap model: <code> The feedback_report_response method is as follows: <code> The feedback_report_response method takes assignment ID as input and returns a list of response ID's for all rounds of reviews(1, 2 or 3). In the RSpec code, we need to test that the function returns list of authors and responses by rounds. In RSpec code, we create mock objects for reviewers, reviewees, team and responses. We execute the function with parameter assignment_id. The expected result is a list of reviewee's in the team and a list of responses associated with individual rounds i.e. 1 , 2 and 3. For other methods and their RSpec, kindly refer github repo. The link to our github repo is: <link> The link to our pull request is: <link> The link to the screencast of running the tests is: <link> Due to time constraint on video, we have not explained all RSpec individually in the video. Please refer the github code to see other defined RSpec files.",Writeup is straightforward. Explained one of the tests.  Would have been helpful if all tests had been explained like this.,"You have done a commendable job on this assignment, and it demonstrates a deep understanding of Expertiza's structure and how to create test cases using RSpec. 

You correctly identified the models that did not require testing. I appreciate the effort you put into explaining each test case in detail and how you planned them out. Your justification for not testing private methods is accurate, as unit testing usually focuses on public methods. 

The factories you crafted seemed fitting for the models you tested, and I found your samples to be helpful in understanding your process.

However, there are a few areas you could enhance for future work:

1. Detailed Explanation: you might want to give a more in-depth explanation of your approach in the written part of the assignment. You provided a lot of code, which is great, but more interpretation of what that code does in plain English will be advantageous.
2. Code Readability: Try to include in-line code comments in your examples. This will help anybody reviewing your code to understand the purpose and function of different sections.
3. Correct use of Terminology: Be careful with your use of terminology. For instance, ""factories"" are used to create objects for testing, not mock objects. Mock objects are a type of test double that stands in for real objects in a testing environment.

Overall, keep up the good work! It’s evident that you've put a lot of effort into understanding both the domain and the technical parts of this assignment. I am looking forward to seeing your continued progress in the course."
133,E1737,"This page is a part of CSC/ECE 517 Final Project for Spring 2017 to describe the changes made by us to the open source software project Expertiza. We are converting the assignment creation form to ReactJS. Following contains a brief introduction to Expertiza, ReactJS followed by the problems we are tackling, our strategy for the implementation and the test plan. Expertiza is a Ruby on Rails based web application where students can submit and peer review learning objects such as codes, articles, websites etc., It is an open source software project funded by National Science Foundation(NSF). The instructor has the capability to create assignments with varied specifications such as topics, courses, team size, level of reviews etc., later review the submitted work and provide feedback. Students can enter their submissions and also review others' work. <link> is the javascript framework developed by Facebook to solve the specific problem, UI rendering . It is developed to solve the problem with complex binding in MVC framework using only one-way data binding. It is used for dynamic reloading of the page. It helps in reloading only the particular component required using Virtual DOM, which makes it fast by temporarily storing DOM Reasons for using ReactJS 1. It has every functionality that an user interface required 2. Easy data binding. 3. Only single component changes are stored/changed without reloading the complete page. 4. Fast and efficient 5. Easy to scale. The Assignment Create and Edit Form are multi level forms. It consists of multiple inputs and user interactions. Many input types have dependency on interactions by the user. For example, on check for a particular checkbox, remaining form is displayed. Also, edit page is reloaded whenever a topic is added. The task is to convert this pages into ReactJS components. Tasks to be done 1. Organize the form layout, create several mockups and validate them to your users 2. Make the table in topics tab sortable by its header 3. Allow users to edit / add topics in the table instead of loading a new page 4. Implement the new layout and convert the javascript to a ReactJS component 5. Validate user entries 6. Fix tooltips - Needed to increase the proximity of the tool tips in the assignments tab. The assignment creation form consists of multiple inputs and requires interactions from the user. The current implementation is mostly in HTML with data validations being done by JQuery. When a user wants to create a new assignment by clicking the new assignment button, a server request is generated and new view is rendered. Again, another server request to make database entry is generated once the user fills in the data and clicks on 'save' button and again a new view is rendered. This kind of implementation doesn't support dynamic view rendering hence lacks the fluidity in overall user experience that one would expect. <image> <image>. Similar to assignment creation page, edit page lacks the dynamic view rendering which makes the user experience cumbersome. Every time user wants to make changes to the assignment, a server request is generated and new view is rendered. The save button hit on completion will again generate another server request and render a new view. <image>. In current implementation whenever a topic is added to the assignment, a request is sent to the server and user is redirected to a form in another page. Upon creation of topic user is rendered back to edit assignment page. This process involves lot of redirection. Now, the task is to avoid this redirection of pages and create a interactive ReactJS form for adding and editing topic. Currently this logic is implemented in new method in sign_up_controller.rb file and is invoked in the _add_topics.rb ruby injection file. With this action new.html.erb page is rendered. This should be avoided. Add topic: <image> Similar is the case for editing a topic. For editing a topic user is rendered to a form in edit page and again redirected to edit assignment page. Edit Topic: <image>. Currently after creating an assignment, we can add topics related to the assignment. The ""Topics"" tab in the edit assignment form shows the list of topics that are added to the assignment. The picture below shows the current page for displaying the list of topics of an assignment. The list is not sortable. The task is to make it sortable using ReactJS by topic id, topic name, Num. of slots, Available slots, Num. on waitlist columns as sorting on remaining columns doesn't give any meaningful display. <image>. The entries for the assignment creation are not according to any restrictions, that can add problem to database maintenance like sorting the entries, comparing them, retrieving. There are many such problem causing situations in the new assignment form, such as This is essential in both new assignment or editing assignment page. 1. User can add the number as new assignment name or he can give only special characters for it like ""$$$$"". 2. Though mentioned a mandatory no special characters, it was not properly implemented. System is accepting the special characters. 3. Neglecting check boxes may lead to confusion with deadlines. <image> UML Diagram The following diagram depicts the flow of events leading to validations. <image>. The new implementation uses ReactJS to generate a drop-down window on clicking on the New Assignment button (private/public) , providing same features as before. Database entry is made on submitting the form and the form is closed. Below is the view of the new implementation: <image>. 1. apps/assets/javascripts/tree_display.jsx.erb 2. apps/controllers/assignments_controller.rb 3. apps/controllers/tree_display_controller.rb. We created a new React class 'NewAssignmentForm' which dynamically creates and displays the form for New assignment. This class has the following methods: <code> <code> <code> <code> <code> In assignment_controller.rb we changed the create method to: <code> In tree_display_controller.rb we added new method get_courses_node_ng. This method returns the course list array of hashes based on the instructor chosen. This logic is similar to the helper method course_options: <code>. Similar to assignment creation, in the new implementation, using ReactJS, when the edit assignment button is clicked, instead of making a server request and rendering a new view, a drop down window appears and saving the details will make the database entry.Since all the processing is done on the client side there will be decrease in the number of server requests. However, the edit form is a multilevel form with different tabs. We managed to implement only the general view as React JS form, hence we added a new action item ""Quick Edit"" which renders the ReactJS form and the ""Edit"" action item works as before. Below is the view of the new implementation: <image>. 1. apps/assets/javascripts/tree_display.jsx.erb 2. apps/controllers/assignments_controller.rb 3. apps/controllers/tree_display_controller.rb. In tree_display.jsx we created a new React class EditAssignmentForm which dynamically creates and displays the form for Editing assignment. This class has the following methods: <code> <code> <code> <code> <code> We also added the following in the class RowAction to display the form fields when clicked on Quick Edit. <code> In assignment_controller.rb we edited update method: <code> In tree_display_controller.rb we edited assignments_method to fetch all the parameters we need to display fields with appropriate values when Quick edit is clicked: <code>. 1. An interactive React JS component should be created and should be called by the ruby injection page sign_up_sheet/_add_topics.html.erb when New Topic link is clicked. This should show a form in that page to create topic. 2. Delete/avoid usage of sign_up_sheet/new.html.erb page. 3. Implement an React JS functional component to handle creation of topic and saving it to database. Tried to add topics using react js code in the file * app/views/sign_up_sheet/_add_topics.html.erb Modified files code: <image> <image> <image> <image>. Following sub-tasks are implemented for sortable feature for topics table. 1. Modify sign_up_sheet/_table_header.html.erb partial to change the table header fields to sortable type. 2. Add sort functionality using ReactJS for each column that is meaningful to be sorted. 3. Below is how output will look like. Below are the files modified. 1. app/views/sign_up_sheet/_add_signup_topics.html.erb <image> 1. app/views/sign_up_sheet/_table_header.html.erb <image> <image> <image>. The following tasks are implemented to achieve users validation, 1. Add the regular expression validation to avoid special characters in the names of assignment or directories. 2. Correcting the code in edit assignment page too. 3. Create validation for edge cases like giving empty values. Here is the display of the implementation: <image> <image>. 1. app/assets/javascripts/tree_display.jsx.erb. These methods are added inside Create/Edit ReactJS class and called whenever Create/Update buttons are clicked: <code> <code>. On exploring, it was noticed that all the existing tooltips work. However, we have increased the proximity of the tooltips in the assignment tab by increasing the size of the images. Rails development is the Test Driven development, which helps in ensuring the implementation of all proposed implementations. We will be writing all the implementations proposed as tests that will eventually be red in rspec and try to make them green by adding to the development part. Steps to manually test the feature are as follows: 1. Log in as an instructor (user-name:instructor6 password:password) 2. Go to Manage->Assignments and click on the Assignments tab. 3. Click on the 'New public assignment' or 'New private assignment' button 4. Verify if drop-down window is displayed. 5. Make valid entries for the available fields and click on 'create'. 6. Verify if new assignment is successfully created. 1. Log in as an instructor (user-name:instructor6 password:password) 2. Go to Manage->Assignments and click on the Assignments tab. 3. Click on the Edit button for any of the available assignment. 4. Verify if drop-down window is displayed. 5. Make changes and click on 'save'. 6. Verify if the changes made are successfully updated. 1. Login as an instructor (user-name:instructor6 password:password) 2. Create an assignment 3. Click 'New Topic' link or 'edit' action in topics table for a particular topic 4. A pop window or form should be displayed in the same page 5. Add topic details in that window/ form 6. Save it 7. Created or modified topic should be seen in topics table. 1. Login as an instructor (user-name:instructor6 password:password) 2. Create an assignment 3. Add 2 topics to the assignment 4. Click sort on Topic ID and check if they are sorted 5. Click sort on Topic title and check if they are sorted 6. Similarly test using other columns. 1. Log in as an instructor (user-name:instructor6 password:password) 2. Go to Manage->Assignments and click on the Assignments tab. 3. Click on the 'New public assignment' or 'New private assignment' button 4. Try adding the assignment using the weird names, with special symbols, ignoring check boxes 5. Verify if the assignment is shown in the table. Another way to check is from editing page too. 1. Log in as an instructor (user-name:instructor6 password:password) 2. Go to Manage->Assignments and click on the Assignments tab. 3. Click on the Edit icon page. 4. Try adding the assignment using the weird names, with special symbols, ignoring check boxes 5. Verify if the assignment which is updated with special characters is shown in the table. 1. Covert the multi-level edit assignment form to ReactJS 2. Convert add/edit topics to ReactJS. 1. <link> sortable-columns 2. <link> adding-reactjs 3. <link>.","Covers all the changes to be made.  There are a good number of diagrams, but the size should be reduced so they are viewable without scrolling.  Could have provided more details on how functionality would be achieved (e.g., saying more than ""make it sortable using ReactJS"").  Plan does not include automated tests.","This is an impressively detailed and comprehensive assignment submission. It is evident that a lot of work went into preparing this report. You have provided an in-depth explanation of the open-source software project, Expertiza, and particularly, on the changes that you have made in migrating the assignment creation form to ReactJS. 

I appreciate your use of headings to section off each aspect of the project and the use of bullet points for clear listings. Your explanation on the use of ReactJS and why it was chosen for this project was informative and succinct. The problems you highlighted and your approach towards solving them was well-explained.

The images and code snippets included in your report create a nice balance of visual and written information. I do notice that the place holders <image> and <code> are used throughout the report. I hope you didn't encounter any difficulty when trying to upload or paste the images and the code, remember to ensure all images and code insertions are successful in your final submission.

The step by step workflow of your project is clear and thorough, it shows a well-planned and strategic approach. The detailed steps for manual testing is also commendable as it shows a conscious understanding of the validation process. 

Also, do not forget to provide proper citation for any external resource(s) if you made use of any.

Lastly, going forward, there are a few aspects that might benefit from expanded explanations. For instance, providing more detail regarding the dynamic view-rendering and user experience issues before and after the switch to ReactJS would be helpful. 

Despite these minor improvements, this is very good work! Your commitment to the task is noteworthy."
134,E1640,"<link> is a web application developed using <link> for online assignment assessment. It is an open source project and its code base is maintained in the <link> . Expertiza authorizes the instructor to create new assignments as well as modify the existing ones. Students can team up with other students in Expertiza to work on various projects and assignments. Students can also review other students' work, thus enabling peer learning. After a particular response is recorded, the rubric gets displayed in graphical form under Your Scores tab. The submitted work can be seen in Your Work tab and the feedback given can be seen in Others' Work. The teammates for a particular project can be seen in Your team tab. Response.rb is a class that manages the response to all rubrics in Expertiza. The review form, quiz attempt, teammate review, review for others' work, filling a survey are all treated as responses. Method display_as_html handles the front-end for displaying a rubric. Response_helper.rb It contains two kinds of methods: 1) Methods related to the display of questionnaires. 2) Methods to open a rubric on selecting a particular section name. This contains a method that rearranges the questions based on the frequency of answers to the questions. In response.rb: 1) The class contains code that checks the rubric type (ReviewResponseMap, MetareviewResponseMap, FeedbackResponseMap, TeammateReviewResponseMap). These classes are sub-classes of ResponseMap. Rather than checking the map type, the code should send a message to the ResponseMap, and the code for specific types of ResponseMaps should be implemented in the subclasses of ResponseMap. 2) Code for calculating scores seems to be incorrect, as it should multiply per-question scores by the weight for each question. It seems to ignore weighting. 3) Most of the code for sending e-mails should be moved to app/mailers. 4) Remove the comment in lines 25–27 about TeamResponseMap; it is no longer relevant to the current version. In response_helper.rb: 1)The rearrange_questions method was written before we added sequence numbers to questions. At the very least, it needs to be modified so that questions above the threshold are kept in sequence. Ideally, it would be extended to allow the person who creates the rubric to specify whether each question could be moved or not, and then rearrange only the questions that are allowed to be moved, and add a column of check boxes to the Rubrics tab for assignment creation, saying whether questions on a particular rubric can be rearranged or not. In response.rb 1) The functionality for email notification was initially cluttered in a single class Response. In the current version, this functionality is been divided into sub-classes depending on the response type. This has facilitated improved modularity and segregation of functionality into different classes. 2) In the current version of the code, the total score is calculated by considering the weights for each question. 3) The code for email notification is in the mailer module in the current version and the syn_message function is used for sending synchronous email messages after a response is entered. 4) The irrelevant lines from TeamResponseMap are removed. In response_helper.rb 1) The response_helper.rb is removed in the current version since it is dead code and not referenced anywhere in the code. The email notification functionality was initially in Response.rb and was shifted to the sub-classes as below: Before Refactoring : Model: Response.rb <code> After Refactoring : Model changed: Response.rb, ReviewResponseMap.rb, MetareviewResponseMap.rb, FeedbackResponseMap.rb, TeammateReviewResponseMap.rb Function added: email In ReviewResponseMap <code> In MetareviewResponseMap <code> In FeedbackResponseMap <code> In TeammateReviewResponseMap <code>. NOTE :- Our project work is concerned on refactoring the code. So no new Rspec tests have been added. New refactoring has been tested and verified using existing Rspec tests. Manual testing has been done for the functionalities which does not have any existing Rspec tests. Steps to test from UI: 1). Login as the instructor. 2). Select Manage Content tab. 3). Create new course. 4). Add new assignment. 5). Select appropriate rubrics. 6). Add the participants to the course. 7). Login in as one the participant. 8). Select the assignment from the participant's assignment list. 9). Submit an assignment. 10). Login in as another participant. 11). Submit the feedback for the previous participant. 12). The participant will receive the feedback mail. 1. <link> 2. <link> 3. <link> 4. <link>.","This writeup is less detailed than some, but then there weren't as many changes to describe as in some projects.  It accomplishes what it needs to.","Dear Student,

Thank you for your in-depth work on this assignment. I appreciate the way you explained the architecture, functionality, and changes that have been made in Expertiza's codebase. The details you provide about the class files, methods, and their functionality give a very clear picture of your understanding of the project's codebase. It shows your comprehension of how different functionalities are connected to each other so well and a clear grasp of refactoring concepts.  

You did a good job identifying some of the code issues within response.rb and generating solutions, such as implementing score calculation and moving most of the code for sending emails to app/mailers. It was also a good call to remove irrelevant comments about TeamResponseMap. 

The refactoring changes you made to email notifications show that you are thinking critically about optimizing code. By segregating the respective functionalities into subclasses depending on the response type, you show you conducted a very detailed study and understandings of the codes.

However, I noticed that your assignment lacks a bit of technical proof for your statements. For instance, snippets of your refactored code would have provided more context and demonstrated the changes you made. Moreover, I'd have loved to see deeper analysis on why some of these refactors are improving the modules, for example, detailing how performance or maintainability is improved. 

Also, it would be useful to suggest a plan for updating the rearrange_questions method, instead of just identifying the need for extra functions. 

Moreover, for future assignments, it would also be better to exclusively note new features or significant changes in the field instead of noting that no new RSpec tests were added and just evaluating the updates with the existing ones.

Lastly, there's a need to clearly articulate your testing steps, this is not clearly outlined and seems to be cluttered. Be specific about what we should look for in each step and what constitutes success. 

Keep improving! Good work! 

Best,
[Your Name]"
135,E1615,"The Expertiza is a software project to create reusable learning objects through peer review. It is a Ruby on Rails based application which can be run on Windows, Linux and Mac OS X. Main Features of Expertiza are: 1. Allows students to work in groups to improve others learning experiences 2. The work done by students/team is subjeted to multiple reviews , minimizing plagiarism 3. Reviewing is done by studnets, which allows instructor/TA to spend less time in grading 4. Large classes can also be handled easily with the help of Expertiza. Review mapping controller contains methods related to peer reviewing strategies. It contains methods to add a reviewer, delete a reviewer, selecting a reviewer. Depending on the number of students and number of submissions, the topics to be reviewed are assigned to the students automatically. If a user wants to look for the team for a submission , it returns the team by comparing the submission id's with the team id's. Also, it assigns quizzes dynamically. Generation of review report, feedback report and teammate review is done. The main aim of this project is to 1. Refactor reporting method(response_report) which is big 2. Use more efficient function sample instead of shuffle for random number selection 3. Remove unused and assigned variables 4. Simplify Automatic_review_mapping_strategy. There are unused variables in the methods which use the stack unnecessarily. So, it is better to remove the unused variables or at the least indicate that a variable is unused. For suppose when both keys and values are not used in a hash but are given as arguments, then the unused variables can be indicated by adding a ""_"" infront of the name or replace the unused variable with ""_"" to represent it as unused variable but allow them in arguments. <code> <code> In the above case teams_hash should consist of a hash with both keys and values but the sorting is done based on values. So the key is replaced with a ""_"" so that the user may deem it unused in the implementation of the process. When sample is used, the elements in an array are chosen by using random and unique indices in the array so that the elements doesn't repeat in the array. This cannot be guaranteed in shuffle. Also by using shuffle[0] we are shuffling all the elements in the array and then picking the first element instead of picking a single element randomly which is more efficient. The following are the couple of places where shuffle[0] was used and is replaced by sample. <code> <code>. The method automatic_review_mapping_strategy handles the number of reviews assigned to a individual and also the number of reviews that can be done with in a team. The method is very long and has many nested if statements due to which the complexity of the method is very high. Instead of a single method handling all the parts of the strategy, it is divided into several parts due to which the code is more readable and also the complexity of code is shared by each method. The method first checks the number of participants that are in an assignment and the number of teams that are present. It then sets the values for the maximum number of reviews that are possible and also the minimum number that are required. Then it assigns the reviews to each of the teams randomly when a request for review is made by a participant. At last it checks if the participant has the minimum number of reviews required after allotting the reviews. If not, it assigns more reviews to valid teams so that the minimum requirement is met. The part of the code that is moved out of automatic_review_mapping_strategy as peer_review_strategy: <code> The method is made private so that it can only be called with in the controller and cannot directly be called through a view. The complexity of the original method reduced after breaking it and can be easily readable now. <code> 4. Moving code specific to models to models instead of controller The method response_report contains code which generates reports based on the input of one of the three of 'ReviewResponseMap', 'FeedbackResponseMap', 'TeammateReviewResponseMap' and 'Calibration'. Calibration is a special case and should be handled in the controller itself. But the other three are models that are subclasses of ResponseMap model. The report is generated for each of the three by calling the ResponseMap model and obtaining the values by querying the database. Moving the code to the models and calling the methods in the model through the controller makes more sense than writing the code in controller. The following is the code snippet from the original method which contains the calls to ResponseMap model: <code> The same code after moving the methods to their respective models looks as follows: <code>. Peer review information: 1. Instructor Login: <code> 1. Student login: <code> Steps for testing UI: 1. Login as an instructor (Using Instructor6 will help you import the participants from other assignments). 2. Navigate to ""Manage->Assignments"". 3. Click on ""New Public Assignment"" for creating a new assignment. 4. Create a new assignment by providing assignment name, selecting a course, submission directory (Give any name) and description URL. 5. Select ""has teams?"" and provide the team size. Click on create to create a new assignment. 1.1. After that, click on review strategy and limit the number of reviews per submission. 1.2. Click on ""Due dates"" and update date for submission and review. Adjust the review date and time in order to test the reviews. 1.3. Click on ""save"". A new assignment is created and it can be viewed in ""Manage->Assignments"" section. 6. In order to add participants, there are two methods to add students to the assignment. 1.1. Click on ""add participants"" against the assignment. Enter the user login to add the student. Add atleast 6 participants so that the review mapping can be seen. 1.2. Click on any previous assignment ""add participants"" and export the students list (I used wiki assignment). 1.3. Click on your assignment ""add participants"" and import the students using the export file. 7. Go back to ""Assignments"" section and click against ""create teams"". 1.1. After clicking on ""create teams"", Click on ""create teams"" in the directed page. 1.1.1. Teams can be formed either manually or automatically. 8. Login as a student to submit the links for assignment (Valid hyperlink must be provided in the submission link). Add submission for atleast 5 students in order to check the automatic review mapping. (Password for student is password) 9. After submitting the links for some students, Log in as an instructor to change the assignment phase to review phase. 1.1. To change the review phase period, Go to assignments section and click on edit. Click on due dates and change the review due date. 10. Now, login as a student and go to others work. Click on ""Request a submission to review"" and check whether a review is assigned automatically. If no assignments are submitted, then this cannot be tested. 11. For teammate review report, author feedback report and review report, click against ""review report"" and all the review reports can be seen by selecting it in the drop down menu. 1. <link> 2. <link> 3. <link>.","Description of ReviewMappingController is incorrect.  Topics are not assigned automatically to reviewers.  Submissions may be assigned automatically, but only if ""Auto-selected"" reviewing is being used.  In the middle of the paragraph, you switch from talking about a UI user to talking about a programmer, without ever specifying the change.
The code snippets you show are hard to read because they scroll off the right side of the screen. 
It would be easier for the user to pick up the changes if ""before"" and ""after"" views were shown side by side.","Dear Student,

I appreciate the overall depth you have gone into for this assignment. Your detailed analysis of the Expertiza software project was certainly insightful. This sort of breakdown is exactly what is to be expected when approaching these kinds of projects. Your firm grasp on the concept thus far is commendable. 

However, I did notice several areas where the work could be improved. Here are some detailed comments:

1.**Spelling & Syntax** - There are a number of misspellings throughout your work. For instance, you wrote 'studnets' instead of 'students' and 'subjeted' instead of 'subjected'. I encourage you to utilize spell-check tools before submitting your work. Not only do such errors detract from the professionalism of your writing, they also make the text harder to understand. 

2.**Code snippets** - Empty code tags were found and no code was included. This may be due to formatting issues or an oversight on your part. Please ensure to include the necessary code in these spaces for proper understanding and critique.

3.**Readability** - There were instances where the text became a tad unreadable due to the denseness of information within single paragraphs. Try to break down the information into different subheadings or paragraphs. This will significantly increase the readability of your assignment.

4.**Peer Review** - The 'Peer review information' section includes placeholder code tags for 'Instructor Login' and 'Student login' but no actual information. Ensure this is corrected in your final submission.

5.**Continue Providing Steps for Testing UI** - This level of attention to detail is excellent. Providing detailed testing steps greatly help understand how deeply you've explored the software project. This part of the assignment is particularly well done.

6.**Use of Examples** - Your use of examples to illustrate your thoughts is commendable and adds value to the work.

Remember, the goal here is to deliver clear, precise, and concise work. Keep focusing on enhancing your skills and I recommend spending some additional time proofreading your assignments before submission.

Best,
[Your Name]"
136,E1854,"This page provides a description of the Expertiza based Semester project. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link> 1.1.8. <link> 1.1.9. <link>. <link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. Expertiza has the ability to require self-reviews on projects, self-review is basically asking each team member in the group to evaluate their project on the same criteria as peer review, these self-review scores do not have much functionality currently. This project seeks to improve upon the self-review system, and extend its functionality. The main points of this project are as follows: 1. Create a method to calculate a derived score (composite score) between self and peer-reviews. The closer the self-review is to the peer-review, the greater the score. Display this score on the ""View Scores"" page. 2. Make sure that the peer-reviews should not be visible before self-review completion. Display the correct review scores accordingly. 3. Display the self-review scores in the ""View Scores"" and heat map of peer-reviews, denoting that they are a different type of review. <image> The instructor has to login and create an assignment by checking allow self-review option. The instructor has to add the topic and assign students to the topic. Now, the student has to login and submit the assignment. The self-review link is visible in the page. The student should give the self-review. After giving the self-review, the student should be able to see the peer review, self-review and the composite score.\. <image> Actors: <code> All the other use cases are implemented except “View Scores with self-review column and composite score” Use Case: View score with self-review column and composite score Preconditions: <code> Student Sequence: <code> Post Conditions: <code>. The composite score is calculated using both self-review score and peer-review score (both are graded over 5 points for each criteria). The composite score is calculated as follows: <code> By using this formula for calculating composite score we are discouraging students from either exaggerating or underrating their performance. The composite score model assigns more weight to the peer review score since the peer review score being used is the average of all peer review scores assigned and hence tends to be more appropriate than a single self-review. Also this composite score formula gives the score on a scale which is identical to the scale of the self and peer review score. Thus this formula is not dependent on the scale of the self-review and peer-review score as it will also return the composite score on the same scale. For example: If someone gets an average peer review score of 3.5/5 and he gives 3.5/5 (self-review score) while reviewing his project, then he will get a composite score of 3.5/5. And instead if the student reviews his project for 2/5 then the student will get a composite score of 2.975/5. As stated above the ability to do self-reviews has already been implemented. This can be seen from the image shown below. The instructor has this ability to enable self-reviews . <image> In our project, we were successful in displaying both the self-review score and composite review score on the view scores page. Shown below is an example of the output in the student profile. As we can see the self-review icon has a blue background to indicate that it is different from other peer reviews. <image> The alternate view was also modified to accommodate a pictorial representation of the self-review scores. The modified alternate view scores page is shown below. <image> The same was achieved in the instructor profile too. In the current implementation of expertiza when self-review was not assigned, the instructor would view the scores of the first student in each team (it wouldn't matter much because without self-review all students in a team would have the same scores). But this would be a problem when self-review was enabled so we decided to display all the self-review scores of all students in the team for instructor view. As it can be seen below self-reviews of all students in the team (distinguished by their usernames) are indicated by blue background to differentiate them from peer review scores. <image>. Test cases are as follows: 1. Peer-reviews cannot be viewed before a self-review is completed. This ensures that the student is not able to see his peer-review score before writing his self-review as the composite score takes into account the difference between the student peer-review and self-review score. 1. Self-review scores are displayed with peer-review scores. This enables the student and instructor to view all his scores in one place. 1. The composite score must be properly calculated. The composite score must be calculated so as to give students more points if their self-review score is closer to the peer review score. 1. Composite score must be visible in both view scores page and Alternate view. The scores must be displayed in both the views. 1. app/controllers/grades_controller.rb 2. app/models/assignment_participant.rb 3. app/models/author_feedback_questionnaire.rb 4. app/models/response_map.rb 5. app/models/vm_question_response.rb 6. app/models/review_questionnaire.rb 7. app/models/teammate_review_questionnaire.rb 8. app/views/grades/_participant.html.erb 9. app/views/grades/_participant_charts.html.erb 10. app/views/grades/_participant_title.html.erb 11. app/models/vm_question_response_row.rb 12. app/views/grades/view_team.html.erb 13. spec/controllers/grades_controller_spec.rb 14. spec/models/assignment_particpant_spec.rb. 1. <link> 2. <link> 3. <link>.","The document describes the method and gives an example, but does not tell how the grading formula was derived.  Has it ever been used anywhere before?  Also, while the document mentions the files that were modified, it does not describe how the code was changed.  The screenshots are very useful in being able to see the functionality that was added.  The test plan is not well developed, as noted by several reviewers.","You provided a detailed presentation of your assignment with comprehensive insights into the Expertiza project and description of the processes. You clearly outlined your project aims, especially on improving upon self-review scores, and enhancing the functionality of Expertiza.

However, there are few areas in your assignment that need improvements.

1. Your assignment lacks clarity in certain sections, making it difficult to fully understand your ideas. I recommend carefully proofreading your work to ensure your thoughts and strategies are well presented.

2. Presentation of figures and images did not correspond with the text, and there was no proper linkage or captions provided. Please provide concise descriptions or captions for images for a better understanding for the reader.

3. You mentioned <code> in multiple sections without providing a further explanation or examples. Please replace these sections with the right code snippets or pseudocode to illustrate your scenarios or provide a clear explanation to understand the context.

4. The sequence in numbering of your test cases was not followed correctly, as you restarted numbering after the first case. Please number your points consistently for ease of reference.

5. The references are not properly formatted. It's important to provide a proper format (APA, MLA, Chicago, etc.), so they are correctly presented and easy to refer by others.

I appreciate your consistency in maintaining complexity and intricate details throughout the assignment. However, ensure your work is error-free and well-formatted next time. Looking forward to seeing improved work from you in the future."
137,E1976,"This page is a description of Expertiza OSS project E.1976 Issues Related to Assignment Creation. Project Github pull request: <link> Github links about this project: <link> Video Presentations: Issue 1354: <link> Issue 1384: <link> Issue 1430: <link>. For this project E1976, like the OSS project, we have three issues that need to be fixed in the expertiza. Firstly, a TA can unassign an assignment from the course which he don't belong to, and when TA does this, the other TA may lose access to the assignment, so they can't fix it. The second issue is, Sometimes, when an instructor creates an assignment and hits “Save” without completely filling out the form, (s)he ends up editing a different assignment. And the third problem is On an instructor's/admin's/TA's homepage, in the assignment list, there are three rows of icons for performing several operations. But right now an instructor is not able to choose whether to see these actions on the homepage or on a tab associated with each assignment. Proposed solution: We want to make sure that the TA can't access other assignments except the assignment which he assigned to this courses And we should then check if he is not in this course, he will not grant the right to unassign assignments. <image> Proposed solution: An instructor should be able to choose whether to see these actions on the homepage or on a tab associated with each assignment. So there should be a setting in the instructor’s Profile that controls these actions. Proposed solution: The problem can be because there are two assignments with the same name.so it would lead to the old assignment when it is created, the system will sort all the lists of assignment names, then find the past duplicate name assignment, resulting in ends up editing a different assignment. During changing the assignment, first we ask which course an assignment is a part of, and then list only those courses that the instructor or TA has access to. So the TA and the instructor can only deal with the courses they related to, but not the irrelevant courses. <image>. The instructor could edit the course settings, and in ""other stuff"" the instructor could change the action icons to show whether these actions on the homepage or on a tab associated with each assignment. So in our cases we need to create a boolean attribute to control the action icons. <image>. While the instructor creates the assignments having the same name with a created assignment, It was dropped into another assignment. In this problem, we need to set a double check while creating the assignments, if the name of the assignment has been used. That will fix the bug and also easy for the students to read. <image>. <image>. <image>. <image>. <image>. we have created a box named ""Action options"" in profile, only instructor can see this box. <image>. Now instructor can only view few actions which are not included in original ""other stuff"" interface. (we rename ""other stuff"" to ""Etc. ... as issue required) <image>. <image>. Now instructor can view all actions. <image>. 1. Login as an instructor 2. Edit the course settings of other stuff 3. Recording a video to show how the homepage change. 1. Login as TA 2. Find out whether TA can view all assignment (this part our mentor need to discuss with the professor to clarify) 3. Try to remove assignment which is not included in TA course 4. Login as an instructor 5. Try to remove the assignment. We have already reproduced this ""same name"" issue successfully. 1. Create two assignments but choose a different course. 2. First one's course is fall 2017, the second one's we choose fall 2016. 3. Hit the ""save"" button of the second assignment, it will automatically show the page of the first assignment of course fall 2017. 4. Add tests in files list below, and pass all tests. <link> <image> <image>. <link> <link> <image> <image>. <link> <image> <image>. 1. Reference from <link>. Manual Testing 1. Log in to Expertiza with the credentials: instructor6/password (on google chrome) 2. Go to the Manage -> Assignments . 3. Click on New Public Assignment 4. On the new assignment creation page, under the General tab, give details for Assignment name , Course (choose CSC 517, Spring 2016) and Submission directory . 5. Check the Staggered deadline assignment? checkbox. 6. Click on the Rubrics tab and give some values for Review and Author Feedback , if there are any other fields apart from these give values to that too. 7. Click on Create at the bottom. 8. Now, click on the the Topics tab and further click on New Topic . 9. Give suitable values to the fields and click on Create . 10. Click on the Due dates tab. 11. Check the Use signup deadline checkbox and give suitable dates for Signup , Round1: Submission and Round1: Review . 12. Go back to the Topics tab and click on Show start/due date at the bottom. 13. Change the Submission deadline date to date later than the date given for Signup on the Due dates tab. 14. Click on save at the bottom. 15. Now, click on the Other stuff tab and and further click on Add participant . It will open in a new tab. 16. Click on Copy participants from course . After it adds the participants, close the tab. 17. Go to Manage -> Impersonate User . 18. Give student6360 for the Enter user account field and click on Impersonate . 19. Click on Assignments and further click on the assignment that was created in the earlier steps. 20. Click on Signup Sheet. 21. You should be able to see a green tick mark under the Actions header and should be able to click on it and signup, which means the issue is fixed. Manual Testing Task Description: Teaching Assistant creating an assignment Precondition: The instructor has set up the page for assignment creation Primary Flow: 1. Log in to Expertiza 2. Select New Assignment 3. Enter the Assignment Name and select Course . 4. Check the parameters for the teams, quiz, badges categories etc. 5. Click Create Task Description: Instructor deleting an assignment Precondition: There exists at least one assignment created by TA. Primary Flow: 1. Log in to Expertiza 2. Select the Delete option in the action section for an assignment that is created by the TA . 3. If Logged in as Instructor , the assignment gets deleted for that action. 4. Else, the current participant is shown the error message that they do not have authorization to execute the delete option if they did not create that assignment . Automated Testing The issue as such did not require modifying the controller spec file for assignments since the changes were only made to the delete function and the test cases written a check for the display of proper flash messages that could be mapped for the modified code functionality. Only manual testing was performed to determine ssuccessful deletion by instructor . Manual Testing 1. Login to Expertiza as an instructor 2. Create a new Assignment 3. Click on the add participant button for the assignment created 4. Modify the participant list by adding an instructor as a participant 5. Check the list to see the instructor added to the assignment as a participant Automated Testing No automated test cases, only manual testing since the modifications are made to the view files. 1. <link> 2. <link> 3. <link> 4. <link>.",Good description of the issues and the changes made.  It would have been useful to have shots of the complete screen for Issue 1384.,"Dear Student,

Well done on your extensive project submission! Your proposed solutions are thoughtful and appear to be extensively researched. The level of detail you've applied to documenting the issues and explaining how your proposed solutions would work is commendable. 

To improve, remember to organize your ideas in a more coordinated and systematic manner. In this case, a clear structure would make your work easier to navigate. For instance, you might want to break down your information into sections with headings for clarity.

Also, while it's wonderful that you've submitted many images as part of your presentation, including descriptive captions for each image would have been beneficial. This way, your reader would know what each image represents without having to assume.

You've also done a good job regarding testing. You included both manual and automated testing procedures, which indicates that you have considered multiple aspects of software testing. I would recommend however that you specify the expected results at each stage. This makes it easier to discern whether the test has passed or failed.

Regarding your writing, pay attention to grammar errors, especially subject-verb agreement and usage of pronouns. For example, the phrase ""which he don't belong to"" should be ""which he doesn't belong to"". Minor mistakes like these can affect the readability of your work.

Lastly, inserting more specific descriptions and context about the assignment would make for a more interesting read.

In conclusion, you have done a good job, but there are areas you could improve. Keep working on presenting your ideas clearly and systematically, and continue paying attention to detail in your testing, and you'll continue to improve.

Keep up the good work!
"
138,E1923,"The export/import feature is the most helpful feature for instructors to set up assignments. The instructors usually have a list of students, teams, etc from their learning management system. Being able to export/import these into expertiza saves a lot of time when setting up an assignment. Expertiza provides multiple export and import features for eg. export students, teams etc. Essentially what it does is it fetches some data from database and save it as a file in desired format. However, same functionality is implemented multiple times for exporting and importing different things. The aim of this project is to design a generic export/import feature. What you need to do is implement a framework which supports exporting and importing functionality based on input. There are substantial degrees of freedom in this project. You need to design the module which will take the database table names, column names from which data needs to be exported or the imported into. So that this module can be used for every export/import feature that expertiza provides. Most imports and exports just import or export a single table. But sometimes exports involve “details.” For example, when questionnaires are imported or exported, the “advice” (guidelines on what characteristics of work merit each score) may be imported or exported along with the questionnaire. I suspect that all instances of import/export of multiple tables are called “details” in the current code. Provide a mechanism so that “details” can be imported or exported along with the main table involved. Existing import functionality is primarily routed through the ImportFileController and an import class method for various models. SignUpTopic and User, rely on helper classes that extract attributes from a hash and create an ActiveRecord object. Questionnaire relies on a helper method that can import Question objects (objects that make up a Questionnaire) from a CSV and adjust the size of the associated QuestionAdvice (the words that pop up after you pick a certain number of stars). However, these functions might be deprecated, as it appears that Question importing is now routed through the ImportFileController unsuccessfully. More detail about specific functions is provided below. 1. import_file_controller , the list of methods in the controller are the following: 1.1. File processing methods: 1.1.1. #get_delimiter - Sets proper delimiter for filetype 1.1.2. #parse_line - Processes line (row) of the file 1.1.3. #parse_to_grid - Turns file into 2D array 1.1.4. #parse_to_hash - Turns file into hash where 'header' stores header row and 'body' stores all contents. 1.1.5. #hash_rows_with_headers - Creates hash for each row of file. Keys are headers, values are row values. 1.2. Import methods: 1.1.1. #import_from_hash - Primary import functionality. Creates objects for hashed rows (from #hash_rows_with_headers). 1.1.2. #import - Larger controller of import, sets error messages and displays. 1. questionnaires_controller , the list of methods in the controller are the following: 1.1. ::import - Allows import from CSV using QuestionnaireHelper (Appears to be deprecated/unused). 1. import_file_helper , the list of methods in the file are the following: 1.1. ::define_attributes - Sets and returns attributes for User object from hash. 1.2. ::create_new_user - Makes a user object in the database. 1. import_topics_helper , the list of methods in the file are the following: 1.1. ::define_attributes - Sets and returns attributes for a SignUpTopic from hash. 1.2. ::create_new_sign_up_topic - Makes SignUpTopic objects in the database. 1. questionnaire_helper (Appears to be deprecated/unused), the list of methods in the file are the following: 1.1. ::get_questions_from_csv - Allows Question and QuestionAdvice import/creation with CSV file. All these models have an ::import method called by the ImportFileController. In addition, SignUpTopic and User objects rely on their helpers, which are mentioned above. 1. assignment_participant 2. assignment_team 3. course_participant 4. course_team 5. team 6. metareview_response_map 7. question 8. review_response_map 9. sign_up_sheet 10. sign_up_topic 11. user. The import functionality should be routed through the ImportFileController. Everything should still work as it does now after our changes; we are cleaning up code and may move functionality to a different location but nothing will get removed permanently. Luckily, most import functionality is routed through the ImportFileController and import class methods on models that are being imported. It makes sense for each model to have its own import method because each model knows what to expect for itself. Making things overly generic will end up contradicting the DRY principle and lead to many nested if statements. We intend to remove other helpers and files, such as the ImportFileHelper, the ImportTopicHelper, and the QuestionnaireHelper to keep import routing consistent. We will also remove the QuestionnaireController and route that import through the ImportFileController. In addition, we will update ImportFileController methods (in particular, #hash_rows_with_headers and #import_from_hash) to make better use of polymorphism and eliminate large and unnecessary if/else blocks. We will also insert more specific object creation specifications. Consider if a user's import contains objects that do not exist in the database. We will provide an option for the user to specify whether or not new/dependent objects should be created and account for this boolean in relevant ::import functions for the models. To summarize our changes: 1. Route all import traffic through ImportFileController and ::import calls on models. 2. Refactor ImportFileController. 3. Insert object creation conditions into all relevant ::import functions and into the ImportFileController form. 4. Add ability for ImportFileController to import Question objects for Questionnaires. (Add question view to views/import_file, introduce Question logic into the controller.) Visually this is what is happening right now (with some files missing for brevity's sake): <image> What we want it to look like: <image>. 1. In the shared.js file there was a method #checkIfUserColumnDuplicate() which we changed to #checkForDuplicates(field_count). This method now checks to make sure that each column header is unique regardless of which model you are in. 1. In the ImportFileController we moved the #start method to the beginning of the file for consistency and readability. 1. The #import_from_hash and the #show method inside the ImportFileController is markedly shorter now then when we found it. We removed most of the case statements. The below images are in the respective order. <image> <image> 1. Questionnaire.rb has a #import method that is now routed through the ImportFileController and the actual act of importing works. We removed all functionality related to importing from the QuestionnaireController and QuestionnaireHelper. 1. We removed the ImportFileHelper and ImportTopicsHelper and moved that functionality into the corresponding models. Having the code segmented made things confusing since none of the functionality was all in one place. 1. We removed import functionality from question.rb because there is no way to import a question out of context from a questionnaire. Importing a questionnaire, means importing questions to fill that questionnaire. 1. SignUpSheet no longer has an import method. That functionality was never used and does not actually currently work in the production version of Expertiza. After discussing with our mentor, we were instructed to removed the import link on the front-end, the import method, and all related tests. 1. The previous way of determining required import fields were to populate the @expected_fields variable which was incredibly hard to find in the code. We have eliminated the need for that variable and have removed all instances of it. 1. We have made things as generic as possible in the .html.erb files so that you can be in any model and the code works on the front end seamlessly. This is done by adding these three methods to each model that has an import method: <code> The above content is specific to the course_team.rb but the three method names are consistent to all the models and are called on the front end. 1. The models that have a ""self.import"" method that does not branch out into other controllers beside ImportFileController will be looked at to make sure they are as concise as possible. None of them can be all the same because they all need to have checks specific to what they need to import. We can, however, make sure that similar models, like assignment_team and course_team, have similar imports. That is what we have done for assignment_team/course_team and assignment_participant/course_participant. Now, these are the final models/places where a user may import a file into Expertiza: - assignment_participant - assignment_team - course_participant - course_team - review_response_map - metareview_response_map - sign_up_topic - user - questionnaire. 1. start.html.erb file has no more case statements by the @model type and everything has become generic. 1. We removed all the partials related to import_file. Which has lead the show.html.erb file to have no more case statements and everything has become generic. The removed files are: - _metareviewer.html.erb - _participant.html.erb - _reviewer.html.erb - _sign_up_topic.html.erb - _team.html.erb - _user.html.erb 1. We have updated some text on the front end related to questionnaire. The import link did not match the capitalization format in the rest Expertiza. Note: Code Climate was not running on Expertiza's beta branch for the last four days of the project. We have done the best we could to removed extraneous lines and white spaces. There were many code climate issues in reference to our project. We have managed to fix 46 issues as a byproduct of refactoring the code. Here is a list of them with their frequency put in parenthesis': 1. Method get_questions_from_csv has a Cognitive Complexity of 62 (exceeds 5 allowed). Consider refactoring. 1. Method get_questions_from_csv has 41 lines of code (exceeds 25 allowed). Consider refactoring. 1. File import_file_controller.rb has 278 lines of code (exceeds 250 allowed). Consider refactoring. 1. Avoid deeply nested control flow statements. (3) 1. Similar blocks of code found in 2 locations. Consider refactoring. (2) 1. Unescaped parameter value 1. Useless assignment to variable - a. 1. Cyclomatic complexity for get_questions_from_csv is too high. [18/6] 1. Assignment Branch Condition size for get_questions_from_csv is too high. [43.3/15] 1. Block has too many lines. [36/25] 1. Avoid more than 3 levels of block nesting. (3) 1. Perceived complexity for get_questions_from_csv is too high. [16/7] 1. Align elsif with if. 1. Space missing after comma. (13) 1. Line is too long. [172/160] 1. Method has too many lines. [108/60] 1. Use the return of the conditional for variable assignment and comparison. 1. Move @optional_count = 0 out of the conditional. (2) 1. Move contents_hash = eval(params[:contents_hash]) out of the conditional. (6) 1. Convert if nested inside else to elsif. 1. Don't use parentheses around the condition of an if. (3). The goal was to get all the export functionality routed through one place, the ExportFileController. The overall effect would have been similar to what we hope to achomplish when updating the import functionality. We ran out of time to work on this functionality. Note: Code Climate was not running on Expertiza's beta branch for the last four days of the project. We have done the best we could to removed extraneous lines and white spaces. All these models have an ::import method that we amended and as a result we need to update the tests. We added or amended tests in their respective .spec files to make sure that the ::import method has 100% coverage. 1. assignment_participant 2. assignment_team 3. course_participant 4. course_team 5. team 6. metareview_response_map 7. review_response_map 8. sign_up_topic 9. user There is one failing test about exporting and we have not touched export functionality. There is another failing test about a review tab that we didn't touch. The project is deployed on an NCSU VCL server. It can be accessed at <link> . A sample instructor login is: 1. Username: instructor6 2. Password: password.","For design doc:There are many good aspects of this design doc.  It explains what was done, and why, in narrative fashion.  It has a useful diagram showing the changes.  But there are also shortcomings.  The ""what we plan to do"" and ""what we did"" are two separate sections, requiring the reader to read both.  It would be easier to read if the ""what we plan to do"" section had been changed to explain what was done.  The code in the Github screenshots is illegible.  There are several really long lists, that would be hard for the reader to grasp.  It would be better if the lists had been refactored into general topics, with a smaller number of items under each header.  (Code in Github screenshots is now legible, and big lists have been broken up. )","Hello,

Firstly, I would like to commend your efforts in presenting such an in-depth assignment. Your commitment to detailing every aspect of your project work is evident, which guarantees that the intentions and process behind your work are clearly projected to your audience. Moreover, your consistency in following a comprehensive methodology to establish your statements is well-exhibited, enhancing the clarity of your report.

To offer you some constructive feedback, do be cautious about the excessive information you've included in some areas which could potentially render the main point less impactful. Brevity is a strength, and it would enhance your assignment's clarity if you could summarize information that is not directly important to your main objective.

For example, the extensive list of methods under each controller and detailed nature of each method description is a bit overwhelming and could possibly be presented more succinctly. A summary of their purpose would be more impactful and easier for the reader to understand.

Also, try using diagrams or charts whenever possible to demonstrate the architectural changes you are proposing. The projected changes to the model structure could be better presented visually.

Lastly, proofreading your assignment to fix minor punctuation or formatting errors like missing periods at the end of bullet points would help improve the overall presentation and professionalism of your assignment.

On a final note, this assignment showcases a tremendous amount of dedication and hard work. With minor adjustments in the delivery of your content, it will enhance the effectiveness of your communication overall. Keep up the good work!"
139,E1989,"The <link> project takes advantage of peer-review among students to allow them to learn from each other. Tracking the time that a student spends on each submitted resources is meaningful to instructors to study and improve the teaching experience. Unfortunately, most peer assessment systems do not manage the content of students’ submission within the systems. They usually allow the authors submit external links to the submission (e.g. GitHub code / deployed application), which makes it difficult for the system to track the time that the reviewers spend on the submissions. Knowing how much time a student spends on a review is helpful when determining the quality of the review itself. That being said Expertiza needs to be able to track and display how much time a student spends on each review. The time spent on a review is the sum of multiple sources: 1. The time spent on the Expertiza assignment review page itself 2. The time spent looking at external pages linked from the review page 3. The time spent looking at downloadable files submitted by other students The purpose of this project three-fold: 1. Gather the timing data from the sources above. 2. Display the data on the ""Review Report"" page (views/review_mapping/_review_report.html.erb) to show the time the student spent per review. Given that previous attempts have been rejected due to UI issues, it is important that this data is displayed cleanly. 3. Write tests that confirm that the above goals are functioning correctly. So far, Expertiza does not have any such feature. However, three teams have already worked on this in the past but their builds were not merged due to some problems. 1. <link> identified how to track the active time of windows opened from the submitted links. ( <link> ) 2. <link> provided detailed insights on how they planned to track time taken by a student in viewing a submission and possible edge cases. Further, they also implemented popups and figured out a way to open downloadable files. However, the details are rendered in a not-so-friendly manner and hence it was not merged. ( <link> ) 3. <link> tried to solve this by incorporating the statistics in the review reports page, but their UI made the page cluttered and not friendly. Further, it was hard to identify which statistic belonged to which review, and there were almost no tests. ( <link> ). After investigating the prior attempts at this task, we have decided it would be best to begin our project by building off of the work done in project <link> . The reason for choosing to build off of this particular project is because they have already put the work into tracking time spent viewing external pages as well as time spent viewing certain types of downloadable files. In order to achieve our goals outlined in the <link> section, the following changes need to be made: The time spent on the Expertiza assignment review page needs to be tracked. 1. Due to Expertiza generating report text boxes with HTML iFrames, we will track whether or not the document hasFocus() to determine when a student is on the page or not. 2. To prevent the user from cheating the system by just keeping the review page open without doing work, a timeout feature will be implemented. After 5 minutes of mouse/keyboard inactivity, a popup will be displayed asking if the user is still working. At that point, the time contributed towards the total by the Expertiza page will stop being tracked until the user interacts with the popup to indicate they are still working. This is already implemented in project <link> . The time spent viewing the external links and downloadable files will need to be made more accurate. 1. Currently, if a student has an external link open as well as the Expertiza page, time is being tracked for both. Changes will be made so that when the student is working on the Expertiza assignment review page time is not tracked for the external links or downloadable files. The overall time spent on the review needs to be displayed in a ""user friendly manner"" on the ""Review Report"" page. 1. Due to complaints on a tabular method, citing the review report table becoming too cluttered, we intend to create a pop-up window that will display the results in a table. The entries in ""Team Reviewed"" will be clickable. When clicked, they will display a popup that contains detailed information on where the time for the review was spent. For example, if a student spent a total of 22 minutes on the review, it will show that the student spent 5 minutes on the Expertiza review page, 10 minutes looking at external links, and 7 minutes looking at downloadable files. It will display these details in text format as well as graphically using a pie chart. The purpose of choosing this design is two-fold: 1. It will not require the instructor to have to go to a different page every time they want more details on a particular review. Given that the review report page takes a substantial time to load, this is a necessity. 2. It will prevent the table on the review report page from being cluttered by figures and too much data. Strategy: In this project, for each review page, we need to deal with different type of links. For online links, such as github repo, youtube link, etc, we use javascript to open a new window detect time when the window is closed. For submitted files, such as txt, jpg, we will open it with views/response/_submitted_files.html.erb. For other files that need to be download and open locally, we can only make approximation for review time. Reviewer Every time a start time is logged for expertiza/link/file, a new entry will be created in the database.End time will be updated on the last entry present for the same link/file. <image> Instructor Time for individual links will summed and then displayed as bar graph. <image>. 1. Created a controller to handle the start/end times of the files viewed by the user. => controllers/submission_viewing_events_controller.rb 2. Created a table in database to log start and end time for each link/file. It's schema is described below. <table> 3. Added view that will display with pie chart when instructor wants to see time spent on individual links/files. <image>. submission_viewing_events_controller.rb The record_start_time function starts the time for links that have been visited by the user. <code> The record_end_time function records the end time for links that have been visited by the user. <code> The mark_end_time function records the end time for links that have no end times. <code> reviewer_details_popup.html.erb _review_report.html.erb _review_submissions_time_spent.html.erb response_times.coffee response_times.scss response_controller.rb response_times_controller.rb responses_times_helper.rb review_mapping_helper.rb response_time.rb _submitted_files.html.erb. Previous implementations attempted to record the time users spent viewing each link, but their solution has multiple problems. The primary problem was that when multiple links were open at the same time (thus overlapping with one another) the times at which they overlap are recorded twice. To fix this, we implemented the following algorithm within \app\views\reports\_review_submissions_time_spent.html.erb: <code> NOTE: The following diagrams are simply meant to help explain the timing algorithm. They are not indicative of the real system. For example, there will never be a time when an Expertiza duration overlaps with a link duration. The following diagram shows an example of what links could look like prior to our algorithm running: <image> After our algorithm runs, one can see that the overlapping segments are eliminated. For convenience, each duration_section is highlighted: <image>. We have made changes to the controllers/submission_viewing_events_controller.rb and added test cases for the same, which have passed all the test cases. The tests can be executed rpec spec and the results for the files we have modified are shown below: <code>. We hope to not need any manual UI testing, though if it is needed, it'll look something like this: Verifying Time is Tracked Correctly: 1. Sign in as as a student 2. Review an assignment 3. Go through the review as normal 1.1. Make sure you open links to github or pull requests 1.2. Make sure you download and/or view files that are attatched 4. Submit your review when you're done 5. Log out as a student 6. Log in as an instructor 7. Navigate to the review report tab 8. You should see a new column detailing the time the user spent on the review. The code we created can be found below. 1. <link> 2. <link> 3. <link> 4. <link> The project could be run locally by cloning the <link> and then running the following commands sequentially. <code>. 1. If a student only saves the review and does not submit it before the due date, the response exists but the entry is not updated as submitted. Because of this the response entry is not updated with the end time and hence when we try to calculate the total response object time, it calculates that as zero and hence shows ""Review hasn't been submitted"". The response table should be updated once it's past due date. This was out of scope for this project hence we leave it as future fix. 2. The ""Save review after every 60 seconds"" checkbox does not work correctly, hence we defaulted that to unchecked as opposed to previous implementation where it was checked, because it hampers with our implementation. This is another fix required. 3. The submission_viewing_event table increases in size very rapidly as it stores start and end times for each link if a particular event occurs. Solution to that would be to save all the entries locally in users system and update the database only with expertiza time and link time after performing the time calculation, once the user clicks Save/Submit. This would prevent the database from saving unnecessary amount of information and also make it work faster.","Very good description of the problem and the approach.  I would have liked to see more description of the code than a single line describing each method.  Most of the files changed don't have any description of the changes.

The algorithm would be more readable if it didn't overflow the text box at the right.

The automated tests should have been described.","Overall, the student's assignment is comprehensive, detailed and shows a solid understanding of the problem at hand. The step-by-step breakdown of their implementation process and the reasoning behind each decision are clear. It is clear from the proposal that the student has taken into account previous attempts and learned from them to create an improved solution.

However, there are some improvements that could be made in terms of clarity and organization. There is a lot of information being communicated, and some parts were a bit hard to follow. Breaking down the text into subsections like 'Problem Statement', 'Previous Attempts', 'Proposed Solution' etc., would help to guide the reader through your thought process. Also, perhaps consider adding a summary section at the end to concisely wrap up what has been covered in the assignment.

The student has provided a detailed plan to build an enhanced feature, considering the experiences of previous teams. The feature for tracking the time spent by students on reviews will be highly beneficial for checking the effectiveness of review process. The proposed solution appears to be technically sound, taking into account problems identified in previous attempts.

One thing to consider is that the solution described assumes students will only work on one thing at a time. In reality, students could have multiple tabs open and switch between them, making the tracking of time spent less accurate. Nonetheless, the solution is a good initial approach to tackle the problem at hand.

It's good to see that you have identified potential issues with your design and proposed some solutions. It's important to consider how these challenges might impact the effectiveness of your solution and how they could be addressed in future iterations.

In terms of coding and technical details, it's nice to see that you've considered testing and included plans for both automated and manual testing modes. Providing actual code snippets, algorithm, and workflow is a big plus.

Regarding the documentation, the addition of diagrams and graphics to visualize the process can help to make the concept more understandable to non-technical people.

In conclusion, this is a very strong assignment that shows a deep understanding of the problem and a thoughtful, well-reasoned strategy for the solution. Solid work!"
140,E1806,"Best stated in the project documentation, “The Expertiza project is software to create reusable learning objects through peer review. It also supports team projects, and the submission of almost any document type, including URLs and wiki pages.” The system makes it easy for instructors to post assignments and manage students. Students are able to work in teams, submit assignments, receive feedback on their work and review their teammates. The project aims at enhancing the usability of the bookmarks feature for any topic. Basic functionality already exists to add bookmarks to topics. When a student logs in to his expertiza account,he/she can sign-up for a particular topic from the list of topics in an assignment. On the sign-up sheet, there is a column for Bookmarks. <image> Users can either view a Bookmark or add a new Bookmark for a particular topic. Users can submit links via add Bookmark to provide helpful sources for the author to complete their work. Users can also view Bookmarks already added for the particular topics. Authors can rank the usefulness of these bookmarks as 1-5 with a drop down menu next to the bookmark. Our project aims to implement this. Also, we want to provide a way for the users who have submitted useful bookmarks to be given credit for it. This can be based on the rating provided by the Author. This project intends to build on the bookmark functionality by allowing instructors to access the bookmark ratings rubric, and designing a way to assess if these bookmarks are being utilized by the author. <link>. When an instructor is logged in, they can manage rubrics under the Manage > Questionnaires tab. However, bookmark ratings are not available to be selected. <image>. After going through the migrations we observed that there have been migrations to add the Questionnaire nodes to the Menu Bar. In these migrations we did not find any code which specifies that the ""Bookmark Rating"" Questionnaire Node has been added to the Menu Bar. We believe that a migration has to be added which will add the Bookmark Rating Node to the Menu Bar thereby enabling the user to see ""Bookmark Rating"" as a type of rubric when they go to Manage > Questionnaires. The addition of migration did not solve the problem completely. When logged in as superadminstrator, we can access the menu editor. The menu editor shows the Bookmark Rating link (as shown below) which was added because of the new migration. Although this change is not visible in the actual Menu because the menu editor is not working properly. This problem was discussed with the instructors and they also confirmed the incorrect functionality of the menu editor. The Menu editor is expected to be replaced in the near future and this should solve the current problem. Admin view shows Bookmark Rating in the menu editor but the change is not reflected in the actual Menu. <image> <image>. When a user logs in as an instructor and selects Manage > Questionnaires, the links associated with the Bookmark Rating rubric are broken. When a user clicks on Bookmark Rating link, it should link to a page to create a new Bookmark rating Questionnaire. However, the link does not redirect to the required page, rather an error message is thrown. <image> <image>. <link> Previously, the Folder node was named ""Bookmarkrating"" because of which, after clicking on ""New Public Item"" or ""New Private Item"" we get an Error message. New migrations have been written in which the node has been renamed to ""Bookmark Rating"" because this is how it has been defined in the Questionnaire Model. Now the links for ""New Public Item"" and ""New Private Item"" works properly resulting in the screens shown below. Page that shows the links for ""New Public Item"" and ""New Private Item"" <image> Page that is redirected to after we click ""New Public Item"" or ""New Private Item"" <image>. The current functionality only allows for the author to review the bookmark, and the reviewer is not able to assess the usefulness of a bookmark. The design below could be implemented to allow for input from reviewers on bookmarks. This would involve modification to the existing classes to add “karma points,” which are points a user acquires for submitting helpful bookmarks. Both the reviewer and the author can submit a 1-5 rating on a bookmark- the author does so based on how helpful they found the link, and the reviewer based on how impactful the bookmark appeared to be on the author’s work. These ratings translate directly into karma points, making a user who submits a bookmark eligible to earn up to 10 karma points for that bookmark. This would require a field for karma points in the user database, where points would be stored and accumulated. Only the instructor would be authorised to view a students karma points, and the instructor would be able to list, sort, and filter users by karma points. How the karma points are utilized is at the discretion of the instructor; two examples of usage could be for recognition of helpful students and awarding participation grades based on a baseline of karma points. <image>. 1. db/migrate/20180326223032_update_bookmark_rating_tree_folder_rating.rb 1. db/migrate/20121127013927_add_bookmarkrating_folder_nodes.rb 1. db/migrate/20180403022842_add_bookmark_rating_to_menu.rb 1. expertiza/app/models/tree_display_controller.rb 1. expertiza/app/models/questionnaire.rb 1. config/routes.rb. The specification for the project did not require us to write automated tests.We have however included tests for UI Testing. 1. Creating a Bookmark Rating Questionnaire 1.1. Login to Expertiza as an instructor 1.2. Navigate to the Manage > Questionnaires menu and select ‘Bookmark Rating’ 1.3. Choose either new public item or new private item 1.4. Enter a name, min score, max score, and choose whether the bookmark questionnaire is private from the drop down menu 1.5. Select ""Create"" 1.6. You will now see a page that will allow you to add questions to your questionnaire. 1.7. Click ""Save"" to save your questionnaire. 1. Most of the functionality for the project was already in place. Our team was required to do the following task : 2. Allow Instructor to add bookmark rating as a type of rubric from the questionnaire menu. 3. Build on the current 0-5 rating system by adding criteria for a bookmark ratings. For example, rather than a simple ask for a 0-5 rating with no rubric, ask the user “How informative was the bookmark?” and “How much did the bookmark influence your submission?” 4. Our team proposed the following extension to the project : 5. In addition to building the feature designed above, karma points could be extended to other parts of Expertiza to reinforce positive user interactions. 1. Expertiza YouTube channel: <link> 2. Expertiza Documentation: <link> 3. Expertiza on Github: <link>.","The writeup explains the hurdles encountered and the solutions you've found, along with suggestions for future enhancement.  I agree with the reviewer who said it would have been helpful to include code … it would give the next person who works on this confidence about where to start.","Dear student,

You and your team have done a comprehensive job in conceptualizing and proposing ways for improving the bookmark functionality in Expertiza. It is evident that your understanding of the project is strong and you have put in a significant amount of work into troubleshooting and analyzing existing issues. Your proposal for introducing 'karma points', a system that rewards students for providing helpful bookmarks is an innovative idea that adds a benefitting gamification element.

However, the report could have been presented in a more organized manner. I’d suggest you to divide your future assignment write-ups by sections and use headers for each topic rather than numbering them all under a single list. It will enhance readability and help your readers follow your thought process with ease. Also, provide references or citations where necessary in order to give due credits to original contributors.

I would suggest for future project proposals you should also try to form a timeline to present an overview of the development, implementation, and testing phases. This gives a clear image of what you expect to accomplish over time. In addition, include an evaluation or testing plan that outlines how you aim to test the efficiency and effectiveness of the proposed changes, this ensures your proposed solution is aligned with the user expectations.

Overall, the project is promising and you have certainly taken thoughtful steps to improve and enhance this educational platform. I encourage you guys to continue putting forth this level of effort and thoughtful analysis in future projects. Keep it up! 

Best,
[Your Name]"
141,E1458,"<link> is a peer review based course management system. It supports project submission,team creation, and review of the submitted material including URLs and wiki pages. Students can manage teammates and can conduct reviews on other's topics and projects. Expertiza is an open source project based on Ruby on Rails. As a part of the OSS project 1 we were expected to refactor the Response Controller of Expertiza. Response Controller is responsible for managing the review versions, finding the latest responses and fetching the review scores. This wiki provides a detailed walk through of our contributions to the Expertiza project with a focus on refactoring. The response controller allows the user to create and edit responses to questionnaires such as performing a review, rating a teammate or giving feedback to a reviewer. Our project requirement was to perform the following changes : 1. Perform authorization properly. 2. Remove the duplicated methods. 3. Reduce the complexity of the rereview method. 4. Move the functionality incorporated in the controller, to the model, as it is the model's responsibility to implement this functionality. The following changes have been made in the project, as described in the requirements document. 1. Authorization to perform actions was done incorrectly via the redirect_when_disallowed method. It is supposed to be done through the action_allowed? method at the beginning of the class definition. Different authorizations are required for different operations. 2. For example, someone should be allowed to view a response if they wrote the response, or they are the person or on the team whose work the response is applied to, or if they are an instructor or Teaching Assistant for the class. The person who wrote a response should be allowed to edit it, but not the person/team who was being reviewed, nor the instructor and neither the Teaching Assistant for the class. 3. Earlier, the authorization was handled by denying incorrect access using the redirect_when_disallowed method, which was a more error-prone way of controlling access. This method has now been removed, and now the class has an action_allowed? method which does the authorization check and allows the user to perform the action only if he/she has the correct permissions. Before Refactoring: redirect_when_disallowed Method was used for authorization purposes. <code> After Refactoring: We replaced the redirect_when_disallowed Method by action_allowed? Method. <code>. 1. There were two copies of the edit, new_feedback and view methods . The second being the newer one, and, according to the rules for method definition, is the one that is currently in use because the latest version overrides the previous versions. We refactored the code by removing the redundant methods for edit, new_feedback and view. Edit method: <code> New_feedback method: <code> View method: <code>. 1. The rereview method was 98 lines long. We refactored the code by turning several parts of it into methods. Now the code is 81 lines long. Before Refactoring: <code> After Refactoring: <code>. 1. The rereview method contained a special code to check whether an assignment is “Jace’s assignment”; this was the first assignment that was ever created with a multipart rubric. It was hard-coded into the system, rather than working on a rubric that was created in the normal way. It is impossible to remove this code without breaking that assignment. It is now implemented as a separate method named handle_jace_kludge. Before Refactoring: The following code was present in the rereview method. <code> After Refactoring: We added two methods named 'handle_jace_kludge' and 'check_user_name_jace?' <code> <code>. 1. Sorting review versions is not a controller responsibility; So we moved it to the Response model . <code> 1. Similarly, the logic for determining whether a review is current or not(i.e., the review was done during the current assignment phase) is not a controller's responsibility and thus was moved to the Response model . <code>. Although ResponseController is a complex class, we managed to improve its code significantly through refactoring. We made use of <link> in order to run analysis of our changes against the original Expertiza code. We have managed to reduce the overall complexity of this class from 719 to 581 and duplication from 685 to 410. Also one of the major refactoring was performed on ""rereview"" method. We have managed to reduce its complexity from 129 to 91 by extracting methods. Original ResponseController on Codeclimate: <ref> <link> </ref> <image> <image> ResponseController on Codeclimate after Refactoring: <image> <image>. 1. <link> 2. <link> 3. <link> 4. <link>. <references/>.","Good, readable, not as extensive as some.","Dear Student,

Thank you for your meticulous documentation of the work you did while refactoring Expertiza's Response Controller. Your report is detailed and precise - I appreciate that you explained your plan of action, provided the results of your changes, and showed how these changes made an impact in the project. It is also great to see that you utilized CodeClimate for analysis to compare the original code with your refactored version.

The way you handled the authorization process shows careful consideration of user permissions and the importance of secure access to parts of the system. This will no doubt enhance the security and integrity of the entire system. Reducing and modifying the multiple copies of the edit, new_feedback and view methods is an effective way to minimize redundancies in the code. 

The biggest achievement, in my opinion, is your work on the lengthy and complex `rereview` method. You've reduced the complexity significantly which is a clear indicator of effective refactoring. 

For future work, please remember to include the actual code within the <code></code> tags. This is crucial to demonstrate how the refactoring has simplified the code structure and improved readability.

Overall, this is a job well done! Keep up the good work.

Best,
[Your Name]"
142,E1971,"<link> is an open-source project based on <link> framework. Expertiza allows instructors to manager courses and assignments for students. Students can form up teams in Expertiza to work on different projects and assignments and do peer review about other students' submissions. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.4. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link> 1.1.8. <link>. 1. E1971 Project aims to fix the associations problems between the Institution and Instructor class. 1. The forked git repository for this project can be found <link>. The following tasks were accomplished in E1971 project: 1. Task1: The institution list should be sorted alphabetically. 1.1. Details: When creating a course, the drop-down list for selecting the institution does not show in alphabetical order. <code> 1. Task2: Adding a new institution during creation of an instructor profile. 1.1. Details: The admin can attempt to create a new institution when creating a new instructor. But, after one types in the name of the institution & clicks create, it crashes. <code> 1. Task3: Listing of instructors should show their institutions on the same line as their new feature. 1.1. Details: When listing users, there is currently no column to display the user’s associated institution. <code>. As the issue is the Institution drop-down list is not alphabetically sorted. We simply added a step of sort when the Institution list was retrieved from the Database. <code>. The issue occurs when the admin trying to create a new instructor with a new institution name. To fix this problem, we added a function to create a new institution and a confirmation prompt to alert the admin. <code> <code>. The issue is that the user page is not displaying the user's associated institution. To fix this issue, we added an 'institution' column in the HTML file retrieving the institution names of each user. <code> <code>. <code>. <code>. <code>. We created 4 institutions and check if they are alphabetically sorted in the selection box <code>. <code>. <code>. <code>. <link>. <link> <link> <link> <link> <link>.","This wiki page is very well structured and clearly guides the reader through the problem/fixes. 
The test plan, however, does not explain what is tested and how.  It just gives a code listing, and the listing does not even contain any comments
There are links to videos, which is nice, but since the videos do not contain audio, it is much harder to figure out what they are showing than it should be..","Thank you for your submission. It's clear from your descriptions that you're able to identify the problems and come up with the correct solutions.

However, your report is somewhat disorganized. It's hard to follow your thought process because there is no clear structure to your writing. Be wary of overloading your reader with too much detail and code snippets without explaining what each of them does.

Additionally, you haven't used the links you've provided in any way. These links seem to interrupt your writing instead of aiding it. It's necessary that links be given proper context in your text, relating to the material you discussed in your assignment to provide additional resources, examples, or relevant information for the reader.

You also need to follow academic writing conventions. Some of your sentences aren't complete and the steps aren't correctly numbered, which is causing confusion.

To improve your assignment, you could:

- Use headers to segment your text and provide a clearer outline of your work.
- Consider the flow of your writing. Each section should logically follow from the one before it and lead to the one after it.
- Explain each code snippet you provide to ensure the reader understands how it connects to your work.
- Make sure all sentences are complete and clearly communicate your intent.
- Properly number your steps and make sure all reasoning within descriptions is clear.
- Include context for any links you provide.

Be sure to cite any external sources properly to give credit where it’s due. Overall, I see a lot of good work here, but presenting it in a more organized manner would greatly enhance its impact."
143,E1924,"Follow the Guidelines mentioned in the <link> page of the project's Wiki Page for building the Project in a Local Environment. Currently, when an instructor updates a questionnaire rubric of an ongoing assignment, the reviews are not reset and moreover, no notifications are sent to reviewers to update them of the changes made. As of status quo, the instructor, post making changes, would have to individually inform each reviewer of the changes made and ask them to change the reviews accordingly. The project aims to resolve the two main issue arising from the problems mentioned above: 1. If a rubric is replaced, or the items/questions are changed, then all the reviews that have been done need to be redone 2. The system should then email the previously done reviews to the reviewer and delete the response object and all associated answer objects. Further descriptions about how the project will be implemented and what files will be changed are mentioned in subsequent sections. <image>. <image> The main function of the code is to change the rubric questionnaire. There are three main functions to change the rubric of a questionnaire: add, remove or edit questions. Editing a question is considered a minor change as it does not change the general format(i.e. number of questions or their types) of the rubric. The two major changes are highlighted, they are adding or removing a question. In case of a minor change the question in the database is simply updated, no other action/notification is required. In case of a major change, the reviews given for that question need to be deleted in case the question has been removed and the consequent changes need to be relayed to the appropriate databases. Moreover, the reviewers, whose reviews have been removed, need to be informed about the changes made and be asked to update the reviews via email. The email-ids for these users have to be queried from the Users database. The solution is divided into 2 phases viz. Identification of edit and Notification. The primary metric for identification of a major change is when the ids of questions associated to a questionnaire change. When a rubric is submitted after an edit, the update method is called. The current rubric is made such that the question type (Radio/Checkbox/True or False) is not editable, however, the wording of the question can be edited. As per the definition of a major change, it is obvious that there is no change in the question ids(records/objects) associated with the questionnaire. Hence this would be a minor change. The questions can be deleted and/or added. We term an edit as major edit if the change involves addition or deletion of a question because it entails a change in the objects associated with the questionnaire. The params passed to the controller also includes a tag/identifier if a new question was added. We are using this tag to identify there was a new question added and hence major change. <image> In the diagram shown above, the ""Save teammate review questionnaire"" would result in a minor change. Clicking on the highlighted add and remove would result in a change of the questions and is therefore a major change. Once this solution finds that the rubric has major edits and there exists some user who has started the response (corresponding records exist), email notification module is initiated. In this phase, these records are pulled from the ActiveRecord and sent to the user through email. Once the email is sent successfully, records are deleted from the DB. At this stage, the user has all the details already added by them and when they click on ""Review"", the questions now correspond to the new rubric. This lets the user respond to the new rubric without losing data for any question. One of the motives behind sending these responses as email is that the first few questions in the review may be similar across rubrics and the user may re-use the same responses when prompted with the new rubric. Firstly, we need to check if there has been a change in the questionnaire, i.e if any question has been added or deleted. For this we use the tags in the params. The view has been coded such that it adds a tag called "":add_new_questions"" whenever there is a post method to add a new question. We have used this tag to identify a major change and redirected to necessary helper methods. This is indicated in the image below: <image> Similarly, we have identified when a question is deleted and redirected again to helper methods. The next step, is to look iterate through answers database and group the answers for the edited questionnaire per user/reviewer. The below UML diagram would assist in understanding the flow of information and the relation between the models. <image> Please note that FK stands for foreign key in the above diagram. Using the question ids returned from view, we obtained the response id from the answer database. We tracked this response id through the response, response_map and user models to arrive at the user id. This has been achieved using the code shown below: <image> Once we have identified the answers, user mail id and other associated information, this has to be mailed to the user and then the records deleted. This has been achieved using the code shown below: <image>. The current rspec file describes various contexts for testing such as adding new questions if attributes weren't correctly entered etc. As stated in the earlier sections, the update method of the questionnaire controller would be edited to identify major changes and trigger emails and deletions of records of responses. A context corresponding to this in the spec file for questionnaire controller under the describe block for update would be added. Currently, we have added two tests: 1. To verify whether a new question has been added or not and check whether the corresponding answers in the questionnaire have been appropriately deleted. 2. To verify whether a question has been deleted or not and check whether the corresponding answers in the questionnaire have been appropriately deleted. 1. <link> 2. <link> 3. <link>.","For design doc:  This is a good description of the rationale and the changes to be made, along with showing how the code was updated.  Only two things jump out at me.  1. It would have clearer if when you showed the update method, you showed it as a diff; I'm sure it existed before, and I'd like to see what changes were made.  Also, it is not clearly stated which controller that change is made to.  2. You should have described what the new tests tested.","Thanks for turning in your assignment. Your work is detailed and comprehensive, and I appreciate that you clearly spelled out your process of identifying and updating a change in the questionnaire. The logical progression of the resolution from identifying the problem to implementing the solution was well-structured. 

However, let's keep a couple of things in mind. Firstly, always aim to clarify your objective before you start explaining the solution. It's great that you've included an elaborated description of all the steps you've taken, but it seemed a bit unclear towards the beginning about what issues you were actually aiming to resolve. The two main problems you mentioned should be clarified more and positioned at the start of the assignment to give readers a clear understanding of the issues at hand.

In terms of the technical details, you've done a good job identifying the types of changes and explaining how you propose to alert reviewers in case of major shifts. Your division of changes into 'minor' and 'major' is intuitive and sensible. However, consider explaining your operation more thoroughly with the aid of pseudo-code or flowcharts. Although the images were a good addition, it would have been helpful if there was a brief description of what each of them illustrates. 

Lastly, when referring to code blocks, make sure to explain what each piece of code does. Although your self-commenting code is beneficial, it would greatly assist less tech-savely readers' comprehension.

Great work on the test cases and maintaining the sequence of logic in your implementation. Your efforts to ensure that the process is systematic and thorough are commendable. 

Keep up the good work and strive for clarity and conciseness in your future assignments."
144,E1754,"Expertiza is a web application which provides a dashboard to the students where they can submit and peer-review assignments, projects, codes, and other such objects. It allows students to review each other’s work and improve their work upon this feedback. Rubric advice allows reviewers to see what characteristics of work merit a particular score. Rubric advice lets a user see what criterion or characteristics of work merit a particular score. An instructor can retrieve peer review assignments and leave some advice or give scores based on some criteria. Similarly, students can log in and retrieve the rubric advice left by the instructor. We mocked the behavior of the user (both as an instructor and student) to see how different scenarios work, like modifying, saving and retrieving advice and building feature tests for it. The testing frameworks used for the same were Selenium and Capybara. An instructor when creating a questionnaire, can associate marks with comments which can enable a student to understand what score is appropriate for a particular work. An instructor can subsequently edit or delete an advice. A student can view and use this rubric advice when peer reviewing other's work. Thus the test cases formed check if an instructor is able to: 1. Create a questionnaire 2. Edit or delete an advice Creating a rubric advice has not been added as a test case because both edit and delete advice make an instructor 'create' an advice. An additional test case to do the same would have slowed down the testing process and hence is not advisable. Student Side: A student, when filling a peer review should be able to see the rubric advice associated with a particular test score. We test this task through adding a test case in the peer_review_spec.rb since Peer Review is superset of the Rubric Advice feature as it is a task where a student uses the rubric advice and submit it. Files changed: peer_review_spec.rb The test case checks if student is able to select a rubric advice that the instructor has created and then submit it. <code> The existing code given creates the required environment for the test student. It sets up a team, assignment and other required elements for the test student to submit a review. <code> The rubric advice is prepared in factory.rb with the following code addition . This allows our test Student to get a ready rubric advice that he can choose. <code> Instructor side: Edit a certain review rubric, and add advice to it. Test that when advice is added for a particular criterion, the advice can be retrieved and that it is exactly the advice that was added. Files added: review_rubric_spec.rb <code> Apart from the major test case for Rubric advice, it is essential to test if the logged in instructor is an authorized instructor. To test this, we have added the following test in review_rubric_spec.rb. Also, the task of loading the questionnaire and the question types is implemented in separate methods to allow reuse. <code> Factories.rb <code> It associates a merit score with each type of advice. As an example, 5 denotes 'very good'. 1. <link> 2. Build passing with Coverage increase of +0.3% <image> <image>. 1. <link> 2. <link> 3. Run the test cases: <code> <code>. 1. <link> 2. <link> 3. <link>.","Fairly readable.  Prose could be written to describe the workings of the test, rather than just their result.  Not clear why testing advice requires verifying that the logged-in user is an instructor.  Shouldn't this be performed in the class that implements logins?","Dear student,

Thank you for your submission. Your assignment on Expertiza, specifically focusing on user (students and instructors) behavior, developing feature tests, and rubric advice review, is exhaustive and well-researched. 

Your ability to understand and extract the crucial functionality of the software is commendable. Moreover, your attempts to draft and simulate various scenarios for both instructors and students indeed add depth to your assessment. Your utilization of Selenium and Capybara for testing highlights your strong grasp of versatile frameworks. 

Your clear comprehension of the interactions between rubric advice, creation and alteration of questionnaires, and the impact of these elements on peer review is encouraging. Your decision to focus on an instructor's ability to create a questionnaire and edit or delete an advice over creating rubric advice shows thoughtful time management on your part.

On the student side, recognising the necessity for a student to view the rubric advice tied to a particular test score during a peer review, and that validating this step is crucial is noteworthy. 

I am glad to see you took an initiative to validate instructor's authority and the load of the questionnaire which shows your attention to detail and the understanding of potential variables that may affect the system.

I encourage you to continue refining your code writing and testing skills. Be cautious with your language formatting - remember to end your sentences and paragraphs appropriately. Also, provide an explanation for the non-text content like links and images.

Continue the great work!

Best,
[Your Name]"
145,E1701,"Expertiza is a web application where students can submit and peer-review learning objects (articles, code, web sites, etc). It is used in select courses at NC State and by professors at several other colleges and universities. Rspec is a meta-gem, which depends on the rspec-core, rspec-expectations and rspec-mocks gems. Each of these can be installed separately and loaded in isolation using require. Among other benefits, this allows you to use rspec-expectations, for example, in Test::Unit::TestCase if you happen to prefer that style. Conversely, if you like RSpec's approach to declaring example groups and examples (describe and it) but prefer Test::Unit assertions and mocha, rr or flexmock for mocking, you'll be able to do that without having to install or load the components of RSpec that you're not using. Unfortunately, Expertiza tests are really slow. If you check the TravisCI, it needs nearly 9 min to run all tests. <code> One reason is that we use fixture to create records in test DB each time running tests. For example, the codes in quiz_spec.rb contain too much create so that prolong testing time. <code> One solution is building an complete database to support all RSpec test without creating new records. Formally, we need to: 1. Create the records in test DB according to the content in fixtures. 2. Check each test file and delete certain DB records creation code that insert default records (eg. create(:deadline_type)). 3. And keep all the test cases passing when using test DB and make sure the time running test cases is shorter than before. 4. You should submit the sql file of test DB to Expertiza. To finish these tasks, we need to modify all RSpec test files in Expertiza and using a new Database:Expertiza_test. test database Rspec tests. <image> In this design, we create a new database for testing, and we save some related information in this database. Every test just need to fetch data from this test database, and after the testing, we need to add some operation to rollback the data. For example, if the test is about creating a new quiz, in this situation, we need to delete this quiz after this test. Because of it, the state of database can be saved, and also it will not influence other test or test this test case again. We design a expertiza_test database to save the test date used for Rspec. The test database owns the same structure as the real expertiza database, including the relations between tables and some restriction of attribute like it cannot be null or some other requirements for different attributes. Besides, the data in test database is the same as the data in factories part in spec, which includes FeedbackResponseMap.rb, Respone.rb, factories.rb, quiz_factory.rb. In this situation we do not need to create some data before testing, and we can use the data in test DB directly. Because of it, the overhead of testing cases will experience obvious decreasing. like the Rspec statements in creating some User objects.: <code> then transfer this into SQL query and then add the information the same as designed for Rspec test into expertiza_test database. We will try two method to achieve the goal: 1. Write a script to create all test data automatically then don't clean the database. 2. We transfer the data in girls_factory into the data base, and there are some steps: 1. we delete some related information in Rails_hepler.rb <code> Those statements is used for adding the technology to clean the database before everytime using Rspec test, and then also clean the database(using turncate to increase the time of cleaning database). 2. We generate a new create rb file, and in this file we just put the create statements in Rspec style function, like create(:deadline_type, name: ""submission"") to transfer the data into database when running rspec create.rb. To accelerate the feature test, we have to eliminate pseudo data creation. Now all the feature tests must create their own data before each test. For an example, now a test first create a user before it can do the login operation. The creation latency is considerable. After building a test database, all the pseudo data creation statement can be removed from the test files. Instead, the tests reference data stored in the test database. This change will not only accelerate the testing time, but also dry out the code. The way tests reference data from database is the same as it does in the development mode. To login, or do other operations, the test can invoke existing user data in test database. Using ""User.find()"" or ""User.where()"", test data can easily be invoked by tests. For existing tests, they can directly use the test database. For new tests added later, they can use the records in test database or create specialized data use FactoryGirl. So to keep the test database up to date ,it needs to be maintained regularly. With test data in the database, we modified the RSpec feature test files: 1. Disable the data clean statement in rails_helper.rb. <code> 2. Eliminate data creation statement in each test case. Delete” create(:assignment)” like code 3. Modify url visit statement. Modify “visit '/student_teams/view?student_id=1'” to @student=User.find_by(name:”student2064”) “visit '/student_teams/view?student_id=@student.id’” 4. Recover test database before or after each change data operation For tests involved with create or delete actions, the data modified should be rollback. airbrake_expection_errors_feature_tests_spec.rb assignment_creation_spec.rb calibration_spec.rb inherit_teams_display_spec.rb instructor_interface_spec.rb list_teams_spec.rb questionnaire_spec.rb review_mapping_spec.rb staggered_deadline_spec.rb topic_suggestion_spec.rb. We run a single rspec test ""airbrake_expection_errors_feature_tests_spec.rb"" to test the performance improvement when using test database. Without a test database, the feature test costs 1:37 minutes: <code> Using the test database, the same test costs 1:10 minutes: <code> The time is decreased by about 20%. Consider the browser's response time in both trial, the improvement proportion should be higher. Here is a video to show the improvement: <link>.","I do not think your UML is correct. (should not include github pull request and github repo, etc.) You pasted a lot of code. It will be better to explain what each piece of code does.","Dear Student,

Thank you for the completed assignment. Your analysis of the web application Expertiza and the need to optimise its testing process is generally well-structured.

You started off well by introducing and providing some context on the Expertiza application and its challenges, especially the slowness of the tests. You then formulated a solution to optimise the testing process using an alternative database. This was comprehensive and well-detailed, especially with the step-by-step approach, solutions suggested and methods to achieve the goals proposed.

However, your explanations could be more clear and concise, avoiding redundancy and over-complication. For instance, in the section where you discuss creating a new database for testing and rolling back the data after test completion, you could simplify your explanation to make it more comprehensible.

Furthermore, the use of code snippets and practical examples is highly commendable as it demonstrates application of theory. Nevertheless, it is problematic that these snippets and examples are not entirely clear due to the lack of proper formatting.

Your determination to improve and optimize the existing system is admirable, and the data displayed towards the end of the assignment showing the time decreased by 20% is a good way to prove the efficiency of the system.

Lastly, great job on working on a video to illustrate the improvements made. This exemplifies your effort and dedication towards the project.

In the next assignment, focus on improving your clarity and simplicity in expression, and also remember to properly format code snippets. There is a great potential in your understanding and application of concepts. Keep working on your writing skills as well to match your technical prowess. 

Grade: B+"
146,E1689,"<link> is a peer review based system which provides incremental learning from the class. This project has been developed together by faculty and students using <link> framework. Expertiza allows the instructor to create, edit and delete assignments, create new assignment topics, assign them to a particular class or selected students, have students work on teams and then review each other's assignments at the end. For the students, they can signup for topics, form teams, and submit their projects and assignments. Students then review the work done by other students and give suggestions to improve. Teams after reviews are allotted scores and they can refer to the peer comments to further improve their work. It also supports submission of different file types for assignments, including the URLs and wiki pages. During reviews, many a time, reviewers may have questions about the submitted material or the authors may want to give some instructions to the reviewers. It may sometimes block the reviewers from progressing with the review. Reviewers can end up submitting empty review forms with all 0s if they cannot figure something out. The aim of this project is to provide a mini-discussion platform for each submission so that reviewers and authors can ask/answer questions in the form of a real-time chat window. For example, if the server on which the application is deployed is down, then the reviewer can send a message that the server is down to the authors and then the authors can get the server up and running and send a message to the reviewer informing the same rather than receiving low grade on that review. To implement the chat feature , we are creating 2 new models i.e Chat and Message. The associations for these models are Chat belongs to AssignmentTeam and has many messages while Message belongs to Chat. Now, the Chat model will contain the assignment_team_id element. Using AssignmentTeam, we can find whether the chat user is a reviewee or the reviewer. 1. Chat (belongs to AssignmentTeam) 1.1. id - primary key - int 1.2. assignment_team_id - id of the team - int 1. Message (belongs to Chat) 1.1. id - primary key - int 1.2. body - contains the message body - text 1.3. user_id - id of the sender. hidden from the UI. - int 1.4. chat_id - id of the chat to which this message belongs to. - int. <image>. 1)Scenario 1: When the reviewer has a doubt and wants to send a message to the reviewee group. A new link for chat will be provided along with the begin/edit options of a review. Clicking on this link will pop a chat up. <image> 2)Scenario 2: When the reviewee group wants to view their messages or send messages to his reviewers. A new link for messages will be provided along with ""Your work"". Clicking on this link will pop-up a chat box where the reviewee can see/send messages. <image>. Most of the web uses Http which uses TCP/IP transports. This means that the connection is initialed by client, server responds to the request and becomes idle. For implementing a chat feature using the above technique requires the client to keep on poling so that it receives the latest messages from the server. Apart from this, there are ways that server initiates the communication with the client when there is data which is called push or comet. Both these techniques involve overhead of http and isn't a very good way for low latency applications. For a better way, we will use web sockets into place which provides persistent connections between a server and a client, which enables both to send data at any time. To implement this we used a ruby gem Faye which is a messaging system with publish-subscribe. It works on Bayeux protocol. We will have the messages of the chat displayed in a partial which is updated using Sync - Realtime Rails Partials. For the live chat, we need to start the rack server using the command rackup sync.ru -E production. Sync helps in updating the partials in the real time. <code> The first tag fetches all the messages that are related to this chat that were previously sent and the second tag fetches new messages in the real time. Message.bychat function helps us in scoping so that only the messages related to this chat are fetched. Using Faye and Sync gems, we prevent the client from polling the server. Instead, we publish the messages to the corresponding chat box and using sync config , we make the users, i.e the authors and reviewers subscribe to this particular chat box. This way, the coupling between various different objects is loosened and messages can be sent back and forth between authors and reviewers without modifying any of those objects. These observers are subscribed and unsubscribed at any point in time without causing further ramifications. This way, the chat functionality does not depend upon the implementation of the User class. Two new models chat.rb and message.rb have been added. The dependency between them is a one-to-many relationship , i.e a Chat has many messages and Message belongs to Chat. The message model also has a many-to-one relation with User while Chat has a one-to-one relationship with AssignmentTeam. We added the relationship corresponding to chats and messages in existing models User and AssignmentTeam. We also added a oncreate method in Assignmentteam for creating a new chat whenever a AssignmentTeam is created. A new controller messages_controller.rb was added. The major functionality this controller provides is that via sync gem, it syncs a new message to the corresponding chat as soon as the new message has been saved which facilitates the real time chat. The student_task_controller.rb has been modified to add a chat_mappings instance variable in the view method which makes the chat objects associated with the reviee team available for the view. A new helper module messages_helper.rb has been added. It contains the method is_reviewer(message) which take the message object as input and return whether the message was sent by author or reviewer. Using the output of these methods, various css classes are added to the message div to provide UI enhancements. The _message_row.html.erb has been added. It is the partial in which messages are rendered row wise in a chat box. The _responses.html.erb partial in student_review view has been modified to provide the Chat option for the reviewer. The reviewer has to click on the Chat link to send or view messages to or from the reviewee team. The view.html.erb in student_task view has been modified to provide a Your messages link for the reviewee team. When the reviewee clicks on this link , a side bar pops up and the reviewee will be able to see all the available chats and respond to the queries of the reviewers. 1. Chats.js file has been added for managing the pop up chat logic. 2. Chats.css file has been added for managing the styles related to the chat popup. Reviewer View: Preconditions: There is an assignment team created and a topic assigned to them. Also, a reviewer has selected their topic to review. Flow of events: 1. Login to reviewer's account. 2. Click on the assignment. 3. Click on ""Other's Work"". 4. Click on the chat button next to the assignment topic. 5. Type the message. 6. Assert the presence of the message in the window. Post conditions: The message has been sent to the author. Author View Preconditions: There is an assignment team created and a topic assigned to them. Also, a reviewer has selected their topic to review. Flow of events: 1. Login to author's account 2. Click on the assignment. 3. Click on ""Messages"" 4. Assert the presence of the message in the window. 5. Type the message. 6. Assert the presence of the message in the window. Post conditions: Author has received the message and can send messages. Testing the newly added Models - Chat,Message. 1. Model validations for the chat model: validating the chat so that it has a unique assignment_team_id. 2. Model validations for the message model: validating each message has a user_id, chat_id and a body. Also, checking that it belongs to both user and chat classes. Currently, a member of the reviewee team can view messages from all of the reviewers in a single pop-up box . Now , each of the reviewees need to keep opening the pop-up box to check if they have any new messages from one of their reviewers.Same is the case for reviewers. In future, a unread messages feature can be developed which shows if the user has any new messages since the last time they have opened the pop-up box. Also, one of the most used features in chats are emoticons. If a proper emoticons library is added, it can enrich the conversations between the reviewees and their reviewers. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.","This is a very good example of what we expect in a design doc.  It could include more details on the tests that were anticipated.  It would also be useful to update it to say what you actually did, as a group following on to your work would need to know this.","Thank you for your thorough and in-depth work on this assignment. Detailed explanation on the development of a mini-discussion platform for each submission between reviewers and authors displayed your deep understanding of the key concepts. You successfully implemented chat functionality improving collaboration and communication between peers in the review process. You also did a marvelous job describing the steps required for implementation and expected workflow.

However, the technical language you used might have made it difficult for a non-technical reader to understand your work thoroughly. Next time, try to simplify your language keeping in mind that your readers might come from diverse backgrounds.

Also, your work would have benefited from keeping explanations of networking topics such as Http, TCP/IP, push, comet, and web-sockets brief, and focusing more on how these concepts are applied to the project. Readers may already have an understanding of these, and redundant explanations can distract from the main focus which is the project.

Your suggestions for future improvements are appreciated. Adding an ""unread messages"" feature and emoticons could definitely make the chat feature more user-friendly and engaging.

Lastly, you need to identify and resolve the placeholders <link> and <image> with relevant contents or links before finalizing the assignment. These seem to suggest that there are relevant sources and illustrations that aren't provided.

All in all, great job on this assignment! It was informative and it was clear that a lot of effort and understanding was put into this project. Keep up the good work!"
147,E1676,"In the current version of Expertiza, members among a team can evaluate each other’s contribution and give appropriate scores based on the same questionnaire. However, in the lifetime of software development, members in a team often take on different roles whose works content are vastly differentiated. Like in an agile development environment, such as Scrum, there are typically <link> can take: software engineer, architect, programmer, analyst, QA expert, tester and UI designers . Job description and evaluation entailed are vastly varied among these roles, thus a generic assessment rubric cannot hold reasonably. The rationale of our project is that we want to give project members the option to evaluate each other's work based on the specific role or duty they take in the development process. This can ensure a reasonable assessment for different duties and can also help to improve the utility of using members-reviewing in the whole reviewing process. Task Description: There are general three aspects we would do in order to achieve the Role-based reviewing function. 1) A new option (check box) would be added to the Review Strategy tab from the instructor view when he creates a new assignment. What’s more, the instructor can create different roles or duties available for the assignment by typing into a text filed. The instructor also has the power to allow multiple members to choose for the same duty. 2) In the Rubrics tab from the instructor view, New rubric would be generated by creating different questionnaires for different roles when adding new assignment. 3) A new option (drop box) would be added to the “Your team” page from the student view when an assignment was created to be role-based reviewing. Student can choose their roles or duties from the drop box which were generated by the instructor for this specific assignment. When the instructor enabled the multiple selection option, different members in the team can choose same duties for this assignment. Tasks can be viewed more clearly by the graph below: <image>. We have modified following three database tables to support role(duty) based reviewing: 1. assignment_questionnaires 2. assignments 3. teams_users <table> <table> <table>. Below are the key files modified: <code> <code>. See <link> section above. Below are the view files that we modified <code> 1] View showing newly added checkbox for setting duty based option and allowing duty share <image> 2] View showing different questionnaire for different teammates based on their duty <image> 3] Assign questionnaire to teammates based on their duty <image> 4] View showing ""select duty"" link for teammates. Every student can select their duty in the team. <image> <image> 5] After selecting, students can update their duty. Also, they will get the review questionnaire based on duty. <image> 6] Review questionnaire based on duty <image>. In our project, we are providing an option of adding duty for different team members in an assignment and giving review options based on their duty. We will add following functionalities: 1. How instructor create assignment with duties/roles 2. How students take duties from a given list of duties 3. How teammate evaluation rubric assign different review questionnaire based on duty. UI will be tested manually. First, we will test creating an assignment as an instructor with different duties and assign different review questionnaires to each duty. Then we will login in as a student and take a duty from given list of duties. We will try covering all edge case scenarios in test cases section. Following will be the test cases: 1. Login in as an Instructor: <code> 2. Login in as an Instructor: <code> 3. Login in as a Student <code> 4. Login in as a Reviewer <code>. For functional testing, we will use RSpec. It uses Behavior Driven Development (BDD) for testing functionality of the system. It provides way to describe specific functionality of the system being tested and helps in better visualization of test cases. We will use Capybara for automating the manual test cases. It is a web-based automation framework and coupled with RSpec. It allow developers to write the test cases which simulate the whole scenario of manual testing. 1. Verify if instructor can select duty option <code> 2. Verify if instructor can correctly set the duty <code> 3. Verify if duty share is allowed <code> 4. Verify if student can select duty <code> 5. Complete test cases are present in following files: <code>. Expertiza <link> RSpec <link> ScrumRoles <link> CapyBara <link>.","Good work with design document. Sufficient information about design
Information provided for both Manual and Automated testing
Explained problem statement with visualizations","Dear student,

This is a comprehensive and substantive submission, containing a mix of concepts, implementation strategies, and proposed testing mechanisms. The realisation of differentiation in team roles and its impact on effectiveness and fairness of evaluation is insightful. Your proposal to incorporate a feature that allows role-based evaluation could be a significant improvement to the current system.

Here are few points I would advise you to consider in future assignments:

1. Before diving into the details of the proposed solution, it is important to first provide a clear and concise problem definition, stating why the current system is not meeting the needs. This sets a good pretext for the reader to appreciate the solution more.

2. While the concept of allowing the instructor to define roles is good, the impact of significant changes, such as on the user experience, should be considered. Adding more options complicates the UI and may lead to confusion, so try to simplify the interface as much as possible while ensure its practicality.

3. Make sure you present your content in a logical and clear manner. Some information seems quite tucked away, and the flow could be improved. For instance, you shared the details of the new database tables that are to be modified quite late in the assignment. It could be beneficial if you briefly mention this when you introduce the new functionality, leading readers to better grasp what is going on.

4. Although you've detailed various functionalities and testing methods, one aspect seems lacking - how are you going to gather and apply feedback? Feedback from users is critical in agile development, so planning how you'll incorporate this could help you develop more effective solutions.

5. Remember to carefully proofread your work before submission. There are a few instances where your sentences are not grammatically accurate and are slightly confusing.

Overall, your efforts are commendable and the new feature could pave way for fairer and more efficient evaluation. I encourage you to build on these insights as you move forward in the course. 

Keep up the good work!
"
148,E1753,"Please note that the requirement for the project has been changed to feature tests (different from the previous review) after discussing with the project mentor and the professor. Updated in Problem statement. Expertiza is an open source project developed by North Carolina State University using Ruby on Rails. It is mainly a tool used to collaborate among students and faculty on a course and act as a common repository to track students’ progress on assignments. It is a simple tool where the instructor creates multiple assignments required and teams are assigned projects. Students submit their work and review other’s work and provide feedback. 1. <link>. 1. <link>. The bidding feature allows students to sort topics by preference. This is needed in order run the team assignment algorithm, to match students with others based off the similarity in their topic preferences. The feature matches students to teams by calling a team forming algorithm hosted on a web service. Teams are then matched to topics by choosing the most common priority chosen by each member in the team for each topic. Topics are then assigned to students with preference given to the largest team. • Students submit bids on the sign-up sheet view. The bidding process is done in the lottery controller. • One set of bids is possible for entire team. When one team member changes a bid, it will affect the whole team. Currently, each participant has a bid record. A Json request is sent to a webservice hosted on PeerLogic which responds with the new teams. (More information: <link> ) • During topic assignment the teams’ bids are determined by using whichever priority most students placed on a topic (Ex. If 3 students set topic 3 as their 1st priority and 1 set it as their second. Topic 3 would be set as the priority for the team.) • Matching algorithm: Teams are first sorted by size and a matching algorithm assigns each team to its highest available bid. This is an only Testing project to write feature tests for the process. The same is explained in screen shots and video attached. The previous requirement regarding the modifications in sign_up controller have been changed to feature tests and the following problem statements have been taken care of. Each team or an individual can go through the list of topics and set priorities for different projects. And once the priorities are set up for all projects, bidding algorithm is executed to assign projects to teams based on the priorities. The following need to be taken care of as part of this work package. (E1753) • Test for the entirety of the bidding process. • Users are able to place bids on interested topics. • Users are assigned topics. /spec/features/bidding_spec.rb. All bidding process like creation of assignment, adding topics and enabling bidding has to be performed before every test case. This code is placed in the before block of the rspec test code. This code is executed before all the test cases. <image> For the first test case, code is written to verify the web-service which runs the bidding algorithm is working properly if the bidding process is enabled. <image> For the second test case, code is written to verify that the bidding process fails if no participant has placed bids. <image> For the third test case, code is written to verify that each user is assigned a topic after running the bidding algorithm. <image> For the fourth test case, code is written to verify that when the user places multiple bids the bid with the highest priority is assigned to the user. <image>. Code coverage is extremely low and only limited to the function signature even after executing 6 test cases. Screenshot below shows code coverage before implementation of test cases. <image> Solution Code coverage has drastically increased after the integration test cases are executed. Screenshot below shows code coverage after the execution of the test cases. <image>. Manual testing of features on Local host is done with a running Expertiza environment. ( As seen on video). The following steps have been taken care of to setup ad run the bidding process manually. • Login as instructor and create assignment. Create topics under the assignment. • Enable bidding and associated properties for the created assignment. • Login as student, create teams and bid for projects. • Login as instructor and run the bidding algorithm. • Login as student and check if topics are assigned. The screen shots for the added feature test cases have been attached below. (Also attached as video file). Test cases written to check for the following scenarios. • Check for whole bidding process to run successfully. • Check for Error message for unsuccessful bidding run. • Check if user is assigned a topic successfully. • Highest priority bid assigned when multiple bids are placed. Screenshot of the executed integration tests is attached below. <image>.","The functionality of the tests is described.  It would be helpful if (i) the working of the test code was described and (ii) the fonts were larger so the code could be read without zooming in.  The section on code coverage refers to integration tests, but these are not mentioned by name in the writeup.","Dear student,

The effort and level of detail you've put into the project is commendable. Your explanation of how Expertiza works, as well as the changing requirements on the project and the allocation for students based on bids, is clear and well executed.

The feature tests you implemented for the bidding process are also comprehensive. You've effectively checked for successful running of the process, an error message for unsuccessful runs, and whether a user is assigned a topic successfully. Great job!

The code and the images you shared are helpful in understanding the executions of the tests. However, your mention of multiple images without actually presenting them within the context of your write up makes the flow of your report somewhat confusing. If using a platform that doesn't support embedded images, consider using textual descriptions or hyperlinks to provide additional context.

I appreciate your initiative in manually testing the functionality on a local host as well. This shows your thoroughness and determination in ensuring quality. 

Your attention to increased code coverage after the execution of test cases also reflects your understanding of the importance of testing in maintaining software quality.

In future, please ensure to check the grammar and syntax throughout your assignment, as there are several minor mistakes that disrupt the readability. Also, remember, properly formatting your documents would make them easier to read and understand.

All in all, you've done a great job! Keep up the good work in following assignments.

Best,
[Your Name]"
149,E1671,"Expertiza is an open source web based peer review system developed and maintained by students and faculty members at North Carolina State University. It enables students enrolled in a particular course to form online teams and complete assignments. The participant, course_participant and assignment_pariticipant models does not have any unit tests. 1. Create a Factory for assignment participant and course participant model. 1. Test the relationships and validations 1. Write model spec for major instances. 1. spec/factories/factories.rb 1. spec/models/participant_spec.rb 1. spec/models/assignment_participant_spec.rb 1. spec/models/course_participant_spec.rb. Unit tests are used to test the functionality of methods in the model. These tests can be based on either test-driven development (TDD) or behavior-driven development (BDD). BDD is preferred for testing because it easy to understand compared to the more specialized TDD.<ref> <link> </ref> In this project, BDD is used to test the functionality using RSpec. RSpec is a testing tool for ruby using the BDD approach.<ref> <link> </ref> Factories are used to populate the database before the tests are run. The factory for the Participant class is already present. The factories for the other two classes will be very similar. The only differentiating value will be type which can either equal AssignmentParticipant or CourseParticipant depending on the class. Below the factories for AssignmenmentParticipant and CourseParticipant are given. <code>. The Participant class is the base class for both the AssignmentParticipant class and the CourseParticipant class. We have used the rspec framework to test each of these three classes. The factory library used is Factory Girl and the factories themselves are located in factories.rb. Tests are usually centered around conditional statements, for example if there is a statement following a condition that evaluates to be true. Here it can be tested that the statement is always executed correctly when the condition evaluates to true. The participant class is used to describe the participants of a university class. Unit tests for this class is written in the participant_spec.rb file. The first few unit tests defined are used to test the value of data members. There are also three unit tests to test the functionality of the fullname, topicname and name methods. <code>. The AssignmentParticipant class inherits from the Participant class. This first test is to validate whenever an object of AssignmentParticipant is created. Then there are three tests for the methods type, average_scores and copy. Lastly there are four unit tests defined to test the functionality of the method import. These tests can be found in assignment_participant_spec.rb. <code>. The Course Participant class is to show the participation of the student into a particular course. The course participant class is inherited from the participant class associated with the course class through belongs_to relationship. We have tested the four different methods of the class course participant. These tests are found in the course_participant_spec.rb file. The first method to test is the copy method. The copy method checks if an assignment participant exists for the corresponding parent_id. If it exists then a null is returned otherwise a new object for assignment participant is returned. We check both the functionality of the methods using two different tests for the method class. The next important method is the import method. The import method consists of four different scenarios and thus we have written test for testing four different scenarios for the import method. The import method takes a record field and input and checks for various condition on the record field and creates the course participant object. Below is a short snipped of the various tests written for the copy and import method <code> <code>. The tests can be run on the terminal from inside the expertiza folder using following commands: For participant: <code> For assignment_participant: <code> For participant: <code>. <link>. <references />.","The CourseParticipant tests are described much more fully than the other tests.  I would have liked to see similar descriptions of the other tests, though as it stands, the code is already pretty readable.","Dear Student,

Thank you for your hard work on this assignment. You demonstrated a good understanding of Expertiza and its functionalities. Moreover, your explanation about the Unit tests and their importance is quite clear. It's great to see you leveraging both TDD and BDD for effective testing.

One area for improvement could be your structure and organization. Your submission has formatting and numbering issues. For example, you have multiple sections labeled as '1' and this creates confusion. Please ensure your submission is well-structured and clearly numbered for ease of understanding. 

In addition, you only provided minimal code snippets to illustrate your work. Providing more comprehensive code would allow a more effective evaluation of your work. If it's hard to include large code blocks, try to focus on the most crucial parts or the ones you have questions about.

Keep up with the good work on testing with RSpec and factory libraries, such as Factory Girl. Please remember to provide any necessary instructions for running the tests, even if you think they may be self-explanatory.

Lastly, it appears as though you forgot to link your reference links where you wrote ""<ref> <link> </ref>"". Please double-check this be sure to include your references correctly, as this is very important for the quality and credibility of your work.

Overall, good job! It is clear you understand BDD, TDD, and the essential principles of unit testing. With a bit more attention to detail and organization, your next assignment will be even better.

Keep up the good work!
Best,
[Your Name]"
150,E1624,"Suggested topic functionality is designed for students to suggest topics they interested in. An assignment can be set up to allow students to suggest topics at the discretion of the instructor. Then, students can suggest topics, and add related descriptions. The proposer can state that (s)he wants to work on the suggested topic. When the instructor approves a suggested topic, if the proposer wanted to work on it, it is assigned to the proposer. Otherwise, it is placed on the signup sheet for anyone to reserve. The purpose of suggested topic is to make the writing assignment more personalized. Currently, there is no functional test for student's topic suggestion function. 1. Understand the flow of the suggested topic function. 2. Do not use the development DB, otherwise the tests will not pass on TravisCI. 3. Create RSpec file in /spec/features/ folder. 4. Use fixtures to create the assignment record and any other records such as participant records in test DB. 5. Use Capybara to write functional tests for these three scenarios. 1.1. One team is on the waitlist. They sent a suggestion for new topic and they want to choose their suggested topic. After their suggested topic is approved, they should leave the waitlist and hold their suggested topic; 1.2. One team is holding a topic. They sent a suggestion for new topic and they want to choose their suggested topic. After their suggested topic is approved and they choose to switch to suggested topic, they will hold suggested topic and their old topic will be released. And if another team is in waitlist of that old topic, that team should hold the old topic now; 1.3. One team is holding a topic. They sent a suggestion for new topic and they do not want to work on their suggested topic. After their suggested topic is approved and they choose to public suggested topic, they will still hold their old topic. Their suggested topic will be added in sign-up sheet. 6. Create multiple tests to check valid and invalid cases. To test the functionality of student's suggest topic, we plan to use Capybara to write the test code for each step listed below, covering all three scenarios. (We wish to add some UI screenshots for each step, for better illustration, but seems the file upload function of this expertiza wiki is available for student user level so far.). In the project, we assume that an instructor account instructor6 and a student account student11 is already created. First step is to login with the instructor account ( instructor6 here), and then create a course with the new public assignment function. We will create the assignment and edit the topic feature to enable the topic suggestions function for student, where in the UI, it means select the ""Allow topic suggestions from students?"" checkbox. Also, to test the second and third scenarios that the student already hold a topic, we will add a new topic with 1 slot for testing the later two scenarios. After all above are done, the course just created can be saved to the test database. In this step, we need to write two functional tests: one is to check whether the course can be added and does the added one have topic suggestion enabled, the other one is to check whether the topic is added by instructor with 1 slot. <image>. After the course is added, the student ( student11 for this test project) will be added as participants to the course. For UI test, it should be entering ""student11"" as the participant name with the ""participant"" choice selected then click ""add"" button. In this step, we need to test whether the student, named student11 , is added to the course correctly. <image>. For the first scenario, which the student does not holding any topic, we should test after login with student11 account and choose the assignment just created by instructor6 . Then, we will suggest a topic with the choice of ""Yes"" for the question Do you wish to work on this topic? and submit the new topic suggestion. In this step, we need to write the function test to check whether the new topic is added and the student is willing to work on this topic if it is approved. <image>. For the second scenario, we should first let the student login and Signup the only topic created by the instructor in the Signup sheet. Then do the same thing as depict in Step 3.1. In this step, we need to write two function tests: one is to check whether the student is already on the student list the topic, and the other one is to check whether the topic's available slots of the topic is 1 and the max number of slots is 2. <image>. An error occurred while attempting to extract the child content. The approve/reject functions should also be tested by using the instructor6 account. After login the instructor account, use the assignment view suggestions function to view and then approve/reject the new suggested topic. In this step, we need to write two function tests: one is to check whether the Signup sheet does have/not have the suggested topic if it is approved/rejected, the other one is to check whether in the student suggest new topics , the topic suggested by student11 is indeed approved/rejected accordingly. Note that, this step is the final test step for the case of suggested topic is rejected. The following 3 possible step 5 is for the case the suggested topic is approved. <image>. In addition to step 4, since the choice is ""Yes"" for willing to work on this topic when the student suggested, we will also need to test whether the student is already on the list of the new suggested topic and the number of available slot of the new suggested topic is 0. An error occurred while attempting to extract the child content. For the student was holding a topic, coupled with the test written for Step 5.1, there is another test need to be written to check whether the slot of the previous held topic is increased by one. <image>.","Should use Factory Girl to create assignment.
Duplicated code on instructors' logging in and approving the topics
","Dear student,

Thank you for submitting your assignment. You have done an extensive job in discussing this topic and it is evident that you have a good understanding of the topic's functionality. 

However, there are several areas you can improve. Your assignment appears to be one large paragraph, making it hard to follow and understand your ideas. A better layout would enhance readability. Use paragraphs, headers and bullet points to properly structure your information. 

Additionally, there seems to be redundancy in your explanations. Try to be concise and avoid repeating the same idea multiple times. This will keep your audience's attention and make your paper more compelling.

When referencing instructional steps, use numbered lists to emphasize sequence which is important for the reader to follow through, hence making your instructions clearer. Points like 1.1., 1.2., 1.3. might be a bit confusing. 

You mentioned testing in several parts of your assignment, but it seems you focus more on what the tests should cover and not how the tests should be structured or the kind of methodology to use for testing. Diving a bit more into the ""how"" would enhance your assignment greatly. 

Your images also seem to be missing from your assignment. It would be helpful if you could include those in your resubmission or explain where they were supposed to be. 

In conclusion, your assignment has potential, but it would greatly benefit from restructuring and rephrasing. Good job on the detailed descriptions and keep on the hard work!

Best Regards,
[Your Name]"
151,E1865,"This project aims to enhance the review mapping of the two conflicting reviews which causes an email to be sent to the instructor when there is a considerable disparity in the grading between two reviews. The goal is to help the instructors by making the process of grading reviews easier and more accurate. Currently, when a new review is submitted and the difference between the score of the new review and (average of the) scores of all previous reviews differ by more than a set threshold, an email is triggered to notify the instructor for such disparity. The email consists of an URL only for the new review. <image> <image>. <image>. Current scenario: The function 'significant_difference?' in the model response.rb takes on the average scores of all the existing reviews (by looping through each review to calculate the average) and compares it with the score of the recent response. If the difference is greater than the limit specified(notification_limit), it triggers an email to the instructor with the new response’s (conflicting response) URL. Implemented changes: Instead of taking on the average scores for existing reviews, we will loop through each review not for calculating the average but to compare the new review score with each review score (a new function will be called to compare with existing responses once a new review is in system). If for any response the notification_limit is exceeded, the review URL of that iteration will be stored and at the end of the function once all the reviews are looped an email will be triggered comprising of the URL of a new page ""conflict_view.html.erb"" which displays the new review and all the previous conflicting reviews.. Files created/changed: 1. response_controller.rb Added a function ""conflict_view"" which returns all the IDs of the conflicting reviews. <image> 2. response.rb Added a function ""scores_and_count_for_prev_reviews"" which checks the difference between the score of the new review and the score of each of the previous reviews and returns the response IDs of all the reviews whose difference is greater than a set threshold to an function named ""significant difference?"" which in turn triggers an email to notify the instructor. <image> 3. conflict_view.html.erb Created a new view to display the new review and all the previous conflicting reviews to the instructor. (File on the github repo: <link> ) 4. routes.rb Added a route for a newly created ""conflict_view"" page. <image> Snapshot for notification email triggered before implementing our changes. <image> Snapshot for notification email triggered after implementing our changes. <image> Snapshot for the view which the instructor receives (before implementing our changes) <image> Snapshot for the view which the instructor receives (after implementing our changes) <image> Please watch the video provided to have a look on our implementation. Link: <link>. 1. Rspec file ""conflicting_response_spec.rb"" is created to check if there is the function significant difference is working and an email is triggered or not. <image>. Expertiza 1. <link> Expertiza Github 1. <link> Github repo 1. <link> Expertiza Documentation 1. <link>.","The wiki page does a good job of describing the changes made.  However, the header, ""Review for Mail check"" is cryptic.  I don't know what it means, or how to get to it.  The text in some diagrams and code snippets is huge, which requires zooming way out to read it.  Also, the code snippets are not really described.  They do contain comments, but only one or two prose sentences describe what they do.","Dear Student,

Thank you for submitting your project. It demonstrates your thorough understanding of the issue at hand and your programming skills. 

It is commendable that you have taken a unique and proactive approach to addressing the issue of disparate reviews and the resulting notifications. You showed an impressive understanding of the existing problem and explained the details with clarity.

Your proposed changes are praiseworthy because they provide a comprehensive view of conflicting reviews, as opposed to just being notified of the most recent one. This will undoubtedly aid instructors in understanding the contrasting views that arose while assessing the same content.

The use of appropriately annotated screen-shots and links adds value to your explanation and enables the reader to verify your statements. 

You've also done an excellent job in breaking down the changes in existing files and creating new ones. However, remember to explain how each alteration contributes to the overall solution to ensure that your reviewers comprehend how all the elements integrate to achieve the desired outcome.

Creating a test file to check the functionality of your solution indicates an aptitude for comprehensive testing and attention to detail. It would be helpful to provide greater details about what the test cases are made of and how they validate your changes.

One point of improvement could be: While it's clear that the URLs of all conflicting reviews are stored, it's not mentioned whether they're stored in a database or as local variables. It would be helpful to mention this as it would clarify how data storage is managed in your upgrades.

Overall, this is an impressive piece of work that indicates a robust understanding of the problem and showcases smart solutions. You have brilliantly identified the pain points in the current system and have addressed them efficiently and effectively. Good job!

Best,
[Your Name]"
152,E1830,"Expertiza Background Expertiza is an open-source educational web application developed on Ruby on Rails platform. Students and Instructors (including TA's) use this application though their credentials. Instructors can add new projects, assignments etc as well edit the previous ones and at a later stage can see the student submission and grade them. They can even put a time limit (deadline) for submitting the assignment. Students can form teams for the projects, submit their work through handles (Wiki page, link to a video etc). Students can even review their teammates and other peers, as well give them any suggestions if required. GitHub hooks to Expertiza to encourage contributors. Expertiza project is supported by National Science Foundation. Description of the current project This project is intended to make Bookmarks more user-friendly, credible and valid. Bookmarks in expertiza are created by reviewers and can be used by authors for their work on any project. On each line of the signup sheet are two icons, one for adding a bookmark to the topic, and another for viewing bookmarks on the topic. If the instructor allows the participants to create bookmarks, then only a participant has access to create and view them. He should be able to create a new Bookmark only if he enters a valid one. Now a new rubric is added for reviewing the bookmarks added to a topic and this is accessible only to members belonging to the topic. Therefore ratings can be now done via a drop-down or rubric. Problem 1 When a user after logging into expertiza goes to 'Create New Bookmark page"" or ""View existing bookmarks page"", he's not able to go back to Sign-up sheet using ""back"" button. <image> Solution : <image> Problem 2 Bookmarks had only one option while reviewing and it was to use a drop down to give a score. Also the average rating metric had a bug and hence showed wrong values even when bookmark was not reviewed. The bug was fixed and the rubric feature was adding a new controller. Now choosing ""Scale"" Option instead of ""Dropdown"" allows one to use a rubric instead. <image> The rubric for rating the bookmark shows up as a link that looks as follows : <image> The rubric looks like : <image>. Scope of our changes The changes made in this project affect the Bookmark Controller so tests are written for its validity. Also we noticed that the Bookmark Model didn't have any testing done so we are planning to test that. While manually testing for correctness we came the issue of average rating present even when no rating of the bookmark was added, additionally the computation of average had a bug and was hence giving wrong average value. The picture below shows the the bug the previous code had : It shows an average rating value of 4.0 even when no review was done. <image>. 1. Fixing Average problem and adding Rubric feature : The following files were modified for fixing the average rating bug and adding rubric for the same. app/models/bookmark_rating_response_map.rb app/controllers/bookmark_rating_questionnaire_controller.rb app/controllers/bookmarks_controller.rb app/controllers/response_controller.rb app/views/assignments/edit/_rubrics.html.erb app/views/bookmarks/bookmark_rating.html.erb app/views/bookmarks/list.html.erb app/views/response/view.html.erb config/routes.rb 2. Tests for Model and Controller : spec/controllers/bookmarks_controller_spec.rb spec/models/bookmark_spec.rb spec/factories/factories.rb. Automated RSpec tests were added to ensure the bookmarks are valid. Separate tests were written for the Bookmark Model and BookmarkRating Controller files. The videos of the tests are uploaded onto YouTube and the links are provided in the references section. Below shown is the coverage details <image> <image> a) Back button for the page ""View Bookmark"" and ""Create Bookmark"" was resolved. 1. Login with the credentials to expertiza. 2. Go to 'My assignments' and select OSS Project/writeup. 3. Select 'Signup sheet'. 4. Many titles for projects are shown. Select a title and choose either 'View Bookmark' or 'Add Bookmark' button 5. If you choose 'View Bookmark', after viewing, press the back button to go back to Signup sheet. 6. You will land up in Sign-up sheet page. 7. If you choose 'Add Bookmark', you can add by giving Bookmark details and save it. 8. Now press back button. 9. You will land in Sign-up sheet page. b) Adding Bookmark Rubric. 1. Login into the expertiza with the Instructor/TA credentials. 2. Go to 'Manage Content -> Questionnaires' 3. Select new public/private item under BookmarkRating 4. Fill in with required values and create it. 5. After this if you go to bookmark rubric option it should be visible c) Allowing Bookmark Rubric. 1. Login into the expertiza with the Instructor/TA credentials. 2. Go to 'Manage Content -> Assignments' 3. Select the appropriate project 4. Now edit the project. 5. Check the box ""Allow participants to create bookmarks?"" under Topics tab if not done already. 6. Choose the appropriate rubric from the list or create one following steps from above. 7. Now under Rubrics tab choose the ""Scale"" option for Scored-question display style. 1. A reviewer can be recognized or credited if he added useful bookmarks i.e if the author has made use of the bookmark. 2. A function to add badges automatically if a participant had submitted more than threshold number of useful bookmarks. 3. The UI is basic and it can be further improved. 1. Expertiza on Github : <link> 2. Videos on YouTube : <link> , <link> 3. Pull Request : <link>.","This is a pretty good narrative of what the authors have done.  It gives screenshots for all bug fixes and describes the tests written.  The only weakness is that it does not say anything about what code has been changed to address the bookmark issues.  It wouldn't have to include code snippets, but it should at least describe the changes.","Your submission displays a thorough understanding of Expertiza and its application in a real-world setting. You displayed an admirable command over the technical aspects.

Strengths: Your identification of specific problems and the detailed descriptions of your proposed solutions including the steps taken were well laid out. The scope of your solutions, such as fixing the average rating bug, adding Rubric feature, and testing both the model and controller was comprehensive. As an instructor, I appreciate that you took the effort to provide a step-by-step solution and line by line file modifications.

Areas for improvement: Make sure to attribute all the sources you used correctly. While you provided links to Expertiza on Github and your videos, you did not provide any in-text citations. This is important when using information from a specific source, not just providing the link in the references section.

Suggestions for the future: Consider including a timeline for the proposed solutions. This may give further insight into your development process. Also, when presenting tests or bugs, adding directly the results of the test runs or the error messages might serve to bolster your case.

I really appreciate your diligence and the thorough job you have done in identifying errors in the program and providing solutions. Your comprehensive commentary demonstrates your ability to not only identify problems but to understand and describe how your proposed solutions would work in practice. Keep up the great work!"
153,E1947,"This page provides a description of the Expertiza based OSS project. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.5. <link> 1.1.6. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.2. <link> 1.3. <link> 1.1.1. <link>. <link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. The following tasks were accomplished in this project: 1. Rename filename such that it follows the coding standards 2. Remove redundant information from method names 3. Add comments to methods and complex lines of code 4. Remove unsafe reflection method 5. Simplify RSpec 6. Try to fix issues from Code Climate. This is a new controller, having recently been separated from questionnaires_controller.rb . It is used to allow students to take quizzes. The idea is that the author(s) of submitted work can write a quiz that is given to each reviewer before the reviewer is allowed to review the work. If the reviewer does badly on the quiz, then we know not to trust the review. It is also possible to set up an Expertiza assignment so that some participants just take the quiz and don’t review the work. 1. A student can create a quiz questionnaire for the assignments that allow a quiz to be generated. This quiz will be taken by the reviewers, once they are done reviewing the development/project. Based on their answers the TA's can know whether to consider the reviewer's review or not based , because if the reviewer didn't perform well on the quiz, then it is likely that the review is not done properly. 1. The maximum number of questions is decided by the instructor when creating the assignment. 1. The student has option to either create True/False, Multiple-Choice Checkbox or Multiple-Choice Radio question. 1. The question cannot be blank and correct answer must be selected to create a quiz. 1. Problem 1 : Rename filename such that it follows the coding standards 1.1. Solution : Currently the file was named as quiz_questionnaire_controller.rb . This doesn't follow the Ruby naming standards. Hence it was changed to quiz_questionnaires_controller.rb 2. Problem 2 : Remove redundant information from method names 1.1. Solution : Since this controller was separated from the questionnaires_controller.rb , the method names were kept the same from the previous controller which had redundant information. Method names were renamed by removing the succeeding '_quiz'. Also valid_quiz was renamed to validate_quiz to make more sense. Also the routes.rb was changed to accept these changes. 3. Problem 3 : Add comments to methods and complex lines of code 1.1. Solution : Many methods had more than 325 lines of code and performed multiple functionalities. These methods were changed by creating private methods that performed individual tasks, thus reducing the lines of code and the complexity. 4. Problem 4 : Remove unsafe reflection method 1.1. Solution : This part was already implemented, hence no changes were made. Method questionnaire_params was already defined and takes care of this issue. 5. Problem 5 : Fix issues from Code Climate 1.1. Solution : Refer to Solution for Problem 3. 1. The method save_choices had a congnitive complexity of 23 and had 37 lines of code. By refactoring, the number of lines was reduced to 20 and private methods create_checkbox , create_truefalse and create_radio were implemented to break up functionality and to reduce cognitive complexity. Before: <code> After: <code> 1. The method action_allowed? has been implemented in quiz_questionnaire_controller.rb to specifically allow Student to edit an existing quiz. 1. The quiz_questionnaire_controller_spec.rb has been updated to allow edit tests to work for Student role. <code> Before: <code> After: <code> Before: <code> After: <code> 1. The method update_quiz has been renamed to update and has been refactored to reduce the line count by breaking functionalities. (The function multiple_choice_checkbox was renamed to update_checkbox and multiple_choice_radio was renamed to update_radio so as to reduce function name length and bring consistency with methods performing create operations: create_radio , create_checkbox , create_truefalse ) The Cognitive Complexity of update method has now been reduced to 15 (from 29). Before: <code> After: <code> <code> 1. The method valid_quiz has been renamed to validate_quiz . The function validate_question was extracted out to only validate the particular question. The part where quiz name was being verified was also taken out of the loop to only verify this once as opposed to verifying in each iteration, which was unnecessary. The Cognitive Complexity of 12 has now been reduced to less than 5. Before: <code> After: <code> <code>. Link to <link> showing the RSpec testing. <image>. <image> <image>.","The structure of the document is good; it is easy to see what has been changed.
It is clearer to paste in code snippets from Github than to use the wiki textbox for it, because the font is more readable and long lines are wrapped.
In the first code improvement, it appears that you moved some code out of save_choices.  Where did it go?  BTW, comments are needed on/about the method.
In general, more comments are needed to explain what each method is doing.
The test plan does not say anything about automated tests.","Dear Student,

Thank you for your submission. Your report on the Expertiza based OSS project is comprehensive. Your understanding of the project and the problems that needed to be solved is evident through your detailed explanations.

The way you presented the problems and your proposed solutions is commendable. The breakdown of each issue and your explanation of how you addressed it shows your attention to both details and effective communication of proposed changes and improvements.

I appreciated your use of code snippets as reference to your changes. This along with your narrative made it easier to track your workflow and understanding the changes you made. The 'Before' and 'After' effects on your code snippets was particularly useful. Where you can, make sure to include code snippets to illustrate your points.

You've demonstrated a good understanding of working with a project's codebase, which includes renaming files to follow coding standards, removing redundant information, adding comments for greater clarity, and working with the Code Climate tool to resolve issues. These are all very important aspects of software engineering.

There are a few areas you might consider for future reports. For instance, it would be helpful to use complete sentences and avoid abbreviations such as 'TA' without previous explanation. Not all readers may find it clear.

Regarding the presentation, your use of numbering for sub-topics seems to be inconsistent, you might want to revisit it. There were also some image placeholders that didn't appear to have images associated with them.

Including examples of your RSpec testing and the results would also strengthen your report. It'll give the reader a clearer idea of the range of testing you have done, and the success of your solutions.

In general, you demonstrated a clear understanding of the project and its needs, and your problem-solving skills were evident. Improvement in structuring and polishing your reporting will only help to elevate your work.

Good job, and keep up the good work!

Best Regards,
[Your Name]"
154,E1912,"Expertiza is an Open Source Web Application Software managed by National Science Foundation. Expertiza is used by many courses including CSC 517 for assignment management. It has functionalities such as peer reviews, teammate reviews and tagging reviews in which students can provide feedback on other's work which helps peer in better developing the project. The Expertiza team currently had to manually fire queries in the database in order to get the tag submissions made by an individual user(student) on each review for a particular assignment. In this way, the team got the data from the entire class, which was then used to feed the Machine Learning algorithms. But many times it used to happen that students made random tags and the ML algorithm was not able to make good predictions out of it, hence in order to solve this issue a new idea was proposed as to select on the students which did not create outliers in the predictions and hence, therefore, it is a good proposal. In order to perform this task following files were identified where the code hasbeen added. 1. In _answer_tagging_report.html.erb view, a button is added for exporting the student's tagged values 2. A checkbox for each row has been added in order to select students whose tags are to be exported(By default all will be selected). 3. A method is written in export_file_controller.rb controller named export_tags that exports the CSV file. The workflow diagram of our implementation is shown here: <image> We have added a default select all checkbox under Report tags done by each user which enables student selection for exporting tags in the CSV file. We have added a column for the checkbox and a button named Export which on click generates the CSV file. <image> Below is the snippet of the same view _answer_tagging_report.html.erb <code>. 1. <link> is the link to a screen recording on how to access the functionality and export the CSV file. We have written a method inside the export_file_controller.rb . Once this method is called it queries on the name array passed from the view and exports the CSV file with the required data. The attributes named variable stores what all data is needed from their respective table and only that data is dumped into CSV. <code> The output file has user_id, tag_prompt_deployment_id, comments and value . We can see that some comments are repeated it is because every review that is received has at least 1 tag for it. Hence we see the repetition. The value column has -1, 0 and 1 as No, not answered and Yes meaning respectively. <image>. The code was written for adding functionality such that selected students data can be dumped into a CSV file. A valid test case for this would be if nothing is selected and still the export button was clicked it would not dump any data into CSV file. The data is well structured so there would not be any scenario that a NULL data will be dumped. Every column will have its value in every row. The functionality for our project was to implement exporting of tagged comments from the Expertiza system. For this, we will approach the project by using the delegation pattern to add exporting capabilities to the export file controller for exporting tags. 1. <link> 2. <link> 3. <link>.","I thought you could have described in more detail what the code does, e.g., what tables and fields are involved, and how you iterate through them.  Giving the final code doesn't provide a very easy way for the reader to understand your approach.","This is indeed a thorough and well-detailed assignment. You cover the understanding and motivation of your project adequately. The role of Expertiza, its capabilities and the use of the Machine Learning (ML) algorithm were well articulated. 

Your exploration of the challenges faced by the Expertiza team gives a clear motivation for your project. You also presented the changes made in the Expertiza software to address these challenges thoroughly. The explanation of the functions and the results of your code, including the generated CSV outputs, was commendably lucid.

However, you could have provided more explicit explanation regarding the logic or techniques used in your ML algorithm. Detailing this might provide more clarity on how it works and why it might not perform well with certain tagged data.

Also, while you provided some information on testing, it would be better if you included more specific examples of test cases. Providing more detailed scenarios can help visualize the behavior in edge cases and how the system would respond to them. 

The links and images unfortunately do not show up and, as such, important information may have been left out from your document. Lastly, explain the delegation pattern you have mentioned at the end of your submission in a little more detail.

Overall, you have done a good job explaining the new functionality built and the rationale behind it. Keep it up!"
155,E1837,"At the heart of Expertiza is the ability to review the work of other teams and review your own teammates.The Review Mapping Controller is at the heart of coordinating all of the necessary steps to assign reviews in various ways to specific students or teams. As such, this controller has become rather large and unmaintainable over time as new types of reviews and review assignment strategies are created. The purpose of this work is to improve the maintainability of this controller based on the goals listed below. - separation of concerns - remove unused methods - properly group like methods - remove SQL statements from the controller into models/helpers where applicable. As part of refactoring, we have introduced several new Helper classes and methods. This helper now contains isolated methods for each report type that needs to be built from the controller. This helper is implemented as a module, so any/all instance variables are added to the class including it. This allows us to keep the controller logic very small but still populate all needed values for the report views. Each report type is represented by a separate method in the Helper and the Helper exposes a single public method to render the report. This allows us to hide implementation details to be changed later as needed from within the module and the controller can generally stay the same. The only caveat is that all of the correct instance variables will need to be defined and populated per report. We considered refactoring the reports section, but after discussion with our mentor, we decided it would be a large enough effort in of itself to change how reports are generated and rendered. The previous implementation for the Automatic Review mapping method ( automatic_review_mapping ) was lengthy and overrode specific arguments within the Automatic Review Mapping Strategy method ( automatic_review_mapping_strategy ) before actually assigning reviews. We decided to implement an actual Strategy pattern here. We created a simple ReviewStrategy class with the following subclasses: - StudentReviewStrategy - TeamReviewStrategy Each of these strategies determines the number of reviews per team, the number of reviews per student, and the total number of reviews needed. After implementing this pattern, we were able to simply use the methods provided on the ReviewStrategy class in the algorithm that assigns reviews with minimal refactoring. Below is a simple UML diagram of these new classes: <image>. We were able to remove the following methods that were either obsolete or had functionality that could be refactored into other methods. - execute_peer_review_strategy : This functionality simply performed a check that is now in automatic_review_mapping. Several methods had raw SQL, or at the very least SQL-like statements. Where possible, these calls were pushed down into their respective models. This method had the following SQL SELECT t.id as t_id FROM teams_users u, teams t WHERE u.team_id = t.id and t.parent_id = ? and user_id = ? It was migrated to be a scope inside of the Team model ( find_team_for_assignment_and_user ). The majority of our changes were refactors, and thusly required a few new tests, but we did need to adjust existing tests to expect proper mocked/seamed methods. <table>. The report generation should be refactored to allow each report to specify how it should be rendered. One idea was setting each report to supply a collection of ""report lines"" that are rendered one at a time in a table. This would allow for each report to specify its data and its rendering functions separatly.","This is exactly what I want in a design document, though I would like to see more of it.  You mentioned which methods you removed, but did not give any examples of changes that you made, beyond listing the methods that were deleted.","You have done a commendable job analyzing and implementing a refactoring strategy for the Review Mapping Controller in Expertiza. Your focus on separation of concerns, removing unused methods, properly grouping like methods, and removing SQL statements from the controller into models/helpers is well-reflected in your work. 

I particularly commend your decision to shift towards a strategy pattern by developing the StudentReviewStrategy and TeamReviewStrategy subclasses under ReviewStrategy for assigning reviews. It not only enhances the clarity of your workflow but also promotes the extendibility of the system in the future.

The migration of SQL statements to respective models, as you demonstrated, is a sound practice that both improves code readability and maintainability. Moving forward, please continue to make every effort to ensure that the database manipulation logic remains in the corresponding models.

The UML diagram you provided was beneficial in understanding the new classes you introduced but you need to be sure to embed the image correctly as it does not display currently in the report. 

Your suggestion for future improvement, particularly the refactoring of report generation to allow each report to specify how it should be rendered, is insightful. Thinking in terms of improving not only the current state but also the future potential of the system is a hallmark of good software development.

However, your assignment would benefit from a bit more detail about the new tests you implemented and how you adjusted existing tests to accommodate your refactors. It would also be helpful to provide more detail about how your changes impacted the overall functionality and performance of the system.

In overall terms, you have a solid understanding of refactoring and design principles, and you've done an excellent job applying these concepts to improve Expertiza's Review Mapping Controller. Keep up the fantastic work!"
156,E1940,"1. E1940 Improving e-mail notification. 1. The forked git repository for this project can be found <link>. The following tasks were accomplished in this project: 1. Issue1: Send new account welcome email to user, when imported from CSV through assignment page. 2. Issue2: Don't send email to reviewers for a new submission after review deadline has passed. 3. Issue3: Adding relevant links to reminder emails. app/models/assignment_participant.rb 1. Call method to send mail after user imported successfully. <code>. 1. Before fixing this issue, we had to write the logic to send emails to reviewers on submissions. app/controllers/submitted_content_controller.rb 1. Added the logic to check for last review date to the function submit_hyperlink <code> 1. Function to identify the reviewers and send mails. <code> app/helpers/mailer_helper.rb 1. Helper function to mail reviewers <code> app/mailers/mailer.rb 1. Mailer function to send the mail. <code> app/views/mailer/notify_reviewer_for_new_submission.erb 1. Email template for the mail <code>. 1. Modified function email_remainder to add functionality. app/mailers/mail_worker.rb <code>. Step 1: Navigate to Manage --> Assignment page. Step 2: Click on add participants for any of the assignments. Step 3: Click ""Import course participants"" Step 4: Choose a csv file to be imported (follow the format given on the website). Step 5: The users mentioned in the csv file and don't exist on Expertiza should get a new user email. Step 6: To check e-mail is received or not, log in with following credentials: username [ 'expertiza.development@gmail.com' ] password [ 'qwer@1234' ]. Step 1: Create new assignment [Manage --> Assignment --> + Button (to create new assignment)] Step 2: Fill the details for the assignments. Step 3: Navigate to due dates. Step 4: Change the number of review rounds to 2. Step 5: Select ""Yes"" in the dropdown for review allowed during submission and select ""Yes"" for submission during the review. Step 6: Add two users to the assignment(author and reviewer). Step 7: Log in with some user credentials (author credential). Step 8: Make a new submission to this assignment. Step 9: Log in with another user (reviewer). Step 10: Submit a review of the assignment submission. Step 11: Login as an author again. Step 12: Edit the submission. Step 13: After this check the mailbox of the reviewer [development mail for development]. Step 14: Reviewer should get the mail to re-review the work. Step 15: Change the due date to some date and time which has passed. Step 16: Now making a new submission from the author account should not send a re-review mail to the reviewer. [Repeat steps 7-15]. This test requires an approaching deadline scenario. Since the reminder mail goes through as a sidekiq background, the part of this issue was to fix the email link. Create a new scenario with an approaching deadline. The email is sent already, we have added the link which was missing, directing users to visit the required page.","This document is mostly just a copy of the code that was written and a list tof steps for manual testing.  As several reviewers pointed out, it doesn't explain why the code was written the way it was.  The steps for manual testing do not explain why things are done in that way, or how they verify that the three issues have been resolved. ","Dear Student,

Thank you for the detailed submission, including the preparation work carried out, the issues resolved, and the corresponding functions implemented. I appreciate the in-depth explanations which make it easier to understand your accomplishment. 

However, your report could benefit from better structuring. It's a bit hard to follow which parts of your discussion are related to each specific issue. To make it clearer, consider dividing your text by issue numbers (i.e., Issue1, Issue2, Issue3) and discuss the corresponding parts together (approach, function, results of each issue should be grouped together). 

Regarding the codes, it would be beneficial to explain more about your considerations when writing them. What challenges did you encounter? How did you overcome them? And why did you think this code was the best solution? Also, you have referenced code multiple times with ""<code>"", but there are no included code snippets. Please remember to include the necessary code snippets during your next reporting which is not present for now. 

For testing steps provided, it offers a clear process to replicate the work and test functionalities - great job on that. However, to further enhance its usability, you may include some snapshots or illustrations for clarity and easier understanding especially for complex steps or crucial steps where text description might be insufficient.

You did well in this assignment. Remember, clarity, structure, and adequately detailed information are crucial in software development.

Keep up the good work!

Regards,
[Your Name]"
157,E1915,"This page provides a description of an Expertiza OSS project. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link> 1.1.8. <link> 1.1.9. <link>. <link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. The following tasks were accomplished in this project: 1. Centralize user authentication logic to support the DRY principle 2. Improve user authentication logic in cases where it was clearly flawed 3. Support this work with RSpec unit tests. 1. Most controllers contain an action_allowed? method which determines which users are allowed to perform which actions 2. This logic is in most cases correct, but is often repeated between controllers (un-DRY) 3. This logic is in some cases slightly incorrect 4. The Roles model provides a helpful method hasAllPrivilegesOf, which could be used to simplify authorization logic. The problems listed below are examples of the four main classes of problems we encountered with Expertiza authorization. This is not an exhaustive list of problems, but is a good representation of the classes of problems addressed. 1. Problem 1 : Much of the authorization logic is repeated (un-DRY). For example, multiple controllers contain the following exact code. <code> 1. Solution 1 : Use one of the helper methods from the new authorization_helper.rb ( <link> ) to allow TAs *and above* (instructors, admins, super-admins) to perform this work. <code> 1. Problem 2 : Some logic is slightly incorrect. For example, some places call for a specific user type, when users ""above"" this type should also be allowed to perform the work. In the following example (advertise_for_partner_controller.rb), only Students may advertise for partners. However per Dr. Gehringer, ""There are no cases I am aware of where a particular type of user can do something that more-privileged users cannot do"". <code> 1. Solution 2 : Use one of the helper methods from the new authorization_helper.rb ( <link> ) to allow Students *and above* (TAs, instructors, admins, super-admins) to perform this work. <code> 1. However, in case there IS a need to know if the current user has one specific role, this is still supported by the helper method current_user_is_a? 1. Problem 3 : Too much authorization logic is present in the controllers. This makes the controllers more difficult to read, and scatters authorization logic, when it would be easier to understand if it were all in one place. <code> 1. Solution 3 : Establish helper methods in the new authorization_helper.rb ( <link> ) to centralize as much authorization logic as possible. In this way, a developer with questions about authorization knows just where to look to find answers - authorization_helper.rb ( <link> ). <code> 1. Problem 4 : Some action_allowed? methods are difficult to follow, and/or knowledge about how the action parameter should affect authorization is buried in another method. <code> 1. Solution 4 : Clean up action_allowed? methods and make the influence of the action parameter visible at this level. <code>. 1. We make use of the existing role.rb model ( <link> ) method hasAllPrivileges of. This logic defines a hierarchy of users, allowing us to easily determine if the current user has a particular role ""or above"". We use this existing method to support the DRY principle, and to keep this logic in the model, where it belongs. We made one correction to this method, to change the logic from "">"" to "">="", to ensure that for example a TA has all the privileges of a TA. <code> 1. We establish several methods in authorization_helper.rb ( <link> ) to expose easy-to-read method names for use in controllers. <code> 1. We establish a method in authorization_helper.rb ( <link> ) to expose an easy-to-read method for determining if the current user ""is a"" [particular user role]. This is used in a minority of cases, because most logic cares if the current user ""is a"" [particular role] ""or above"". <code> 1. We establish several methods in authorization_helper.rb ( <link> ) to centralize more complex authorization logic so that it is not scattered among controllers, but rather is kept in the same helper file as other authorization logic. Only a few of these methods are shown below. <code>. 1. Add ""include AuthorizationHelper"" at the top of the controller definition. 1. Look through authorization_helper.rb ( <link> ) for the method(s) you need. 1.1. If you find the method definition comments lacking, please add to them. 1. If you do not find a method you need: 1.1. Add a new method to authorization_helper.rb ( <link> ). 1.2. Comment the new method so that future developers can understand your work. 1.3. Add new tests covering your new method, to authorization_helper_spec.rb ( <link> ). 1.4. Ensure that authorization_helper_spec.rb ( <link> ) still passes with zero failures. 1. What the authorization helper needs in order to work correctly: 1.1. The authorization helper needs users to have IDs. 1.2. The authorization helper needs users to be associated with roles. 1.3. The authorization helper needs roles to exist. 1.1.1. this is handled in spec_helper.rb ( <link> ) 1.4. The authorization helper needs session[:user] to be populated with the current user. 1.1.1. this is handled in rails_helper.rb ( <link> ) in the stub_current_user method 1. Writing RSpec tests for new controllers (provide these needs): 1.1. Use the factories defined in factories.rb ( <link> ) to create objects to manipulate in your tests. 1.1.1. factories were carefully designed (prior to the creation of the authorization helper) and we should take advantage of them 1.1.2. ensures that objects are more fully formed than would be the case with a simple double 1.1.3. specifically, ensures that created users have roles 1.2. Use the create(:some_factory) style. 1.1.1. ensures that the created object has an ID 1.3. Use the stub_current_user method. 1.1.1. ensures that session[:user] is populated 1.4. Explicitly set session[:user] to nil if you need to simulate the total lack of any logged-in user for a test. Our strategy for gaining confidence that our code changes did not break anything was as follows: 1. Run all existing controller RSpec tests after our changes, several times, to ensure that we have not introduced any failures. <code> 1. Write new comprehensive RSpec tests, in authorization_helper_spec.rb ( <link> ), for every public method in our new helper, authorization_helper.rb ( <link> ). Run these tests, several times, to ensure that the new code works as intended. Please note that the output that you see may differ slightly, as more tests may be added. <code> 1. The test suite for a single helper method is below. There are many such suites in authorization_helper_spec.rb ( <link> ). This example illustrates our general strategy: test missing input, test bad input, test various acceptable forms of input, test scenarios that lead to ""true"" and to ""false"" return values. <code>. 1. <link> 2. <link> 3. <link> 4. <link>. 1. <link> 2. <link> 3. <link> 4. <link>.","On the micro level, every change made was well described.  On the macro level, I would've liked to see an overview of the new methods you created and what they would be used for.  E.g., one use case is to make sure that someone with at least a certain level of privilege is executing method m.  Another use case is to make sure that only users involved with a review, meta-review, teammate review, etc. can see it.","Dear student, 

Thank you very much for this thorough and detailed assignment. Your explanations are clear and concise. You have a deep understanding of the Expertiza OSS project and the description of the tasks completed were on point. 

I especially appreciate the step-by-step description of the problem and subsequent solutions for each scenario - your attention to detail is highly commendable. You also provided clear guidelines on how to use various methods which is very helpful from a development perspective. 

However, I've noticed that you have several placeholders (""<link>"") scattered throughout the text. These placeholders are meant to be filled with appropriate URLs or connections to other parts of your description. Don't forget to replace them with the actual information so the assignment provides complete information.

Moreover, while your assignment is thorough, it would be beneficial to work on the organization of your content. Some parts of your work seemed to flow into each other which makes it a bit difficult to distinguish between different sections. Dividing your work into larger sections like ""Introduction"", ""Methods"", ""Problems and Solutions"", and ""Conclusion"" could enhance the readability of your work.

Overall, your understanding of the concept is evident and your solution-driven mentality is commendable. Keep putting the same effort into your future assignments. 

Best,
[Instructor's Name]"
158,E1664,"Expertiza is an open source web-based platform for the organizing and management of student project submissions and their evaluation, that supports augmentation of subject knowledge and accelerated learning via peer reviews. The application is meant for two types of users, instructors and students to use the application. Instructor can create and manage a course, enroll students in the course, create, manage and personalize assignments, project submissions and reviews for the particular course. Students can make their project submissions for the assignments allocated to them by their instructors for a course, give peer reviews, teammate reviews, create quizzes for their project reviewers, provide feedbacks and view their grades. Assignment Creation can be done in Expertiza by an instructor for a particular course. Two types of assignments can be created, Private and Public. Further, there are various ways an assignment's attributes can be modified by personalizing reviews, deadlines, teams allocation, rubrics, calibration etc associated with the particular assignment. Each one of these in turn have many other options through which an instructor can be selected and modified. There are many functionalities within assignment creation, thus the main motive for testing of this feature is to ensure that an instructor can create an assignment without any hick-ups with all of its properties intact. And this is. 1. assignment_creation_spec.rb (Capybara spec file) 2. factories.rb (FactoryGirl's factory file. Test cases have been written using RSpec and Capybara. These two combined prove to be an excellent testing tool at the developer's disposal. RSpec is a very powerful testing tool primarily used Behavior Driven Development (BDD). In RSpec, test cases are written such that they describe the specific functionality in the system being tested and helps user in better visualization of what the test cases are supposed to do. Capybara is another extremely helpful testing tool specifically used for feature testing. It is a web-based automation framework, and coupled with RSpec allows developer to write the test cases which simulate the whole scenario. It comes with a user friendly DSL as the actions specified are very intuitive and easy to understand and follow. Due to continual development of Expertiza, some of the existing test cases that were implemented with relatively older version of Expertiza were found broken at the starting of the project. To make the assignment creation testing complete, and to avoid covering the same scenarios again by adding new working test cases unnecessarily, these test case were fixed. Some of the fixes that were provided as part of this project are as follows: 1. Some of the functionalities for which the test cases were written have been remodeled so they had to be skipped. 2. Running the test cases were giving an error in the code, when fetching a row from the deadline type table. 1. We noticed that the structure of the test file was wrong. The code to populate the the ""deadline types"" did not run, but were supposed to run for each test case. We made this code run for all test cases. 3. Rubrics test cases were searching for links that weren't present on the page. These issues were also fixed. 1. Test Assignment Creation a. Test Creating public Assignment: This test will check if public assignments are getting created properly or not with proper attributes. <code> b. Test Creating private Assignment: This test will check if private assignments are getting created or not with proper attributes. <code> c. Create Assignment for Team: This test will check the creation of new private assignment for the team. The maximum size of the team is 3 and the test will check if all these features are there or not. <code> d. Create Assignment with Quiz: This test will check the creation of new private assignment with the quiz. The maximum number of questions in the quiz is 3 and the test will check if all these features are present or not. <code> e. Create Assignment with review visible to all reviewers: This test will check the creation of new private assignment with review visible to all the reviewers. <code> f. Create public micro-task assignment: This test will check creation of new public assignment with microtasks. <code> g. Create calibrated public assignment: This test will check creation of new calibrated public assignment. <code> 2. Test General Tab of Assignment Creation a. Edit assignment available to students: This test will edit the existing assignment and enable micro tasks and calibrated options. The test will verify if all these options are updated in the assignment. <code> b. Edit number of quizzes available to students: This test will check the feature of editing the number of quizzes in the existing assignment. <code> c. Edit number of members per team in an Assignment: This test will check the feature of editing the maximum number of members in a team for an assignment. <code> e. Edit review visible to all other reviewers: This test will verify the feature of adding/removing review visible to all the reviewers for an assignment. <code> f. Should create teammate review row in rubrics: This test will verify that adding teams and team members in an assignment will create one more row of teammate review in rubrics. <code> g. Check if checking calibration shows the tab: <code> 3. Test Topic Tab of Assignment Creation a. Edit topics properties - Check all options <code> b. Edit topics properties- uncheck all options <code> c. Add new topic : This test will check feature of adding new topic for an assignment. <code> d. Delete existing topic: This test will check feature of deleting new topic for an assignment. <code> 4. Test Rubrics Tab of Assignment Creation a. Update review questionnaire rubric: <code> b. Update scored question dropdown <code> c. Updates author feedback questionnaire <code> 5. Test Review Strategy of Assignment Creation a. Test all auto selects feature <code> 6. Test Due dates tab of assignment Creation a. Loads the due dates page <code> b. Set the deadline for an assignment review: This function will test if deadlines are getting assigned properly or not for the review. <code> 7. Test Adding participants by Instructor a. Add New Participants to assignment: This test will verify if an instructor is able to assign new participants to an assignment. <code> b. Verify assignments assigned to participants: This test will verify if assignments are properly assigned to participants. Participants should be able to see newly assigned assignment in their page. <code> 8. Check if assignment can be added to a course: It will check an assignment can be added to the course <code>. We have uploaded video showing how the tests are run and their result. If user wants to test the newly added feature test, please clone the master branch of our git repository and perform following steps: 1. git clone <link> 2. cd expertiza 3. rspec spec/features/assignment_creation_spec.rb. Activated github repository in travis. Whenever we push changes in our repository, travis will start building and run all test cases. At the end, it will give the final result consisting of the number of test cases passed and failed and the overall build result. Travis result <link>. 1. Github Expertiza <link> 2. RSpec <link> 3. Capybara <link>.","As mentioned by a couple of reviewers, this writeup does not explain the rationale behind the tests.  It simply gives their title, one sentence of description, and the test code.","Your assignment provided a thorough analysis of Expertiza, an open-source web-based platform for student project management and evaluation. Your explanation on differentiating the applications and its uses for students and instructors was comprehensive. Assignments and its several factors like project submissions, reviews, quizzes, feedback, and grading were adequately highlighted. You laid out various details about assignment creation to signify its importance and associated attributes like deadlines, team allocation, rubrics, and calibration.

Your focus on explaining the significance of testing in the assignment creation feature was well emphasized. The analysis on test cases, broken modules, and their fixed versions is commendable. You have effectively provided extensive information about different tests related to assignment creation. The variety of tests you covered around assignment properties, team creation, quizzes, viewership, microtasks etc., are quite vast and comprehensive. Also, the look into more detailed aspects like the general tab, topic tab, rubrics tab, review strategy, due dates, and participant roles was comprehensive and organized.

Apart from these, the detailed step-by-step guide for running tests was also very helpful. Your inclusion of a video demonstration is an admirable bonus. Your focus on the utilization of GitHub and Travis for reflecting test results is also beneficial.

However, in some parts of your assignment, ""<code>"" was included which seems out of place, make sure to remove those or replace them with corresponding code snippets or functionality.

Overall, the work you put in researching and presenting this topic is clear and sets a good example for your peers. Your work was well-structured, informative, and precise. Keep it up!"
159,E1850.3,"It is an open source software created by North Carolina State University's students. It works on ruby on rails framework. This platform allows instructor to post notification about tests and assignments and also allows students to view grades, submit assignments, find teammates etc. Review_response_map.rb file is a newly added feature in Expertiza. The ReviewResponseMap class in the file is the sub class of ResponseMap class.The file review_response_map.rb deals with mapping of review's review to the feedback that reviewee gives to that review. Since the file is new it is not tested. We have worked on the file review_response_map_spec.rb which use RSpec framework to perform unit testing on the given file. 1.Create a new file named review_response_map_spec.rb under spec/models folder 2.Write RSpec unit tests to make the path coverage above 90%. 3.Coverage as many edge cases as you can. 4.Achieve as high branch coverage as you can. We will use the mutant-rspec gem to measure test thoroughness and fault-finding capability of your tests. We created the following stubs to implement unit testing: <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code> <code>. <code>. <code> <code> <code> <code> <code>. <code> <code>. <code>. <code>. <code>. review_response_map.rb review_response_map_spec.rb spec_helper.rb. We used RSpec framework to test the given file.RSpec is a 'Domain Specific Language' (DSL) testing tool written in Ruby to test Ruby code.It is a behavior-driven development (BDD) framework which is extensively used in the production applications. The basic idea behind this concept is that of Test Driven Development (TDD) where the tests are written first and the development is based on writing just enough code that will fulfill those tests followed by refactoring. It contains its own mocking framework that is fully integrated into the framework based upon JMock.The simplicity in the RSpec syntax makes it one of the popular testing tools for Ruby applications. The RSpec tool can be used by installing the rspec gem which consists of 3 other gems namely rspec-core, rspec-expectation and rspec-mock. <link>.","In the Test Plan, you should explain why you created the various stubs, instead of just listing them.  The rest of the document just lists the tests, with the exception of why you used RSpec, which could apply to any of the testing projects.","Dear Student,

I appreciate your hard work and dedication that reflects on this assignment. The way you detailed how the platform allows instructors and students to interact with each other and how review_response_map.rb helps in mapping the review's review to the feedback showed that you understand the nuances of the Expertiza software very well.

Your understanding of Ruby on Rails framework and RSpec framework is commendable. You've presented the importance of unit testing in Ruby using RSpec and provided clear instructions about the creation of a new file to conduct unit testing, achieving path and branch coverage, and handling edge cases. It's also appreciable how you've thoroughly explained behavior-driven development and how it integrates with the RSpec framework to drive the codes' readability and simplicity.

However, in the mid-section, where you mentioned about the stubs implementation, you mentioned <code> several times, but it's not clear what these codes are. Please remember always to replace placeholders with the actual code or information.

Additionally, there wasn't any practical testing examples you provided in the assignment. It would have been more informative if you would have included how you created the review_response_map_spec.rb file, wrote RSpec unit tests, and implemented stubs. Moreover, adding actual extracted results from your testing, including test coverage metrics and edge case handling, would drive your points home noticeably. 

For your <link>, please ensure to provide the actual online reference so that it provides deeper insights. Proof-reading your work for such missing details before submission could help to avoid such issues.

Overall, well done! With a bit of polishing and adding in the details, your assignment would provide a valuable in-depth, practical insight into unit testing in Ruby using RSpec and your contribution to Expertiza.

I hope that this feedback is helpful. Let me know if you have any questions or need further clarifications.

Best,
[Instructor's Name]"
160,E17A4.2,"Calibration is the term used for rectifying, or checking or determining something. In the context of this project, a 'Calibrated review' is the one which is performed by student and instructor as well, so that student can check on his work by comparing with instructors' response for the same assignment. If the student’s review “resembles” the staff-member’s review, then the student is presumed to be a competent reviewer. Since calibrated reviews are just for checking on our progress, they are not graded. They are just meant for practice, so that peer review (which are performed later) can be performed well which is graded. In order to gain practice for giving a reviews , the Student should be able to give calibration reviews before providing peer reviews. Thus, the Instructor should be able to enable calibration for every new assignment. By this way, the student can improve peer reviewing by comparing his/her results with expert reviews for the same assignment. At present, the instructor is able to calibrate the students’ peer review abilities on Expertiza by creating only a separate assignment for this purpose. In this separate assignment that the instructor creates, the student and the instructor will simultaneously do peer review for the project. After submission of the reviews, the student's and instructor's reviews are compared and a calibration report is generated for the student to view and improve their peer reviewing skills. Unfortunately, for students to practice peer reviewing, a separate assignment has to be created every time. In order to facilitate sufficient practice for peer review, this is not a convenient method. The objective of this project is to enable calibration to be one part of the normal assignment. The instructor should be able to turn on this feature if necessary and provide the corresponding calibration deadline. The student should be pre-assigned with sample assignments. Once the student submits the calibration reviews, the calibration results comparing the student and expert review are provided to the student. When the actual review period starts, the student will review other assignments, and submit peer reviews. So the total number of reviews calculated should not count calibration reviews. Tasks are listed as below: 1. To integrate calibration feature into a normal assignment, a new due date, that is calibration due date needs to be added in deadline_types table. So a migration needs to be written for implementing this. 2. When instructor checks “Calibration for training?” and saves the assignment, in “Due dates” tab, a row should appear to deal with calibration due date. The other content of this row is just the same as other due dates. 3. In student_task/list page, current stage column should display calibration when the assignment is in calibration period. 4. In student_review/list page, in Other's work, calibration reviews need to be excluded from the peer reviews because calibration reviews should not count towards the total number of peer reviews done or towards the peer review grading. For this purpose, they need to be separated. To achieve this goal, filter the reviews with timestamp earlier than submission due date, which means reviews are done in the calibration period. The wording and numbering on this view should be changed to: Calibrated review 1,2,3 to represent review done in calibration period; Review 1, 2, 3 to represent reviews done in the normal review period. The current system has the following actors: a) Instructors: Users who have administrative privileges to create/edit assignments and impersonate students b) Students: Users who submit assignments and peer reviews In the current system, the calibration functionality works correctly. In the assignments' edit page, once the instructor enables “Calibration for training?” and saves the assignment, an extra tab ""Calibration"" appears. After this, the instructor needs to add several sample assignments (right now instructor needs to impersonate several students to submit sample assignments) and do expert review beforehand. This is the existing functionality. In the proposed system, the entire flow of the assignment submission done by the student, changes. First is the calibration review of sample assignment, then normal assignment submission followed by rounds of peer reviews for the submitted assignments. Flow: 1. As an instructor, a new Assignment ""Project 4"" was created. 2. In assignment edit mode, when calibration is not enabled, the ""Due date"" tab appears as shown below: <image> 3. Once the “Calibration for training?” (see the below figure) is enabled, in addition to the “Calibration” tab, a new row for calibration deadline entry appears under the “Due dates” tab (see the figure below) before submission row. The due date for the calibration review is entered and the assignment is saved. <image> <image> 4. 2 students are assigned as participants (student1, student2) and 1 student (student3) as reviewer for the assignment ""Program 4"". Then, the Instructor impersonated one of the participant students, say student1, and submitted a sample assignment that is to be used for calibration review. 5. The review strategy was set to ""Instructor-selected"" for calibration review. Then, the instructor assigned student3 as a reviewer for this sample assignment submitted by the expert and also, submitted an expert review for this sample submission. 6. Now student3 is impersonated. The ""current stage"" of the assignment ""Program 4"" shows as ""calibration"" on the student_task page as shown below: <image> 7. As student3, on getting into ""Program 4"", the ""Other's work"" link is enabled (as shown below). This is enabled even before submission period as we should allow students to enter calibration review beforehand. If calibration is not enabled for the assignment, the others' work link will be enabled only after submission period. <image> 8. In ""Other's work"", one calibration review for the sample assignment is displayed for which the reviewer can submit the calibration review. <image> 9. Once the calibration review is submitted, the ""show calibration results"" link is displayed which shows the scores against the expert review. Show calibration results gets enabled when the expert and the student submits the review. <image> 10. Once the calibration due date elapses, the assignment enters the ""submission"" period. During this period, student submissions are made. The review strategy is set as ""auto-selected"" and number of reviews allowed are set to 2. 11. When impersonated as student3, in other's work, both the calibration and assigned peer reviews are displayed as shown below <image> The reviewer can now request new submission for peer review. Also, the number of reviews required and allowed considers only the peer reviews and not the calibration reviews. Since only one peer review is present, the ""request new submission for review"" button is enabled. Once a new review is requested since there are 2 peer reviews, the ""request new submission for review"" button is not displayed. This shows that only the peer reviews are considered for the total number of reviews allowed and required. After completion of the calibration reviews (before the due date), the student should submit the assignment on/before the submission deadline, which is the existing functionality. Since the students have had enough experience during the calibration period on peer reviewing, the next task will be carried over effectively. Peer reviewing is the concept of review your peer’s work. This concept enables the students to understand the solution to a problem from multiple perspectives. This will also embed new ideas and the skill of constructive criticism in the student. Hence, the student will provide peer reviews after the submission of their work. Use Case Diagram : <image> 1. Add/Edit Assignment: Enable Calibration Use Case Id: 1 Use Case Description: Instructor can select the option - ""Calibration for training?"" Actors: Instructor Pre Conditions: The assignment is present in the assignments list Post Conditions: Instructor can navigate to the edit assignment page where the enable calibration option is present 2. Edit Assignment: Set Due Dates for Calibration and Peer Reviews Use Case Id: 2 Use Case Description: Instructor can set due date for calibration under due dates tab Actors: Instructor Pre Conditions: Once calibration option is enabled, a separate row for calibration should be created Post Conditions: The instructor should be able to see the new date set for calibration. Special cases: Calibration deadline should come before the submission deadline. 3. View the current stage in assignments as ""Calibration"" during the calibration period Use Case Id: 3 Use Case Description: In assignments home page, the assignment should now be in the calibration period. Actors: Student 4. View the pre-assigned sample assignments in ""other's work"" tab which can be opened even before submitting the assignment Use Case Id: 4 Use Case Description: Student should be able to see the list of assignments in others' work tab for reviewing Actors: Student Pre Conditions: Sample assignments are provided by the instructor for the student to review and the tab ""other's work"" is enabled. 5. Submit 'n' pre-assigned Calibration Reviews Use Case Id: 5 Use Case Description: Student can now review those assignments and submit them Actors: Student Pre Conditions: Sample assignments are provided by the instructor for the student to review Post Conditions: Student can now see and edit the newly submitted review and also see the instructor's review for the assignment 6. View the 'Calibration Result' after submitting Use Case Id: 6 Use Case Description: Student can see the comparison between student's and instructor's reviews for the pre-assignment Actors: Student Pre Conditions: Student had already submitted a calibration review Post Conditions: Student can now view the comparison results 7. Submit the assignment before the due date Use Case Id: 7 Use Case Description: Student should submit the assignment before the submission deadline Actors: Student Pre Conditions: An assignment exists and the calibration review is submitted Post Conditions: Student can successfully submit the assignment before the deadline 8. Request for a Peer Review Use Case Id: 8 Use Case Description: After the student submits the assignment, the student can request to do peer review of other student's submission Actors: Student Pre Conditions: peer review period has started and other students' submissions are available for reviewing Post Conditions: Student should be assigned with a project for reviewing. 9. Submit the Peer Review and request for next one after minimum number of peer reviews are completed Use Case Id: 9 Use Case Description: After the student requests for a peer review, he can review the assignment and submit it, After minimum number of reviews are commpleted, he/she can request for more assignments to be reviewed Actors: Student Pre Conditions: Student received an assignment for peer reviewing Post Conditions: View and edit options are available for the submitted review until the peer review period deadline All the actions performed by the student can be done by the instructor by impersonating a student. 1. MVC The project is implemented in Ruby on Rails that uses MVC architecture. It separates an application’s data model, user interface, and control logic into three distinct components (model, view and controller, respectively). 2. Dry Principle The existing functionalities in Expertiza are reused, thus avoiding code duplication. Whenever possible, code modification based on the existing classes, controllers, or tables will be done instead of creating a new one. Example: Currently, calibrated reviews are handled separately and peer reviews are handled separately. In our enhancement, we need to merge both the reviews. So instead of duplicating the code in calibrated reviews, the same code is used to handle both the reviews. No design patterns are used because existing methods are modified and no new methods are created. So the framework remains the same. The following files were modified to implement the feature: migration file: <code> app/controllers/student_review_controller.rb <code> views/student_review/list.html.erb <code> views/assignments/edit/_due_dates.html.erb <code> app/models/deadline_right.rb <code> app/controllers/assignments_controller.rb <code> app/views/student_review/_responses.html.erb <code> <code>. To test this feature in GUI, perform the following steps: 1. Login as instructor in Expertiza. 2. Create a new Assignment. 3. Click edit assignment and in the general tab, select the option - 'Calibration for training?' and click 'save' 4. Once that option is enabled, a new tab opens in the name 'Calibration'. Now, under Due dates tab, a new row would have been created for 'calibration'. 5. Enter the Due Date for the calibration round (Enter a date which is before the submission due date) and save the assignment. 7. Go to the calibration tab and submit one expert review for the sample assignment. 8. Impersonate as student and under assignments home page, the assignment for which calibration was enabled will now have the current stage as 'calibration' 9. Now select that assignment and go to other's work link, which should be enabled. 10. One review will now appear as calibrated review. Begin the review and submit. 11. Now on the same page i.e other's work , you will see a new link: ""Show calibration results"" for the respective calibration review. 12. Once the calibration period is over and submission period starts, the students can now submit the actual assignment. Post submission due date, the peer review period will start. 13. When the peer review period begins, in others' work, the student will now see two sections: Calibrated review and Review. 14. Here, the total number of reviews count only the peer reviews. Automated tests are written in calibration_spec.rb and staggered_deadline_spec.rb file under specs/features folder. The RSpec tests cover the following scenarios: 1. If calibration is enabled, check if a new row is created in the deadlines table with the deadline type as Calibration. 2. During the calibration period, check if the current stage shows as calibration <image> <image>.","Overall, this is a very good document.  It describes the functionality comprehensively and is pretty readable.  There are a few opportunities for improvement: It doesn't discuss code changes at all, just UI changes.  Some of the screenshots are so large that you need to zoom way out to see them.  The automated tests are not extensive and do not consider edge cases.","Feedback:

Your assignment provides a comprehensive analysis of an 'Assignment peer review functionality' using a calibration technique. It is well-structured with clear explanations, making it easy for any reader to understand what you are proposing and implementing. It is commendable how you elaborate on the process flow in the form of steps, and the use cases provide valuable insight into the functional requirements of the system. 

However, I have a few recommendations for you:

1. Illustration: It would have been better if actual diagrams or screenshots could have been incorporated where you mentioned '<image>'. This would provide a visual representation and enhance understanding.

2. Terminology: While you have clearly articulated the functionality of various stages, it would have been better if all the technical terms used were defined at the beginning or where used for the first time. This would make it easier for someone without a technical background to understand your work.

3. Spelling and Grammar: Ensure you proof-read your work before making a submission. There are minor spelling and grammar issues observed during the review.

4. Writing Style: Some sentences were too long, which might cause confusion or misunderstandings. Ensure you break up your sentences into simpler constructs where possible.

5. Test Case Scenarios: It's great you are planning to write automated tests. It's recommended to describe some additional test cases that cover corner scenarios.

Despite these minor issues, overall this is a well-developed and technically sound project. It demonstrates a good understanding of the subject matter. The proposed changes to the system are logically sound and likely to lead to improvements in the functionality of the site. Good job! Keep it up!"
161,E1632,"<link> is an open source type of project that has been undertaken by the National Science Foundation. Various articles, codes in multiple languages and links can be submitted using the platform. It is popularly used by students studying at NC State to submit assignments, review works and get feedback. It allows users to switch between multiple environments if an user is not satisfied with a particular environment. The setup development can be done using OSX, Linux or Docker. While using the OSX method and Linux method (RHEL), shell access and root access is a prerequisite. Docker is another method to install Wikipedia. It is cross Operating System (OS) compatible. Docker pull is needed to pull the docker image. Docker run is then used on port number 3000. Expertiza allows user to contribute to their project. The expertiza project needs to be forked and cloned to create a local directory. Changes can be pushed and committed to a new branch. Finally the code is reviewed and changes are possibly made after a pull request. The project is related to the class scheduled_class. The associated MVC framework relate to sending out reminder emails around the deadline of a task. The project objective includes- 1. Removing duplicate code that is common in scheduled_task.rb and delayed_job.rb. 2. Subclass Deadline_Type in the perform method. 3. Refactoring mail_signed_up_users to multiple named methods and modifying it in a more elegant manner. 4. Checks to the new refactored code. One of them looks like: <code>. This includes the splitting of the method to multiple methods to make it more elegant Earlier Code: <code> Modified Code: <code>. The perform method has been modified to a large extent as it now uses Single Table Inheritance (STI) <link> instead of if-else cases statements. Earlier Code: <code> Modified Code: <code>. The scheduled_task_spec.rb is the test class for the above changes.All the test cases pass for scheduled_task_spec.rb following our changes. <link>. Installation for Reviewers Because asynchronous events require a daemon running in the background and the new Delayed::Job class for Rails 4 has additional fields, the following steps are recommended. 1. Install Expertiza and execute 'bundle install' 2. Create database and perform data migration using 'rake db:migrate' 3. Execute 'rails generate delayed_job:active_record' at the prompt. This will create a delalyed_job file in /bin directory. 4. Execute 'rails generate delayed:upgrade' if delayed_job has been created before. 5. Enter your smtp server account settings in config/environments/production.rb file. You may find an example in config/environments/developments.rb file. 6. Start the rails server by entering rails server 5. Start the delayed_job server by executing RAILS_ENV=production bin/delayed_job start Please watch the video : <link> to see how to test the use cases of the functionality that we have refactored.","The cycle detection may miss come cycles.
There should be UI which allow instructor to input the k.
There should be some visulization, or at least table of cycles in the report page.","Thank you for your well-detailed assignment submission. You provided a comprehensive overview of the project, detailing the usage, installation process and modification of the program code which shows a clear understanding of the content. The breadth of your knowledge about the Expertiza project – from its benefits to its setup and development methods – is impressive. 

Your articulated project objectives clearly and explained the changes you made to the code thoroughly. The step-by-step guide on the installation process will be useful for reviewers and show your understanding of each phase in the setup. 

However, it would be beneficial in future assignments to include more specific information about how certain aspects of the software function. While you mentioned that you refactored mail_signed_up_users, further clarification about this method as well as the new methods you introduced would be helpful. Also, it would be great if you could show how the actual codes have been modified instead of just indicating pointing to codes as ‘<code>’. 

In addition, please ensure to proofread your work to avoid typos and confusion. For instance, in the installation for reviewers, you have two step 5 mention. 

Lastly, providing a video for testing use cases is an excellent idea and adds to the clarity of your presentation. Keep up the good work and maintain the level of detail in future assignments."
162,E1746,"This page provides a description of the Expertiza based OSS project. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.1.4. <link> 1.1.1.5. <link> 1.1.4. <link>. <link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. The following tasks were accomplished in this project: 1. Complete the pending tests in user_spec.rb There are many pending tests needed to be finished. And for the methods which are needed to be refactored or renamed, this is also can been seen as writing failing tests first. 1. Refactor get_user_list method. The get_user_list methods contain many conditions and each of them has a lot of code which makes the method very long. The factor is to transfer the statements to the corresponding subclasses ,and writing method calls instead. 1. Refactor self.search_users method The method has many repetitive codes which are used in the conditionals. We refactor it by writing a single method call and let the method call to choose the conditional. 1. Rename methods and change all other places it is used. 2. Use find_by instead of dynamic method. The find_by_name or find_by_email method which are used in the user.rb is like old style code. And this kind of code can be replaced with new dynamic ones like, find_by. There are many pending tests in the file 'user.rb'. What we have done is finishing these pending tests and makes them pass.The user_spec.rb file on github is below. <code>. The task is to write failing test first and ,move if conditions to corresponding subclasses (eg. ta.rb, instructor.rb) with same method name,then replace the conditional with the relevant method calls. First writing the failing test first according to the requirements of the refactor. <code> The next step is to move if conditionals to its relatively subclasses. In this case,the superadministrator.rb, instructor.rb and ta.rb. <code> <code> <code> Then replace the conditional with the relevant method calls. <code> So the refactor of get_user_list method has been done. This task is required to write the failing test first and extract duplicated code to a new method. First, write the failing test. <code> Then,extract duplicated code to a new method.Since this is kind of changing original method.So below is the changing on github. <code>. First, is to write failing test of the renamed method which has been finished in mission one.So just skip to the second part to rename them. is_recursively_parent_of → recursively_parent_of? <code> is_creator_of? → creator_of? <code> is_teaching_assistant_for? → teaching_assistant_for? <code> is_teaching_assistant? → teaching_assistant? <code> After writing the test, it is going to rename the method in the user.rb. Below is the changed part of the code. <code>. ：：There are three lines using find_by_name and find_by_email which are now be instead of find_by[params].The task is to replace the old one to refactor the method. First,writing the failing tests,here is the original test code including find_by method. <code> And below is the new failing test <code> And so as the other codes contain find_by method <code> And then change the find_by_name and find_by_name in the user.rb file in to dynamic one. <code>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. Clean Code: A handbook of agile software craftsmanship. Author: Robert C Martin.","There are descriptions of all the methods written.  It would be helpful to have more detail, but it is good that they made an attempt to document it.","Your work on the Expertiza based OSS project is comprehensive and well organized. You have done a great job segmenting your task and providing step-by-step breakdowns of your methodologies for each task. The fact that you provided specific examples of the pieces of code you have worked on adds to the clarity of your work.

However, there are some improvements that can be made. Your description is lacking an introduction to what the Expertiza based OSS project is. It would be beneficial to provide a brief overview at the beginning of your assignment. Additionally, you should strive to provide context to the various link resources you mentioned throughout the assignment.

Furthermore, your use of grammatical structures and punctuation makes your text less readable in specific parts. There are several run-on sentences, which could use revision.

You are also recommended to explain more about why certain methods needed renaming or refactoring. What criteria did you use to determine when a method was too long or a name was insufficient? This can provide a deeper understanding of your problem-solving process.

Finally, in the tasks you said you accomplished in this project, you numbered each point as ‘1’ followed by a sub-point '2'. Please sequentially number each of your primary points for clarity and proper organization.

Overall, you have done a decent job with this assignment. Making the above suggestions can greatly improve your future assignments."
163,E1713,"Expertiza is an open source web application which allows an instructor to manage assignments. It has various features viz. creating new assignments, customizing existing assignments, automatically allocating submissions for peer review etc. It has been developed using the <link> framework, and the code is available on <link> . In this project, the files <link> and <link> were to be refactored. The methods contained in these files were too long, and needed to be either shortened, or used polymorphically, or deleted altogether if they were not being used. They also were to be refactored semantically if the code did not follow good Ruby coding practices. After an instructor creates an assignment in Expertiza they will have the ability to edit the details of the assignment by clicking the Edit action icon beside the assignment. From the ""Editing Assignment"" screen instructors have the ability to set due dates for each round of an assignment on the ""Due dates"" tab. On this tab, the instructor can elect to apply a late policy to the assignment by checking the ""Apply penalty policy"" checkbox and selecting a late policy from the adjacent drop down menu. If no late policies exist, or if the instructor wishes to define a new late policy, then they can click the ""New late policy"" link to define a new late policy. An instructor can define a late policy with the following fields: 1. Late policy name - This name will show up in the drop down menu on the ""Due dates"" tab when editing the assignment. It is not enforced to be unique. 2. Penalty Unit - With the options of 'Minute', 'Hour', and 'Day' this field will define the frequency with which penalty points are deducted if an assignment is submitted after a due date. 3. Penalty Point Per Unit - This is the amount of points which will be deducted from the student's score for the assignment round every time the Penalty Unit time has elapsed between the due date and the submission date. [Range: > 50] 4. Maximum Penalty - Points will continue to be deducted from the assignment round score for each Penalty Unit time that has elapsed, but the number of points deducted will not exceed the Maximum Penalty [Range: 1..50] Once an assignment has a late policy applied to an assignment, students' submissions will be checked against deadlines to determine if the late policy should be enforced. The penalty is applied to the grades under two circumstances. When a student is viewing an assignment task and they click on the ""Your scores"" link, the applicable penalties will be applied before displaying. Also, when an instructor is viewing the list of assignments on the ""Manage content"" page, if they click the icon for ""View scores"" the penalties will be applied to all submissions within the list which were submitted past the due date. The penalty_helper.rb and late_policies_controller.rb files are central to the creation and maintenance of late policies. Late policies are created by instructors and associated with assignments. The late_policies_controller.rb file is primarily used in the communication with view where late policies are displayed, created, or modified. The penalty_helper.rb file includes many useful methods related to late policies and the penalties which result from their use. For instance, if an assignment is designated as having penalties calculated then when it is graded the PenaltyHelper module will allow the penalties for each assignment to be calculated and applied to the final grade for the assignment. This effort was initiated with the intent of refactoring some longer methods with redundant subprocedures so that the overall structure of the code is cleaner, concise, and DRYer. This was achieved by performing analysis on the files to identify methods which are not used within the Expertiza code base, methods which are too long, and redundant code which can be extracted from other methods and replaced with a call to a single method. This is controller class for late policies. It handles all the basic operations on late policies like create/edit/delete policy. The project goal was to refactor the code of create and update methods to make them smaller and more readable. Three helper methods were added in the PenaltyHelper module to make the code shorter. There was a common input check in both create and update methods which was separated to write two new methods ""check_penalty_points_validity"" and ""check_policy_with_same_name"", which helped to reuse the code. <code> <code> In case of update action call, there was a part of code which was updating already calculated penalty objects based on the updated late policy. This part was written as a separate method in the helper class with name ""update_calculated_penalty_objects"". <code> Some variable names were changed in order to make it easier for reader to understand the meaning of code. There was some unused commented code which was removed. This is a helper class which contains methods which calculate the different penalties, and are then brought together in one Hash object. The aim was to keep the methods below 25 lines of code if possible. Out of the numerous methods in the file, there were 3 substantial methods, namely calculate_penalty, calculate_submission_penalty, and compute_penalty_on_reviews crossed the 25 line limit. calculate_penalty is the main method of the PenaltyHelper module. It is called from the <link> module. The other methods are called from within the calculate_penalty module. The method mainly contains a few assignment statements, and some method calls. There was no scope for it to be shortened further without risking non-operation of some functionalities. A particular segment of code converted a time difference into respective unit. This code was inserted into a method with the parameter 'time_difference'. The conversion segment was called in calculate_submission_penalty, as well as compute_penalty_on_reviews. Inserting the conversion logic into a separate method allowed the simplification of both methods. <code> The method was called in two places. <code> <code> Apart from the method which was defined, some other methods which were not being called were removed, extraneous statements which were written and then commented were also removed. Also, minor modifications in places where code did not follow Ruby grammar were made, for eg: a space was added between 'if' and the condition statement. The project formerly had no tests associated with these source files. Our refactoring added moved functionality out of the controller and into the helper module, therefore our testing focused on validating the helper methods in penalty_helper.rb. <table>. Instructions on how our reviewers should validate the impacted functionality to ensure that it still works. First, set up your Expertiza environment. Navigate to <link> and click the ""Make a Reservation"" button. Sign in with your Unity ID. Click the ""Reservations"" button and then click ""New Reservation"". In the environment drop down box select the ' [CSC517, F15] Ruby on Rails / Expertiza' environment, set your session duration, and click the ""Create Reservation"" button. Once your reservation is ready you should see a Connect! button. Click it and copy the IP address. If you don't have PuTTY then download it. Open PuTTY and paste the IP address in the hostname field and click ""Open."" Confirm connection at the security dialog. Log into the server using your Unity ID and password. Once logged in, execute the following commands to setup the Expertiza environment. <code>. Now, to run the tests, make sure you are in the project's root directory (i.e. ~/expertiza/). Run the following command: <code> Once it is complete, the output should contain the number of test cases and how man of them passed or failed.","Somewhat hard to follow because penalty object was not defined.  Should have been described like late_policy.  Writeup showed the ""after"" version of code, but not ""before"", so the two couldn't be compared.","Hello,

I appreciate your hard work put into this assignment. Your understanding of the Expertiza environment and its different functionalities is commendable. I especially appreciated your work on the refactoring of the code to make it DRYer, more concise, and easier to read. Your inclusion of the description of the problem and detailed explanation of the solutions you have implemented, makes it clear that you have a good understanding of the assignment.

However, there are some areas that need further improvement:

1. Please provide pseudo code, code snippets, or processed code so that I can understand the specific changes you have made during your refactoring process. Specifics would help assess your work better.

2. In future assignments, consider focusing on determining the impact of your changes. While it's great that you've run tests and stated the results, some deeper analysis on how your changes may have affected performance or usability would be beneficial.

3. Make sure to clearly describe the steps taken to refactor the code. Details such as what methods were refactored, the reasons behind refactoring these specific methods, and the impact on the codebase will help in better understanding your choices.

We encourage improvements and learning from your end! Good job overall and keep up the good work.

Best regards,
[Instructor's name]"
164,E2008,"<link> is a web application developed using Ruby on Rails Framework whose creation and maintenance are taken care of by students as well as the faculty of NCSU. Its code is available on Github <link> . Expertiza allows the instructor to create and edit new as well as existing assignments. This also includes creating a wide range of topics under each assignment that students can sign up for. They can also publish surveys and reviews, view statistical results, set deadlines for assignments and make announcements. It provides a platform for students to signup for topics, form teams, view and submit assignments and give peer reviews and feedback. Background: In Expertiza students can review each other’s projects and even each other as teammates. Students can view their project scores and instructors can view student's teammate review scores on the view scores page. This Summary helper aids in calculating these scores and rendering the results on the view scores section of an assignment. Summary helper is a helper module that consists of methods used to calculate scores for these reviews. This is for the use of instructors. Requirement: E2008 is an Expertiza OSS project which deals basically with refactoring app/helpers/summary_helper.rb to reduce the code climate issues such as 1. <link> 2. <link> 3. Method/line too long 4. Unused variables / access modifiers A good method should have: 1. Assignment Branch Condition size <= 15 2. Cognitive Complexity <= 6 3. No. of lines in a method <= 25. The following are issues which were found in the code: <table>. <table>. <table>. <table>. This method is used to summarize reviews by a reviewer for each question. Changes Made: This method could be refactored into smaller methods namely summarize_reviews_by_reviewee and summarize_reviews_by_reviewee_assign where summarize_reviews_by_reviewee calls summarize_reviews_by_reviewee_assign to get average scores and summary for each question. Before: <code> After: <code> Impact: 1.1. Assignment Branch Condition size for summarize_reviews_by_reviewee is reduced from 44.61 to 20.64. This method is used to summarize the review for each questions Changes Made: 1.1. This method was refactored into 3 smaller methods namely summarize_reviews_by_criterion , summarize_reviews_by_criterion_questions and end_threads . 1.1. The method summarize_reviews_by_criterion calls summarize_reviews_by_criterion_questions to get answers of each question in the rubric. 1.1. The method summarize_reviews_by_criterion_questions starts many threads to process each question and closes it by calling the function end_threads . Before: <code> After: <code> Impact: 1.1. Assignment Branch Condition size for summarize_reviews_by_criterion is reduced from 42.34 to 17.2 1.2. Cognitive complexity is reduced from 16 to 7. This method is used to produce summaries for instructor and students. It sums up the feedback by criterion for each reviewer Changes Made: 1.1. This method was refactored into 4 smaller methods namely summarize_reviews_by_reviewees , summarize_reviews_by_teams , summarize_by_reviewee_round and end_threads . 1.1. The method summarize_reviews_by_reviewees calls summarize_reviews_by_teams which inturn calls summarize_by_reviewee_round to get answers of each reviewer by rubric. 1.1. The method summarize_by_reviewee_round starts many threads to create requests to summarize the comments and closes the threads by calling the function end_threads . Before: <code> After: <code> Impact: 1.1. Assignment Branch Condition size for summarize_reviews_by_reviewees is reduced from 89.93 to 16.64 1.2. Cognitive Complexity is reduced from 17 to 7. This method calls web service to store each summary in a hashmap and use the question as the key. Changes Made: Removed variable summary <image>. This method adds the comment to an array to be converted as a json request. Changes Made: The method is broken down into 2 smaller methods namely break_up_comments_to_sentences and get_sentences where get_sentences is called by break_up_comments_to_sentences to get sentences in desired format. <image> Impact : 1.1. The Cognitive complexity of break_up_comments_to_sentences reduced from 6 to <5. This method returns the rubric for given assignment Changes Made: 1.1. In IF CONDITION: Removed unnecessary use of variable which was being used only once (questionaire_id) and replaced the variable with its assignment (assignment.review_questionnaire_id(round + 1) 1.2. In ELSE CONDITION: Removed unnecessary ternary operation for variable questionaire_id and replaced the variable with its assignment (assignment.review_questionnaire_id) <image>. This method is used to calculate average round score for each question. Changes Made: Refactored the method into 2 smaller methods namely calculate_avg_score_by_round and calculate_round_score where calculate_avg_score_by_round calls calculate_round_score to calculate average round score and calculate_avg_score_by_round rounds the round_score upto 2 decimal places. Before: <code> After: <code> Impact: 1.1. Assignment Branch Condition size for calculate_avg_score_by_round is reduced from 18.57 to <15. Coverage increased (+17.1%) to 41.407%. <link>. Login Details: USERNAME: instructor6 PASSWORD: password Click Assignment >> Click the View Submissions of Madeup problem >> Click on any student >> Click on Madeup problem >> Click on Your Scores <image> <image> <image> <image> The 3 main functions of the Summary helper are summarize review by reviewees, summarize review by reviewee and summarize reviews by criterion. To check summarize reviews by reviewees is working we should get the output similar to the one shown below. This function summarizes all the reviews and displays average score. <image> To check summarize reviews by reviewee is working, click on any review. <image> A new webpage pops up with all the reviews and scores given by an individual. <image> To check summarize reviews by criterion is working, click on any criterion. This should display summarized reviews and scores for a particular question in the questionnaire. <image>. 1. Modularize summarize_by_rounds to even smaller modules so that Assignment Branch Condition size is reduced from 36.73 to 15.00. 2. Create more test cases for the new modularized methods.","The documentation clearly explains most of the code changes they have made. Some descriptions should be more detailed, e.g., ""Removed variable summary""  Why is the refactored method clearer without it?
They also explained how their code changes address Code Climate issues. They have given a detailed explanation of their manual testing plan as well. However, there is no mention of automated tests.
They added huge chunks of code in the beginning and then shifted to github view. So that looks a bit inconsistent. Otherwise, i think wrt to the project the documentation is pretty good. 
","Thank you for your diligent and comprehensive work on this assignment. You have apparently invested a significant amount of effort into understanding, deconstructing, and refactoring this application's logic, which is appreciable.

Your explanation of the code's original issues and your subsequent remedying changes are both lucid and succinct. The usage of tables and images throughout your report makes it easier to digest and visualize the work you've done, which is a thoughtful touch. 

It's apparent that your changes have led to improvements in the clarity and simplicity of the code, which are key metrics of code quality. As you've demonstrated, modularizing long and complex methods can significantly reduce cognitive complexity and improve maintainability. 

Encouragingly, the breadth of your changes indicates that you've significantly reduced the ABC size for many methods, another important gauge of readability and maintainability. 

However, there are a few areas we can improve further on. Your explanation of the code and the changes made can be a little too detailed, it might make sense to use a higher-level overview in parts, rather than going into minute detail for each method. It can be overwhelming to try and follow all at once for anyone who isn't already intimately familiar with the written code. 

Moreover, provide direct links to the exact Github lines in your assignment to make it easier for anyone interested in referencing your work.

The steps you have mentioned for checking the functioning of summary helper features are a good way to measure the success of your refactoring. Keep it up!

On your future improvements, the tasks you have identified are indeed helpful and would lead to a more smooth-functioning code. And be sure to give equal importance to testing since refactoring can potentially derail the application if tests aren't updated to suit the new code structures.

Overall, well done on this extensive project, and keep up the good work!"
165,E1663,"For users intending to view the deployed Expertiza associated with this assignment, the credentials are below: 1. Instructor login: username -> instructor6, password -> password. Expertiza is an educational web application created and maintained by the joint efforts of the students and the faculty at NCSU. It’s an open source project developed on Ruby on Rails platform and its code is available on Github. It allows students to review each other’s work and improve their work upon this feedback. The current project deals with addition of AJAX whenever we add a new record or modify an existing record. In the current scenario, we submit the entire page to save a record and reload the entire page back again. Using Ajax, we should only submit the newly added record information to server instead of submitting the entire page. This project takes care of below scenarios: 1. Add Participants: Once an assignment has been created, an instructor can Add Participants to the assignment. 2. Add/Delete TA (Teaching Assistants): Once a course has been created, an instructor can Add/Delete TAs to the course. 3. Edit Questionnaire: Modify the Edit Questionnaire screen to use ajax while adding new questions to the questionnaires. 1. Controllers 1.1. participants_controller.rb 1.2. course_controller.rb 1.3. questionnaires_controller.rb 1. Views 1.1. course 1.1.1. _add_individual.html.erb 1.1.2. _ta_list.html.erb 1.1.3. add_ta.js.erb 1.1.4. remove_ta.js.erb 1.1.5. view_teaching_assistants.html.erb 1.2. participants 1.1.1. add.js.erb 1.1.2. list.html.erb 1.3. shared_scripts 1.1.1. add_individual.html.erb 1.1.2. _user_list.html.erb 1.4. questionnaires 1.1.1. _ajax_partial.html.erb 1.1.2. add_new_questions.js.erb 1.1.3. edit.js.erb. We have added respond_to method in add method of participants controller and add_ta/remove_ta methods of course controller, which will allow us to render both javascript and html requests from these methods. In course controller the function looked something like this: <code>. The same methods added in participants were added in questionnaire controller, the difference being in the action the controller takes after receiving a JS request. In the partial _questionnaire.html.erb, the attribute remote was set to true. This is rendered as the attribute ""data-remote"" being set to true in HTML, which allows the rails UJS (unobtrusive JS) to make AJAX calls without needing any jQuery statements. To implement the functionality, the controller renders a JavaScript file in place of the usual .html.erb. The JavaScript file then takes action on the webpage it is called on. In the case of adding new questions, the page is updated with the new questions by the JavaScript file that is called. This is achieved by rendering a partial in the JavaScript file and then using jQuery to update the page with the rendered HTML. This seemed like a good approach as we are reusing the render method. Although new partials had to be created, the JavaScript functionality is easy to understand. Additional divs were added in the HTML to serve as hooks for the jQuery statements to update HTML on the page. Additionally, saving questions in the edit questionnaire section also works on AJAX, and flashes the standard rails success message without refreshing the page. We have put the :remote => true flag on the link or form tag in our .html.erb files (view) for the element where we wanted to trigger the AJAX call, like, <code> <code> With :remote => true, rails will not automatically switch views, which allows the JQuery to be run instead. This can be used with a form_tag, a link_tag, or other types of tags. RSpec Testing There were no existing test cases for the course controller. We have added some related to the functionality which we have worked on. The following test verifies mapping between TA and course: <code> Below test verifies whether error message is displayed or not when TA does not exist: <code> The test below verifies whether TA is removed from the course or not: <code> UI Testing Following steps needs to be performed to test this code from UI: 1. Login as an instructor. 2. You will land on Manage Content page with list of courses and related actions to it. 3. Under action column try to Add TA for any course. 4. It will take you to Teaching Assistants page. 5. Try to add a valid TA for eg. teaching_assistant5549. As soon as you press Add TA button, list will get updated with the newly added TA without refreshing the page. 6. If you try to delete any TA, a popup will open to confirm your action, press ok and you will see that particular TA is deleted in the background. 7. Similarly, for perform these actions for Add participant action for any course. Table will be updated with newly added participant without refreshing the page. 8. To test add questionnaire, switch to questionnaire tab from courses tab and click on add questionnaire. 9. As you add questions, page would not refresh and questions would be added as expected. 10. If you try to delete any question, delete action would also not refresh the page and perform the required action.","The documentation is well structured thus. it's short and easy to find information. Test cases could surely be extended. I'm questioning the approach "" the controller renders a JavaScript file in place of the usual .html.erb. The JavaScript file then takes action on the webpage it is called on"". why not just render html pages that have links to those javascripts? It would have been nice to see some reasoning there. ","This is an overall well-written and thorough assignment submission. You've provided a clear explanation of your project alongside the technology used and the functionality the system holds. Here are a few comments and tips to further improve your work: 

1. Structure: There is a bit of a lack of clarity in the organization of your content, particularly when referring to the scenarios your project accounts for. Please consider using bullet points or numbered lists to better delineate different areas of focus in your assignment. This should improve readability and comprehension.

2. Explanation: Try to delve a bit deeper when explaining technical aspects of your project like AJAX incorporation and controllers' functionality. Readers with a variety of technical expertise may be reviewing your work and clearer, more detailed explanations can ensure all readers fully comprehend your work.

3. Testing: Outstanding job discussing both RSpec and UI testing methods. You've clearly demonstrated how to test your application. Remember to also include your expectations of each test outcome for further clarity.

4. Security: Remember, it is not advisable to disclose login credentials as you did at the beginning of your assignment. Even though it's part of a class assignment, it's important to keep information security best practices in mind.

Again, great work. It's evident that you've learned a lot from this course and have been able to apply it effectively in your assignment."
166,E1812.1,"This wiki page gives a description of changes made under Expertiza OSS project E1812 assignment for Spring 2018, CSC/ECE 517. Because this project is just a unit test, it cannot be tested via UI. Per Dr. Gehringer's instructions we have posted <link> to prove the tests work. In the video, the unit tests are run from the terminal, and then we check the coverage. The goal of our project was to have at least 90% coverage, which we achieved. Contents 1.1. <link> 1.1.1. <link> 1.2. <link> 1.3. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.4. <link> 1.1.1. <link> 1.5. <link> 1.6. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.7. <link>. <link> is an open source web application developed with <link> framework. This application allows students to access assignments posted by an instructor, submit their work (articles, codes, websites), review others work submissions. Expertiza gives a chance to improve students’ work based on their peer-reviews, and it can also help in grading students’ submissions based on that feedback. Students can form their teams for an assignment, otherwise, teams can be assigned automatically. The OnTheFlyCalc model does not have any test cases corresponding to it. Thus, the task of this assignment is to write unit tests for on_the_fly_calc.rb using RSpec. The test cases should be fast, effective, and achieve the maximum code coverage, i.e. > 90%. On_the_fly_calc is a module that is included in assignment.rb. This module calculates the score for both students and instructors. E.g., when a student clicks “view my score”, Expertiza calculates the review scores for each review. This is called “on the fly” because expertiza stores the review scores based on each question (in answers table), but does not store the total score that a reviewer gives to a reviewee. It directly calculates the total review score for each review, using the score values in the answer table during run-time. As a part of the project the file listed below was created and saved under spec/models folder: 1. on_the_fly_calc_spec.rb The file listed below was modified due to some code issues in it 1. on_the_fly_calc.rb (path: app/models) <code>. What we need to do is to write tests for four public methods listed in the module OnTheFLyCalc. However, the on_the_fly_calc itself has some code issues in #scores, and IDE reports some errors when we run the test case for it. Thus, we need to modify the module itself a little. For this project we use <link> which is a testing tool for Ruby, created for <link> (BDD). In order to accomplish this task, that is to build tests for the OnTheFlyCalc model, we need to implement the following plan: 1. Set up the Expertiza environment; 2. Understand the functionality of the model; 3. Understand the relative methods and objects involved with each function of the model; 4. Create test objects; 5. Write ‘it block’ test scenarios with appropriate contexts for all public functions of the model, and check if all <link> pass. To DRY up our tests, we use ""before"" and ""let"". The following set-up lines create variables that are common across tests: <code>. The function compute total score totals the scores of each questionnaire in an assignment. <code> To test this function We mocked the calls made in the Questionnaire class. For example, to mock the call: <code> we used the rspec line which looks like this <code> similarly, other calls made to <code> was mocked using calls that look like :- <code> cases for consideration : 1. when avg score equals nil 2. when avg score is not equal to nil. Below is most of the code used in the test case. It is relatively simple. The first test case is for when assignments vary by rubrics. We check that the function returns {}. This is correct because we set reviewer to nil so that reviewer will be set to {} in the ""reviewer = {} if reviewer.nil?"" statement. In the second test case we check that it returns {1=>{1=>50}, 2=>{1=>30}}. This is correct because we create 2 response maps and set their value to 50 and 30. <code> <code>. This function calculates the average score and score range for each reviewee (team). <code> We consider 2 scenarios to test for this function: 1. When current assignment varies rubrics by round: function computes avg score and score range for each team in each round and return scores <code> 2. When current assignment does not varies rubrics by round: function computes avg score and score range for each team and return scores <code>. <code> This method calls a lot of private methods to calculate a score hash. To test this method we had to mock calls made in these private methods. When varying_rubrics_by_round? is true this method calls <code> <code> <code> we mocked the call to 1. so it is not covered in our coverage as it just initializes our hashes. to mock the call to 2. and 3. calls such as the ones given below can be seen in our test cases. <code> we are basically mocking calls to run through all lines of the methods and only calls that is returning something or are assigning value to a variable need to be mocked. for example the call <code> is to mock the call made to compute_score function in the Answer class we made it to return an empty hash. cases for consideration : 1. when current assignment varys rubrics by round and number of assessments is 0.in this case <code> <code> 2. when current assignment varys rubrics by round and number of assessments is non-zero. 3. when current assignment does not vary rubrics by round. 1. To run RSpec for a particular file (on_the_fly_calc_spec.rb): <code>. We have a 92.74% coverage. Below is a picture of the results from the coverage. <image>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.","This is pretty readable, explaining the need for on_the_fly_calc, and how the tests work. Would have liked to see more explanation of compute_avg_and_ranges_hash. 
Nit:""varys"" should be ""varies""","It's evident that considerable effort has been put into this assignment. The details provided about your work, methods and testing approach are thorough and commendable. The inclusion of the process and methods used, as well as specifics about the test cases used, and a clear explanation of the considerations during your tests are crucial for effectively communicating the depth and breadth of your efforts. 

One suggestion to improve your work might be to make it more organized. Even though detailed information was provided, it was difficult to follow given it was not well-structured, for example, some parts felt like a continuous stream rather than separated into sub-sections. You could revisit and re-categorize your assignment into clearly defined headings and sub-headings, that would make it much easier for a reader to understand the flow of your work and grasp the details with clarity. 

Additionally, the multiple instances of ""<link>"" in your project report are not very helpful. If these are placeholders for actual links, it would be useful to provide those to corroborate your work and for reviewers to refer to. 

Finally, it’s great that you've achieved a high percentage of coverage. But I suggest you also document the cases where testing could not be done or you faced difficulties as well. This is a learning exercise, so it’s as important to understand what couldn't be done or what could be improved upon. 

Keep up the good work! And remember, refining presentation skills is an ongoing process that will help your good work shine even brighter."
167,E1714,"In order to sign up or drop teams from a topic, an instructor must first impersonate a student and then perform the necessary action. The current workflow introduces unnecessary complexity to the process. To add or drop multiple teams, the instructor must impersonate each student and navigate back and forth between the same set of pages. An instructor can view a list of all the topics for any given assignment. Each topic shows any signed up teams and whether students are signed up or waitlisted. The proposed change introduces a new button next to each team that allows an instructor to remove a team from a topic. In this manner, an instructor can drop a team from a topic with relative ease. An additional button was also implemented to give an instructor the option to sign a specific team up for a topic. An instructor can select a team by specifying one of the team members. If the student specified by the instructor is not part of a team, a team is created for the student as part of the signup process. The signup button is located in the topic name box and redirects to a new page. The new page contains a form where the instructor can enter a student's name. Once a team is added, the instructor is redirected back to the edit assignment page where the topic is updated with the specified student's team. From the instructor's edit assignments page with the tab topics selected, the instructor should see a list of topics for the given assignment. For each topic, the instructor should be able to: 1. Sign a student up if ""No choosers"" is displayed 1.1. If the student is part of a team, the whole team should be signed up 1.2. If the student is not part of a team, a team should be created with only the given student as a member 2. Sign a student up for the waitlist if a team is already signed up 1.1. If the student is part of a team, the whole team should be signed up 1.2. If the student is not part of a team, a team should be created with only the given student as a member 1.3. The team should be added to the end of the waitlist Each action is performed by choosing the green checkmark next to the desired topic name. From the instructor's edit assignments page with the tab topics selected, the instructor should see a list of topics for the given assignment. For each topic, the instructor should be able to: 1. Remove a team's signup for a specific topic 1.1. The team should no longer be signed up for the topic 1.2. Any waitlisted teams should now be signed up for the topic 2. Remove a team from the waitlist for a specific topic 1.1. The team should be removed from the waitlist Each action is done by choosing the X enclosed by a red circle next to the desired team. Please review the information below on how to manually test the implemented changes. Login Information: <table> Review Steps: 1. Check with assignments a student is signed up for 1.1. Log in as a student 1.2. On the main page, there should be a list of assignments which the user can be removed from signup 1.1.1. Note removing the signup only works if the student hasn't turned in work or the drop deadline has not passed 2. Add a student to a course or assignment 1.1. Log in as an instructor 1.2. Go to ""Courses"" tab to add a student to a course, go to ""Assignments"" tab to add a student to an assignment 1.3. Choose ""Add Participants"" button under ""Actions"" column. It appears as a person wearing a blue shirt with a green plus above them 1.4. The list shows all users currently signed up and what role they have 1.5. Scroll to the bottom of the bottom of the page 1.1.1. Type in the student's name in the text box next to ""Enter a user login"" 1.1.2. Ensure the ""Participant"" radio button is selected 1.1.3. Select add 3. Navigating to the assignment topics page 1.1. Login as an instructor 1.2. In the top red navigation bar, choose ""Manage"" 1.3. Select ""Assignments"" above the search bar 1.4. Click the pencil button under actions column for any assignment 1.5. Select the ""Topics"" tab 4. Signing a student up 1.1. Navigate to the assignment topics page 1.2. Under the ""Topic name(s)"" column, click the checkmark for a given topic 1.3. At the redirected page, type in an existing student user 1.4. You should be redirected back to the ""Edit Assignment"" page, select the ""Topics"" tab to view your change 5. Remove a team's signup from a topic 1.1. Navigate to the assignment topics page 1.2. Under the ""Topic name(s)"" column, click the x surrounded by a red circle for a given topic 1.3. You should be redirected back to the ""Edit Assignment"" page, select the ""Topics"" tab to view your change 6. Check to ensure a student can see his addition or removal from a topic 1.1. Sign in as a student 1.2. Select the assignment of interest on the home page 1.3. The ""your work"" link should be grayed out with a message ""(You have to choose a topic first) "" if you've just removed the user's signup 1.4. The ""your work"" link should be active if you've signed the user up 1.1.1. Select the link ""signup sheet"" 1.1.2. The topic you've signed the user up for should be highlighted in yellow. The topic_name partial is the primary view for this feature. It renders the table cell where the topic, team, and students are listed. The following links were added to the partial where appropriate: <code> Note that the instructor will see a different set of links depending on whether or not a team has already been assigned to a topic. If no team is present, only a single link that adds a student and their team will be visible. If a team is already present, then an additional link that drops that existing team will be visible. In this scenario, the signup link will add students to the waitlist instead. This additional view renders a form where the instructor can specify a student for the signup action. The instructor is redirected to this page after clicking the signup link in the topic names partial. <code>. The signup_sheet_controller is where most of the new functionality is introduced. These functions are based on the existing signup and delete actions, but are modified to match the context an instructor is given. For example, the signup action validates the user the instructor supplies and no longer uses the session user. Similarly for the delete action, the user must be extracted from the team ID. The flash messages were also modified to notify an instructor rather than a student. <code> <code>. Since we added new functionality, we needed to create new preconditions for testing. We describe the preconditions below. RSpec is utilized to perform the unit tests under the spec/controllers/sign_up_sheet_spec.rb file. We do not test adding multiple students since it is already tested with existing functions. We can assume that signing up a student will sign up the whole team as indicated by the contract with the existing function. The same contract exists for removing a student's sign up. We also wish to make a distinction in the goal of our functionality. It is not to remove one student from the team. It is to remove the whole team from a topic. The addition of too much extra functionality will clutter the system, thus we don't implement or test the addition or removal of an individual from a team since it is implemented elsewhere. We create two students and an instructor. We also create an assignment which adds the two students as participants. Two teams are created with a student assigned to one of the teams. The other team is used for tests where no work is submitted. Two topics are created and use the assignment deadline. One student is signed up to a topic and is used to test the delete functionality. The other student is signed up by the instructor and tests the signup functionality. The objects are refreshed before each test. <table>.","It would definitely help to see screenshots of the functionality.  Also, writeup does not specify what happens when there is more than one slot for a topic.  When showing modifications, it is good to show before & after snippets, e.g., cutting & pasting from the Github diff.","Dear Student,

Thank you for your thoughtful and comprehensive work on this assignment. You have made impressive strides in elucidating various nuances of the functionality. Also, you have explained your thought process well, which helps understand your approach towards solving this problem. 

However, I have some suggestions to further enhance your work:

1. **Clearer Explanation**: You might want to explain your ideas in a simpler and more natural language. For example, nontechnical individuals may have trouble understanding terms like 'impersonate a student,' 'redirect,' or 'tab topics.'

2. **Structuring**: Your work has great content, but it tends to become confusing from time to time due to the lack of clear subheadings, line breaks, or indentations. By breaking your information into paragraphs or including bullet points, you can help to guide the reader through your thoughts more naturally. 

3. **Avoid Repetition**: Some parts of the assignment appear to be repeated. Refrain from repetition unless it is deliberately done for emphasis purpose.

4. **Conclusion** It would be good to add a concluding section summarising the changes you implemented and testing done.

Overall, this assignment shows a good understanding of the topic and I'd encourage you to make these minor adjustments to elevate your report to the next level.

Best,

[Your Name]"
168,E1955,"<link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. This project in particular intends that the students collaborate with each other and work on making enhancements to the code base by applying the concepts of Rails,RSpec, DRY code,Test driven development etc. This provides an opportunity for students to contribute to an open source project and learn further about software deployment etc. RSpec is a unit test framework for the Ruby programming language. RSpec is different than traditional xUnit frameworks like JUnit because RSpec is a Behavior driven development tool. What this means is that, tests written in RSpec focus on the ""behavior"" of an application being tested. RSpec does not put emphasis on, how the application works but instead on how it behaves, in other words, what the application actually does.Each RSpec file contains one or more tests. Each test ensures if a particular feature of our website is working properly.The output of an RSpec run will tell you exactly what features aren't working. The benefit is that tested code is unlikely to break unnoticed.The tests are run every time someone makes, or updates, a <link> . Below are the tables that are related ti student task functionality <link>. The following is an Expertiza based OSS project which deals primarily with the student_task.rb and student_task_spec.rb. It focuses on writing RSpec unit tests for the code affected or added. The goal of this project is to attempt to add sufficient unit tests to this part of the application and increase its path coverage to above 90 percent. The following tasks were accomplished in this project: 1. Complete the insufficient unit tests for student_task.rb. 2. Increase path coverage from only 31.91% with 30 lines covered to above 92.55% with 87 lines covered. 3. Cover edge cases. 4. High branch coverage to be achieved. There are different tasks that a student can perform. 1. He can see all the assignments that he has been assigned to. 2. He can see details of each assignment like marks, his team, send invitation to student to join a team 3. Review other students' work <link> <link> The following functions were tested: 1. complete? This function returns true if the participant stage deadline is ""complete"" or else return false. 1. content_submitted_in_current_stage? This function returns true if the participant has submitted hyperlinks in the current stage and the stage is in ""submission"" 1. hyperlinks This function returns all the hyperlinks submitted by the participant team 1. in_work_stage? A assignment is said to be in work stage if its stage is any of ""submission"", ""review"" or ""metareview"" 1. incomplete? This function returns true if the participant stage deadline is not ""complete"" or else return false. 1. metareviews_given? * reviews_given? A participant can review other people's work and add comments. Also a user can review a review, called ""metareview"" that is given to him. A review comment is mapped to assignments or other reviews by the table response_tags via the reviewed_object_id. This method checks if the participant has given any metareview and return true otherwise. 1. metareviews_given_in_current_stage? This function checks if the assignment is in ""metareview"" stage and metareviews. 1. not_started? This function checks if the assignment is in any of ""submission"", ""review"" or ""metareview"" stage 1. relative_deadline 2. reviews_given_in_current_stage? 3. revision? 4. from_participant(participant) This function return the StudentTask from the participant with assignment, topic, current_stage 1. from_participant_id(id) This function return the StudentTask from the participant with assignment, topic, current_stage using the participant id 1. from_user(user) 2. get_author_feedback_data(participant_id, timeline_list) 3. get_due_date_data(assignment, timeline_list) 4. get_peer_review_data(participant_id, timeline_list) 5. get_submission_data(assignment_id, team_id, timeline_list) 6. get_timeline_data(assignment, participant, team) 7. teamed_students(user, ip_address = nil) This function return the list of all the students that the logged on user has teamed up until now. 1. started? Checks if the current stage is ""incomplete"" and content_submitted_in_current_stage? reviews_given_in_current_stage? || metareviews_given_in_current_stage? and return true and false 1. topic_name Return the name of the topic. 1. Mock Objects The following mock objects were created/built before the commencement of automated testing for student_task.rb (model) code. <code> Below are some of the functions tested 1. Function: teamed_students - Write a test case to find teamed up students. This method is an instance method, having a user passed to it. It return the list of students that the current user has teamed up. It does not consider the teammates that are from calibration assignments The test cases described check for the following scenarios: 1. When not in any team returns empty 2. When assigned in a cource_team returns empty 3. When assigned in a assignment_team return the list of teammates <code> 1. Function: get_due_date_data - Write a test case to get the due dates of the assignment. This method is an instance method, having an assignment and timeline_list list passed to it. The test cases described check for the following scenarios: 1. When an assignment passed to the method has no assignment attributes. 2. When an assignment passed to the method has some attributes but not the attribute due_at 3. When an assignment passed to the method has some attributes along with due_at due_at attribute is checked, upon which the timeline_list is populated with the updated_at and label values. <code> 1. Function: get_peer_review_data - Write a test case to get the peer review data. This method is an instance method, having an review and timeline_list list passed to it. The test cases described check for the following scenarios: 1. When no review response is mapped. 2. When review response is mapped. <code> 1. Function: get_author_feedback_data - Write a test case to get the feedback response This method is an instance method, having feedback and timeline_list list passed to it. The test cases described check for the following scenarios: 1. when no feedback response is mapped. 2. when feedback response is mapped. <code> 1. Function: get_submission_data - Write a test case to import participants This method is an instance method, having a submission and timeline_list list passed to it. The test cases described check for the following scenarios: 1. When no submission data is mapped. 2. When submission data is mapped and hyperlink is not submitted or hyperlink is removed. 3. When submission data is mapped and operation is submit_hyperlink. 4. When submission data mapped and operation is Remove Hyperlink. <code>. What we need to do is to set up the environment and complete the 'student_task.rb' and 'student_task_spec.rb' to increase the path coverage from only 43.0% with 43 lines covered and 57 lines missed to above 90%. You can run RSpec tests by executing the command: <code> After that, you can see the detailed coverage information by opening this file in your Expertiza folder. <code>. The code we created can be found below. We have also linked the video of our tests running with coverage to showcase the work we have done. 1. <link> 2. <link> Test Coverage: <link> <link>. The project could be run locally by cloning the Github repository <link> and then running the following commands sequentially. <code>. 1. While creating the test for ""reviews_given?"", given below, it seems the function is returning string value instead of boolean value as ""j.class.to_s[/Review/]"" gives a string when the class of ""j"" starts with ""Review"" <code>.","There are lots of spelling/grammer/formatting errors. 
[About Expertiza/About Rspec] -> ok, 
[DbSchema] -> this section seems to have no importance. If it is necessary then more explanation of the schema design and relevance to the project is necessary. The image here is hard to navigate/read. 
[Project Description] -> layout of this section is hard to follow. Indentations indicate wrong subsections for function explanations and testing plan. Simply changing the font for the method name, and inlining the description after the method name, would have improved readability greatly.
Several functions are missing explanation (needs to be consistent). In the test plan, the mock objects are just listed.  It would have been very helpful to have a description of why they were created and how they would be used.  Ideally, that should be done in comments inside the code.  Additionally, why were only some functions elaborated upon? Were these functions more important? 
However, the description of what the tests do is very good, and among the best I have seen this year.  To some extent, this counterbalances the deficiencies in other areas of this report, especially since this is a testing project.
[Video] -> Editing is needed to draw focus to the results of the test rather than spending 3 minutes watching '...'. In general, the overall formatting of the wiki needs to be revised to enhance reader understanding and clarity. Images should be embedded rather than linked and reference as to why they are included. Otherwise, the reader has not motivation to redirect to the image and make connections.","This is a comprehensive and thoroughly detailed project work. It's impressive to see the high level of dedication you've exhibited in understanding and implementing the concepts of the Expertiza framework, Rails, RSpec, DRY code, and Test Driven Development. 

Your document has done an excellent job highlighting the various tasks you've accomplished, including the improvement of path coverage and coverage of edge cases. The focus on testing individual functions within the code is commendable, as it ensures that each part of the program is functioning as expected. Also, your thorough testing of various scenarios is a demonstration of good testing practice. 

Nevertheless, there are areas in your document that need improvement.
For instance, there are a few numbering errors in the list of functions that you tested. Every item in the list of functions is labeled as ""1."", which can be confusing to the reader. Please revise the numbering for clarity. Additionally, it would be beneficial to separate different sections (like explaining framework, functions tested, the actual code used etc.) with appropriate headings for an easier read.

Regarding your challenge with the ""reviews_given?"" method-to resolve this, you might want to check whether the class name of 'j' is among the descendants of the 'Review' class instead of checking whether it starts with 'Review'. This might provide the boolean value you are expecting.

Your work on setting up the environment for the 'student_task.rb' and 'student_task_spec.rb' is commendable, but it is not clear how you plan to increase the path coverage - providing some insights on your approach would make this section more comprehensive. Other than these, your assignment is well-done.

Please keep up the good work, and I'm looking forward to seeing how you tackle the next challenge. Good luck!"
169,E1877,"The following credentials are recommended for testing the changes: 1. Instructor Login: Username: super_administrator2 Password: password 2. Youtube Link: <link> 3. Github Pull-Request Link: <link>. Expertiza is a web portal which can be used to manage assignments related to a course. It provides a platform to view assignments, manage teams, select topics and work on improvement through anonymous peer reviews. Expertiza allows instructors to view kinds of reports of assignments in their courses such as submissions, scores, and review reports. To improve the report views, some table columns such as team name, score, the average should be made sortable by using the same existing sort library. 1. #issue 1: We have to sort “Topic name”, “Team name”, “Team member(s)”, “Links” alphabetically in the “view submissions” table. <image> 1. #issue 2: We have to sort “Team” alphabetically, sort “Average” and “Range” (the first percentage) for “View scores” table, <image> 1. #issue 3: For “View review report” table, we can see that the columns “Reviewer” and “Metric” are already sortable. So we need to make other columns sortable. We have to sort “Review done” by the first number than the second number (e.g., 0/1, 0/2, 0/3, 1/1, 1/5, 2/2...), sort “Team reviewed” alphabetically and sort “Score awarded / Avg. score” (the first percentage) in both ascending or descending order. <image> 1. #issue 4: For “Author feedback report” table, we have to do several changes. The first change includes changing the header name “Review response rejoined” to “Review responded to” and “Last rejoined at” to “Last responded at”. After that we are supposed to sort “Rejoinder” and “Review responded to” as string (alphabetically), sort “# author feedbacks done” by the first number than the second number, and sort “Last responded at” as a date. We will select MM/DD/YYYY as the default format for date. <image> 1. #issue 5: We have to sort the first 3 columns as a string and sort the last column as a date(MM/DD/YYYY) in the “View scores” table <image>. We will be using tablesorter jQuery to sort the table. For table columns which have constraints on them for sorting, we will be creating custom scripts which tablesorter library supports to sort those columns. According to the problem type, we are supposed to perform three kinds of sorting. All these have one thing in common. Adding up the tablesorter script in the body before using them. After including the script, we are supposed to do some modifications in the table tag by including the class. Three types of scenario may arise: 1. Sorting by columns alphabetically - To sort the columns alphabetically, the table-head attribute must include sorter-true class with it to enable the sorting alphabetically. 2. Sorting by date - It includes adding of a date default format in the script to denote the sorter type that must be used to sort the column of the date. 3. Sorting by the first number followed by the second number - It will require splitting up of the data into two parts separated by '/' and then sorting the first part, followed by the second part. tablesorter is a jQuery plugin for turning a standard HTML table with THEAD and TBODY tags into a sortable table without page refreshes. tablesorter can successfully parse and sort many types of data including linked data in a cell. It has many useful features including: 1. Multi-column sorting 2. Multi-tbody sorting 3. Parsers for sorting text, URIs, integers, currency, floats, IP addresses, dates (ISO, long and short formats), time. Add your own easily 4. Support secondary ""hidden"" sorting (e.g., maintain alphabetical sort when sorting on other criteria) 5. Extensibility via widget system 6. Cross-browser: IE 6.0+, FF 2+, Safari 2.0+, Opera 9.0+ 7. Small code size. <image>. The following files were modified: 1. app/views/assignments/list_submissions.html.erb (issue 1) 2. app/views/grades/_team_title.html.erb (issue 2) 3. app/views/grades/_tabbing.html.erb (issue 2) 4. app/views/grades/_team.html.erb (issue 2) 5. app/views/grades/_team_charts.html.erb (issue 2) 6. app/views/grades/_team_title.html.erb (issue 2) 7. app/views/grades/view.html.erb (issue 2) 8. app/assets/javascripts/grading.js (issue 2) 9. app/views/review_mapping/_review_report.html.erb (issue 3) 10. app/views/review_mapping/_feedback_report.html.erb (issue 4) 11. app/helpers/review_mapping_helper.rb (issue 4) 12. app/views/review_mapping/_teammate_review_report.html.erb (issue 5). We have modified the views/assignments/list_submissions.html.erb by adding the tablesorter class in the table tag. Then with the table head, we added suitable classes and added scripts at the top of the file to sort the table contents within the file. Added the following script to the file. <code> Then, we changed the table to this. <code> <image>. We have modified the /view.html.erb, _teams.html.erb, _team_title.html.erb and _team.html.erb by adding the tablesorter class in the table tag. In this section, we were facing some issues and the code was highly unstructured. Also, the JavaScript was not proper in terms of usability and there were some elements which were not working properly as the code was static. We cleaned the code in these four files including the assets/javascripts/grading.js file. To make the view expandable, we made this change to the grading.js file. Also as the view which expanded on clicking of plus sign(beside Team Name) was added as a row, we made it as a columns and are expanding this column using javascript and css. We made this change as tablesorter library was sorting the expanded view as well and spoiling the table structure on sorting the table by Team name. <code> <image>. We have modified the views/review_mapping/_review_report.html.erb file and also added a custom script to sort ""Reviews done"" and ""Score awarded / Avg. score"". To sort ""team reviewed"", we used tablesorter which is similar to the issue#1. Following script has been added for custom sort. <code> <image>. Initially, we referred to /views/review_mapping/_feedback_report.html.erb file for making the changes. In this, we started by renaming the column which was quite easy. Then we applied tablesorter for ""Rejoinder"" and “Review responded to”. For ""Last responded at"", we added the date feature which is set to MM/DD/YYYY format. Again for the “# author feedbacks done”, we used the same script which was used in Issue#3. The script after adding date has been added below: <code> We have demonstrated the implementation part of the image below. You can see the arrow marks beside the table header. This has been implemented with all the other issues as well. You can refer to our YouTube video for further reference. <image>. To solve this issue, we used the same tablesorter jquery plugin as used in issue 1 combined with the date data member as used in issue 4. We have modified the /views/review_mapping/_teammate_review_report.html.erb file to complete the solution. <image>. 1. Login as a super_admininstrator2. 2. Click Assignments tab next to Courses 3. Select the ""View submissions"" icon for the assignment for which you want to see the report of 4. Sort the table by clicking on headers. 1. Login as a super_admininstrator2. 2. Click Assignments tab next to Courses 3. Select the ""View Scores"" icon for the assignment for which you want to see the report of 4. Sort the table by clicking on headers. 1. Login as a super_admininstrator2. 2. Click Assignments tab next to Courses 3. Select the ""View report"" icon for the assignment for which you want to see the report of 4. Sort the table by clicking on headers. 1. Login as a super_admininstrator2. 2. Click Assignments tab next to Courses 3. Select the ""View report"" icon for the assignment for which you want to see the report of 4. Select the ""Author Feedback report"" from the drop-down menu 5. Sort the table by clicking on headers. 1. Login as a super_admininstrator2. 2. Click Assignments tab next to Courses 3. Select the ""View submissions"" icon for the assignment for which you want to see the report of 4. Select the ""Teammate Review report"" from the drop-down menu 5. Sort the table by clicking on headers. 1. <link> 2. <link> 3. <link> 4. <link> 5. Clean Code: A handbook of agile software craftsmanship. Author: Robert C Martin.","The wiki is detailed and well organized, they included many screenshots to explain the changes they’ve made and compare the UIs before and after their changes. However, the UML design document is not UML; it's just a flowchart. They also added more explanation about their solution of sorting one table as suggested in the demo. Most 2nd round reviews gave them the highest scores.","This is a comprehensive project and you have shown an impressive understanding and application of the topic. Your description of the various issues, respective solutions, and testing strategies are noteworthy. 

1. Firstly, you’ve identified and outlined the problems very clearly. This is crucial and sets the basis for solving the problems. 
2. Secondly, not only have you identified and solved issues but also you have made improvements to the existent unstructured code. This shows your proactive approach and commitment to code quality. 
3. Lastly, the presentation of your solution is organized and easy to understand. The visuals you’ve provided ensure easy-to-understand steps and solutions. The testing strategy and steps are also well outlined. 

However, there are some areas that could be improved: 
1. You should always include error handling or mention possible fallbacks in your solution. 
2. The code snippets you’ve mentioned are not visible. Please make sure to include code snippets properly. 
3. It's good you included references to outside sources, but please provide more specifics like page numbers or chapters, so people can look more into the topic if they want to.

Overall, it's a job well done, keep it up!"
170,E1822,"The aim of this project is to extend the functionality of badging that was implemented previously. [ <link> ]. The primary objectives for this project are as follows: 1. Allowing Instructor to create new badges - which involves adding name and badge image and letting the instructor add them to the assignment 2. Students must be able to suggest ""Good Teammate"" badges during the teammate review periods. 3. Students must be able to suggest ""Good Reviewer"" badges, for reviews received. 4. Create a pipeline to enable instructor to manually approve badges suggested by students. The use of badges will encourage students to have a visual motivation based on their achievements and thus perform better. This has the ability to improve the overall class performance. With such an aim of improving the over all class performance, badging system for Expertiza was implemented, as an [ <link> ]. In that implementation, certain students are awarded badges when certain criteria are met which may include exceptional academic performance in assignments, project submissions etc. Two such badges, Good Reviewer and Good Team mater were implemented, with students receiving them automatically based on a threshold score in those categories. This was a static system with fixed number of badges. The team had implemented the system, by introduction of 3 new badge related tables 1. “badges” :- id , name, description 2. “assignment_badges” :- id, badge_id, assignment_id, threshold 3. “awarded_badges” :- id, badge_id,participant_id. The primary motivation behind this project is to give more flexibility to the instructor to assign badges instead of relying solely on automatic scoring. Also, allowing students to suggest Good Teammate and Good Reviewer badges for their peers will give them an incentive to put in more effort towards carefully reviewing other's work, and encourage them to actively participate in team projects. The following steps briefly describe the implementation steps taken during the course of this project. Two major flows exist in this project , one being new badge creation and associating them with the assignment. Second one is modifying the flow for good teammate and reviewer badges to be present in appropriate question section. <image>. When an assignment is created/edited, there is a checkbox called ""Has Badges?"" . Checking this renders the ""Badges"" tab. This tab currently lists the two available badges namely ""Good Reviewer"" and ""Good Teammate"" as specified in expertiza/app/views/assignments/edit/_badges.html.erb . To add a new badge which is a new functionality, we display a button, at the end of the badges tab, which redirects the user to a page enabling him to create a New badge. The new form fields include Badge Name , Image and Description . Upon saving the user is again redirected back to the earlier assignments display display. <image>. We change this view to allow an instructor to add a new badge, and select all badges that will be applicable to this assignment. The view is changed to display all the available badges and a check box to select each of them. It was initially present as a badge vs threshold display. Once the user clicks save, entries are modified in the data base. <image>. Similar to Good Teammate badge, in the existing workflow, good reviewer was also assigned based on score and threshold. This is modified in our implementation, in a similar way as that of teammate badge. We add a ""Good Reviewer check box"" as a question in the feedback of the reviews given page. An entry is made to the awarded badges table with the approval status as 0. Once this field is changed to 1, it would display badges in the assignment row . <image>. Currently, the awarded_badges table has no column to indicate the approval status of an awarded badge. A db migrate was run to include this column. Once approved by the instructor, the badges assigned would be visible in the assignment tab of the website as shown in the image. Badges corresponding to each of the assignments will be seen on the row of that particular assignment. <image>. 1. expertiza/app/models/assignment_badge.rb - create badges without threshold method was added 2. expertiza/app/models/assignment_form.rb - update assigned badges method was added. this method modifies the db entries for assignment_badges table based on the checkbox entries 3. expertiza/app/models/awarded_badge.rb - suggest badge method was added, which is called when badge is suggested by student by checking the checkbox in questioner. 4. expertiza/app/models/badge.rb - functionality to get image name from name was added. 1. expertiza/app/controllers/assignments_controller.rb - Modifications were done to include the functionality of displaying all badges in the badges tab and check box based selection process 2. expertiza/app/controllers/badges_controller.rb - This was a new file added in this implementation . Code on handling new badge creation, in create method was added. 3. expertiza/app/controllers/response_controller.rb - Modification to process question responses from checkbox about badges were added to this file. 1. expertiza/app/views/assignments/edit/_badges.html.erb - Modification to display all available badges to badges tab as checkbox was done. Also a link to creating a new badge is provided 2. expertiza/app/views/badges/new.html.erb - New file to create a new badge was added to this file 3. expertiza/app/views/badges/_form.html.erb - New file to create a form for badge was added to this file 4. expetiza/app/views/response/response.html.erb - Modification to display checkbox questions in review questioner was added to this file. 1. Add a new column 'approval_status' in the awarded_badges table. 1. Routes for badges was added. New rspec file was added in spec/models/badge_spec.rb. Test cases were written to validate the different conditions of creating a new badge. Here are the test cases: 1. it is valid when it has a name, description and image name 2. it is invalid when it does not have a name 3. it is invalid when it does not have a description 4. it is invalid when it does not have an image name. 1. The approval workflow is currently missing - when a student assigns a badge to a peer, the approval status is set to 0 and it will never appear in the other student’s homepage. Workflow to change the status by the instructor must be implemented. 2. There is currently no way for a newly created badge to be assigned to a student through the UI, even if it has been added to an assignment. This needs to be implemented. 3. Instructors cannot directly assign “Good Reviewer” badge through the UI. A separate flow to enable instructors to do that would be useful. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.","The explanation has been improved, and the design document covers most of the bases.  However, it is still weak at describing the working of the code; there is just a listing of files changed, without an explanation of how the added functionality required making these changes.","Dear Student,

Well done on this comprehensive submission! It's clear that you've put a significant amount of effort into this project, and it shows. Your in-depth analysis and detailed explanation of the new badge functionality you've implemented illustrates a good understanding of the system requirements. 

I appreciate the level of detail in your explanation of the existing and new functionalities in this project. Your proper annotation of the changes made and how these relate to the overall project objectives is excellent. The way you've outlined the new functionalities and associated them with the respective codes represents a clear understanding of your work. 

I also commend you on the inclusion of test cases for the new functionalities and the identification of areas that require further development. Your critical analysis of the current limitations and how these could be addressed in future iterations of this project is exceptional.

However, it would be more beneficial if you could share more about the challenges faced during the implementation of new functionalities and how they were addressed. This helps understand your problem-solving skills and resilience.

As next steps, I encourage you to explore the missing features mentioned, especially in terms of the approval workflow and the direct assignment of badges by instructors. 

Thank you again for your diligent work. This project shows your deep understanding of this topic, bu more importantly, your technical and practical skills in implementing a project of this complexity from inception to completion. Keep up the excellent work!

Best,
[Your Name]"
171,E1907,"Expertiza is an open source webapp that was built on Ruby on Rails stack. It provides a platform to students with various features like peer-reviewing projects, submitting work, form teams, viewing grades, etc. The project is maintained by students and faculty at NCSU. The file response_controller.rb handles the operations on responses based on user permissions. The user is redirected to the appropriate place on Expertiza after the action is complete. The responses are from the completion of peer reviews and questionnaires. The controller takes care of tasks such as creating, saving, editing, updating and deleting these responses. The problem statement for E 1907 can be viewed here <link> The pull request of our project can be viewed here <link>. Problem: edit_allowed function The function name is misleading - it checks if the response can be viewed by a person or not. Refactor to a more appropriate name. <code> Solution: The edit_allowed? function was renamed to view_allowed? in the response_controller.rb file. <code>. Problem: Move the pending_surveys function to survey_deployment_contoller.rb. Ensure that moving the function does not break the code functionalities. The original code for the pending_surveys method in the response_controller.rb is shown below. <code> Solution: Moved the pending_surveys function to survey_deployment_controller.rb Made changes in the following files and folders: 1. app/controllers/survey_deployment_controller.rb (the pending_surveys method was moved to this file) 1. app/controllers/response_controller.rb Original - <code> New - <code> 1. config/routes.rb Original - <code> New - <code> 1. spec/controllers/respose_controller_spec.rb Original - <code> New - <code> 1. Moved pending_surveys.html.erb from views/response to views/survey_deployment. Problem: The assign_instance_variables method violates several principles - The method is doing two things, and the method is not really needed at all. It is called only in two places and does entirely different things based on where it is called from. The original assign_instance_vars method is shown below: <code> Solution: The assign_instance_vars method was removed as it was not needed. The logic from this method was combined with the Edit and New sections as shown below. The edit method with modifications. <code> Moved assign_instance_vars for the New action inside the new method : - <code>. Problem: In the create() code in create method, especially the was_submitted and is_submitted part, is hard to understand. It can be cleaned up. The original code of the create method is shown below. <code> Solution: The first instance of was_submitted was removed. This variable was renamed to previously_submitted in the other lines of the create method. The purpose of this variable is to determine if the response was previously submitted or the submitted response is a new response. These changes are shown in the code below. <code>. Problem: The private methods have few to no comments. Solution: Comments were added to the private methods as shown below. <code> <code> <code> <code> <code> <code> <code> <code>. Problem: Redirect method has a if-else ladder. See if it can be refactored to something more understandable. Originally, the redirect method was :- <code> Solution: A local variable was created to hold the description of the action to be taken by the redirect method. The if-else ladder was transformed into a switch (case) statement to make the code more legible. The modifications to the redirect method are shown below. <code>. The test file used for the response_controller.rb was located in the */spec/controllers/response_controller_spec.rb. This test was previously created from a different project. However, the test file did have to be modified since the pending_surveys method was removed. The following snippets of code show the modifications to the test file. Original content: <code> Modified content: <code> There were no observed failures after performing the modified test. After completing the changes to the code, the code modifications were committed to GitHub. Then, a pull request was performed on the committed code. During this process, two automated bots were used to analyze the code. These bots were from Code Climate and from Travis CI. The Code Climate bot did not detect any major errors with the code. However, it did comment that the code complexity was too high for some methods. Since our team did not make any changes to these sections of code, no additional changes were made to the code to resolve the complexity concerns. The logic for the code appears to be working and it was uncertain how the logic could be further reduced to lower the code complexity score. The second bot, Travis Ci, performed four different analysis cycles on the committed code. It reported that the code passed its inspection with no issues. 1. The problem statement for E 1907 can be viewed here <link> 2. The pull request for this assignment can be viewed at: <link> 3. Team Branches: All the three team members have contributed towards the project and their branches can be viewed here <link> 4. Screencast: <link> 5. Expertiza Main Repo <link> 6. Expertiza Documentation <link>.","The descriptions of most of the changes are clear.  However, the project asked you to add comments where needed, and very few of these comments or descriptions appear in the design doc.  You did include method comments for private methods, but not the bodies of those methods, which makes it hard to see the value of the comments.","Overall, this assignment demonstrates impressive depth of analysis and critical thinking. You clearly understand the issues at hand and worked diligently to troubleshoot and address them. Your solutions reflect your attention to detail.

Your knowledge of programming languages and concepts is noteworthy and your practical application of those skills to optimize and improve the Expertiza project is commendable. Also, you did a fantastic job explaining the thought process behind each decision you made, which made it easier to understand the problem and solution.

Several areas stood out as particularly strong:

- Indicating the issue and then outlining your specific approach to resolution
- Demonstrating how to handle error messages and failed tests
- Effectively utilizing automation to improve your project's quality
- Successfully migrating methods between classes in a way that improved the application logic
- Additionally, using the test suite to ensure your code doesn't break any existing functionality is a great practice.

There were a few areas where more annotation would be helpful:

- The code snippets are a great addition, but please ensure to include both original and revised code. This will allow for a side-by-side comparison of what was initially written and what it was replaced with.
- A few lines/sections of code did not have comments, and this might make the code harder for others to understand. It will be beneficial to include as many comments as possible to explain specific lines or sections of your code.
- Additionally, while it's great that you noted the complexity issue found by the Code Climate bot, it might be beneficial to further investigate methods to reduce this complexity.

Despite these minor areas, your submission is overall quite strong. I can see the time, effort, and thought you put into this assignment, and I commend your commitment to creating quality work. Well done!"
172,E1559,"Code refactoring is process of changing the code to make it more maintainable, without changing the functionality of the code. Some of the reasons for performing refactoring are: 1. To remove duplicate code. 2. To make the code more maintainable. 3. To divide functionality of the class. Expertiza is a web application where students can submit and review learning objects like code, writings, etc. It gives scope for creation of reusable learning objects. Students submit assignments, which can than graded through peer reviews. The Expertiza project is supported by the National Science Foundation. JoinTeamRequestsController and InvitationController. invitation_controller.rb is used by a user to invite other users to join his/her team. It performs validation before creating a request. Following chunk of code checks whether the user is allowed to get the invite or not. <code> Now, invited user can accept or reject the request. Once the user has accepted the request, he can be seen as a part of the team. join_team_requests_controller.rb is used when user decides to join a team. This is achieved by creating an advertisement for the team. Once the advertisement is created, it is shown in the Topic Selection section. The user who wants to join the team can send a ""Request"" to the members of the team. The members can then decide whether to send him/her an invite or decline the request. The invitation_controller.rb is doing the required task but it is difficult to understand the code, hence it becomes difficult to maintain the code. And the functions in the accept and create method can be broken down into separate methods. In join_team_request_controller.rb has duplicate code in various methods which can be removed by creating a separate method for this common code. invitation_controller.rb 1. Rename to Invitations_Controller.rb, as is not in accordance with current naming convention. 2. Add comments explaining what each method does, and comments on how important variables are used as currently there are no comments. 3. Refactor create and accept methods. Shorten and clarify them by adding private methods, as create and accept methods currently have a lot of code. 4. Change the find_by_sql call(s) to Rails (Active Record) statements. 5. Make sure that it can be used by a user with a TA or instructor account, if they are participating in this assignment. 6. Change grammatically wrong or awkward flash messages. join_team_requests_controller.rb 1. Add comments to the code. 2. Remove duplicate code, from create and accept methods. 3. Decline and destroy method should check for successful operation before returning. 4. Change grammatically wrong or awkward flash messages. The controller renaming had to be incorporated in different files of the project. The table contain the file names along with the lines before and after the changes. <table>. <table>. <table>. <table>. To test the functionality of join_team_request_controller and invitations_controller, please follow the steps provided in the video below. This video covers the functionality of how these controllers work. This will help in manually testing the functionality. <link>. <link> <link> <link> <link> <link>.","As to what's been done, there are only tables and no explanatory text.","The assignment you've submitted demonstrates a good understanding of code refactoring and its importance in making code maintainable and efficient. Your work delving into Expertiza's controller files to provide detailed suggestions for improvements is commendable. Your well-reasoned and detailed strategy for improving specific parts of the code (like renaming the controller to follow a more conventional naming pattern, adding necessary comments, refactoring specific methods, etc.) clearly demonstrates your grasp of enhancing existing codebases.

You also managed to catch potential bugs like failing to validate successful operations where needed, flagging either incomplete error handling or none at all. This is a great point, as it shows you are considering other aspects of code quality too.

However, there's room for improvement. The assignment would benefit from a more streamlined structure and clearer language. Organize your thoughts and points better to avoid jumping from one point to another and back.

Your tables should also have clearly defined headers and values -- currently, they seem to be missing data. Please make sure to include the necessary information in them. However, I assume from your context that those tables recorded the changes you've made, which is a good practice.

Regarding the videos you referred to for testing the functionality, please provide a brief summary or key points viewers should pay attention to, as it would help understand their importance and role better.

Keep up the good work, I am looking forward to seeing more of your analyses and code improvements."
173,E1870,"Expertiza supports multi-round peer reviews. Currently, in this situation, student who did not do the previous round peer reviews can still do the subsequent round peer reviews, but will lose about 50 points according to the deduction policy. Therefore, it will be fairer to provide instructor an option to decide whether a student can do the subsequent round peer reviews when s/he did not do the previous round peer reviews. In assignment#edit page “Review strategy” tab, add a checkbox (e.g., “Allow student to join reviews late”*) to allow instructor to decide whether students can do the second round peer reviews without the first round peer reviews; by default this box is unchecked and it only appears when there are multi-round peer reviews. 1. Before <image> 1. After <image>. Currently, when students didn't request enough reviews(e.g. Each student is required to do at least 2 reviews, but s/he only request one in the first round), they can still request more reviews in the second round, but will lose points due to lack of first round reviews. Now, we want to add a functionality to split the case. Below is the flow chart that explains the improvement. * Note that whether submit or not doesn't matter, as long as request, it counts. <image>. 1. First, check whether a certain assignment is multi-rounds Go to expertiza/app/models/assignment.rb, find the following function <code> <code> check current rounds, if >=2, then checkbox can be clicked. 2. Then, Edit the database Go to DB, add an attribute named 'is_second_round_allowed_checked' to assignment 3. Finally, add the function Go to expertiza/app/models/assignment.rb, add a function called 'allow_second_round_review'. When rounds <2, do nothing; else, allow second_round reviews if box checked. 4. Change the view of student_review as following: <code> where the second if-statement ensures that the student can only have request option during first peer review round or get the permission from instructor during second or more round. We plan to write a feature test for the project. Go to expertiza/spec/features folder, add a file named 'Allow_second_round_review'. Below is the details of our test. 1. Log in as instructor 2. Navigate to “Manage…”,then “Assignments” 3. Under “Actions”, choose “Edit” 4. Navigate to “Review Strategy” 5. See the checkbox “Allow student to join reviews late”. 1. Log in as student 2. Navigate to “Assignments” 3. Choose an assignment 4. Navigate to “Others’ work” 5. Student cannot do the second review without the first one. 1. Log in as student 2. Navigate to “Assignments” 3. Choose an assignment 4. Navigate to “Others’ work” 5. Student can do the second review without the first one. <link> <link> <link> <link> <link>.","This is a good description of the code changes that were made.  The changes were not extensive, but  they are cited directly in the design doc.  The test plan could have been elaborated similarly.  But no code is shown for it.","Dear Student,

Great job on the assignment! You've demonstrated a good understanding of the Expertiza system and came up with practical improvements for multi-round peer reviews. 

Your detailed explanation, including step-by-step implementation plans, was communicated effectively with clarity and depth. The flow chart was an excellent addition and greatly helps visualize the steps involved in the process.

Your approach to handle late entrants for peer reviews seems fair and takes into account different round situations, which shows thoughtful consideration. Furthermore, the specification of a feature test to validate the functionality shows your dedication to the high quality of the product.

However, please be careful about including mock code in the assignment without a proper code block. Proper formatting would make it easier to read. Also, a more thorough explanation of the test cases in your testing plan would result in a more robust application. 

Furthermore, while it is great to see your included hyperlinks, it would be helpful to label these with a short description instead of just '<link>'.

Overall, great work on this assignment. You have demonstrated clear understanding and creativity in improving the system. Keep it up in your future projects too, while considering the feedback.

Best regards,
[Your name]"
174,E1825,"Expertiza is a web application where students can submit and peer-review learning objects (articles, code, websites, etc). It is used in select courses at NC State and by professors at several other colleges and universities. -- Expertiza project. The E1825 project is a course project for CSC 517 - Object Oriented Development and Design for Fall 2018. It involves adding some enhancements to the existing system. The primary goal of this project is to differentiate past due assignments from current assignments. The tasks to be completed are as follows:- 1. Add past due assignments to the student’s task list (on Student View). 2. Color code assignments by closeness to due date (on Student View). 3. Check for correction in due dates of assignments (when an assignment’s due date is edited, it should be appropriately moved from the “Past assignments” list to the “Current Assignments” list if needed) 4. On Student Task page, separate the list of 'teamed with' students from the current tasks box. 5. Write the required tests before implementing/refactoring the methods in the above-mentioned classes. student_task_controller.erb app/views/student_task/list.html.erb student_task_helper.rb Airbrake_exception_errors_feature_tests_spec.rb. will_paginate_array_fix.rb student_task_controller_spec.rb. The existing system contains the view where all the assignments of a student are displayed as a single list regardless of their due date. Now we have created a separate table for assignments that are overdue by the student. The displayed list is such that the most recent due assignment is shown at the top. To accomplish this task we have modified student_task_controller.rb and list.html.erb file (in student_task). A helper function was also added to format a string into multiple lines. In student_task_controller a new instance variable was created to capture all the student tasks that are overdue in ascending order of dueness. The existing instance variable was used to capture all the tasks that are currently due. In the view file i.e list.html.erb, a new table is created to contain a list of past assignments. The current task-table on the homepage contains all the assignments displayed in white background. So to alert the user of approaching deadlines, we color code the background of each assignment title as red, orange, yellow or green depending on the proximity to its deadline. To accomplish the above-mentioned task, we added a helper method for student_task_controller that receives a due_date and calculates the days remaining for that date and then using this value it returns a string which denotes what should be the background of the row. Separate the list of 'teamed with' students from the current tasks box Currently, the current task lists and the student you have teamed up with are being shown in the same box. We need to separate these two. To achieve this we create an additional box, by adding a new ""taskbox"" div tag in list.html.erb. So the task list and the teammates are shown in different boxes. You can find the snapshot of the changes here: <link> <link>. Our project involves mostly changing the view based on certain conditions. The testing of our project is based on simply checking whether the elements on the view change after a certain condition is satisfied, like changing of the background color for tasks as we approach the deadline. For example, if the due date is within a day, then the background color should be red or if it's more than 10 days it should be green.","The strategy to fix the issues is not clearly laid out. The authors have also not included any sample output / screenshots. The project revolves around changes in the UI so screenshots would have a gone a long way in helping a reviewer understand what the project was about.

Several reviewers also think the test plan is inadequate

Code snippets are included as png images, instead of text. Overall, the structure of the document does not look very organized.","Dear student,

Excellent work on the Expertiza project. You understood and addressed everything that was required of the assignment. You have described your thought process very well, and your focus on providing more context helps bring your reasoning to the foreground. 

There are some aspects I would like you to consider:

1. I noticed that most of the work done is centered around the front-end, dealing with features such as changing background colors and separating lists. While the changes you have implemented are important and help to improve the user experience, it would also be beneficial to shift your attention towards improving some of the back-end processes.

2. The second enhancement asks you to color code assignments by closeness to the due date. Although you have implemented this feature well, you could have elaborated more on how the colors are chosen and what specific conditions are used to determine this.

3. Another aspect worth mentioning is the testing part. You mentioned that you are simply checking whether the elements on the view change after a certain condition is satisfied. While this works in most of the cases, considering a more robust testing mechanism that also includes handling possible edge cases would be better.

Final point is related to your presentation. It's fairly dense, you could improve it by breaking the content into shorter paragraphs for easier reading. 

Overall, this is a significant piece of work, and you made good progress throughout the project. It is clear you have strong understanding of the concepts taught in class. I look forward to seeing your future projects.

Keep up the good work!

Best,
[Your Name]"
175,E1614,"This page provide the details of the changes done as part of the refactoring response controller project(E1614). Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.1.4. <link> 1.1.1.5. <link> 1.1.5. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.6. <link>. <link> project is a platform to create reusable learning objects through peer review. It is an open source project which uses <link> framework. The main aim of this project was to refactor the response_controller. The following tasks were completed as part of refactoring in this project: 1. Moving variable declaration to right places. 2. Removing unused variables. 3. Fixing code duplication. 4. Replacing if else block with switch statements. 5. Remove the unreachable code. The Response controller is responsible for the CRUD (Create, Read, Update and Delete) operations on responses. The users can fill out a questionnaire such as review rubric or feedback on the partner's contribution. So the ResponseController handles the various operations on the responses, which are objects that Expertiza creates when you fill out a questionnaire. There were two variables ""msg"" and ""error_msg"" in the create method which were declared and initialized to blank strings and then again assigned some string value before it was used in the method. So we moved the variable declaration to the place were it was used and removed the unnecessary variable declaration. Below if the code snippet for the changes done: <code>. There were some unused variables in this controller. The edit method contained a variable ""array_not_empty"" variable which was not used anywhere. So we removed the unused variables. There was some duplicate code in the update method. So we removed the duplicate code and retained the code snippet inside the if block. Below is the modified code for the update method: <code>. The redirection method used the if-else statements. The if-else block was replaced with switch statements. Below if is the code snippet for the redirection method after the code changes: <code>. In the action_allowed? method of the controller there was a case for the ""edit"" case which was getting executed all the time making the second case block unreachable. Modified the code to use the proper case statements for ""edit"", ""delete"" and ""update"". Below is the code snippet for the action_allowed? method after the code changes: <code>. As the main motive of the project was refactoring the response controller, we list down below the steps to test the flows involved with response controller so as to make sure that nothing is broken due to changes done as part of refactoring and the functionality as expected. 1. Login as a student user. 2. Click on the Assignments tab and Select the assignment you want to submit review for others work. 3. In the assignments page click on others work and select one of the assignment for review. 4. Click on Begin and then answer different questions which are presented in the review rubric. 5. Once done with the review, click on Submit review to submit the review. 1. Login as a student user. 2. Click on the Assignments tab and select the assignment you want to submit the teammate review. 3. Click on the your team option. 4. In the teammates page, click on the Review option against the user you want to submit the feedback. 5. Fill out the questionnaire presented in the teammate review rubric. 6. Once done with the responses, click on Submit review to submit the review for the teammate. 1. <link> 2. <link> 3. <link>.","The code snippets are rather large, and they really don't show the changes done.  They seem to be the ""after"" view.
It would be better to show before & after side by side, as is shown in Github.","Dear Student,

Thank you for your clearly structured presentation of your assignment on refactoring a response controller project. It's clear that you've understood the essence of software refactoring well and applied it in your work. You have meticulously illustrated your process, explaining the purpose of each task and its accomplishment with impressively organized code snippets.

However, there are a few areas that could be further improved. Firstly, your assignment contains an abundance of links that don't seem to lead anywhere or provide relevant information for the task at hand. If these are references, they should be clearly labelled as such, and should direct the reader to pertinent and operational sites.

Secondly, while you have included a decent level of detail in your explanation about the refactoring process, I suggest adding more about the reasons behind certain choices. Why, for example, did you switch from using if-else statements to using switch statements? What would be the advantage of the latter over the former in this context? This would give the reader a better comprehension of the logic behind your work.

Lastly, your testing steps at the end are well crafted but could be more detailed in stating what outcomes the user should expect to see. Adding expected results for each step would assure that the test is going as planned and the changes didn't break any functionality.

Overall, I appreciate your dedication to this project. With a bit more clarity and detail, your explanations can go from good to great. Keep progressing at this fine pace!"
176,E1641,"This controller sets up mappings between reviewer and reviewee. It handles all different types of response maps (review response map, author feedback response map, teammate review response map, meta review response map and quiz response map). The class has functionality for five different kinds of Responses: reviews, metareviews, teammate reviews, author feedback (“rejoinders”), and quizzes. The controller has many methods and involve with many other controllers and views, the code is long and complicated. Some of the methods in this controller have unreasonable name associated with their functions, some methods are too long, some methods haven't been used by any other methods or views. Our work is to refactor these problems and make the code more beautiful. The problems are: 1. The class has functionality for five different kinds of Responses: reviews, metareviews, teammate reviews, author feedback (“rejoinders”), and quizzes. Method names for dealing with the 5 different kinds of objects should be as similar as possible, and they should share helper functions when possible. 2. Method response_report has some SQL - like code. Rewrite with Active Record. 3. Test whether method add_user_to_assignment is used. There is no way that this method should be in ReviewMappingController. Please remove this method and caller. 4. There was a self-review feature, the method add_self_reviewer , get_team_from_submission are related to this. Two views calls add_self_reviewer are ""show_available_submissions_for_quizzes.html.erb"" and ""show_available_submissions.html.erb"". The names of views are not related to self_review feature. Plus those two views are not called anywhere. Please verify this and if so, you should delete those two views, two method and also related records (e.g. in routes.rb). 5. Method delete_all_reviewers actually only deletes the outstanding review response maps (the ones which has been initiated, but there is no response yet). So it should better be named delete_outstanding_reviewers . You can try to test this method by clicking “Assign reviewers” icon on an assignment. 6. Method release_reservation should be renamed as release_mapping . In addition, delete it if you find this method is not called anywhere. 7. Method delete_mappings is problematic. It does not looks like a controller method. Please refactor it or delete it if you can validate that this method is not called anywhere. 8. Method automatic_review_mapping_strategy is too long. Please refactor and test it. 1. Merged add_reviewer and add_metareviewer to add_reviewer. Merged delete_reviewer and delete_metareviewer to delete_reviewer. Modified delete_all_metareviewer to delete_all_reviewer. Based on the TA's requirement, we implemented this part on the other GitHub pull request. <link> 2. Change the rails query from sql like code, like ReviewResponseMap.where(['reviewee_id = ? and reviewer_id = ? ', params[:contributor_id], reviewer.id]) to more rails quey like ReviewResponseMap.where(reviewee_id: params[:contributor_id],reviewer_id: reviewer.id) 3. We search the function name( add_user_to_assignment ) in the whole files, and find that this method is invoked in ""participants_helper.rb"", and also being invoked in the function of add_reviewer and add_metareviewer in the controller of review_mapping_controller 4. By searching the whole project and routes, we verify that methods add_self_reviewer and get_team_from_submission in this controller are not called by any other methods except for views ""show_available_submissions_for_quizzes.html.erb"" and ""show_available_submissions.html.erb"". And those two views are not linked to any other views. So they are deleted from the project. 5. We already renamed method delete_all_reviewers to delete_outstanding_reviewers and changed the corresponding button name at the corresponding view (_list_review_mappings.html.erb). 6. By searching the whole project and routes, we verify that methods release_reservation in this controller are not used in anywhere. 7. By searching the whole project and routes, we verify that methods delete_mappings in this controller are not used in anywhere. 8. Method automatic_review_mapping_strategy have many long lines. We already shorten each long line to multiple lines. And also, we split this long function into three different functions. The rails query we change in this controller: 1. From <code> To <code> 2. From <code> To <code> 3. From <code> To <code> 4. From <code> To <code> 5. From <code> To <code> 6. From <code> To <code> 7. From <code> To <code>. <code> <code> <code>. <code> <code>. def delete_reviewer <code>. def delete_all_reviewers <code>. 1. We test Refactor of add_reviewer, add_metareviewer, delete_reviewer, delete_metareviewer and delete_all_reviewer both from UI and Rspec. Here is a link of the UI test. <link> . Also, you can check the code of this pull request. <link> 2. We test delete_outstanding_reviewers refactor from the UI. Here is a video for this test. <link> 3. We use some data to test the result of old query and new query in rails console <code> <code> <code> 1. We write RSpec feature tests to prove that all changes are correct and the project performs well as before. All tests have passed. Automatic_review_mapping method The function of method automatic_review_mapping is to automatically assign reviews on students in teams when instructor set either student review number or submissions review number. There is constraint that only one of the two numbers must be set value other than 0 (that is, one is 0 and other is not 0). To test the correctness of our refactoring, we design a scenario and 4 cases of assigning reviews to students: Case 1. Instructor has not set both students review number and submissions review number (They are both 0). The page will show a notice. Case 2. Instructor set both numbers (They are both not 0). The page will show a notice. Case 3. Instructors set students review number. The controller will change database: create new relationship in ReviewResponseMap. For example, if assign student review number to 2, and there will be 20 peer reviews in total and need to allocate to 3 teams. So each team get 7 reviews on average and 1 team’s artifact will be reviewed 6 times. Case 4. Instructors set submissions review number. The controller will change database: create new relationship in ReviewResponseMap. For example, if assign submission review number to 3, and there will be 21 peer reviews in total to allocate to 10 participants. So every participants get 2 reviews. 9 among 10 participants will review 2 teams’ artifacts and 1 participant will review 3 teams’ artifacts. require 'rails_helper' <code> <code> <code> <code> Refactoring add_reviewer, add_metareviewer, delete_reviewer, delete_metareviewer, delete_outstanding_reviewers and delete_all_metareviewers Since we merge methods have similar functions, we need to test their functionality. Here is a feature test work flow include those refactored functions. <code>.","There is a good description of the needs and of how the code has been changed.  This is exactly what we wanted.  However, it is not very effective to juxtapose ""before"" and ""after"" versions of the code without any annotations showing changes.","Thank you for the thorough and detailed walk-through of your work in refactoring this code. Your approach to identifying problematic methods and instances of code, such as lengthy methods or unused methods, is well executed. Your explanations, justifications for each step, and your methodology in merging and renaming to make the class more manageable is a very instructive approach for code organization and readability.

I appreciate your effort in renaming confusing methods, simplifying lengthy ones and getting rid of those that are not being used anywhere. Your initiative in improving readability and maintainability of the codebase is commendable.

I also commend you for testing all the changes you've made and even writing RSpec tests to ensure that the updated class still functions correctly. Details of your test cases are very thorough, showcasing an excellent understanding of system performance. The testing you have done to ensure the functionality has not been compromised by your modifications are highly appreciated.

I found the section about your testing strategy, specifically when discussing automatic_review_mapping, particularly enlightening. You're considering all the edge cases, which is impressive.

However, there are code snippets labelled ""<code>"" which are not connected to any codes, which makes it confusing. Therefore, make sure all of your code examples are correctly filled in or replaced with a proper abstract next time. 

Overall, Great job on this assignment! I look forward to seeing more of your code in the future."
177,E1763,"Expertiza is a web application developed using Ruby on Rails that serves as a peer-review system. The application allows students to submit and peer-review learning objects (articles, code, web sites, etc). It is an open source project and it's codebase is maintained in GitHub. We are contributing to Expertiza as a part of our Object-Oriented Design and Development's Open-Source Software (OSS) Project. Our goal in this project is to fix various issues related to staggered deadlines for assignments. A staggered-deadline assignment is an assignment in which different topics have different deadlines. In this Wiki Page, we will explain the changes that we have made for the same. Currently, the system requires the instructor to enter, manually, all submission and review deadlines for all topics. It would be better if the instructor could enter the deadlines once, and have them be applied to a specified set of topics. We were also asked to create a ""Duplicate Topic"" button for the instructor, to copy a particular topic within a assignment. Currently the assignment topics are displayed on the basis of ""first created"". Thus we have to sort the topics sorted based on the topic_identifiers. Testing is not a requirement of this project. Motivation Currently when the instructor wants to assign the same deadlines to certain topics, s/he has to manually enter all deadline dates. Each deadline includes date and time. Now if there are review rounds (which we assume there are), the instructor will have to enter all dates manually. This task is time consuming and just wasted effort. It will be more efficient to have a method where the instructor can assign this deadline to certain selected topics from the assignment. In an assignment that has staggered deadlines, say a topic has 3 slots. For the first round only 1 slot was taken. Now in the second round, another team wants to sign-up for the topic. This team will not be allowed since the deadline has already passed, even though slots are available. The solution to this problem is to let the instructor duplicate a topic with remaining slots and set the duplicate topic deadline to the latest deadline of all topics(default) or any date that s/he wants. The current display of topics is not intuitive in the sense that say, topic 1.1.1 was created after topic 2.1. Now the newly created topic (1.1.1) will be displayed after 2.1. Thus, we will display the topics sorted according topic identifier. If a topic is created without identifier it will be displayed before all the topics with identifiers, on the basis of ""first created"". Modified Files 1) app/controllers/sign_up_sheet_controller.rb 2) app/views/sign_up_sheet/_due_dates.html.erb 3) app/helpers/sign_up_sheet_helper.rb 4) app/views/layouts/application.html.erb 5) app/views/sign_up_sheet/_all_actions.html.erb 6) app/views/sign_up_sheet/_add_signup_topics_staggered.html.erb 7) app/views/sign_up_sheet/_add_signup_topics.html.erb Approach Taken To Implement Changes 1) For the first issue where the instructor was forced to enter due dates manually for each topic, we have added a checkbox against each topic in the assignment. The code for this was added in the due_dates.html.erb file. We have also provided a text box at the end for the instructor to enter the due dates for the selected topics. This text box is auto-populated with the latest deadline of all topics in that assignment, thereby saving the instructor the hassle of having to enter all the fields from scratch. Then we have updated the save_topic_deadlines method in the sign_up_sheet_controller. This is the method called when we want to save the new deadline entered. The logic we have used to modify due_dates.html.erb: Add a checkbox tag before each topic.Also, if the checkbox is checked add the topic_id to an array ""selected_ids[]"" <image> Provide a text box for the instructor to enter the new deadline for the selected topics. <image> The default deadline for the textbook is set to the latest deadline among all the topics under the assignment. This is achieved by a helper method <image> Call the save_topic_deadlines controller method with this array and entered date as parameters The logic used to modify save_topic_deadlines: Receive the array of selected topics and new deadline from the view Loop over each of the topic. Assign the new deadline from the text box to the topic that has a selected checkbox <image> 2) Along with the check-boxes, we have also implemented shift+click for topic selection. Without it the instructor would have to select each topic individually. Thus with this, if the instructor selects a single topic, then presses shift and selects another topic, then all the intermediate topics will also be selected. This saves the instructor the hassle of going and explicitly selecting each topic. This is achieved using a javascript written in the due_dates.html.erb. The logic is: Get the checkbox selected by the instructor If shift key was pressed, get the last checked checkbox. Loop over each checkbox between the two checkboxes and change the status of each checkbox to selected. <image> 3) We have also sorted the topics that are displayed for the assignment based on the topic_identifier. Managing a number of topics which are all out of order can be troublesome. Currently the topics are displayed in the order in which they were created which is not intuitive. Say the instructor first creates a topic with identifier ""4.1"". Second s/he creates another topic with identifier ""1.2"". Intuitively the newer topic must be displayed first. This is not the case in the current version. Thus we have added that. This is achieved by adding a simple line to the views of the topics. (i.e add_signup_topics_staggered.html.erb and add_signup_topics.html.erb) <code> We use the inbuilt method .order with the parameter :topic_identifier. 4) To implement ""duplicate topic"" button, we have added the button under the actions menu for each topic in the sign_up_sheet/_all_actions.html.erb view file. We have taken the following design decisions regarding the duplication of topics: -> If all the slots are available for the particular topic, then instead of duplicating a topic, the instructor can just extend the deadline and allow students to signup. -> If no slots are available, then the instructor will first have to increase the number of slots and then try again. To implement this logic we have added a new method in the sign_up_sheet_controller. The method duplicates the topic using the following logic: Find the topic using the topic_id that we sent from the view. Get the available slots fo the topic. Depending on the available slots, if topic is to be duplicated call assign_values method. In the assign_values method, we set the various parameters of the duplicate_topic (identifier, assignment_id, link, description etc) to their corresponding values from the original topic. The remaining parameters are assigned with some modifications. The name is saved with the word "" copy"" appended at the end. The number of max_choosers for this duplicate topic is equal to the available slots for the original topic. If the topic is not to be duplicated(if available_slots==0 or available_slots==max_choosers), error out and display appropriate error message. <image> <image> Screenshots Of The Implemented Features 1) Log in as Instructor. On clicking on 'Manage Content' a screen is rendered which lists the existing assignments. 2) Click on the edit assignment button for any assignment. For the purposes of this screenshots we will select ""Madeup problem"". 3) For the first feature we can see that we have added a checkbox against each topic. We can also see the ""New deadlines for selected topics"" text box. This text box automatically fills the boxes with corresponding values of the topic with the latest deadlines of all topics. All these are clearly visible in the screenshot below. <image> 4) Since multi-select cannot be shown with images, we have shown it in the screen-cast. In the following couple of screenshots we have selected various topics and entered a new date for all of them only once. When we press the save button the dates entered in the text-box is applied to all the selected topics. <image> <image> 5) Sorting. From the topics displayed in the image below we clearly see that they are sorted. <image> 6) The first case is when we try to duplicate a topic with zero slots available. In this case too it will not duplicate a topic and display an error message. <image> 7) The second case is when we try to duplicate a topic with all slots available. It will not duplicate the topic and display an error message. <image> 8) Success!! <image> Testing We have tested these features in the video using the following steps: 1.1. Login as an instructor since these features will not be available for other user roles. 1.2. Go to assignments and for a random assignment press the edit button. We have selected ""Madeup problem"" for our screenshots and videos. 1.3. Go to topics. You can see the ""duplicate topic"" button in the action column for all topics. 1.4. To duplicate a topic press the button for any topic. 1.5. Depending on the conditions mentions above it will successfully duplicate or it will error out with the appropriate message. 1.6. For the second feature click on the ""Show start/due dates"" button at the bottom. 1.7. Select check-boxes against topics whose deadlines you want to change. 1.8. To check shift-click functionality select one topic. Press shift and select another topic. All topics in the middle will also be selected. 1.9. The text box at the bottom has the latest values of all the topics by default. 1.10. Change the deadlines and click on ""Save"" button. 1.11. The entered deadlines are saved for all topics selected. Demo Video Link <link> Additional Links <link> <link> <link> References <link> Team <link> <link> <link>. 1) app/controllers/sign_up_sheet_controller.rb 2) app/views/sign_up_sheet/_due_dates.html.erb 3) app/helpers/sign_up_sheet_helper.rb 4) app/views/layouts/application.html.erb 5) app/views/sign_up_sheet/_all_actions.html.erb 6) app/views/sign_up_sheet/_add_signup_topics_staggered.html.erb 7) app/views/sign_up_sheet/_add_signup_topics.html.erb. 1) For the first issue where the instructor was forced to enter due dates manually for each topic, we have added a checkbox against each topic in the assignment. The code for this was added in the due_dates.html.erb file. We have also provided a text box at the end for the instructor to enter the due dates for the selected topics. This text box is auto-populated with the latest deadline of all topics in that assignment, thereby saving the instructor the hassle of having to enter all the fields from scratch. Then we have updated the save_topic_deadlines method in the sign_up_sheet_controller. This is the method called when we want to save the new deadline entered. The logic we have used to modify due_dates.html.erb: 1) Log in as Instructor. On clicking on 'Manage Content' a screen is rendered which lists the existing assignments. 2) Click on the edit assignment button for any assignment. For the purposes of this screenshots we will select ""Madeup problem"". 3) For the first feature we can see that we have added a checkbox against each topic. We can also see the ""New deadlines for selected topics"" text box. This text box automatically fills the boxes with corresponding values of the topic with the latest deadlines of all topics. All these are clearly visible in the screenshot below. We have tested these features in the video using the following steps: 1. Login as an instructor since these features will not be available for other user roles. 2. Go to assignments and for a random assignment press the edit button. We have selected ""Madeup problem"" for our screenshots and videos. 3. Go to topics. You can see the ""duplicate topic"" button in the action column for all topics. 4. To duplicate a topic press the button for any topic. 5. Depending on the conditions mentions above it will successfully duplicate or it will error out with the appropriate message. 6. For the second feature click on the ""Show start/due dates"" button at the bottom. 7. Select check-boxes against topics whose deadlines you want to change. 8. To check shift-click functionality select one topic. Press shift and select another topic. All topics in the middle will also be selected. 9. The text box at the bottom has the latest values of all the topics by default. 10. Change the deadlines and click on ""Save"" button. 11. The entered deadlines are saved for all topics selected. <link>. <link> <link> <link>. <link>.","This is a really good writeup.  It could be improved still further if standard Mediawiki topic headings were used throughout instead of ""1)"", ""2)"".","Dear student,

Thank you for your detailed discussion of your participation in the Expertiza open source project. Your approach demonstrates a good understanding of the project's objectives and of the Ruby on Rails framework.

I particularly appreciate your detailed descriptions of the changes you made to the application. It's clear you have considered user usability in your project, with the addition of features like checkboxes for each topic and the shift + click function to select multiple topics, both of which serve to enhance user experience.

Your presentation of the issue of staggered deadlines and your proposed solutions were also outlined well. However, remember to test your code extensively before submission to ensure that the functionalities work as expected. While, at this stage, testing was not a requirement for this project, it is good practice to familiarize yourself with testing strategies early on.

Your screenshots and demo video were useful for visualizing the changes you've made to the software. In the future, consider including comparisons of the Expertiza UI before and after your changes.

Finally, it would be helpful if you could try to efficiently present your implementation methods, perhaps through usage of bullet points or sub-headings, currently, your submission is rather long which can make it hard for readers to follow.

Overall, excellent work on your open-source contributions to Expertiza. Keep up the good work!

Best regards,

[Instructor's Name]"
178,E1813.1,"<link> is an open source web application based on <link> framework, supported by the National Science Foundation. It is a place where students can submit and peer-review learning objects (assignments, codes, write ups, websites, etc). For an instructor, expertiza allows to create and customize new or existing assignments. For students, it allows to create and work on various projects and assignments. It provides a platform to peer review other students' submissions across various document types, including the URLs and wiki pages. In software engineering, behavior-driven development (BDD) is a software development process that emerged from test-driven development (TDD). Behavior-driven development combines the general techniques and principles of TDD with ideas from domain-driven design and object-oriented analysis and design to provide software development and management teams with shared tools and a shared process to collaborate on software development. BDD focuses on: 1. Where to start in the process 2. What to test and what not to test 3. How much to test in one go 4. What to call the tests 5. How to understand why a test fails Test-driven development is a software development methodology which essentially states that for each unit of software, a software developer must: Define a test set for the unit first; Make the tests fail; Then implement the unit; Finally, verify that the implementation of the unit makes the tests succeed. This definition is rather non-specific in that it allows tests in terms of high-level software requirements, low-level technical details or anything in between. One way of looking at BDD therefore, is that it is a continued development of TDD which makes more specific choices than TDD. In computer programming, <link> is a software testing method by which individual units of source code, sets of one or more computer program modules together with associated control data, usage procedures, and operating procedures, are tested to determine whether they are fit for use. Ideally, each test case is independent from the others. Substitutes such as method stubs, mock objects, fakes, and test harnesses can be used to assist testing a module in isolation. Some of the advantages of unit testing are: 1. Finds problems early: Unit testing finds problems early in the development cycle. This includes both bugs in the programmer's implementation and flaws or missing parts of the specification for the unit. In test-driven development (TDD), which is frequently used in both extreme programming and scrum, unit tests are created before the code itself is written. When the tests pass, that code is considered complete. 2. Facilitates change: Unit testing allows the programmer to refactor code or upgrade system libraries at a later date, and make sure the module still works correctly (e.g., in regression testing). The procedure is to write test cases for all functions and methods so that whenever a change causes a fault, it can be quickly identified. Unit tests detect changes which may break a design contract. 3. Simplifies Integration: Unit testing may reduce uncertainty in the units themselves and can be used in a bottom-up testing style approach. By testing the parts of a program first and then testing the sum of its parts, integration testing becomes much easier. 4. Documentation: Developers looking to learn what functionality is provided by a unit, and how to use it, can look at the unit tests to gain a basic understanding of the unit's interface's API. 5. Design: When software is developed using a test-driven approach, the combination of writing the unit test to specify the interface plus the refactoring activities performed after the test is passing, may take the place of formal design. Each unit test can be seen as a design element specifying classes, methods, and observable behavior. This project is to write unit tests using rspec for menu_items.rb model. The unit tests are to be written to make the path coverage of menu_item.rb more than 90% and achieve the highest possible branch coverage. The files to be understood and created are: 1. app/models/menu_items.rb 2. spec/models/menu_items_spec.rb. The task in hand was to write test cases for testing the menu_items model file. No Rspec file for the corresponding model exists so there was a need to create a new file and build tests from scratch. For this purposes different sub tasks involved 1. Setting up the Expertiza environment 2. Understand the functionality of model file in menu_items.rb 3. Understand the linked data attributes being used, like controller_actions, content_page, permissions_id 4. Creating stub entries for testing different functionalities. 5. Writing testing conditions for different functions and cross checking with the expected outputs. We used the Ubuntu-Expertiza image to setup the environment. We forked the master from Expertiza, cloned that and then run through the command terminal. cd/expetiza/app/models The menu_item.rb model file is present in this directory. Menu Items is a model which gives the functionality to the top menu bar in the Expertiza website. It controls the display of drop down menus and its sub menus. It directs how these drop downs are displayed with regards to different users which have different permission attributes. A super admin has the permission to edit the menu bar, by adding or deleting menu item blocks from it. Upon adding each item, he gets to position it either in the main menu bar or into different sub categories. Following are the parameters associated with the menu_item model: 1. Name: This parameter gives the name to the menu item. 2. Label: This parameter gives the label to the menu item. 3. Parent id: It gives the id of the parent and establishes the hierarchy of the various objects of the menu item model. It can also be 'null' which means that it will be the base category. 4. Sequence id: It gives the sequence numbering for determining the way the attributes are ordered within a parent. 5. Controller action id: This parameter is associated with the direction in which the user is directed onto. 6. Content page id: This parameter is also associated with the direction in which the user is directed onto. Different instance methods and class methods exist in this models . Brief description of each of them are: 1. find_or_create_by_name(params): Class Method This method finds or creates a new entry with the given name obtained in params. 2. delete: Instance Method This methods deletes the entry and all the child entries (entries having the same parent id) lined to it 3. above: Instance Method It returns the entry that is above a present sequence number for a given parent id 4. below: Instance Method It returns the entry that is below a present sequence number for a given parent id 5. repack(repack_id): Class Method It modifies the sequence numbers, making them in order, removing the skip entries present in it. It is performed after certain sequences have been deleted. repack_id tells the parent id under which these changes are to be made 6. next_seq(parent id): Class Method It returns the next possible sequence id corresponding to a given parent id entries. This function would be helpful if we wish to add a new entry and find out which sequence id is to be given to it. 7. items_for_permission: Class Method It returns the set of items that are possible to be displayed for a given permission id and also based on controller action id and page id being present for it. Stub objects are needed to be created for any unit testing criteria.These objects are loaded freshly and deleted after every testing condition. Several methods exist for creating such a objects, whose parameters need to be designed to satisfy the conditions under test. Using 'factories' is one such method where few of the attributes are filled in with predefined values when an created. Here, for this specific case, we haven't used, factories method as, the number of attributes were limited in menu_items model and could be filled in completely with the required values each time. For testing menu_items, we created required entries into the database using ""Let"" and ""MenuItem.create"" method, giving different values for each of the test inputs to cover the required testing conditions. <code> The above is an example entry used for menu item. 5 more similar objects were created with entries giving combinations of parent_id, sequence numbers and controller_action_id. We also created objects for controller_action and content_page which were used to define conditions for coverage of items_for_permission. A total of 13 unit tests were performed for testing all the functions in menu items model file and achieving complete code coverage. The conditions that needed to be tested are as below: 1. .find_or_create_by_name: <code> 2. #delete: <code> 3. #above: Test cases were written to check the below conditions: <code> 4. #below: Test cases were written to check the below conditions: <code> 5. .repack: Test cases were written to check the below conditions: <code> 6. .next_seq: Test cases were written to check the below conditions: <code> 7. .items_for_permissions: Test cases were written to check the below conditions: <code>. After writing the test cases we used SimpleCov to measure the C0 coverage of our rails application. After running rake spec to run the test cases, SimpleCov creates a directory called coverage in our rails application folder. This folder called coverage contains an index.html file which when opened in a browser renders an html page which gives the C0 coverage of each of the files in the Controllers, Models, Helpers in the app directory. For our case, the C0 coverage of the menu_items.rb file in the Models folder increased from 0 to 100. Following are the screenshots of the completed code coverage taken from coverage/index.html: <code>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.","Too much of the document introduces BDD and unit testing, which the readers can be expected to know..  Also, it shouldn't be necessary to discuss setting up Expertiza on your machine. 

What follows this is a list of items, parameters and methods.  Lists are hard to read and remember.  A list could appear as a table, but should be accompanied by narration to help the reader comprehend what's in the list. The case descriptions don't fit in the boxes, which makes them hard to read.","Dear student,

Thank you for submitting your assignment. I am impressed with the level of thoroughness and detail in your assignment. Your understanding of test-driven and behavior-driven development, as well as unit testing, are clearly articulated. Your detailed analysis of the menu_items model file and its functionalities demonstrates a deep understanding of the intricate parts of the software.

You were successful in writing comprehensive test cases for each of the object model's functions, which is commendable. Your use of different tools for testing, such as SimpleCov for measuring code coverage is also noteworthy.

Furthermore, your clear explanation of stub objects and the use of 'factories' showcases your ability to assess and employ different testing methodologies as per the requirement.

Few areas you can consider for improvement:

1. While your work in setting up the Expertiza environment and understanding the menu_items model is commendable, it would have been beneficial to explain any challenges you faced and how you overcame them. This gives an insight into your problem-solving ability.
2. When explaining your testing strategies, make sure you balance between going into meticulous technical details and providing an overarching conceptual understanding that non-technical or beginner audience would understand.
3. Screen shots of the completed code coverage are missing in your assignment. Please ensure to include proof of work where needed in your future submissions.

Overall, this is excellent work. You've demonstrated great understanding and execution of complex software testing principles and methodologies. Keep up the good work!

Best,
[Your Name]"
179,E2078,"In Expertiza, it is currently possible to check the “Allow self-review” box on the Review Strategy tab of assignment creation, and then an author will be asked to review his/her own submission in addition to the submissions of others. But as currently implemented, nothing is done with the scores on these self-reviews. There has been a previous attempt at solving this problem, but there were several issues with that implementation: 1. The formula for weighting self-reviews is not modular. It needs to be, since different instructors may want to use different formulas, so several should be supported. 2. There are not enough comments in the code. 3. It seems to work for only one round of review. View documentation for previous implementation <link> . Our objectives for this project are the following: 1. Display the self-review score with peer-review scores for the logged in user 2. Implement a way to achieve a composite score with the combination of the self-review score and peer-review scores 3. Implement a requirement for the logged in user to self-review before viewing peer-reviews 4. Assure that we overcome the issues outlined for the previous implementation of this project. Back-end 1. app/controllers/grades_controller.rb 2. app/helpers/grades_helper.rb 3. app/models/assignment_participant.rb 4. app/models/author_feedback_questionnaire.rb 5. app/models/response_map.rb 6. app/models/review_questionnaire.rb 7. app/models/self_review_response_map.rb 8. app/models/teammate_review_questionnaire.rb 9. app/models/vm_question_response.rb Front-end 1. app/views/assignments/edit/_review_strategy.html.erb 2. app/views/grades/_participant.html.erb 3. app/views/grades/_participant_charts.html.erb 4. app/views/grades/_participant_title.html.erb 5. app/views/grades/view_team.html.erb Testing 1. spec/models/assignment_particpant_spec.rb 2. spec/controllers/grades_controller_spec.rb. The following diagram illustrates how the self-assessment feature should work between student and instructor within Expertiza. In summary, an instructor can create an assignment and enable self-review. A student can then submit to the assignment creates by the instructor and provide a self-review. Only then can the student view all of their review scores. <image>. It should be possible to see self-review scores juxtaposed with peer-review scores. Design a way to show them in the regular ""View Scores"" page and the alternate (heat-map) view. They should be shown amidst the other reviews, but in a way that highlights them as being a different kind of review. In the current implementation of Expertiza, students can view a compilation of all peer review scores for each review question and an average of those peer-reviews. For our project, we plan to add the self-review score alongside the peer-review scores for each review question. In the wire-frame below, note that for each criterion there is a column for each peer-review score and a single column for the self-review score. Currently implemented in the system, the avg column takes an average of all the review scores. These scores (peer-reviews average and self-review) will be used to determine the overall composite score for the team's reviews. Furthermore, the average composite score is displayed on the page under the average peer review score, labeled ""Final Average Peer Review Score"". How we plan to derive a composite score is explained in detail in the follow section <link> . <image> In the alternate view, our plan does not alter the current interface too much. The only addition we plan to implement is additional columns for the self-review average and for the composite (final) score a student has received for an assignment. Likewise, there is now an additional doughnut chart providing a visual of the composite score (green) alongside the final review score (yellow). <image> Note: The diagrams above are wireframes. The values displayed are not be taken literally, they are for design purposes only. Implement a way to combine self-review and peer-review scores to derive a composite score. The basic idea is that the authors get more points as their self-reviews get closer to the scores given by the peer reviewers. So the function should take the scores given by peers to a particular rubric criterion and the score given by the user. The result of the formula should be displayed in a conspicuous page on the score view. The formula we use to determine a final grade from, 1) the peer reviews and 2) how closely self reviews match the peer reviews, uses a type of additive scoring rule, which computes a weighted average between team score (peer reviews) and student rating (self review). More specifically, it uses a type of mixed additive-multiplicative scoring rule, which multiplies student score (self review) by a function of the team score (peer reviews), and adds its weighted version to the weighted peer review score. This is also known as 'assessment by adjustment'. The formula is a practical scoring rule for additive scoring with unsigned percentages (grades from 0%-100%). The pseudo-code for a function that implements the formula is as follows: <code> where: <code> and where: avg_peer_review_score is simply the mechanism already existing in Expertiza for assigning a grade from peer review scores. and where: w - weight - (0 <= w <= 1) is the inverse proportion of how much of the final grade is determined by the closeness of the self review to the average of the peer reviews (w is the proportion of the grade to be determined by the original grade determination: the peer review scores). An example: 1. The average peer review score is 4/5, the self review score is 5/5. 2. The instructor chooses w to equal 0.95, so that 5% of the grade is determined from the deviation of the self review from the peer reviews. The final grade, instead of being the peer review score of 4/5 ( 80% ) is now: 0.95*(4/5) + 0.05*(4/5*(1-|4/5-5/5|/(4/5))) = 79% . If the instructor chose w to equal 0.85 (instead of 0.95), the grade is 77% (instead of 79%) because deviation from peer reviews is a larger weighted value of the final grade. The above is a basic version of the grading formula. It is basic in that it only allows deviations of the self review scores from the peer review scores to result in a decrease in the final grade and a deviation will always result in a decrease of the final grade. We propose another parameter to the formula, l - leniency, as another way (in addition to w - weight) for the instructor to modularly determine the final grade for an assignment. The parameter l - leniency - can determine a threshold by which the final grade will account/adjust for self reviews' deviations from peer reviews only when the deviation reaches this threshold (measured in percentage deviation from the average peer review). If the difference does not meet the threshold, no penalty will be subtracted from the peer review. In addition, if the difference does not meet the threshold (the self review score is sufficiently close to the peer review scores), the instructor can choose to add points to final grade based on the magnitude of the difference. Since the formula is a mixed additive-multiplicative scoring rule (mentioned above), the instructor needs to simply pick l - leniency - as a percentage (similar to the functionality of w). To recap: w should be chosen based on the instructor's desired percentage (w) of the final grade to be determined from peer reviews and, conversely, the instructor's desired percentage (1-w) of the final grade to be determined by the extent to which self reviews deviate from peer reviews. In addition, l - leniency, should be chosen based on the instructor's desired percentage of the deviation of self review from peer review that could result in no grade deduction from the deviation if the deviation is sufficiently small (or even a grade increase if the instructor wants to increase the score of individuals with a small deviation). The following is pseudo-code for if an instructor wishes to not subtract from the final grade if the deviation is sufficiently small. Notice that the leniency condition, the instructor's desired percentage of the deviation of self review from peer review , is naturally part of the grading formula in SELF: <code> In addition. instead of assigning a final grade equal to the avg_peer_review_score if the leniency condition is met, the grade can be adjusted (increased) if the instructor wishes to do so, since the self review is sufficiently close (determined by l) to the peer reviews. The formula for determining the final grade would thus add the small extent of deviation to the final grade rather than subtracting it (in SELF, 1 - ..., is changed to 1 + ...): <code> where: <code> In this case, the pseudo-code is: <code> Using the previous example (average peer review score is 4/5, self review score is 5/5, w = 0.95), the self review score (5/5) differs by 25% of the peer review score (4/5). In other words, |avg_peer_review_score - self_review_score|/avg_peer_review_score = 1/4 = 25%. Based on l - leniency, the instructor can decide: 1. if a 25% deviation is sufficiently large to warrant penalizing the final grade by (1-w)*(SELF) (so that the final grade is 79% , instead of 80%). 2. if a 25% deviation is sufficiently small to warrant keeping the final grade as grade = avg_peer_review_score, with no penalty for the deviation (so that the grade is 80% ) 3. if a 25% deviation is sufficiently small to warrant increasing the final grade by (1-w)*(SELF), where the SELF formula contains a 1 + ..., instead of a 1 - ... (so that the grade is 81% ). In order to incorporate the combined score into grading, we will change the logic in grades_controller.rb, which implements the grading formula. We will remove most of the code from the previous implementation since the formula/method used is unsatisfactory. With the new grading formula, the grades_controller can assign a final grade by following these steps: 1. We can obtain the peer review ratings and the score/grade derived from them by calling scores(), which then calls compute_assignment_score(), both from the assignment_participant.rb model. In order to compute the assignment score, compute_assignment_score() calls another method named get_assessments_for(), which is located in review_questionnare.rb model. 2. The get_assessments_for() method will call the reviews() method, also located in assignment_participant.rb. 3. Finally, the reviews() method will get the scores by simply calling the get_assessments_for() method located in the response_map.rb model. 4. Once the scores have been retrieved by using the various model methods, the controller can use the scores to calculated a final grade by using the formula. This grade is then passed to the view. Below is a flow diagram for how grades_controller.rb, which implements the grading formula (as mentioned in the first step) and presents the grade in the view (top of the diagram). Note: The self-review scores are obtained by using the true parameter in all the methods calls (as shown in the diagram), whereas the peer-review scores are retrieved similarly but omitting this parameter. <image>. There would be no challenge in giving the same self-review scores as the peer reviewers gave if the authors could see peer-review scores before they submitted their self-reviews. The user should be required to submit their self-evaluation(s) before seeing the results of their peer evaluations. By being able to self review before peer review, it allows the author of the assignment to have an unbiased opinion on the quality of work they are submitting. When the judgement of their work is not influenced by others who have given feedback, they are able to get a clearer view of the strengths and weaknesses of their assignment. Self reviews before peer reviews can also be more beneficial to the user as it can show if the user has the correct or wrong approach to their solution compared to their peers. In the current implementation of self review, the user is able to see the peer reviews before they have made their own self review. The reason that this is occurring is due to the fact that when the user goes to see their scores, the page is not checking that a self review has been submitted. In order to fix this issue, we will add a boolean parameter to self review and pass it to viewing pages where it is called. When a user is at the student tasks view, the ""Your scores"" link will be disabled if the user has not filled out their self review. If the user has filled out their self review, then he/she will be redirected to the <link> page. Below is a control flow diagram for how a student will be able to view their peer and self review score. <image>. The following code and UI screenshots illustrate the implementation of displaying the self-review scores alongside the peer-reviews. This also includes displaying the final score that aggregates the self-review score utilizing a chosen formula. The final score derivation process is described in the <link> task. View Team Review Scores (view_team) The view_team.html.erb file is responsible for the display of the peer-review scores heat map. In this implementation, we added a display for the Final Average Peer Review Score, which is the score that takes the average self-review score into consideration based on a set formula. Additionally, there is now a self-review score column (highlighted in cyan) that displays the self-review score for each criterion alongside the peer-review given. <image> <image> <image> The following screenshot shows the final result of the code implementation. <image> Alternate View (view_my_scores) The _participant_*.html.erb files are responsible for the UI display of viewing assignment scores in the Alternate View. The following implementation shows the addition of the new columns for self-review score and the final composite score (along with a doughnut chart for the final score). <image> <image> The following screenshot shows the final result of the code implementation. <image> Response Map for Reviews The following code implementations illustrate the response map additions for the response mapping. This is responsible for the functionality of conducting a self-review and gathering the results per assignment. <image> <image> <image> <image>. In the following screenshots we have implemented code in the grades_controller.rb to call upon helper functions in the grades_helper.rb that will compute the peer and self final score. The formula that will be chosen depends on which formula the instructor selects when they create the assignment. <image> <image> <image> <image> Instructor View for Reviews The following screenshot is the code that we implemented to allow a teacher to a which formula, in the UI, to use to account for self-reviews in the assignment review grading. <image> The screenshot of the interface below is the resulting UI from the code implementation above. <image>. The following screenshots are the files which we implemented booleans so that a student will not be able to see their scores unless they have filled out their self reviews. <image> <image> <image> <image>. Our project will utilize various testing techniques. These methods of testing involve manual testing (black box testing) and RSpec testing (white box testing). Credentials 1. username: instructor6 , password: password 2. username: student3000 , password: password 3. username: student4000 , password: password The steps outlined for manual testing will become clearer upon implementation, but the proposed plan is the following: 1. Log in to the development instance of Expertiza as an instructor6 2. Create an assignment that allows for self-reviews. To allow for self-reviews, check the box ""Allow Self-Reviews"" in the Review Strategy tab. 2.1. Make sure the submission deadline is after the current date and time 2.2. Likewise, the review deadline should then be greater than the submission deadline 3. Add student3000 and student4000 to the newly created assignment (i.e. ""Test Assignment""). This test will assure that the logged in user cannot view their peer-reviews for a given assignment unless they have performed a self-review. 1. Sign as student3000 1.1. Submit any file or link to the new Test Assignment 2. Log back in as the instructor6 2.1. Edit the Test Assignment to change the submission date to be in the past, enabling peer reviews 3. Log in as student3000 4. Attempt to view peer-review scores by clicking on ""Your Scores"" within the Test Assignment. This button should be disabled 5. Log back in as the instructor6 5.1. Edit the Test Assignment to change back the submission date to be in the future 6. Log in as student3000' 6.1. Perform a self-review 7. Log back in as the instructor6 7.1. Edit the Test Assignment to change the submission date to be in the past, enabling peer reviews 8. Log in as student3000' 8.1. Go view peer-review scores by clicking on ""Your Scores"". This button should now be enabled. This test confirms that the the students self-review scores are displayed with peer-review scores. It additionally confirms that self-review scores are considered in the review grading with the calculation of a composite score. 1. Sign as student3000 1.1. Submit any file or link to the new Test Assignment 1.2. Perform a self-review 2. Repeat step 1 student4000 3. Log back in as the instructor6 3.1. Edit the Test Assignment to change the submission date to be in the past, enabling peer reviews 4. Log back in as student4000 4.1. Perform a peer-review on the submission from student3000 5. Log in as student3000 6. Go view peer-review scores by clicking on ""Your Scores"". 6.1. Assure that there is a column for self-review scores 6.2. Confirm there is a composite score calculation underneath the average peer review score. 7. Go back to the assignment view. Click ""Alternate View"" 7.1. Confirm that there is a new column illustrating the self-review average 7.2. Confirm that there is a column in the grades table displaying composite score (Final score) 7.3. Check is there is a doughnut chart displaying the composite score (Final score). We plan to implement new RSpec tests to verify our implementations of the composite score calculation and the requirement to self-review first. Once written, we will be able to go more in-depth on the details of our testing. The following screenshot is an rspec test that we added in the grades_helper_spec.rb file. This tested to see if the Vossen formula that we implemented would output the correct score when given a average peer, average self review score, weight, and leniency. <image>. Our repository : <link> Pull request : <link> Video demo : <link>. <link> <link> <link>.","The general approach is described quite well.  The description of the self/peer-review grade calculation is very clear.  The document contains all of the required parts.  However, there is not enough description of the code changes; in most cases, code diffs are just pasted in without further discussion.","This is an excellent work! Your presentation is well-structured, logical, and comprehensive, covering all the aspects of the project including problem statement, back-end and front-end roles, testing methods, and implementation details. The use of precise diagrams, tables, and flowcharts is impressive, making the paper more understandable and readable. 

The formulas you devised for the composite score are well-explained and thoughtful, considering various situations and instructors' preferences. 

The included section on potential challenges and your strategies to overcome them is a nice touch and enhances the overall quality of your work. The implementation of pseudocodes and the testing methods provides a clear perception of your understanding of the programming concepts. 

Nevertheless, there is always room for improvement. 

1. You could emphasize a little more on the significance of this project in the introductory part, explaining how this implementation could help learners and instructors in their assessment process.

2. While your documentation is thorough and comprehensive, it might be more approachable if you would break down some of the denser paragraphs into bullet points or subheadings.

3. Lastly, the article sometimes dives into the code’s specifics which while appropriate for a more technical audience could be slightly obscure for those less familiar with programming.

Overall, this is a commendable job and illustrates a profound commitment to the project task. Keep up the good work!"
180,E2087,"Expertiza includes the functionality of notifying instructors when a conflict occurs in review scores for a submission. Currently, when two reviews for the same submission differ significantly, an email is sent to the instructor of the course, but there is no link to the review that caused the conflict. This improvement will allow the professor to have links to the reviews that caused the conflict and will be formatted better to help the instructor understand the conflict. 1. The functionality is good but the UI of conflict report needs work. 2. The UI needs to be cleaned up a little. When charts have only one or two bars, the chart can be compressed. The reviewer whose scores deviate from the threshold can be displayed in a different colored bar. 3. Tests need to be refactored. 4. They included their debug code in their pull request. 5. They have included a lot of logic in the views. 6. Shallow tests: one or more of their test expectations only focus on the return value not being `nil`, `empty` or not equal to `0` without testing the `real` value. The previous team implemented new logic to determine if a review is in conflict with another and created a new page to link the instructors to in the email. Because their functionality was good, we will mainly be focused on improving the UI of the conflict reports. Furthermore, there is a lot of logic that lives in the views that can be refactored and moved to controllers. Additionally, there is debug code that can be removed and tests that can be fleshed out. File: app/views/reports/_review_conflict_metric.html.erb The UI can be improved for the conflict metric to give more information on the conflicted reviews. File: app/views/reports/_review_conflict_metric.html.erb The logic to determine if answers are within or outside of the tolerance limits can be moved to functions outside of the .erb file. <image> <image>. To verify the conflict notification is working correctly, a mock assignment will be created and two reviews will be entered that should trigger a conflict. Successful retrieval of the email and verification of the links included in the email will provide sufficient verification that the changes were successful. File: spec/models/answer_spec.rb Currently, tests only check if the values are not empty. More tests can be written to make sure the actual value is being returned correctly. File: spec/controllers/reports_controller_spec.rb More tests can be written to ensure correct names and values are written. Moved following methods from review_mapping_helper.rb to report_formatter_helper.rb 1. average_of_round 2. std_of_round 3. review_score_helper_for_team 4. review_score_for_team. Adding base_url from the controller as this method is not accessible from model <code> <code> This method generates statistics (average, standard deviation, tolerance limits) for each round. This method was created to move logic that was previously contained in a view to a helper class. <code> This logic highlights all reviews' score in red which is out of limit range, and all other background color will be green. <code> Passing the colors to bar background. <code> comprising the chart height for how much it need to clearly display all data. <code>. Based on the previous changes from last group, the notification email triggered will send to the instructor whenever a new review is significantly different from other people's review, who has the same submission team (the threshold is specified in the ""Notification limit"" on the Rubric tab of assignment creation). The graph showing below is the previous team email UI. <image> On the email notification, the formatting can be improved to make it more readable and clear as to which links relate to what actions and what caused the conflict to trigger. The previous group of snapshot for the view which the instructor receives <image> On the 'review for mail check' page, more information can be added to indicate if a review has a conflict. We will add indicators beside each review that have conflicts. We added a link for review_conflict_report_url, which will let instructor to access the review conflict report page by the email he received. <image> Chart before improvements. <image> Chart after improvements. <image> The improved chart has the student name on the y-axis, scaled chart sizes, and more intuitive highlighting with red bars indicating an out of limits score. This is a great improvement to the previous implementation where only the student name was highlighted to indicate an out of limit score. Added additional tests to cover the average and standard deviation calculations. File: spec/helpers/review_mapping_helper_spec.rb <code> File: spec/controllers/reports_controller_spec.rb Improved tests for conflict report controller. Tests now check for correct values rather than just null or empty. <code>. GitHub - <link> Pull Request - <link> Demo Video - <link> Website - <link>. 1. Previous Wikipedia page - <link> 1. Previous Final Video - <link> 1. Previous Pull Request - <link> 1. Previous Github Repo - <link>.","The document is readable, and does a good job of explaining changes, especially to the UI.  I would have liked to see it cover more of the changes (less than 1/3 of the code changes, other than tests, were described), and also focus less on the previous implementation of the project, since readers are going to be interested in the functionality, not a previous project that was never merged.","Feedback:

Dear student,

Excellent work on your assignment. You have put in commendable effort in detailing out the intricacies of your project. You paid attention to areas such as UI improvements, moved logic from views to controllers, debugged code, refactored tests, and improved overall functionality - which is impressive. 

However, there are a few pointers for improvement: 

1. You could work on the clarity of your explanations as there is some confusion arising due to the lack of clear differentiation between your work and the work done by the previous team.
2. While presenting tests, a good practice is to include both the test scenarios as well as their justifications. This will display a more comprehensive understanding of the subject.
3. You incorporated a lot of logic in the views. Although it is not always incorrect to do so, it's a good idea to keep the views as simple as possible. Consider moving some of the logic to your controller or model.

About your diagrams, they are very well done with clear explanations. However, taking the time to enhance your images will increase their utility. Don't be afraid to use more color, text, or labels if it helps explain your diagrams more clearly.

Lastly, your initiative of creating a mock assignment to verify the conflict notification is a smart move, demonstrating practical thinking.

Keep up the good work and continue improving. You're doing great! 

Best,
[Your Name]"
181,E1613,"For testing the changes made, the following credentials are recommended: 1. Instructor Login: username: instructor6 password: password 2. Student Login: username: student11 password: password 3. Student Login: username: student1862 password: password The above users are suggested for testing because there are a few users which would lead to exceptions upon login for unknown reasons completely unrelated to our work. Expertiza is a web portal which can be used to manage assignments related to a course. It provides a platform to view assignments, manage teams, select topics and work improvement through anonymous peer reviews. For the instructor it provides complete control to create assignments, view reviews submitted and provide feedback. The instructors also have an option to publish the students work based on the rights provided by the student. The following were the tasks identified to accomplish through this project. These tasks are part of the sign_up_sheet_controller.rb and sign_up_topic.rb 1. WI-1: Method ad_info in the sign_up_sheet_controller.rb users sql query to retrieve the desired objects. This needs to be changed so that action records are used instead and a hash/array of the required object is returned. 2. WI-2: Delete the method add_default_microtask after confirming that there is no reference to the method. 3. WI-3: The view_publishing_rights method brings up a webpage to the instructor on whether the course staff has been granted or denied the right to use each submission in the future. The current implementation of the project works only for assignments that have topics assigned to them. This needs to be enhanced to include assignments that do not have associated topics as well. Another change that needs to be brought about is that the view_publishing_rights needs to be refactored and moved to the participants controller. 4. WI-4: The methods slotAvailable? implemented in the sign_up_sheet_controller.rb needs to be removed from the controller. The methods should only exist in the corresponding model. 5. WI-5: Method other_confirmed_topic_for_user is only referenced by the method waitlist_teams. The method wait_list_teams is not referenced anywhere. These methods need to be removed if it is confirmed that they are not used anywhere else. 6. WI-6: Expertiza provides a functionality to import topics from a file (.csv or .txt). This feature is currently not tested. Test the functionality of this feature and fix it if broken. Another change that needs to be brought about is that the current implementation requires that each row of the imported file needs to have four columns. However the fourth column which represents ""category"" is not mandatory and it should be possible to import a document which does not include values for this column. 7. WI-7: Add Rspec testcases to test the changes implemented above. The following files were modified for this project. 1. app/controllers/participants_controller.rb 2. app/controllers/sign_up_sheet_controller.rb 3. app/models/sign_up_topic.rb 4. app/models/signed_up_team.rb 5. app/models/team.rb 6. app/models/waitlist.rb 7. app/views/participants/view_publishing_rights.html.erb 8. app/views/sign_up_sheet/list.html.erb 9. app/views/sign_up_sheet/show_team.html.erb 10. app/views/sign_up_sheet/view_publishing_rights.html.erb 11. app/views/tree_display/actions/_assignments_actions.html.erb 12. app/helpers/import_topics_helper.rb 13. app/assets/javascripts/tree_display.jsx 14. config/routes.rb 15. spec/features/instructor_interface_spec.rb 16. spec/features/team_creation_spec.rb. For this work item the following files were modified: app/controllers/sign_up_sheet_controller.rb: In this file the method ad_info is defined. This method was defined using sql query to provide its results. To change this method in such a way that it uses active record associations changes needed to be made to the function as shown below. Additionally since the new implementation returns a list of hashes the way in which this result is accessed in show_team method was also changed to accommodate this change. Original Code: <code> Modified Code: <code> Additionally changes were also required in the models signed_up_team.rb and team.rb. This was because these associations were required to fetch required data using active record associations. The following changes were made to the files: app/models/signed_up_team.rb: <code> app/models/team.rb <code>. For this work item the file app/controllers/sign_up_sheet_controller.rb was modified. After performing a code-analysis it was concluded that the method add_default_microtask was not referenced from any other part of the project. Hence it was safely removed. The first part of this task is it enable the view_publishing_rights view to all the assignments. When logged in as an instructor, (s)he can go to the list of assignments by navigating through Manage > Assignments . Here, only the assignments which have topics associated with them have the icon to go to the view_publishing_rights page. This icon should be available to all the assignments. This view of the assignments/courses is known as the tree_display . The part of the code that made sure that only the assignments with topics have this icon is in app/assets/javascripts/tree_display.jsx . <code> Here we see that the code that adds the icon to the content if two conditions are met. To get the icon for all the assignments, the change to made is pretty simple. Move the code outside of the two if conditions. <code> All the business logic that will be used to display content in the view_publishing_rights.html.erb is in the sign_up_sheet_controller.rb . Logically speaking, this should be in the participants_controller.rb , since we are taking about the publishing rights provided by the participants of the assignment. The next part of the tasks involves moving the view_publishing_rights method to the participants_controller.rb . sign_up_sheet_controller.rb <code> view_publishing_rights then calls the load_add_signup_topics method. In that, a lot of attributes are set to be used in the view. But in reality, the view just made use of the @sign_up_topics and @assignment . But the load_add_signup_topics is used in multiple places within this controller, and to cater for the needs of all those views, a lot of extra attributes are set. In other words, the method is doing more than one thing. Also, the two relevant attributes to be used in the view_publishing_rights views are not set up ideally. Only those assignments that have topics can be shown in the view. This should be changed so that all assignments should show up, because a participant can be in any type of assignment, and this view is for viewing the publishing rights that the participant has provided. So, by using @sign_up_topics"", the scope is limited to just the assignments with topics in them. So, apart from moving the method to the participant_controller.rb , the following code was added so that the participants of any type of assignment can be viewed. Original code (what was in place and moved, but did not work as expected) <code> Modified code <code> The final part of this task was to move the corresponding view to the views/participants views/sign_up_sheet/view_publishing_rights.html.erb <code> The above view had a lot of controller related logic in it. Since it is not the best of practices to have such logic in the view code, the changes shown above in the participants_controller.rb had to be made, so that the view code is just responsible for displaying the information rather than computing it as well. views/participants/view_publishing_rights.html.erb <code>. For this work-item the slotAvailable? method was removed from the file app/controllers/sign_up_sheet_controller.rb . This method is already implemented in the model app/models/sign_up_topic.rb . For this work item the file app/controllers/sign_up_sheet_controller.rb was modified. After performing a code-analysis it was concluded that the method other_confirmed_topic_for_user was not referenced from any other part of the project. Hence it was safely removed. For this work-item the files that were modified included app/helpers/import_topics_helper.rb . In this file one thing that has been changed is the variable used to represent the row array. This was done in order to remove any confusion. The array represents the individual columns of a particular row. Additionally since the category column is an optional column a check has been added to verify its existence before assigning it to the attributes hash. Original Code: <code> Modified Code: <code> Another file that was modified for this work-item is app/models/sign_up_topic.rb . This was also modified to remove the ambiguity caused by the variable name row . This was changed to columns . Additionally the original check which verifies whether the number of columns in each row is 4 was modified so that it also works if the imported file has only 3 columns. Original Code: <code> Modified Code: <code>. We have added Rspec test cases to check functionality of import feature and view_publishing_rights view. These Rspec tests are present in ""spec/features/instructor_interface_spec.rb"". The tests use csv files that are present in ""spec/features/assignment_topic_csvs/"" folder. View Publishing Rights : This test case checks whether view_publishing_rights page has column headers ""Topic name(s)"" and ""Topic #"". Since an assignment created without a topic does not have topic name and topic id. The test case will fail if the page contains topic name and topic id. <code> Import tests for assignment topics : There are 4 tests written under this category.They check the topics import feature. The file which is to be uploaded should contain 3 compulsory fields and the fourth field is optional. The tests perform the following tasks: Check the import pass when the import file has 3 columns. <code> Check the import pass when the import file has 3 or 4 columns. <code> Check the import fail when the import file has 2 columns. <code> Check the import fail when the import file doesn't have valid data. <code>. Since majority of the tasks for this assignment was code refactoring, only a few of these can be seen and tested through the UI. Follow the instructions below to check the: 1. view_publishing_rights 1. Login as a instructor (better to log in as an instructor that has assignments in the tree_desiplay view. For eg. instructor6) 2. Navigate 'Manage > Assignments' 3. Against each assignment in the table, an icon for 'view_publishing_rights' can be seen 4. Click on the 'view_publishing_rights' icon against any assignment 5. If the assignment has topics (eg. Wikipedia contribution), the table in the view will have 'Topic Name' and 'Topic #' displayed. 6. If the assignment does not have topics, the table will not have the above two columns 1. Topics import feature for an assignment 1. In the tree_display view of assignments, click on the edit icon. (Or while creating a new assignment) 2. Click on 'Topics' tab 3. Click on 'Import topics', towards the bottom of the page 4. Select a valid CSV file. The first, second and third columns should be the topic identifier, topic name and number of slots available, respectively. Note that the topic identifier should be more than 10 characters long, else import will fail. The CSV can have an optional 4th column for 'category' but this is displayed in the UI 5. In case of invalid CSV import, an error message will be shown.","Good narrative describing changes made.
Topic headers ""WI-1"", etc. are not very informative, esp. in the Table of Contents.  You should explain what ""WI"" stands for and write out a short name of the change you made.","Dear Student,

This assignment submission is both impressive and detailed in its explanation of the steps undertaken to implement the given tasks. I'd like to commend you on the extensive work you've put into not only code refactoring and enhancement, but also in writing clear, comprehensive explanations of the changes you made and why you made them. Your thorough analysis and thoughtful decision-making process were evident throughout your work.

Your meticulousness in undertaking tasks to improve the existing code and your efforts in creating test cases to validate the changes made is praiseworthy. The way you explained each task, documenting the original code and discussing the modifications showcase a great understanding of software development practices.

You have also done an excellent job in providing an in-depth description on testing each functionality. It's clear that you have put a significant amount of effort into ensuring that end users will understand how to use the modified features.

However, make sure to include actual code snippets instead of '<code>', to help give more detailed understanding of your code. I understand that for confidentiality reasons, you may have had to exclude the code but for a proper review, actual lines of code will be more helpful.

In conclusion, great job on this project! Your work demonstrates a strong command of programming and problem-solving skills. Be sure to keep up the great work as you move forward with your programming journey.

Respectfully,
[Your name]"
182,E2108,"<link> is an open-source project based on <link> framework. Expertiza is a complete instructor-student usage website where the instructor can assign assignments, deadlines, grades, etc that is required for the course. Similarly, the students can use this website to perform the tasks required as part of the course like project or assignments submission, forming groups and collaborating with them, as well as reviewing projects and teammates. This project focuses on a specific feature of expertiza which allows administrators, instructors or teaching assistants to impersonate another user (like a student) and access their account. The demonstration for the feature is as shown below. <image> figure 1 <image> figure 2 <image> figure 3. Expertiza allows administrators, instructors and Teaching Assistants to impersonate other users like a student. This allows the impersonator to view assignments, deadlines and submissions of other students. The rules to impersonating a user is, the impersonator has to be an ancestor of the impersonate. The hierarchy of impersonation is as follow: super administrator -> Administrator -> Instructor -> Teaching Assistant -> Student Note: impersonation cannot happen within the same level of hierarchy. For Example, a Super Administrator can impersonate any user apart from other Super Administrators, an Administrator can impersonate Instructors, TA, Students and not other Admins and so on. The aim of the project is to refactor the impersonate controller. The pre-existing code had the following major issues. 1. All functions related to impersonate controller were present in a single method which is 79 lines long. 1. Presence of repetitive code (Around 40 repetitive lines) <code> 1. Block nesting <code> 1. Too many return statements <code> 1. The impersonation can be done by using an impersonate bar which currently does not allow initial impersonation. <image> This project is focused on resolving the issues mentioned above. Basic login details: (Instructor login is only available) username -> instructor6, password -> password When logged in as an instructor, under the manage option in the ribbon as in Figure 1, select impersonate user. Upon redirected to impersonate page, enter the account which needs to be impersonated. It impersonates that user provided that user can be impersonated. Now a new button called revert appears on the ribbon as in figure 3, this can be used to revert the impersonation and return to the instructor profile. The above-mentioned issues have been tackled by refactoring the impersonate controller by splitting into many smaller methods which are later called by the main impersonate controller. The following are the refactored new methods that help in tackling the issue1 apart from each being specifically for some issue rectification: 1. check_if_user_impersonateable 2. display_error_msg 3. overwrite_session 4. check_if_special_char 5. do_main_operartion. This method plays the main role in tackling issue3 - 3 levels of block nesting apart from issue1. Intial Code <code> After recfactoring - Moved to separate method <code>. This method is used to tackle issues1, 2 and 4. All the error message related code is moved to this method. <code>. This method reduces the number of return statements used in impersonate controller, apart from reducing the size of the controller. Initial Code <code> After Refactoring - Moved to a separate method and accessed through the adapter method do_main_operation <code>. This code is used to reduce one functionality performed under the impersonate controller. This method checks to see if the given username is acceptable. Older version consisted only of the following snippet of code. <code> In the current code, the following code is added to accomodate the navigation bar funcionality of impersonate. <code>. This like an adapter method that is used to interface the impersonate method with display_error_msg and check_if_user_impersonatable. One main purpose to do this is to make the methods flexible for change apart from reducing the number of lines from the impersonate controller. <code>. Initially, while using the anonymized view to impersonate the account: student8597, we received the following error. <image> This occured as the following method was initially splitting the name using <code> Thus while doing the above function, what happens is that the student’s name is searched for a space and the ID is obtained as the numerics after the space, which isn’t the case for our user’s names (eg: student8597). Thus we had to modify this method under app/models/user.rb to the following: <code> In the above code snippet, what we are instead doing is, directly finding the user from the anonymized_name which in the errored case as in the figure above was ’’student8597'’. Apart from these changes, we also had to include the following statements in various parts of the impersonate_controller.rb file to ensure the the previously written test for anonymous view doesn’t break anywhere. <code>. The broken part of this refactoring project, as compared to the previous year’s, was the Navigation bar on the top right part of the screen. As mentioned earlier, in order to impersonate we have two methods: Using the Manage --> Impersonate User Using the Navigation Bar. However, as far as the previous submission goes, the Navigation bar’s functionality wasn’t complete. The aim of this refactoring is to also fix this and enable the impersonate functionality to work from there as well. The previous submission broke while trying to use the Navigation bar for impersonation because of the wrong passage of params between the views and controllers. In order to make the impersonate from the Manage --> Impersonate User work, the form that was rendered was the expertiza/app/views/impersonate/start.html.erb. Here, the field filled was :user. And was then checkd for in the impersonate_controller.rb. However, the Navigation Bar makes use of the :impersonate symbol to pass the impersonated user’s name and other details to the controller, for which no check was included earlier. Thus, there was no way to procure a user from the navigation bar. In the current submission this is fixed by including the following check in the impersonate_controller.rb/check_if_special_char: The check_if_special_char is a function which checks if the Username entered is valid or not. <code> As you can see, in the above code snippet, there is a check for the :impersonate’s params, which earlier was missing(Refer <link> ). The UI testing of this project can be performed on three fronts: 1. The normal impersonate functionality from the Manage tab and Revert functionality. 2. The impersonate functionality using the navigation bar. 3. The anonymized view's impersonate functionality(both from the Manage bar as well as the navigation bar). You can use the following details of various users to test the heirarchies and the impersonations between them. Note: You cannot login as a super_administrator2, as the login details are unknown. However, we have included ways to test the inability for a lower hierarchy memeber to impersonate the super_administrator. <table> To test out the three fronts, follow the steps mentioned below under each sub-heading: Checking if impersonating a user is working <code> <image> figure 7 <image> figure 8 <image> figure 9 <code> <image> figure 10 <image> figure 11 <code> <image> figure 12 <image> figure 13 <code> <image> figure 14 <image> figure 15. In order to perform the following testing: <code> <image> note: The above screenshot was captured after instructor6 impersonated student8597, you can also try to impersonate student8597 <image>. <code> <image> <code> <image> <image> <code> <image> <image>. Instructor should be able to impersonate a user while already impersonating a user but from navigation bar. This test is to ascertain the functionality of the user being able to impersonate another user(obeying hierarchy) through the navigation bar on the top right hand corner. This is to test the rectification of the previous issue, where this functionality was broken. Here, we test the functionality by first logging in as the instructor(id:2) and then first impersonating a student1 using the main menu’s Manage tab. This redirects us to the student1’s page. Now, from the navigation bar, we try to impersonate another student, student2. This test finally checks if the session is true and the parameters are correct. <code>. This test verifies the functionality that is available with from the Anonymized view. It checks for the impersonation from both the ends - Through the Manage tab as well as the Navigation Bar. <code>. The following are the links to the useful pages in understanding this project(as of Spring 2021) 1. <link> - General wiki describing the Expertiza project. 2. <link> - Youtube page to expertiza tasks. 3. <link> - GitHub repo that maintains code for Expertiza. 4. <link> - Spring 2020's wiki for the refactoring of impersonate controller. 5. <link> - Spring 2020's pull request for the refactored impersonate controller. 6. <link> - Pull request for the work done in Spring 2021.","The first thing I noticed was that the title omits the word ""Refactor"", which could cause trouble finding or understanding the page.  The description of the issues is pretty terse (e.g., ""Block nesting""), doesn't really explain what needs to be changed.  The code snippets are pretty long relative to the explanation of changes made.  You could help the reader a lot to understand if you wrote a paragraph describing the changes and highlighted somehow (e.g., Github diff view) where the changes were made in the code.","Dear student,

You have certainly put together an extensive and detailed analysis. You thoroughly explain the original issues with the impersonate controller, offer your solutions, and outline the process you took to implement them. Your explanation of terms and logic flow is generally clear and easily understood. 

However, where you can improve is in your organization and formatting. The text seems a bit dense which could potentially make it hard for the reader to follow. Use of headers to break up the long-running text would improve readability and navigation through your assignment. 

Also, the assignment would benefit from a clearer presentation of the 'before' and 'after' coding sections. This could potentially be done with side-by-side comparisons or even just clearly labelled separate segments. It would make it visibly easier for someone to compare the original code to your refactored code.

Additionally, where you mention ""<image>"" and ""<code>"", it would be helpful to actually include the referenced images and code snippets as these seem to be key elements to your project.

Finally, while you have quite comprehensively detailed your process and results, it would be constructive to also include some reflection. For instance, discuss what you learned from the process, potential alternate solutions you considered, and how this project might be further improved in the future.

Overall, great job on demonstrating technical understanding and critical thinking. With better organization and improved presentation styles, your assignments will certainly reach a higher-level of quality. Keep up with the good work!

Best regards,
[Your name]"
183,E1731,"Expertiza is an opensource web based platform developed to assist students in educational institutions to perform peer reviews and group projects. The reviewing is done through a mechanism where students will be sent request to review work and the system will analyze and publish a summarized report. The software is designed in MVC (Model-View-Controller) architecture using Ruby on Rails. Today, Expertiza stores the scores based on each response to each criterion, but no holistic scores are stored. The ""answers"" table only contains the scores that user A has given user B on each criterion. This means that if we need to know what score A has given B based on 100, we have to rely on the code to calculate it every time the score is requested. This design slows down Expertiza as every time an instructor clicks on ""View Scores"", all the calculations are done to display the score. The situation is even worse if we want to weight the scores by the reputation of each reviewer, which is a measure of how closely that reviewer's scores match other reviewers. In this case, the system potentially has to do thousands of arithmetic calculations to display the score for a particular assignment. We propose that we have two mechanisms to handle the holistic scores, depending on the current state of the assignment: This new approach will take the responses and the database will act as a storage environment. 1. OnTheFlyCalc: 1.1. Calculates holistic scores over a set of data: A set of records in answers table, namely the responses from user A to user B on each criterion. 1.2. When an assignment is still ongoing, the reputations for each reviewer will be calculated and handled by OnTheFlyCalc 1.3. This is similar to the current scenario 2. LocalDBCalc: 1.1. Calculates the holistic score over a single db query: ""get the score that user A gives user B on assignment 999 on round 2"" 1.2. When an asignment has finished, all the reputations will be calculated by LocalDBCalc and stored, since they are finalized. So, when the scores are requested, they will be fetched using a single db query and displayed 1.3. This will be a new addition to the code as currently there is no class. In this project, our goal is to make the OnTheFlyCalc and LocalDBCalc work only for peer-review scores. As future projects will introduce other types of scores, the solution must be extensible. 1. A new database table ""local_db_scores"" with following columns will be created to store the holistic scores: 1.1. id: int 1.2. score_type: string 1.3. round: int 1.4. score: int 1.5. response_map_id: int (this will be reference to the response_map table) 2. A new column ""local_scores_calculated"" with boolean type will be added to ""assignments"" table 1.1. This has the default value false 1.2. The value will change to true when the holistic scores for that assignment are stored in local_db_scores table 3. A new icon will be added to the list of Assignments on the Manage Assignments page for instructor 1.1. When this icon is clicked, the holistic scores will be calculated using store_total_score method in LocalDBCalc class and then inserted in this new table ""local_db_score"" 1.1.1. If the record to be inserted is a finalized peer-review score, the type stored in the database will be ""ReviewLocalDBScore"" and the reference_id will be the response_map id 1.1.2. The peer-review scores will be calculated and stored for each of the review rounds because it is possible that user A only reviews user B in one out of several rounds 4. When a request is made to view the total scores, depending on whether local_scores_calculated column of the assignment is false or true, either OnTheFlyCalc or LocalDBCalc will be called to calculate the total score To achieve this functionality, following classes will be created: 1. OnTheFlyCalc: 1.1. This class will contain a method ""compute_total_scores"" which will compute the total score for an assignment by summing the scores given on all questionnaires and return this total score when an instructor tries to view scores for an ongoing assignment 1.2. It will also contain methods to calculate the average score and score range (min, max) for each reviewee(team) for peer-review 1.3. Currently OnTheFlyCalc already exists as a module. As it is only used by assignments, we plan to change it into a class and change all its methods into static methods 2. LocalDBCalc: 1.1. This class will also contain a method ""compute_total_scores"". But this method will compute the total score by querying and summing the scores saved in local_db_scores table instead of summing the scores given on all questionnaires 1.2. It will also contain a method ""store_total_scores"" which will be called when an instructor clicks on ""Save Scores to db"" icon for an assignment 1.1.1. This method will compute and save the total scores for all the response maps (reviewer -> reviewee) in the assignment for each round in local_db_scores table. <image> As seen in the above image, when a user A reviews another user B (or team), a response map is created containing individual scores and responses to questionnaires. When an instructor clicks on ""Save Scores to DB"" icon for an assignment, ""store_total_scores"" method is called in LocalDBCalc class which calculates the holistic scores for each response map from the individual scores and saves it in local_db_scores table. This also sets the ""local_scores_calculated"" attribute to true for the assignment. Now, the next time someone tries to view these scores, they are computed using the scores saved in local_db_scores. <image> The above image shows the mechanism which will be followed. When an instructor tries to view scores for an assignment, 1st it will be checked if the local_scores_calculated attribute is true or false for the assignment. If it is false, compute_total_scores from OnTheFlyCalc class is called which will add the scores from the questionnaires. However, if it is true, compute_total_scores from LocalDbCalc class is called which will add the corresponding scores from local_db_scores table. 1. Created a new table local_db_scores with columns id, score_type, round, score, response_map_id (foreign key to response_map table) 1. Added a new boolean type column named ""local_scores_calculated"" with default value false to assignments table 1. OnTheFlyCalc class: 1.1. Changed ""OnTheFlyCalc"" module from on_the_fly_calc.rb file into a class 1.2. Changed all its methods into static methods and passed assignment as a parameter for all the methods 1.3. Removed the line ""include OnTheFlyCalc"" from assignment.rb file 1.4. Made changes in all the places (eg. review_mapping_controller.rb) where any method of OnTheFlyCalc was called, so that the corresponding static method gets called now with assignment as a parameter 1. LocalDbCalc class: 1.1. Created a new file local_db_calc.rb with a new class ""LocalDbCalc"" 1.2. Created a static method ""compute_total_score"" with assignment as parameter 1.1.1. This method calculates the total score by adding all the scores of the given assignment stored in local_db_scores table 1.3. Created a static method ""store_total_scores"" with assignment as parameter 1.1.1. This method saves the total score of each response map of the given assignment for each round in local_db_scores table 1. Condition for choosing LocalDbCalc/OnTheFlyCalc 1.1. compute_total_scores is called from 3 files namely ""assignment_team.rb"", ""assignment_participant.rb"" and ""participant.rb"" 1.2. Added a new condition in the scores method in these files which checks if the ""local_scores_calculated"" attribute is set (true) for the given assignment 1.1.1. If it is set (true), compute_total_scores from LocalDbCalc class is called 1.1.2. If it is not set (false), compute_total_scores from OnTheFlyCalc class is called 1. Manage Assignments UI 1.1. Created a new icon for each assignment. Clicking this icon stores the total scores for each response map of the assignment for each round in local_db_scores table. It then sets the local_scores_calculated attribute of the assignment to true 1.2. The code for this is in assets/javascripts/tree_display.jsx 1.3. Created a new method in assignments_controller.rb named ""store_scores_to_db"" which gets called when the above mentioned icon is clicked 1.4. This method calls the ""store_total_scores"" method in LocalDbCalc class 1.5. A route is also created for this newly created store_scores_to_db method 1.6. Note: Clicking on the icon twice for the same assignment saves the latest scores again, and while viewing the scores, only the latest entries from the local_db_scores table are considered. The newly created LocalDbCalc class in models/local_db_calc.rb file with 2 static methods ""compute_total_score"" and ""store_total_scores"" <image> <image> Some of the changes to models/on_the_fly_calc.rb. Changing model to class and methods to static methods by passing assignment parameter. <image> The addition of the new icon on Manage Assignments page to save the scores to database. Filename: assets/javascripts/tree_display.jsx <image> The new method in assignment_controller.rb which gets called when the newly created icon is clicked. <image> The condition used for calling either OnTheFlyCalc or LocalDbCalc. This is similar in assignment_team.rb, assignment_participant.rb and participant.rb <image>. The project can be broken down into below use cases: 1. Instructor wants to store the total scores for each response map, round for an assignment in the database. Instructor clicks on ""save scores to db"" icon and the scores are stored 2. Instructor/User wants to view the scores for an assignment before storing the local scores. Total scores are calculated ""on the fly"" by adding score given for each question by each reviewer 3. Instructor/user wants to view the scores for an assignment after storing the local scores. Scores are calculated by using the values stored in local_db_calc database. The above use cases can then be translated into three major scenarios that we need to test. The following table contains the main scenarios we will cover when testing our project. <table>. 1. Currently OnTheFlyCalc and LocalDbCalc are used to compute the total score for an assignment. More functionalities as below can be added to calculate/display the total scores for a team in an assignment or the total score given by each reviewer. The below mentioned additions/changes will heavily improve the response time. 1.1. LocalDbCalc stores the total score for each response map for each round 1.1.1. These stored values in local_db_scores table can be used directly every time a student wants to view the total score they received from a particular reviewer in a particular round or when an instructor wants to see the total scores by each reviewer given to each team. 1.1.2. These stored values in local_db_scores table can also be used to calculate the total score received by each team, every time a team wants to view their total score or an instructor wants to view the total scores received by each team. 2. Adding conditions to show the ""save scores to db"" icon only when an assignment has finished, and stop showing it again once the scores are stored. 1.1. Currently this icon is present all the time and can be clicked on multiple times, even when an assignment is ongoing. So clicking on this adds the same/updated entries to the database. While viewing the scores, only the latest scores saved in database are considered. 1.2. So, as a future work, this can be modified such that the icon is seen only when an assignment has finished and the scores are not yet stored. This will prevent the scores being stored multiple times or before an assignment has finished. 3. Adding the functionality to remove the scores stored in the database. This will especially be useful after implementing the above mentioned future work because after the above future work functionality, the icon to store the scores will not be shown and if scores are updated somehow, they can't be stored again. 1.1. In our current functionality, if the scores are updated, the latest scores can be stored again because the icon is always present. 4. Add functionality to call OnTheFlyCalc to compute the scores of an assignment whose scores are already stored (if required). 1.1. Currently, once the scores are stored in database for an assignment, every time LocalDbCalc will be used to view the scores of that assignment.",Good work … explains functionality well.  Could use a screenshot or two.,"Firstly, I commend your thoroughness and detail in your assignment. There is clearly a lot of thought, effort and time that has gone into not only planning your proposed solution, but also in implementing it. Your premise of improving performance in the Expertiza system by reducing the need for on-the-fly calculations is solid and you've approached it in a very systematic and thorough manner. There is, however, always room for improvement, so hence my feedback targets certain areas.

1. Structure and Organization: Your report is comprehensive and detailed but it could benefit from better formatting and organization. Use headers to divide the report into sections such as 'Introduction', 'Methods', 'Results' etc. This will make it easier for the reader to follow and understand your work.

2. Clear and Concise Writing: There were some areas in your assignment where your explanations were needlessly verbose and complex. Try to present your points as clearly and concisely as possible. Remember that sometimes less is more.

3. Visual Aids: More screenshots or diagrams to visualize your changes could be helpful. The ones you have included so far look good but adding more would enhance the reader's understanding and break up larger chunks of texts. 

4. Future Work: Your reflection on potential future work is excellent. You showed a deep understanding of the project and its needs moving forward, which is impressive.

5. Testing: I would suggest adding more about how you tested these changes, and what the results of these tests were. Did you benchmark before and after? 

Overall, this is an excellent job! Keep up the good work. Try and focus on making your work a little more reader-friendly in the future, but the core content of your assignment is exceptional. Well done."
184,E1764,"Expertiza is an educational web application for students to submit the articles, code, websites and peer-review learning objects. It is an open source project based on Ruby on Rails and developed by students for many years and keep refactoring and fixing bugs upon peer review. This project is to refactor grades controller which calculates the grades of assignment participants' from peer review and views of listing the scores. After refactor the previous work, it is the part of TLD that use RSpec to examine the correctness of functions and do the integration test. 1. grades_controller.rb 2. grades_controller_spec.rb. The main purpose of grades controller is to allow students and instructors to see grades and reviews through Expertiza, providing functions such as update scores, view teams, make chart and calculate penalties. Some functions were written in long and redundant way which makes it hard to understand and behaves inefficient. We extract some part of functions to become a helper function to make each function more clear and easier to understand. Besides, we slightly change some variable names by using more specific words to promote the readability. Grades_controller_spec includes 10 Rspec tests for each function inside the grades_controller.rb. Some of the tests are integration tests and the rest are unit tests. 1. Refactor make_chart method 2. Refactor calculate_penatly_attributes method 3. Refactor assign_all_penaties method 4. L136-138, L146-150: Refactor instructor_review method 5. L109: Use find_by instead of dynamic method 6. L178: Adjust the format of sprintf 7. Finish pending test in grades_controller_spec.rb. 1. Refactor make_chart method This is a function to make a bar chart based on the grades of participant. The original implementation contains lots of duplicated codes, so we extract the duplicated part out as a helper function called drop_decrement_from_scores. We make the type of participant scores as parameters such as metareview, feedback and teammate. <image> A helper function for make_chart method. <image> 1. Refactor calculate_penatly_attributes method We refactor this method by using zip function to prevent from running the loop three times when passing the different parameters and promote the readability. <image> 1. Refactor assign_all_penaties method We refactor this method by restructuring the code to make it clear and easier to understand. <image> 1. Refactor instructor_review method We refactor this method by replacing 'where.first' to 'find_or_create_' and then create. <image> 1. Use find_by instead of dynamic method When assign questionnaires, we extract the 'find type' statement out from the for each loop, in this case, we can reduce the execution iteration. Instead of using 'find_by', we use 'where' because 'find_by' will return the first element that match the condition; however, 'where' will return all the elements match the condition. <image> 1. Refactor format over sprintf Instead of using sprintf function, we use the format printing here which is more flexible and concise. <image>. For the integration tests, we tested four actions in grades_controller and five scenarios in total: 1. view 1. when the current assignment varies rubric by round, it retrieves questions, calculates scores and renders grades#view page 1. when the current assignment doesn’t vary rubric by round, it calculates scores and renders grades#view page 2. view_my_scores 1. when view_my_scores page is not allow to access, it shows a flash error message and redirects to root path (/) 3. view_team 1. it renders grades#view_team page 4. edit 1. it renders grades#edit page The output coverage is 55.61% now, and the stats are here ( <link> ). There are still some pending tests to be finished: 1. view_my_scores 1. when view_my_scores page is allowed to access 2. instructor_review 1. when review does not exist 1. when review exists 3. update 1. when total is not equal to participant's grade, it updates grades and redirects to grades#edit page 1. when total is equal to participant's grade it redirects to grades#edit page 4. save_grade_and_comment_for_submission 1. it saves grade and comment for submission and redirects to assignments#list_submissions page. 1. Pass all tests created in grades_controller_spec.rb 2. Although some tests are passed, there still a room for improving the test coverage.","The descriptions of the refactorings are adequate, and the tests are motivated well.  The Solutions Implemented and Delivered section should have contained some subheadings, instead of just bullet points.","Dear Student,

Thank you for your comprehensive work on the Expertiza application. Your detailed explanation of your approach in refactoring and testing is especially impressive. 

Your focus and understanding of Ruby on Rails and RSpec are evident in the way you have tidied up the code, made it more efficient, and enhanced readability. Your actions in extracting segments of functions and renaming variables for clarity show good software development sense and understanding. The logic and rationale for your decisions were clear and understandable. 

Though the screenshots or images were not included, the text description provides a fair understanding of the changes you have made. It's always best to include screenshots or code snippets for a well-rounded demonstration.

The integration test suite is substantive, with varied scenarios. However, a coverage of 55.61% is good but there's room for improvement. It would be beneficial to strive for a higher coverage percentage. I will advise you to work on the pending tests mentioned as it will further increase your test coverage.

In your next assignment, I recommend that you pay attention to formatting of your work. The piece seems to struggle with numeration and separation of points. Strict adherence to clear formatting and structuring methods can greatly enhance readability.

You've done a stellar job. It will be exciting to see your progression through this course. Continue to pursue clarity, efficiency, and comprehensive testing in your coding practice.

Best,
[Your Name]"
185,E2080,"The <link> project takes advantage of peer-review among students to allow them to learn from each other. Tracking the time that a student spends on each submitted resources is meaningful to instructors to study and improve the teaching experience. Unfortunately, most peer assessment systems do not manage the content of students’ submission within the systems. They usually allow the authors submit external links to the submission (e.g. GitHub code / deployed application), which makes it difficult for the system to track the time that the reviewers spend on the submissions. Expertiza allows students to peer review the work of other students in their course. To ensure the quality of the peer reviews, instructors would like to have the ability to track the time a student spends on a peer-review. These metrics need to be tracked and displayed in a way that the instructor is able to gain valuable insight into the quality of a review or set of reviews. Various metrics will be tracked including 1. The time spent on the primary review page 2. The time spent on secondary/external links and downloadables. 1. <link> were able to implement the tracking mechanism for recording the time spent on looking at submissions that were of the type of links and downloadable files. The time spent on links were tracked using window popups when they are opened and closed. The downloadable files of the type text and images were displayed on a new HTML page to track the time spent on viewing that. Each time a submission link or downloadable file is clicked by the reviewer, a new record is created in the database. This causes a lot of database operations which degrades the performance of the application. Also, the way in which the results are displayed is not user-friendly. Other than these issues, the team provided a good <link> of the feature. 2. <link> started with E1971's implementation as their base and tried to display the results in a tabular format. The table included useful statistics but it is being displayed outside the review report to the right side which does not blend in with the review report table. Also, the table is hard to read as a lot of information is presented in a cluttered manner. It is hard to map each statistic with its corresponding review. Furthermore, the team did not include any tests. 3. <link> is the most recent implementation, built from earlier designs, features a solid UI and ample tracking of review time across the board. They started off with project E1791 as their base and focused on displaying the results in a user-friendly manner. For this purpose, the results are displayed in a new window so that it does not look cluttered. The issue of extensive database operations still remains as future work in their <link> . 1. From the suggestions of the previous team, <link> , we plan to improve their implementation by reducing the frequency of database queries and insertions. In <link> current implementation every time a start time is logged for expertiza/link/file, a new entry is created in the database. As a result the submission_viewing_event table increases in size very rapidly as it stores start and end times for each link if a particular event occurs. The solution is to save all entries locally on the users system and once the user presses Submit, save the entry in the database. 2. Secondly, <link> implementation has a decent UI that effectively displays the necessary information to the user. We plan to add minor improvements to their UI to try to improve usability. 3. The previous team also mentioned other issues involving the ""Save review after 60 seconds"" checkbox feature, that may be looked into in the case of extra time. PStore is a file based persistent storage method that is based on a hash. Ruby objects (values) can be stored into the data store file by name (keys). Data can therefore easily be read and written to as needed. To create a PStore file you need the following declaration: <code> If the file ""filename.pstore"" does not exist it will be created with the given name, otherwise the existing data will be read. In this case, ""store"" will now point to a persistent hash that you can begin to read and write to. PStore requires all reads and writes to occur within a transaction block. Transaction blocks avoid the problem of multiple processes accessing the same store, since only one transaction can run at a time. Any number of changes can be done in one transaction and a transaction can be ended prematurely using either abort() or commit(). See <link> for more information on PStore. To preserve the logic implemented by team E1989, our Local Storage class is designed to have the same methods you would use to access an entry in a database, but instead interfaces with a PStore file. This allowed us to refactor E1989's methods in the ""submission_viewing_events"" controller without potentially breaking their implementation. For instance, in team E1989's method ""record_start_time"" the line: <code> is intended to check if a link is already opened and timed by looking up the link via the ""where"" method. This line was refactored to: <code> The ""where"" method is instead an instance method of the LocalStorage class that looks up the link in the same way, but in the PStore file rather than the database. To solve the issue of too many viewing event entries in the database, two separate kinds of ""save"" methods were written. ""save"" saves a viewing event entry into the PStore file, while ""hard_save"" saves entries stored in the PStore file, in the database. This allows us to save entries into the PStore file and only officially save those entries in the database once the review is complete. Our method ""remove"" in the LocalStorage class removes entries from the PStore file. This method is called in the ""submission_viewing_events"" controller after saving an entry into the database. The following is the flowchart presented by E1989 that does a good job outlining the logic for tracking the time students spend reviewing: <image> The following flowchart outlines how PStore and its methods work together to emulate methods used to access a database <image>. Our implementation is centered around two different classes and the default 'pstore' gem Our two classes work together to limit data written directly to the database. This class serves as a sort of ""instance"" or a standard for representing the tracking of the time for a single link which was visited. <code>. This class serves as the medium for transaction of data between the local @registry instance variable, pstore and the database It manages the pstore ""hash"" by restricting access and saving instances of LocalSubmittedContent when required. It has a lookup feature with .where() where the user can search for LocalSubmittedContent given specified parameters Lastly it provides the functionality to save the entries from pstore into the database <code>. The main feature that we want to test is that the intermediate review timings that we are planning to store on the browser's local storage are being accurately stored or not. There are already tests written to test the total time tracking feature. We will be adding additional tests to test the storage and retrieval of the intermediate timings. Our major focus for this project is to change the current implementation to use significantly less number of database operations by storing the intermediate timings in the local storage of the browser and write only the final time spent on viewing the submissions. So, the only manual UI testing that can be performed is to check if the total time spent by students is accurately tracked and can be viewed by the instructor. This can be tested using the following steps: 1. Log in to Expertiza as a student and go to the assignments tab. 2. Click on a particular assignment and review the submission by click on links and spending some time viewing them. 3. After reviewing is done, submit the review. 4. Log out from the student account. 5. To look at the time spent on the reviews, log in as the instructor. 6. Click on the assignments tab. 7. Click on the review report icon beside the specific assignment that you reviewed using the student's account. 8. You should be able to see the total time spent on the submissions by the student. RSpec tests were written to test the following LocalSubmittedContent methods: 1. initialize 2. to_h 3. ==. RSpec tests were written to test the following LocalStorage methods: 1. initialize 2. save <code> 1. sync <code> 1. where <code> 1. read <code> 1. hard_save <code> 1. hard_save_all 2. remove <code> 1. remove_all. 1. <link> 2. <link> 3. <link>. 1. The ""Save review after every 60 seconds"" checkbox does not work correctly, hence we defaulted that to unchecked as opposed to previous implementation where it was checked, because it hampers with our implementation. 2. Because methods in the submission_viewing_event controller were modified to implement LocalStorage, there should be Rspec tests added to test those refactored methods.","The description is quite readable, and the diagrams are good.  The document considers only changes made by this team, not the code that was written for the previous project and is still present in their commit.  This would require the reader to consult the previous document in order to understand the changes made by this project.  Description of the classes changed is good, but it would have been better if prose had been written about the individual methods.","First of all, thank you for going to such great lengths to articulate your project in a detailed manner. It is clear that your team has a deep understanding of the software and its related implementations. 

Your project expands nicely on E1989's work and I appreciate how you've focused on refining the user interface to improve usability. It’s significant that you took initiative to enhance the data write process by capitalizing on the browser's local storage, which effectively addresses the performance issue with numerous database operations. It's great to see the problem-solving skills at work.

An important part of every development cycle, I notice you did include tests for the system which is positive. Writing adequate tests, as you've done, signifies good practice and ensures that the features are working as expected. 

However, it is important to elaborate on the impact of your implementation on the clients. How will this less frequent writing to the database improve the user experience or the application performance?

Also, I advise you to provide more information regarding some of the issues encountered during testing e.g, the problem with ""Save review after every 60 seconds"" checkbox. How does this problem affect your implementation and what do you propose as a way to address it in future efforts?

Lastly, while you have given links to your codebase or other potentially useful resources, they seem to have been omitted from the report. Please ensure to include these and also properly comment your code to foster maintainability by future developers and easier understanding by individuals investigating your solution.

Overall, your work indicates a good understanding of the software and an ability to extend its functionalities significantly. Great job!"
186,E1925,"Expertiza provides teammate reviews to gauge how much each team member contributed, this information could be generated from data from external tools like Github (for example, number of commits, number of lines of code modified, number of lines added, number of lines deleted.) from each group’s submitted repo link. Currently, Expertiza provides Teammate Reviews under View Scores functionality for each assignment. 1. Teammate Reviews functionality in the View Scores page gauges teammate views on how much other team members contributed to the project. We need to augment this data with data from external tools like GitHub in order to validate that feedback. New metrics will be appended under each student data under the same functionality. 2. Github Metrics under View Submissions page should include a bar chart that shows the number of commits by the team throughout the assignment timeline. This will help instructors to get a team overview, and aid grading process. While this data will not have marks associated directly, it will prove useful to the instructor in differentiating the performance of team members and hence awarding marks as per contribution. Overall data for the team, like the number of committers and number of commits may also help instructors to predict which projects are likely to be merged. The link for our project PR is <link>. Extract Github metadata of the submitted repos and pull requests. 1. The metadata should be stored in the local Expertiza DB. For each participant, record should include at least: 1.1. Committer id 1.2. Total number of commits 1.3. Number of files changed 1.4. Lines of code changed 1.5. Lines of code added 1.6. Lines of code removed 1.7. Lines of code added that survived until final submission [if available from Github] 2. The code should sync the data with Github whenever someone (student or instructor) looks at a view that shows Github data. 3. The data for teams should be shown in the instructor’s View Scores window, in a new tab, probably between Reviews and Author Feedback. 1.1. Design a good view for showing data on individuals. Please discuss this with the project mentor(s). 1.2. It seems to me that this should be on the Teammate Reviews tab, right below the grid for teammate reviews. The reason for this is that we’d like to see all the data on an individual in a single view. For teams, by contrast, there is already a pretty large grid, and potentially multiple grids for multiple rounds, so adding a new grid is more likely to clutter the display. 4. Create a bar chart for the # of lines changed for each assignment team on “view_submissions” page. The x-axis should be the time starting from the assignment creation time, till the last deadline of the assignment, or current time, whichever is earlier. This task has been partially implemented by another group for project E1858. Github Metrics Integration in 2018 Fall semester. Detailed document about project E1858 on framework design and implementation can be found in <link> and the PR for Project E1858 is shown in <link> . However, their work has been rejected with the feedback ""They have integrated the github metrics into expertiza to show the number of commits, pull requests status, etc against every project. They have also integrated it into the metrics. Looks like they covered the edge cases. The code looks good but needs comments as it is pretty complex. The documentation feels like it is flooded with code, if there was a description of the changes, it would have been better. Extensive tests, but it might be good to see if additions to existing tests really belong in those same tests"". The goal of our current project is to resolve issues existing in their previous work, refactor codes they created and modify their code following ""DRY"" principles. The ultimate goal is to have the Github Metric Integration work in Expertiza. <image> 1. Use Case diagram of two approaches to append 'GitHub contribution metric' in teammate review. 2. Use Case diagram explaining approach to add new column 'GitHub contribution metric' in 'View submission. Actors: 1. Instructor: This actor is responsible for viewing GitHub metrics of teams and team members of an assignment. Pre-Conditions: 1. The Team should have submitted the assignment with a PR link or GitHub repository. Primary Sequence: 1. The instructor should login. 1. The instructor should browse teams for an assignment. Post Conditions: 1. Instructor will be able to see the team contribution done by each team member in 'View Submissions' page using graph diagrams, as shown in the figure. 2. Instructor will be able to see the work done by each student in 'Teammate Review Tab' with new metrics table appended at the end, as shown in the figure. Github Metrics Features can be accessed from manage content UI <image> Then click the 'view submissions' <image> Then we can see 'Github Metrics button' in each project submission <image> Below is the bar chart of commit numbers. <image> We can see the details in the following part. <image>. After understanding the project E1851, We found some issues in this project and give our solutions below. Problem: The related codes for Github related functionalities are most implemented under ""Grades_Controller"". This design obviously violates a good design pattern because Grade_Controller involves too many functions. Solution: To improve it, we should create a separate ""Github_Metrics_Controller"" which is specifically responsible for functions related to Github Metrics. Following the MVC architecture, we will also need to create corresponding Models and Views for the new controller. Problem: There are some JavaScript codes in inappropriate positions. For example: <code> Solution: We need to replace JavaScript codes to 'assets' fold. Problem: Lots of codes in their current implementation violate ruby's ""DRY"" principles, such as redundant codes, meaningless names, long coding block and so on. Solution: We will refactor their code and fix code smells with the help of code climate platform. For example, some code like the format below can be rewritten in the shorter line. <code> The solution to the example: create a hash table for all of the instance variables and refactor all the usage of the variables. <code> Some code like the format below can be rewritten and shorten by putting } in one line. <code> Also, there are many useless spaces make the code look less elegant. To make sure the refactor code can work correctly, we need to run the original rspec test code and add some new test. Besides, we are plaining to test from UI to make sure all the features work. The test results are shown below. 1. Run and pass existing RSpec Tests after refactoring 2. Develop New RSpec Tests for the new features 3. UI testing on the deployed project. For the existting test, we need to mock roles: <code> All the test can be found in ""expertiza/spec/controllers/grades_controller_spec.rb"" now, we will refactor it since we need to build new controller. We test several conditions : 1. Views 1.1. when user has logged into to GitHub 1.2. when user hasn\'t logged in to GitHub 1.3. when current assignment does not vary rubric by round 2. view_my_scores 1.1. when view_my_scores page is not allow to access 1.2. when view_my_scores page is allow to access 3. view_team 4. edit 5. instructor_review 1.1. when review exists 1.2. when review does not exist 6. update 1.1. when total is not equal to participant\'s grade 1.2. when total is equal to participant\'s grade 7. save_grade_and_comment_for_submission 8. get_statuses_for_pull_request 9. etrieve_pull_request_data 10. retrieve_repository_data 11. retrieve_github_data 1.1. when pull request links have been submitted 1.2. when pull request links have not been submitted 12. retrieve_check_run_statuses 13. view_github_metrics 1.1. when user has logged in to GitHub 14. authorize_github 15. get_github_repository_details 16. get_pull_request_details 17. process_github_authors_and_dates 18. parse_github_pull_request_data 19. parse_github_repository_data 20. make_github_graphql_request 21. get_query 22. team_statistics 23. organize_commit_dates The new rspec test file is <link> . You can run the following code rspec spec/controllers/github_metrics_controller_spec.rb to test the result. Our rspec test coverage is 100. The test video is <link>. For this project, we add an API from the GitHub, all we need to do is to test whether the API can work appropriately after changing codes to another controller and moving javascript codes. Management -> Assignment -> Github Metrics You can see the test result in <link>. We added and changed the new controller github_metrics controller and some ralated files. 1. <link> 2. <link> 3. <link> 4. <link> The GitHub metrics part is separated into the new files. Previous work includes JavaScript code. After carefully testing and examination, we found these JavaScript code were another version of the implementation of our task. So we remove those redundant codes to make our code clean. 1. <link>. We create a hash table to cover all the created instance variables. 1. <link>. we set the callback URL as: ./auth/github/callback <image>. <link> <link> <link> <link> <link> <link>.","For design doc: You do a good job of explaining the problems with the previous implementation.  And you show code that has been changed.  I think there should be more comments.  A Github diff view would be clearer than the monochrome wiki listing.  The main issue that I see, though, is that when you show code that has been changed, you don't say what file it is in.  True, the reader could search in Github.  But (s)he shouldn't have to.","Thanks for the detailed assignment submission. It's clear that you've put in a lot of work into understanding the existing Github Metric Integration and figuring out how to improve its shortcomings. Here are a few points of feedback:

1. You have identified the problems clearly and proposed solutions for the same. But, it would be useful to see some actual refactored code snippets in the assignment for the parts where you mention that you are going to make a change.

2. While you've provided a detailed plan for improving the system, including mock-ups of what the updated system would look like, it would be even more helpful to get a sense of your progress with screenshots of your implemented changes.

3. You mentioned several tests, which shows thoroughness. However, it's not clear if these tests completed successfully or any issues encountered during testing. Please add this in future submissions.

4. It would be nice to see an assessment of how much your changes improved efficiency or user experience. If possible, try to quantify these improvements.

5. Please ensure to format your submission for better readability. It would make your assignment easier to follow if you could use headings to organize the different sections.

Great work thus far! I'm looking forward to seeing how you implement these improvements in your next assignment."
187,E1970,"This page provides a description of the Expertiza based OSS project. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.1.1.1. <link> 1.1.1.1.2. <link> 1.1.1.2. <link> 1.1.4. <link> 1.1.1.1. <link> 1.1.1.1.1. <link> 1.1.1.1.2. <link> 1.1.1.2. <link> 1.1.5. <link> 1.1.1.1. <link> 1.1.1.1.1. <link> 1.1.1.1.2. <link> 1.1.1.2. <link> 1.1.6. <link> 1.1.7. <link> 1.1.8. <link>. <link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. The following tasks were accomplished in this project: 1. Fix <link> 1.1. The ‘view submissions’ page of an assignment does not have an appropriate header. 1.2. The header should be added to reflect text such as “Submissions for <assignment name> 2. Fix <link> 1.1. The New review page contains a spurious ""p"" before each criterion is shown 1.2. The status p (paragraph) should be removed 3. Fix <link> 1.1. When an assignment is being created with a rubric that uses the “Use dropdown instead” option, it falsely indicates the save was successful. 1.2. The save is not persisted when we review the assignment rubric. The option “Use dropdown” is not selected. 1.3. The option should be saved in database and reflected on the review page. None of the bug fixes requires design patterns. The ‘view submissions’ page of an assignment does not have an appropriate header. The header should be added to reflect text such as “Submissions for <assignment name>. <image>. 1. The view submission page currently has no title representing which homework submission the viewer is viewing, a title needs to be added into where the red circle is. 1. View The view shows what's presented to user of this page, if we would like to have additional information displayed on the page, we would need to find the corresponding location to add it first: <code> In this case, the blank space above team E1877's change should be where the red circle stands. <image> 1. View change Since this page already uses `@assignment` in a lot of places, and we found it in the corresponding controller, so directly using it wouldn't pose additional problems as the query of the assignment is already done in the back-end. <code>. When reviewing other people's work, the text box for review entering always contains a spurious HTML tag. <image>. 1. This is a problem of the tinyMCE plugin which is used for text editing purposes for Expertiza, changing configuration of the plugin may solve the problem. 1. Configuration file Someone had similar issue on some other settings, refer to this <link> , we could also edit the `tinymce.yml` file accordingly <code>. <image> 1. Configuration change When we remove this p, the status bar becomes empty, and renders no use, so we removed it from the display <code>. (This should be 1352, there must be a typo in the project google doc) When an assignment is being created with a rubric that uses the “Use dropdown instead” option, it is indicated the save was successful. However, the save is not persisted when we review the assignment rubric. The option “Use dropdown” is not selected. <image>. 1. the ""dropdown"" checkbox status appears to be not saved, or not displayed correctly if it is saved. 1. Isolate problem We checked the database schema and found the ""dropdown"" attribute in there actually represents the dropdown menu next to checkbox, this needs to be refactored in the future when there are more than 2 values in the dropdown (currently saved as boolean) <image> 1. DB:migrate to solve the issue we have to first create the attribute inside of database 2. We found that the view could only either pass a value or not pass a value instead of passing true or false when checkbox is checked or unchecked; whatever value entered in the `value=` field would get passed to DB <code> 1. To fix this issue, we have to setup another DB:Migration to have a default false value in this attribute 2. A mysteries function of `copy assignment questionnaire` (why copying it? who uses this function?) need to have this new attribute in there in order to pass data to DB 3. the view needs to be modified in order to reflect the database. <image> 1. DB change There's a new attribute `use_dropdown_instead` in `assignment_questionnaires` table now, it's default value is false <code> 1. Controller change The attribute `use_dropdown_instead` is being passed by all functions relating to rubric editing now <code> 1. View change The view reflects values stored in use_dropdown_instead now <code>. 1. Test submission page header, use `view_submission_header_spec.rb` <code> 2. This is a configuration change of a plugin, cannot be tested with Rspec 3. This involves another bug much bigger than the scale of this project: in `./app/helpers/assignment_helper.rb:63` <code> The `DeadlineType.find_by(name: type)` cannot find anything, which stops us from visiting assignment creation or edit page, see `create_assignmenet_save_checkbox_spec.rb` for details. Following are a few testcases with respectto our code changes that can be tried from UI: <link> 1. To see homework title related to submission, go to ""Manage > Assignment > View submissions"" after logging in with a instructor account 2. To review text box for reviews: 1. 1.1. Login as a instructor 1.2. Create an assignment set submission time to be an hour later 1.3. Log in as student A 1.4. Do assignment, then submit 1.5. Log in as student B 1.6. Do assignment, then submit 1.7. Login as a instructor 1.8. Set submission deadline to be an hour earlier 1.9. Log in as student A 1.10. Go to view other's work, and ask for a new review 1.11. Begin review, user should find the textbox without the P 3. To see the checkboxes reviewing what's saved: 1. 1.1. Login as a instructor 1.2. Create an assignment, set checkboxes in rubric items 1.3. The landing page (edit assignment) should review the checkboxes checked in previous step. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. Clean Code: A handbook of agile software craftsmanship. Author: Robert C Martin.","Problem statements are clear.
In the Solutions, when you present a view, it would be very helpful to identify what in the view has changed (using Github diff view).  It would be a lot clearer than pasting in ""before"" and ""after"" code sequences.
In Issue #1352, I don't understand why the dropdown menu would need to be refactored in the future.  I can't understand the two different ways that dropdown is being used.
When you present a test, you should explain in prose what it tests and how it works.  It's also not clear why the first test tries to add a member to an assignment team.
In the ""Testing from UI"", it's not clear what you intend for a user to do when it says ""Do assignment, then submit.""  This should be explained in more detail.","Hello,

Thank you for your comprehensive project assignment submission. The effort you have put into addressing and attempting to fix the bugs within the Expertiza system is commendable. However, it would greatly improve clarity if you had provided a brief introduction and conclusion to bring together the multifaceted aspects of this project. 

There are some points to consider for future assignments:

1. References to <link> without providing relevant URLs can be confusing. Provide the actual URL or note if they are placeholders.
 
2. When you address bugs, it might be helpful to group them efficiently, discussing the issue and the fix within the same section rather than spreading them out.

3. It's a good practice to add relevant comments in your code snippets in assignments, making it more comprehensive for the reviewer.

4. Clear testing instructions are important in such project assignments. You've done a good job in this area, just ensure any action to be undertaken is clearly defined.

5. Lastly, ensure you properly cite all references as per the academic integrity policy.

Overall, great work with the assignment. Your approach towards solving the bugs and walking us through the solution process shows your understanding of the subject at hand. Keep improving and keep up the good work! 

Best,

[Your Name]"
188,E1459,"Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link> 1.1.8. <link> 1.1.1.1. <link> 1.1.9. <link>. <link> is a web based application used by students and professors to create, select, submit and review assignments. Selection of assignments may be individual assignments or group assignments. The assignment is configured by the professor. Peer reviews can be conducted by fellow students in the class. Additionally the professor can review the assignments submitted by the students. Assignments are what Expertiza calls learning objects. Learning objects consist of such things as articles, websites or web applications, or code. The Expertiza project is open source with many programmers contributing to the code base. The source code is available at <link> . Due to the open source nature of this application the code is not always as clear, concise and as standardized as it could be. This project seeks to resolve some of these issues by applying sound object oriented design principles along with standard RESTful naming conventions where possible. This project is focused on the signup_controller and its fringe classes. The role of the signup_controller is to process requests from the user to sign up for an assignment. The purpose of the controller is to process actions from the user; however, in many cases the controller is doing functions that should be provided by the model. Any calculations should appear in the model rather than the controller. The code should use RESTful names such as new, create, edit, and delete. In many cases it does not. Methods should be no more than 30-40 lines long. Any longer and the reader needs to rely on their working memory to remember what code that is outside of their view does which is an inefficient and error prone way to read code. Other classes that are involved in this process include the sign_up_sheet_controller a number of views that pertain to assignments, topics and fixtures and functional tests and model classes such as sign_up_sheet.rb and sign_up_topic.rb. The sign_up_sheet_controller handles actions pertaining to creating assignments. On the first round of refinement the code was simply cleaned up by untabifying the code and using the Rails and Expertiza coding standard of using two spaces for indentation. Untabifying the code eliminates variations in tab stop configuration in programmers editors. This makes the code more readable to those who view the source code so that blocks don’t look like run together. In the following examples, the original programmers did not employ the <link> (DRY) principle to their code. We attempted to correct this by cleaning up duplicate code and removing function calls that provided no additional value or functionality from the call it makes within it. Some methods were renamed to ones that more closely align with Rails naming conventions. In the app/controllers/sign_up_sheet_controller.rb the index and add_signup_topics actions were changed to index_signup and index actions respectively. These two actions did similar functions and were made clearer by merging them. <image> The design of the SignUpSheetController class controls two different behaviors of the SignUpTopics model: creation of topics for an assignment by the instructor, and allowing students to sign up for a topic. To clearly distinguish between these two different behaviors, all actions performed by the instructor to manage a topic (index/create/update/destroy) were renamed to follow the standard Rails naming convention. All actions performed by the student (index/create/destroy) to sign up for a topic have the suffix _signup. The issue with these methods were that they didn’t follow Rails naming conventions for displaying a list of items and they were not representative of the the functions that they performed. The add_signup_topics method displayed a list of topics for the teacher to modify the topics. The index method although following Rails convention in naming the function name did describe its purpose with respect to the scope of the controller in which it lives. The index method originally listed the topics for the student to sign up from. This however is the sign up sheet controller and therefore the index method would have been expected to list topics and perform actions on them at a higher level. The teacher is concerned with the assignment as a whole. That is the teacher is concerned with listing and acting on a large number if not all of the topics on the assignment and better aligns with the name of the controller (signup_sheet_controller). Therefore the add_signup_topics method was renamed to index and the original index method was renamed to index_signup. The latter was renamed using the index convention but with the _signup suffix. The original index method displayed the list of topics that the user could sign up for. In this case the student is interested in acting only one one topic therefore the signup suffix reflects intent. In the Model View Controller (MVC) paradigm code pertaining to the business logic of an application belongs in the model layer of the program. This paradigm was broken in several places in sign_up_sheet_controller.rb file. For instance, the confirm_topic method is used in the sign_up_sheet_controller.rb file to assign a topic to a user after performing several model layer checks to make sure that the user can, in fact, be assigned a topic. This code is better moved to the model layer as its performing business logic and not simple validation or control statements. The decision was made to move this method into the SignUpTopic model. There were also several “utility” methods that we believe were added to the controller at some earlier point and are now obfuscated due to the efforts of previous groups of students to improve the code. For instance, the otherConfirmedTopicforUser(assignment_id, creator_id) and slotAvailable?(topic_id) methods did nothing other than call a method in the model and return the result, this sort of complexity is unnecessary. We removed these methods from the controller as they achieved nothing and did not make the code any easier to read. <image>. The following is a complete list of files that were changed. <code>. A <link> file has been written explaining how to access features updated in this project. Much of the content of this file has been repeated here for convenience. The following accounts have been created on the test environment. Administrator account: 1. admin - Password: admin Student accounts: 1. student1 2. student2 3. student3 4. student4 5. student5 6. student6 7. student7 8. student8 9. student9 To log in as a student first log in as an admin and then use the Manage=>Impersonate User functionality to switch the student account of your choice. There are two assignments pre-creted: 1. due_date_assignment1 : Due date is same for all topics. 2. staggered_deadline_assignment1 : Due dates for topics are staggered based on a topic heirarchy. These two assignments are provided for testing convenience - you are free to add topics and have students sign up/ drop topics. However, PLEASE DO NOT DELETE THESE TWO ASSIGNMENTS . The assignment controller/view has a bug which makes adding assignment deadlines impossible. Deadlines for these two assignments were manually populated in the database. You are free to create a new assignment for this purpose. <link> <link> May be invalid after a few weeks <link>.",Insufficient explanation of changes.,"Dear Student,

Thank you for your thorough and well-structured content. I appreciate the considerable amount of work you have put into creating and documenting your assignment. The depth of your code analysis and your thoughtfulness in explaining various components of the Expertiza project are commendable. 

Your notes on cleaning up the code, using standard naming conventions, and applying object oriented design principles were insightful. The way you described and rationalised the changes made to the SignUpSheetController class illustrates a deep understanding of the MVC paradigm. 

The decision to refactor and shuffle code between the Controller and Model layers to maintain a clean separation of concerns was a wise move. Cleaning up unnecessary method calls as well as renaming methods according to Rails conventions definitely helps to improve maintainability and readability of the code.

The few recommendations I have include the following points:

- It may be beneficial to include more visual aids to support your code manipulation such as code snippets, flowcharts, or diagrams. This will enhance your readers' understanding.
- In the further explanation of your work, don't forget to highlight any challenges or learnings from this assignment.
- Lastly, when it comes to sharing links, kindly ensure that they all work and lead to the expected resources. This will help in cross-verification of the codebase and other resources.

Overall, great work with this assignment! I'm looking forward to seeing more of your future projects. Keep up the good work in maintaining and improving the open-source codebase.

Best Regards,
[Your Name]"
189,E1807,"Expertiza is an open source project based on Ruby on Rails framework. Expertiza allows the instructor to create new courses, assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can use the expertiza platform to form teams to work on various assignments/projects. Students can sign up for various OSS topics to work on, peer review other students submission. Students can submit their assignment in the form of URLs, upload files. 1. For Instructor, username: instructor6, password: password 2. For Student, username: student7490, password: password 3. For Student, username: student7495, password: password. Sometimes when a reviewer fills out a review rubric, one or more fields can be left empty by the reviewer. While calculating the peer-reviewed score, the program is counting the empty fields as zero. However, this is not correct. The empty fields should not be counted at all, as this may affect some other metrics (like average score) of the reviewee. <image>. While calculating the peer-reviewed score, the program checks whether the score is empty or not. If a score is empty, it should not be counted while calculating average score. Only not null review scores are to be counted while dividing by the total number of reviews, for the average score calculation. <image>. GitHub link 1. <link> Pull Request link 1. <link>. /app/models/vm_question_response_row.rb. The method ‘average_score_for_row’ is used to calculate the average peer-reviewed score. We added a variable ‘no_of_columns’ to count the number of review scores that are not null. We changed the way the average score is calculated. Previously, ‘row_average_score’ was calculated by dividing by ‘@score_row.length’, where the length will include both null and not null values. Now we divide ‘row_average_score’ by ‘no_of_columns’, which does not include null scores. <image>. /spec/models/vm_question_response_row_spec.rb. We added a RSpec file for the class ‘VmQuestionResponseRow’ to test the method ‘average_score_for_row’. We tested the following scenarios for calculating average score: 1. All scores are not nil 1.1. This is the scenario where no fields are left empty. Average score was calculated correctly in this scenario before the issue fix. We test that the score is calculated correctly after the issue fix too. 1.2. All not nil scores that are all zero are also tested to ensure that the output is zero. 2. All scores are nil 1.1. This test ensures that when all fields are empty or are nil, average score is also nil instead of being zero. 3. Mixture of nil and not nil scores 1.1. This test ensures that when some fields are left empty, they are not taken into consideration while calculating average score. To compute average score, the total score will be divided only by the total number of fields that are not nil. 1.2. We tested this scenario by including or excluding zeroes in the scores and varying number of nil scores to verify correctness in average score. <image> <image> <image>. 1. <link>. Expertiza 1. <link> Expertiza Github 1. <link> Expertiza Documentation 1. <link> RSpec Documentation 1. <link>.","Good writeup, and good motivation for the changes that you made.  Would have been helpful to explain the magic hex constants in the tests.","The assignment is generally well-written and it shows that the student understands the problem and the solution. He has explained in detail about the changes made to the 'average_score_for_row' method and he also demonstrated a good understanding of the Ruby on Rails framework. Overall, the student demonstrates a good grasp of programming concepts and an advanced skillset in Ruby on Rails.

Additionally, the testing section was quite thorough and well done. It's a good practice to consider various test scenarios to ensure the program's correctness when changes are made; he demonstrated this well by considering three different scenarios.

However, here are some detailed comments and suggestions for improvement:

1. Links or placeholders ('<link>' or '<image>') used in the text should be replaced with actual GitHub repository links and relevant images/screenshots for better understanding.
2. The assignment structure should be improved. It would be great to divide the text into clear, distinguishable sections like 'Problem Statement', 'Solution Description', and 'Testing'. 
3. Consider numbering the provided scenarios correctly. The numbering is repeating itself in multiple places, so it's not entirely clear which points go with which scenarios.
4. Avoid repetition in text. For example, 'Expertiza Github link' is repeated more than once. 

Consider making these changes for your submission to be completely effective and clear to any reader, and keep up the good work!"
190,E1988,"An error occurred while attempting to extract the child content. The objective of this project is to: 1. Add a feature for students to toggle the visibility of their reviews. When reviews are marked 'public', instructors will have the option of adding them as a 'sample review' to any assignment. When reviews are marked 'private' they will not be shown to other students as a sample. 2. Add a feature for the Instructor to select a subset of 'public' reviews and make those reviews visible as sample reviews of any of their assignments in the course. 3. Add a feature for instructors to select a subset of 'sample' reviews and set those reviews as sample reviews for a particular assignment. 4. Create a view where the student can see a list of sample reviews of the assignment and have a detailed view of each. The goal of this project is to enable instructors to select certain reviews to show as examples to the entire class. Thus the students will be able to see good reviews that one student has submitted for another student's work. The students will be able to get understand what a good review looks like and what exactly is expected from them when they review any other team's work. 1) Creating a checkbox : When a student submits a review, they should be able to choose if they want to make their review public or private. Thus we added a checkbox to the review page. Checking this checkbox will make the review public. Unchecking it will make the review private. When this status changes, a message is displayed next to the checkbox saying if the status was changed successfully. 2) Allow students to make a review private : Students should be able to change the visibility of their review even after they have submitted it. A checkbox similar to the one described above was implemented where students can see the reviews they have given. If a review has been made private after an instructor has selected it as a sample review, it is still not displayed to students as an example review. 3) Allow instructors to select (remove) sample reviews : If a review has been made public by the reviewer, the instructor is able to select that review to be made a sample review. If the review is already a sample review, the instructor is able to remove from the set of example reviews. If the review was private, the instructor is shown a notice that 'This review is private.' and they are not allowed to select it as a sample review. This selection can be done when the instructor is viewing the review. 4) Set some of selected reviews as sample for an assignment : Sample reviews can be identified by the assignment, reviewer (a participant) and the reviewee (a team). When editing an assignment, the instructor is able to select past assignments, select a reviewer and select the reviewee. The way in which the instructor selects the assignment is to select the from a dropdown. the assignment dropdown is populated with all the assignments that the instructor has created and all the assignments that belong to the course. When the assignment is selected, the reviewer dropdown will then be populated with the names of the reviewers whose reviews have been made public and have been selected by the instructor. Once the reviewer is selected, the reviewee dropdown will get populated with names of teams to whom the review has been given. This will identify the selected review. The instructor will be able to set it as sample review for the current assignment. This means that the instructor can even set a review from any of their earlier assignments as a sample. 5) Allow students to see sample reviews : When a student wants to review other team's work, they will be shown a list of sample reviews that the instructor has selected for them. In the list each review is a link to the full review. 1. Create migration to create a column called status which can take on the values 'selected' = 2, 'public' = 1 and 'private' = 0. Changes will reflect in db/schema.rb Status can have 3 values as listed below: <table> 1. Create a checkbox in a view: views/response/response.html.erb . To allow students to mark their reviews as public. 1. Add code to check the status field from response.html.erb and update the db, in controller: app/controllers/response_controller.rb (in method ""create""). This will reflect the choice of the student in the database. 1. The instructors will select sample reviews from a set of public reviews. The code change will be in the file team_users_popup.html.haml which is under the views/popup directory. 1. Students will be able to view sample reviews. The code change will be in the file list.html.erb which is under the views/student_review directory. 1. In order to paginate and display a list of reviews to chose from for the instructors, we will have to create partial view files. 1. The instructor will be able to view the reviews which have been marked public by student. Those reviews will have an orange border around them. This is implemented in app/views/reports/_review_report.html.erb 1. The code to check the visibility status of a review is implemented in app/helpers/review_mapping_helper.rb. 1. Use Case - <image> Power Users: Instructors, TAs, Admins and Super Admins. 1) They added a facility for instructors to select individual reviews and set them as a sample. Hence a migration was created to create a model. The model has an assignment id and a response_map_id. The assignment_id is the id of the assignment for which the sample is to be shown. The response_map_id is the id of the sample review. 2) A column called visibility was added to the responses model which will show if the review has been marked 'private', 'public' or 'selected'. We plan to improve the code which was implemented last semester. This code implements the functionality of the given problem statement. But they lack standards which are required to merge into the expertiza branch. So we plan to reuse the code and modularize it by refactoring and taking care of all the unnecessary parts of the implementation by removing the new reports, modified icons and new files under the test folder. Since all this has been already implemented. In our approach, we will modify the code to work on the reports that already existing in the assignments. In our project, the implementation of new functionality would be through a Delegation pattern which is an object-oriented design pattern that allows object composition to achieve the same code reuse as an inheritance. This shows the overall flow of what the users of the system should be able to do. We will write tests such that the entire flow will be completely tested. As a Power User (TA/Instructor/Admin/Super Admin) (Scenario 1) 1. Log in 2. Click on Manage->Assignments 3. Displays a list of Assignments 4. Click View Report/Review for a particular assignment. 5. Displays a list of reviews submitted by students. 6. Click on any review in ""team reviewed"" column for a particular student. 7. Displays the summary of reviews submitted by that student, with a ""Make as sample"" button on the right of every review. 8. Click on ""Make as sample"" for the intended reviews, which opens a popup that displays a list of all assignments that are a part of the instructor's courses. 9. From this list select all assignments for which the review has to be shown as a sample. 10. Click on 'Submit' after selection (this closes the popup). 11. Navigate to view reviews of that particular assignment and click on ""Sample Reviews"". 12. A new page is opened that lists out all the sample reviews of the assignment. As a Power User (TA/Instructor/Admin/Super Admin) (Scenario 2) 1. Log in 2. Click on Manage->Assignments 3. Displays a list of Assignments 4. Click Edit for a particular assignment. 5. Click on the review tab. 6. Select an assignment from the dropdown 7. Select a reviewer from the second dropdown. 8. Select a reviewee from the third dropdown. 9. Click 'Add' button to add the selected review to be shown as a sample for this assignment. 10. Add as many sample reviews as you want in the same way. As a Student (Scenario 1) 1. Log in. 2. Click on Assignments 3. List of assignments is displayed. 4. Click on any assignment for which the review has to be submitted. 5. Assignment task page is displayed. 6. Click on ""Other's work"" to open the reviews summary page (at /student_review). 7. Below the heading ""Reviews for ..."", click on the ""Show sample reviews"" link. 8. This opens a page where the student can view all sample reviews for that assignment. As a Student (Scenario 2) 1. Log in. 2. Click on Assignments 3. List of assignments is displayed. 4. Click on any assignment for which the review has to be submitted. 5. Assignment task page is displayed. 6. Click on ""Other's work"" to open the reviews summary page (at /student_review). 7. Chose to review any of the teams' assignments that are displayed. 8. Select a team for review and fill in the review. 9. Before submitting the review, select the checkbox that says ""I agree to share this review anonymously as an example to the entire class"". 10. After clicking on the submit button, the review submitted has been made public. <link> <link> <link>.","The description of the problem is quite readable.  The implementation is well described in prose, but it would help to see some of the code snippets that were introduced.  This is the reverse of many design docs, which show the code, but don't adequately explain what was done. ","It appears that you've put a significant amount of thought and detail into this project, demonstrated by your elaborate explanation of the features and steps required in implementing this project. However, it might be helpful to organize your writing more efficiently, possibly by using clear headers or breaking up your text into diverse paragraphs for each point or feature to enhance readability. 

You've correctly outlined the project's functional features, but further considerations might include testing and debugging procedures, project timelines, code sustainability and scalability, and potential risks or issues that might arise. Additionally, the explanation of your planned improvements is a bit indistinct; perhaps you could provide more specific details on what exactly needs to be refined from the previous semester's code. 

Moreover, the term 'private' and 'public' might cause some confusion in interpreting your planned features—consider replacing these with something more descriptive to avoid any misunderstandings. 

Your User Stories or Scenarios perfectly show how the system is intended to function from both instructor and student perspectives. However, ensure that the wording of these scenarios is consistent; for example, using ""click"" in all instances instead of alternately using ""select"".

Lastly, it seems that there are broken links at the end of your submission, or they might just be placeholders. If those are intended to be actual links, please make certain they're functioning correctly in your next draft. 

Overall, you've done a commendable job on this assignment. With a few improvements and a bit more clarification on certain points, you're well on your way to a successful project. Keep it up!"
191,E1529,"<link> is a web application developed by Ruby on Rails framework. It serves as a peer review system for professors and students at NC State and some other colleges and universities<ref> <link> </ref>. Students can submit different assignments and peer-review reusable learning objects (articles, code, web sites, etc). It is also a powerful tool for professor to manage courses and assignments and so on. The latest ""Rails 4"" branch of Expertiza, although combined with various enhancements from the past two years, is seriously broken, from data migration to key feature implementation. Part of the reason has been the design strategy and code changes by various teams. This is a feature that has already been partially implemented in Expertiza <link> implemented both sychronous and asychoronous mailers. Sychronous Emails refer to the Emails sent immediatly after an event (e.g. when student receive a peer-review). Asychoronous Email we implemented by the Gem ""delayed job” and when a task (asychronous Email) is added to the delayed queue, a count-down number of minutes needs to be specified. Our team aims to extend this project. This wiki page documents the problem analysis and provides a guideline for future development and enhancement. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.2. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.3. <link> 1.4. <link> 1.1.1. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.2. <link> 1.5. <link> 1.1.1. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.6. <link> 1.1.1. <link> 1.1.2. <link> 1.7. <link>. E1451. ​Create Mailers for All Email Messages <link> <link> <link> (Merged in <link> ) Extending this project, the new system should be capable of 1. If one task is added to the delayed job queue, the asychronous Email should be updated or deleted automatically. 2. Add UI to visualize for the task in delayed job queue, instructors should be able to view tasks related to the assignments they have created. 3. Keep log of the scheduled tasks when they are scheduled and done, record events in the same log as project <link> . 4. [optional] support more scheduled task: 1.1. instructors are able to schedule the time to drop all the outstanding reviews (reviews which has not been started) 1.2. instructors are able to schedule a specific time to send Emails to all the assignment participants who are still not in any team to find or form one. 1.3. (new) instructor should be able to schedule a time to drop all the topics which are held by 1 person teams. 5. create tests to make sure the test coverage increases. Mailers: 1. delayed_mailer.rb Models: 1. assignment_form.rb 2. due_date.rb 3. delayed_job.rb(new created) 4. scheduled_task.rb(new created) Views: 1. _due_dates.html.erb 2. _assignments_actions.html.erb 3. scheduled_tasks.erb(new created) Controllers: 1. assignments_controller.rb. 1. gem 'delayed_job_active_record' <link> encapsulates the common pattern of asynchronously executing longer tasks in the background<ref> <link> </ref>. It allows to support multiple backends for storing the job queue. By using 'delayed_job_active_record' gem, we can use delayed_job with Active Record. This Active Record backend requires a job table. After running rails generate delayed_job:active_record and rake db:migrate, a ""delayed_jobs"" table is created in our database. This gem integrates well with many <link> backend such as MySQL. Using this gem, we can store all scheduled tasks queue into the ""delayed_jobs"" table. 1. gem 'paper_trail' PaperTrail allows to track changes of models' data, which is good for versioning. You can see how a model looked at any stage in its lifecycle, revert it to any version, and even undelete it after it's been destroyed<ref> <link> </ref>. Using this gem, we can keep log of the scheduled tasks. All our code follows the <link> on Ruby style. Initially, when we want to verify the email function, we found many time issues in this system. That blocks our work about email notification. Some related problems are explained and analyzed in this section. Firstly, when we set a due time to test the mail features, we found the display of time is incorrect. In the “Assignment Edit”->“Due dates”, when we modify the “Date & time” of the deadline, the displayed time will be 4 hours ahead of the time we saved. <image> Set due time <image> After we click the save button, we can see that all the time are 4 hours ahead of the set time <image> The deadline time is stored correct in the database After several tries, we found that every time when we click ""save"", the saved time is 4 hours earlier then the last saved time. However, the time in the database is alway correct as the time we save. After we analyze, we found the problem may lay in the line of 68 of views/assignment/edit/_due_dates.html.erb file. <code> When we declare a Data object, this Data() function will perform a time zone conversion automatically. Yet Rails’ default timezone stored in database is UTC. So the displayed time(local time, which is EDT) and time in database is different. In the previous version, when current time is compared with the time stored in database, they may apply to different time zones so that the result of comparison may be wrong. When we delay a deadline of an assignment, for example, we set the deadline of metareview from2015/03/28 16:00 to 2015/04/04 20:00 and set the reminder hr to 16 hours. <image> Delay a time After click ""save"", the run time showed database is about 8:00 am. Since 20-16=4, the correct run time is 4:00 am. <image> Time Stored in Database The reason why there is a four-hour time difference is generated from the file application_form.rb , method find_min_from_now(due_at) , and line 142 time_in_min=((due_at - curr_time).to_i/60) . due_at is the system time for Rails (UTC), while curr_time is the local time which is EDT. The two time zones have four-hour time difference. This time, we add a new delay in Review section, we delay the deadline from 2015/03/22 21:00 to 2015/03/30 21:00, and set the remind hr to 8 hours. <image> Delay a new deadline type However, the delayed_jobs database form is still the same, which means in one assignment there is only one reminder can work. As a result, we conclude that only one due_time record associated with different period exists in the database: 1. In Expertiza, one assignment has several period, such as submission, review, metareview. Administrates are able to set and postpone due dates for each period separately. 2. In the previous version, when the instructor postpone the review deadline and then postpone the submit deadline, the submit deadline’s modification will replace the the review deadline’s modification in database. 3. In this case, if both of them need Email reminder, there will be no Email about the former modified deadline. 4. After our analysis, we found the due time object is identified with assignment_id, instead of deadline type id. In the previous version, there is no UI to display the reminders of assignments. There is no way for instructors to view or delete their delayed tasks related to an assignment. We are going to add a button under Assignment->edit, and add a view to display all delayed jobs derived from the delayed_jobs table in our database. We convert current time to the same time zone as the deadline stored in database. Then the result of comparison will be right so that it can be used for further usage. In app/models/assignment_form.rb , we modified curr_time=DateTime.now.to_s(:db) to curr_time=DateTime.now.in_time_zone(zone='UTC').to_s(:db) in the find_min_from_now method, to make sure when calculating the minutes from now, the time zone is right. Also, to make sure the right display of time, when log in as a administrator, go to Profile and choose the Preferred Time Zone to be ""(GMT-05:00) Eastern Time (US&Canada)"". In each Assignment, each deadline type (E.g review, submit, metareview) should has its own Email reminder time in the database. New postponed deadline of one type can only replace the same deadline type in the same assignment id category. This bug has been fixed by TA. All the scheduled tasks are in the delayed_jobs table in database, so the system will read from that table to show all the tasks' information. A new page is created to show all of those scheduled tasks and there is also a delete button for instructor to delete any task. Instructor can view this page via a view delayed jobs button in assignment->edit . The code in app/models/assignment_form.rb add the scheduled tasks into delayed_jobs table. <code> After adding to the delayed_jobs, the database will store each task's assignment's id, deadline type, due date, task run time etc. <image> the delayed jobs table in database We create a file scheduled_tasks.erb in the path: /views/assignments to show the form. In this file, we use a @scheduled_jobs = DelayedJob.all to read all datas from the ""delayed_jobs"" table. <code> The following two pictures show our UI works. <image> add a button to display all scheduled tasks <image> The UI to show all the scheduled tasks. According to the project <link> , there is a paper_trail<ref name = ""Paper_trail Gem""> <link> ]</ref> gem which can keep log of the models' data. What we need to do is let it also keep track of our scheduled task data. has_paper_trail need to be written into a model which has inherited from ActiveRecord::Base. In our project, Delayed::Job should be such model. However, it is written in the Gem file which we can not directly modify. Thus we create a new file named delayed_job.rb in models folder, make it inherit from Delayed::Job , and add has_paper_trail in it. It is like: <code> When the delayed_jobs table changes, a Delayed::Backend::ActiveRecord::Job record is automatically created in the log. In assignment_form.rb , we define a method to change the item type displayed in the log. <code> Then we call it in add_to_delayed_queue method of the same file. Every time when the delayed_jobs table has added or deleted or updated data, the log can keep track of them. The following picture shows what the log is after creating scheduled tasks. You can see a ""Search log"" under the ""logout"" button. <image> four scheduled tasks are added in log. In our system, we would have four scheduled time: submission, review, metareview and team_formation. When due time comes, the system takes corresponding actions. These scheduled actions are called scheduled tasks. <image> Support more scheduled tasks. In this task, instructors should be able to schedule a time to drop all the outstanding reviews, which means the reviews which has not been started. Firstly, we create a new deadline type called ""drop_outstanding_reviews"". When we set the review’s due date, add an item into “delayed job” queue at the same time( refer to ""Add UI to visualize for scheduled tasks""). When the review is due, it will automatically call a method to find all the outstanding reviews (reviews which have not been started) in the database then delete them. There are two tables in the database to store the information about the reviews: responses and response_maps . responses is used to store all the submitted reviews while response_maps stores all the requested reviews, which means if one review has began it will not stored in responses table. Thus, we just need to find the review data in response_maps while not in responses for one assignment and delete them in database. We add a method in /models/scheduled_task.rb named drop_outstanding_reviews to drop those reviews. <code> Then, add the following code in perform method of the same file to drop one specified assignment's outstanding reviews at the due time. <code> The following screenshots show the function realization: <image> Before outstanding review is dropped <image> After outstanding review is dropped We set a review deadline in ""Assignment""->Edit->due date"". For better test, we enforce the action run time is 1 minute later after setting a deadline and adding it to a delayed_job queue. It is achieved by setting diff = 1 in add_to_delayed_queue method. In order to add into the delayed_job table in the database, we need to check ""Apply penalty policy"" and choose one policy type after setting a deadline. Then no matter which due time it is set, the action runs 1 minute later. To trigger the delayed_job table, we need to run: rake jobs:work . You can refer to this <link> to test all the features manually. In this project, our jobs involve two gems as mentioned above. They are ""Delayed Job"", which can insert a job into queue and execute it at a certain time, and ""Paper Trail"", to log actions like create, update and destroy for a model. We write rspec tests to make sure that the functionality works well. In ""scheduled_task_spec.rb"", we test the functionality that when a due date is created, then delayed jobs of certain deadline type will be created. We may take ""team_formation"" deadline as an example: <code> When team_formation deadline is created, there will be two delayed jobs created. One is reminder email and the other one is drop topics from students who don't have a team yet. For the functionality of keeping log of scheduled tasks, ""has_paper_trail_spec.rb"" file is used to make sure that when a delayed job instance is created, one log will be generated. <code>. <references/>.",Very good documentation of what's wrong in the way that time is being handled (though this is not the major point of the project). One of the main points of this project is to set up tests so the instructor knows e-mail is being sent.  This is not covered in the doc.,"Dear student,

You have put a tremendous amount of work into your assignment, and I can tell that you have a strong understanding of the web application for peer review system you mentioned. You have mentioned the shortcomings and difficulties encountered with Expertiza and how your team plans to extend it. Your critical analysis and planning are highly commendable.

You detailed the issues, including the incorrect time display and the issue involving incorrect time comparisons. This meticulous attention to detail will serve you well both in your ongoing studies and future professional life.

Your explanation of how new functionalities should be developed was well articulated and clear. However, you should enhance your assignment with more visual aids. Screenshots and diagrams can help the reader to follow your plans and understanding more easily.

Additionally, you listed the classes and gems you used in your project, which is excellent for documenting your process, but I noticed you did not provide a comprehensive reflection for each one. Remember to also break down what each class and gem did for you and the challenges, if any, they presented.

Last but not least, it is great to see you have implemented test cases to ensure the reliability of your project.

Well done on your assignment! You have demonstrated a clear understanding of the web application you are trying to enhance. Keep up the excellent work.

Best,
[Your Name]"
192,E1922,"<link> is a web application where students can submit and peer-review learning objects (articles, code, web sites, etc). It is used in select courses at NC State and by professors at several other colleges and universities. ( <link> ). <link> is a 'Domain Specific Language' (DSL) testing tool written in Ruby to test Ruby code. It is a behavior-driven development (BDD) framework which is extensively used in the production applications. The basic idea behind this concept is that of Test Driven Development (TDD) where the tests are written first and the development is based on writing just enough code that will fulfill those tests followed by refactoring. It contains its own mocking framework that is fully integrated into the framework based upon JMock. The simplicity in the RSpec syntax makes it one of the popular testing tools for Ruby applications. The RSpec tool can be used by installing the rspec gem which consists of 3 other gems namely rspec-core, rspec-expectation and rspec-mock. ( <link> ). There are few tests for assessment360_controller.rb. We had to test the following functions: 1. action_allowed 2. all_students_all_reviews 3. course_student_grade_summary 4. populate_hash_for_all_students_all_reviews(assignment,course_participant,reviews,hash_per_stu,overall_review_grade_hash,overall_review_count_hash, review_info_per_stu) 5. find_peer_review_score(user_id, assignment_id) 6. format_topic(topic) 7. format_score(score). 1. Write RSpec integration tests to make the statement coverage above 90%. 2. Cover as many edge cases as you can. 3. Achieve as high branch coverage as you can. The code we created can be found below. We have also linked the video of our tests running with coverage to showcase the work we have done. 1. <link> 2. <link> 3. <link> With the goal of getting at least 90% coverage, our tests got about 97.94%. The way we split up the work by having Jasmine take care of the function: all_students_all reviews while Louis took care of course_student_grade_summary. This helped with potential merge conflicts since both these functions are the biggest of the file and working on them would allow both to make progress at the same time. The following files were the ones either edited or used as aid. 1. <link> <code> 1. <link> <code> 1. <link> <code>. In order to run the integration test, run the following command via terminal: <code>. Below shows the outline of what our test look like: assessment360controller <code> <code>.","The wiki page is very short and does not describe why you wrote the tests you wrote, or how those tests operate.  It just gives pointers to the code.","Hello,

Impressive work on your assignment submission. Your detailed and comprehensive approach to writing and explaining the test cases is commendable. Understanding the concepts of 'Domain Specific Language' (DSL) and behavior-driven development (BDD) is key to successful software development, especially when using Ruby, and your grasp of these concepts is clear.

You've shown excellent knowledge in using RSpec, a prevalent testing tool for Ruby applications, illustrating the different gems and how to use them effectively. Kudos on achieving 97.94% coverage, exceeding the goal of 90%! This shows deep understanding and application of the material.

The way you split up the work also demonstrates good team interaction and effective project management skills. The different roles you played in testing different functions prevented potential merge conflicts and boosted efficiency.

Your inclusion of relevant details such as the files you edited or used for aid, along with clear instructions on how to run the test using the terminal, is an excellent practice. Other developers would be able to replicate your process and understand your work more efficiently.

One potential area for future improvement is providing a rundown of how exactly you approached the edge cases and branch coverage. Discussing specific examples or challenges you encountered would add even more depth to your excellent work.

Don't hesitate to discuss such details in the future to enhance your submissions even more. Your excellent effort on this assignment is much appreciated and I'm looking forward to seeing how you apply these skills further in the course. Well-done!

Best Regards,
[Instructor's name]"
193,E1800,"Expertiza is a web application where students can submit and peer-review learning objects (articles, code, web sites, etc). It is used in select courses at NC State and by professors at several other colleges and universities. -- Expertiza project. For the E1800 project, a course project for CSC 517 at NCSU during the Spring of 2018, certain improvements were made to the Expertiza system. Primarily, the goal of this project was to add past-due assignments to the student task list. The full list of tasks (the original task list with modifications from instructor feedback) is: 1. Issue #80: Add past-due assignments to task list (on Student Task page). 2. Highlight with specific colors current and next due dates (on Student Task page). 3. Check for correction in due dates of assignments 4. On the Student Task page, separate the list of 'teamed with' students from the current tasks box. 5. Show required action on: every student has to review others work and give feedback. 6. Write all the required tests before implementing/refactoring the methods in the above mentioned classes. Some Additional tasks accomplished by our team are: 1. Added pagination to past-due assignments on task list 2. Made various UI enhancements to the student_tasks page, specifically regarding the layout of elements. 3. Refactored student_task_controller.rb. student_task_controller.erb app/views/student_task/list.html.erb student_task_helper.rb airbrake_exception_errors_feature_tests_spec.rb. will_paginate_array_fix.rb student_task_feature_spec.rb. Currently, the student task list consists of one list of all assignments that are and have been assigned to the student regardless of their due date. Now a separate table exists for assignments that are past due. This table is sorted to show the most recent past due assignments at the top of the table. The table that used to be all student tasks is now assignments that are currently due. This table is sorted by due date to show assignments that are due the soonest at the top of the table. This change mostly involved changes to the student_task_controller.rb and list.html.erb files. A helper function was also added to the student_task_helper.rb file to break a string into multiple lines, even in the middle of a word, if it contains a word that is very long. In the student_task_controller.rb, a separate instance variable was created to contain only student tasks that are past due and sorted by date. The existing instance variable was recycled to contain all of the student tasks that are still currently due. In the list.html.erb file a new table was created to hold all of the past assignments. Both the current assignments and past assignments tables are also individually paginated if there are more than 10 of either. To create the ability for the will_paginate gem to add pagination based on an array the will_paginate_array_fix.rb file was added to the initializers folder. <image>. Currently, all of the tasks in the table have a white background regardless of when the task is due. To make it more apparent when due dates are approaching, each row will now highlight green, yellow, orange, or red depending on how many days out the assignment is due. This change involved adding a function to the student_task_helper.rb file as well as a change in list.html.erb. The change in student_task_helper.rb was a function that receives a due_date in Time format, converts it to DateTime then does a subtraction to DateTime.now to get how many days until the due date. Based on the result the function will return a string containing a color that will be the background of an individual row in the current assignments table. <image>. After speaking with our mentor, we came to the conclusion that this was not an issue; therefore meaning no changes needed to be made for this point. Presently, the required actions list does not show entries for review tasks. That is, the list only displays tasks that have yet to be started. Therefore, once an assignment has been submitted, additional required actions such as reviews do not appear. In order to solve this problem, a few lines of code were added to student_task_controller.rb. This code retrieved all active student tasks, and adds tasks which both are in the review phase and for which the student has yet to submit a review to the required task list. <image> In addition, a bit of creative discretion was used and an icon was added to draw the user towards the Review link when it is active. This can be seen in the capture below. The current assignments will show all assignments that are not completed, and if the assignment is in the review phase, it will display a small warning icon indicating action needs to be taken. The screenshot below demonstrates this on the ""Unknown"" stage, since, because of the afromentioned issues with testing, an assignment in the review phase could not be created for testing purposes. However, the logic is in the view, and is a simple string compare, so if the stage is in Review, the icon will show up. <image>. As mentioned in the “Adding past-due assignments to task page” task, the primary assignment list on the student_task page has been updated. In our new version, the list separates tasks that have been completed from ongoing tasks. This both improves the page aesthetically as well as draws attention to ongoing tasks. Previously, these were often buried underneath many past tasks which were already completed. Another task completed which enhances the usability of the student_task page is adding pagination to current and past assignments. Specifically, If there are more than 10 past or current assignments due, each table will individually paginate. Meaning you could be on page 2 of current assignments but also page 4 of past assignments. This makes the lists easier to read and parse for users with many tasks. Prior to this project, the Code Coverage report displayed many warnings for student_task_controller.rb. Primarily, these warnings were clear signs of excessively high complexity within methods. In several cases, the cyclomatic complexity of methods was too high. In others, the perceived complexity or assignment branch condition size was too great. In order to fix as many of these issues as possible, the class was refactored. In some cases, several comments within methods were used in order to divide one method into logical pieces, a clear code smell. In order to fix many of these issues, the ""Extract Method"" refactor was used. That is, methods were split into more logical, easier to read and follow pieces. Several other refactoring methods were utilized to make this file easier to understand, as it does perform many separate logical tasks. For example, the method view was flagged in Code Climate with the message: Assignment Branch Condition size for view is too high. [24.62/15] . In order to correct this, the original method: <code> was refactored using the 'extract method' refactor, leading to the following, where init_participant , init_assignment , and init_timeline are separate, short, methods. <code>. The <link> was used to test our changes. We had trouble testing our changes on the normal .OVA distribution. For example, we could not conduct testing from an instructor's view and manage assignments and due dates, which was an important part of our test plan. The Lubuntu image resolved this, but, as can be seen below, invovles a slightly different user interface than the normal Expertiza. As this documentation shows, much of our changes and features involved solely the view. Testing for our project revolved around simply ensuring that the view changed as per the various conditions defined. This method of navigating the site and ensuring if X, then Y should be Z is the best way to test in our case, since the view's final product, in the end, is a visual resultFor example, the coloration of due dates could be tested by navigating the site as a dev user, and making sure that if an assignment stage is due in more than ten days, then the row should be green. Likewise, if a stage is due in a day, the row should be red. . The steps to do this are: 1. Log in as an instructor If logged in as instructor6, student563 is a student in your WCAE 2008 course 2. Select one of your courses(i.e WCAE 2008) 3. Click the create assignment icon <image> 4. Enter an assignment name, use ""./"" as a submission directory, and add a rubric field. 5. Assign to a student/class <image> Make sure that the student you are adding is a student of the instructor you are logged in as. i.e student563 is a student of instructor6. <image> Also make sure to change the due dates <image> 6. Check to see if the coloration works as expected (change the due date to test each case). Rspec tests were written for the list method in the student_task_controller.rb file. There wasn't an existing student_task_controller_spec file so one was created to perform this testing. The testing consists of creating assignments with different attributes (due date in the future, due date in the past, and available or not) in order to test the functionality of the list method. Depending on what assignment gets tied to the student task, different instance variables will be populated with student tasks or be empty. The four tests that were added are very similar in nature: describe '#list' do <code> <code> <code> <code> These tests verify that the appropriate instance variables a being assigned to the correct values.These test were created to test the refactor that we performed on the list method of the student_task_controller. Two checks were also added to the airbrake_exception_errors_feature_tests_spec.rb file where the list view is being loosely tested. These lines were added to verify that the ""Current Assignments"" table and the ""Past Assignments"" table have content. <code> However, refactoring was conducted and so RSpec tests were written for those instances. <image> As seen above, our pull request passes the Travis CI build.","A very readable description of what has been done.  I'm not sure I agree with some of the design decisions, e.g., hardwiring the pagination scheme, making the backgrounds as intense as they are.  But the design decisions are clear from the documentation, and that is the goal of the writeup.  I thought the four RSpec tests should have been described individually.  All in all, an excellent job.","Great job on the development and thorough explanation of your project, especially on the improvements to Expertiza. Your report is indeed comprehensive and gives precise details on your technical adjustments and the motives behind them. Your attention to the user experience, especially your focus on the clarity and ease of understanding tasks for the student, is particularly noteworthy.

The planned tasks, your approach to addressing these tasks, and the additional tasks you took on certainly demonstrate your team's hard work and commitment. Iterating the original assignment list with instructor feedback would have likely made things clearer though. 

Furthermore, the details on the modifications done, the problems encountered as well as the workflow of the solutions to these problems give valuable insights. It is good that you also tested your solutions to ensure they work as intended.

The documentation accompanying your changes aid in better understanding your modifications. Screenshots or any sort of graphic content would have been beneficial throughout the document, however there is a placeholder text indicating ""<image>"". Make sure that these were not accidentally omitted from the document.

For the future, I would recommend including a summary at the end of each task to summarize the changes made. Additionally, it would be helpful to provide a clearer explanation of the reasons behind taking on additional tasks. Overall, thanks for providing clear insights into your process and the detailed write-up on your improvements to the Expertiza system. Well done."
194,E1855,"The way Expertiza is set up right now is that only peers can review your work. However, there are cases when the course staff (Instructor/ TAs) would want to submit reviews as well. This project aims to implement this feature by allowing course staff to review the project on the same metrics as other students who review the project. The current system does not allow instructors to submit reviews of student work. We will work upon the feature which will let them review using the same review form that students use to do reviews. This is how some of the pages we are concerned with, currently look. <image>. <image>. Following changes will be made to let staff perform reviews as well: Step 1: Add a way for the instructors to perform a review. We have implemented links to Begin review , Edit review , View review and Submit review in the assignment submissions view. When the instructor/TA reviews a work for the first time, he/she is added as a participant and a review response mapping is created. Files edited: 1. View: app/views/assignments/list_submissions.html.erb - To add links in the instructor view 2. Controller: app/controllers/review_mapping_controller.rb - Method: add_instructor_as_reviewer In the second case, we can see a 'Begin review' link. This is the initial state when instructor review has not been added to the submission. Once the instructor adds a review and submits it, we can see the 'Update review' link. If the deadline has passed, Update Review will change to View Review. In case he just saves the review, an 'Edit review' link will appear. If the review deadline of one round is passed, the 'Edit review' link becomes 'Update review' link. This follows in line with what the student sees while performing a review. Similarly, just like students instructor would not able to edit the review once submitted. Instructor can update it till the final submission deadline passes. <image> <image> Step 2: Add the instructor review in Your Scores table in case he has reviewed your work. Provide an icon to highlight the special nature of an instructors review. Files edited: 1. Assets: app/assets/stylesheets/grades.scss - Icon to make an instructor's review distinct from other reviews 2. View: app/views/grades/view_team.html.erb - To modify the ""Your scores"" page to include an icon next to the peer review score indicating that the instructor's score is not included in the final peer review score. 3. Models: 1.1. app/models/answer.rb - Method: compute_scores | Modification in logic to ensure instructor review scores are not counted in the overall score of the student. 1.2. app/models/vm_question_response_score_cell.rb - Included a new variable called 'is_instructor_review' to identify an instructor review 1.3. app/models/vm_question_response_row.rb - Change in average_score_for_row method to not include an instructor review score 1.4. app/models/vm_question_response.rb - Modified the add_answer method to include the is_instructor_review to each row_score object A student should be able to make out if an instructor has reviewed his/his team's work. In case the instructor performs a review on the team's work, there will be an icon next to the instructor's review along with explicitly stating that it is an 'Instructor review'. The average peer review score for the team has been modified to exclude the instructor's scores. Same has been taken into account for the average score calculated for each row. <image> Like shown in the above picture we can see a info button on which if we hover the text is shown. Possible icons : <code>. We added a test for a method add_instructor_as_review . 1.Created a stub and mock to find the assignment team. <code> 2.Created a stub and mock to map the review with their response in ReviewResponseMap. <code> 3.Created a stub and mock to add current user as a participant in the assignment. <code> We use the above-mentioned stubs and mocks to test the following scenarios: <code> Using a similar approach we tested select_reviewer and select_metareviewer functions. After running the above test, we found out that all the test cases passed resulting in 71% coverage of review_mapping_controller.rb. Expertiza 1. <link> Pull Request 1. <link> Expertiza Github 1. <link> Expertiza Documentation 1. <link>.","Generally a good job of documenting the work.  Readable description.  I question whether describing the modifications in terms of files modified is the best organization.  The test plan is well defined, but could be more readable in a variable-width font.","Dear student,

You've done an exceptional job on this assignment involving the enhancement of the Expertiza system. Your proposal to include course staff in the reviewing process enhances the system's functionality significantly. What I admire most is your detailed outline of the changes required.

The step-by-step process you used to detail system modifications and enhancements in step 1 are clear, and I appreciate your diligence in specifying the exact files affected with each change.

In Step 2, the idea to differentiate the instructor's review from the peer review with an icon will indeed be very clear and beneficial for the users. The ability to exclude instructor scores from the overall score is a good call, as these scores may unduly influence the team's overall score.

Your testing methodology based on stubs and mocks is well-structured. The 71% coverage is excellent, and the thorough discussion about the function testing is very much appreciable.

While overall, this is a fantastic job, there are a few areas you could consider improving in future endeavors. Be sure to include some focus on the user interface and user experience elements of the changes. The actual integration of the feature into the application should also be outlined clearly, along with any additional steps like cloud deployment or database migrations.

Again, outstanding job and keep up the excellent work!

Best regards,

[Instructor's Name]"
195,E1771,"Expertiza is an open source webapp built on Ruby on Rails stack. It provides a platform to students with various features like peer-reviewing projects, submitting work, form teams, viewing grades etc. The project is being built and maintained by students and faculty at NCSU. team.rb is a fairly complex file. It contains a lot of methods that are long and hard to understand. These methods need to be broken down into simpler and more specific methods that are easier to read/understand. Also, the few instances of code duplication that exist should be removed. <code> Elaborating the edits made: Previous code: <code> This method has been edited and divided into following methods: Renamed the methods has_user to user? , get_node_type → node_type and get_author_names → author_names and also updated the function calls so that they call the correct (newly renamed) methods. <code> was refactored to <code>. <code> <code> <code> were changed to <code> <code> <code>. <code> <code> <code> were updated to <code> <code> <code>. We have completed all the pending tests in the file team_spec.rb and all the test cases are passing. This can be checked in the pull request which is linked below. Github Link to Pull Request: <link>.","The writeup says what was done, but not how or why it was done that way.  One would not learn much more from reading the documentation than from perusing the code.","Dear Student,

Thank you for your dedication to this project, your efforts to improve the readability and functionality of the Expertiza application is commendable. 

Your decision to break down complex methods into simpler, more readable ones and to eliminate code duplication shows a firm understanding of good coding practices. I can see your ability in maintaining clean code and improving system efficiency.

However, your report lacks explicit information about what you specifically changed. I appreciate that you listed the methods that were renamed and how they were edited, but there are several instances where lines of code are just represented as ""<code>"". We can't really judge the improvements or the impact of your changes based on this description. Therefore, I encourage you to include specific examples of the code before and after your changes for clarity.

It's great that you were also able to complete all the pending tests in the team_spec.rb file. On the plus side, confirming passing tests provides assurance of the robustness of your changes.

For future assignments, please consider offering more expanded explanations and examples for the changes made. This will certainly improve the comprehensiveness and usefulness of your documentation.

Lastly, please ensure that all of your hyperlinks are working properly so everyone can easily view your code.

Good work on this assignment and I look forward to seeing further improvement in your upcoming works.

Best,
[Your Name]"
196,E1606,"Expertiza is an open source peer review system developed by students and faculty at North Carolina State University. It allows students to form teams, submit assignments and review the work of their peers. In addition, it lets an instructor create new assignments, questionnaire for reviews and so on. It is built in Ruby on Rails platform. Questionnaire is one of the most important components of peer review. It aids the instructor in assessing the reviews of a project, which in turn helps in grading. It lets the instructor create a set of questions(rubric) that needs to answered by students in order to complete their review. It also lets the instructor create a question advice that aids the reviewing process. We have been given the task of creating functional tests for the questionnaire creation function as currently, there are none. In order to complete the task we will be using Capybara to write functional tests to 1. Create new questionnaire. 2. Create/Edit/Delete different types of questions. 3. Create/Edit question advice for criterion and scale questions 4. Create multiple tests to check valid and invalid cases. Functional tests are tests which ensure that the functionalities of a software system, as specified in a design or requirements document, are working as expected. Functional tests do not test a function or a method within a class but rather the functionality of the entire system. There are many frameworks that perform functional tests in Ruby. One such framework is Capybara. Capybara is framework, written in Ruby, that lets developers test their web application through simulations. It can be integrated with Selenium and Webkit. Before writing code, we decided to build the different workflows of the system. A workflow is a sequence of steps a user would follow, within the web application, in order to complete a desired task/function of the system. Understanding the different workflows helped us write comprehensive test cases for various functionalities within the questionnaire system. Below is one such workflow. 1. Login 2. Click on ‘Questionnaires’ link. 3. Create ‘New Public review’ 4. Click on ‘Create‘ 5. Change the min, max or public values and ‘update’. 6. Click on ‘Add’ after choosing type of question. 7. Type in values for the question. 8. Click ‘Save review questionnaire’ There are 10 types of questions. 1. Click ‘View/Edit Advice’ 2. Edit the advice. (Only criterion and scale types have advice) 3. Click ‘Save and redisplay advice’ 4. Click ‘Back to questionnaire’ link. The test is to check whether a questionnaire can be created and the functionalities of the function are working. <code> The above code is written in Capybara and it creates a public questionnaire of type review. There are three text fields and one dropdown box which have to be filled to create the questionnaire. The values are populated using the fill_in function for the text fields and the select function for the dropdown. Finally, the ‘create’ button is clicked. For the test to pass successfully, there has to be a new questionnaire named ‘Review 1’ which exists in the test database. Hence, we use the expect function to check for the presence of the questionnaire. If there is no such questionnaire, then the test has failed and the functionality of the function has not been implemented correctly. There are ten types of questions in Expertiza - Criterion, Scale, Dropdown, Checkbox, TextArea, TextField, UploadFile, SectionHeader, TableHeader and ColumnHeader. The question type can be chosen while creating the question from a dropdown menu. Three different actions can be performed on each question - create, edit and delete. <code> The above code snippet shows a creation workflow for the criterion type question. Once the add button is clicked, a new question is created and the link to remove the question appears along with it. Using this we can test whether, a new question has been created. Also, once the questionnaire is saved, a message appears on the Expertiza system confirming that the questions have been saved. By checking whether the message appears or not we can test whether the functionality has been implemented properly. <code> The above code snippet tests whether the question has been edited successfully or not. When a question has been edited with some content, the same content remains in the text field for the question. This can be used to test the successful editing of the question. <code> The created question can be deleted by using the link ‘Remove’ which has been specified along with it. Also, after successful deletion a message appears implying that the question can be deleted. Thus the presence or absence of this message can be used to test for the delete functionality. Only two types of questions in Expertiza have an advice associated with them - the Scale and Criterion type questions. The number of text areas in the advice page depend upon the number of Scale and Criterion type questions and each question has a number of advice text areas, one for each possible score which can be assigned for a particular question. This is obtained by using the ‘minimum’ and ‘maximum’ possible scores provided while creating the questionnaire. Two types of actions are possible for the advice - create and edit. <code> The above code snippet shows the way in which the advice is created. The button ‘Edit/View Advice’ is present for each questionnaire and the resulting page has all the text areas for the scale and criterion type questions in the questionnaire. There is also a heading which provides directions to the user that the questionnaire can be edited. This message can be used to test for the button’s functionality. Once the advice is created with some content, the presence of a message implying that the advice is saved and the presence of the saved content can test for the create functionality. <code> The workflow for the edit functionality is similar to that of the create advice functionality. The tests can be run on the terminal using the command: <code> A seed value is used to randomize the order in which the tests are run. This is because all the tests are independent and so every test must be able to run at any time so that all the functionalities can be tested successfully. All the tests are run and depending on whether a test passes or fails, we can find out which of the functionalities are successfully implemented in the system. 1. <link> - <link> link for forked repository 2. <link> - Github link for original repository 3. <link> - Github link for Capybara.","Looks like a very good writeup, at the appropriate level of detail.
Code snippets would've been more readable if they'd been single-spaced.","The assignment you presented is well explained and it shows that you have a solid understanding of the given task. You have done a good job in describing how peer review works and the role of Expertiza in this process. You elaborated well on how Capybara will be used for testing functions and validating the correctness of the workflows you described. Your assignment reflects a deep understanding of the process and methods to accomplish the task effectively.

One point of improvement is in the structure of your work. Due to its length and the amount of detail involved, it was a bit challenging to follow. Breaking it down into more cohesive sections with clear headings would make it easier to grasp the main ideas and follow your train of thought. 

You also included some pieces of Capybara code, but they are not clearly marked and explained. Providing specific code examples is an excellent approach for this type of assignment. However, it would be more beneficial to explicitly display and detail these snippets to show your understanding and their role in the task. 

In addition, please don’t forget to remove the placeholders like ""<code>"" and ""<link>"" and replace them appropriately with the actual code snippets or links.

Lastly, I noticed that you didn’t mention explicitly about how you will handle errors or what the testing phase involves. It would be helpful to explain how you will identify and rectify potential issues or bugs during testing and how you will confirm that functionalities are working as expected.

Overall, you have shown significant comprehension of the task at hand, which is commendable. Please make these few changes and the assignment will be excellent. Good job!"
197,E1653,"Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.6. <link> 1.1.7. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.1.4. <link>. <link> is an open source web application based on <link> framework. This application facilitates submission and peer review of assignments and team projects. Students can upload their assignments and URLs linked to their work on expertiza which can be reviewed by the instructor and peer reviewed by other students. Expertiza also expedites the process of selecting/assigning topics and choosing team mates for team projects. Instructors can also create and customize assignments for students and create review rubrics which are used by students for peer reviewing others' work. 1. Change allow_action? method of questionnaires controller to restrict unauthorized access to edit review rubrics. Only those Instructors who own the rubric or their Teaching Assistants should be allowed edit them. 2. Display an error message when a user who is not the owner of a questionnaire attempts to edit it and redirect him back to the page he came from. 3. Fix the working of import and export methods(dumping and loading criterion) in the Questionnaire controller. 4. Perform feature testing for the import and export methods of questionnaire controller. 5. Remove old and unused code related to rubric import and export. 6. Write feature tests for criterion advice. 1. <link>. 1. questionnaires_controller.rb 2. QuestionnaireHelper.rb 3. Questionnaire.rb 4. questionnaire_spec.rb 5. spec/features/import_export_csv_oss/ (New folder created containing 3 test files). 1. An instructor can no longer change others' review rubrics but can only view them. If he attempts to do so, an error message will be displayed and he will be redirected back. 2. Only those review rubrics can be modified by an instructor which are owned by him. 3. A Teaching Assistant can modify only those review rubrics which are owned by the instructor under whom he works. 4. A CSV file containing the questions with the correct column names can now be imported into the rubric. 5. A rubric can also be exported in CSV format to a destination path on our local system. 1. Changes in allow_action? method of the Questionnaires controller. The action_allow? method earlier provided access to all users to modify or view any review rubric. <code> The action_allow? method now provides access to modify a rubric to those instructors who own the rubric or the Teaching Assistants who work under them. However, any user can view the contents of the review rubric. <code> 2. a. Modification of import method declared in the questionnaires controller. The code initially was not using the read method to read the file data and was unable to import a file. <code> The modified code now reads data from the file and calls the method get_questions_from_csv and passes the data to it. The method reads data in rows and saves each row as a question. It then saves each question. <code> b. Removing unwanted code and modifying the get_questions_from_csv method declared in the questionnaire controller. The method get_questions_from_csv defined in the questionnaire helper was unable to read data from the file. <code> The unwanted code from the get_questions_from_csv method is now removed and the modified code successfully reads data from the csv file and saves questions present in the from of rows in the rubric. <code> 3. Removing dysfunctional code from the QuestionnaireHelper and adding a new method in questionnaire.rb model The create_questionnaire_csv method was not functional and was removed from the QuestionnaireHelper <code> The to_csv function was added in the questionnaire.rb model class which generates a CSV out of the data in the question table which can then be exported to a local machine. <code>. A set of feature tests using the RSpec framework have been added to test the implemented functionalities. Test data from spec/features/import_export_csv_oss/ was used to run the test cases. 1. The file to be uploaded should not be an empty file. The following test case checks if the imported file is empty. <code> 2.The following test case validates an imported CSV file. The test case passes if all the questions get successfully imported. <code> 3. The following test case validates the names of all columns in the imported CSV file. The following example shows that this test case passes when there's an error in the column name of the imported file. If we change this test file with the one in the above two cases, and change expect().to to expect().not_to, we can see that it does exactly what we require it to. <code> 4. The following test case validates that no error message appears on the page while exporting. <code> 5.The following test case validates if a user is able to edit an advice. <code> 6. The following test case validates that the changes made in the advice page are re-displayed. <code> 7.The following test case validates if a user is redirected to the edit advice page after clicking on the 'Edit/View advice' button <code> 8.The following test case validates if the changes made in the edit_advice page are saved to the database after the 'Save and redisplay advice' button is clicked. <code>. 1. Login to expertiza as 'instructor6' (Username: instructor6 Password:password) 2. Select 'Questionnaire' Tab under Manage Content 3. Click on any one of the Review tab (For eg: Review, Metareview, Author Feedback) 4. Click on edit button of a questionnaire which is owned by instructor6 (This can be found out from the expertiza_development database using query: select name from questionnaires where instructor_id=6;) 5. User should be redirected to a page where he can edit the questionnaire 6. Impersonate 'teaching_assistant520' (is a TA under instructor6) and repeat steps 2-5 7. User should be redirected to a page where he can edit the questionnaire 8. Repeat the above steps for a questionnaire which is not owned by the instructor 9. An error message is displayed above the 'Manage Content' title. 1. Login to expertiza as 'instructor6' (Username: instructor6 Password:password) 2. Select 'Questionnaire' Tab under Manage Content 3. Click on any one of the Review tab (For eg: Review, Metareview, Author Feedback) 4. Click on edit button of a questionnaire which is owned by instructor6 5. Click on 'Browse' button under 'Import/Export (from/to CSV format)' and select a file of CSV format which contains the questions 6. Click on 'Import from CSV' button. The questions in the files should be saved into the questionnaire 1.1. This can invite future research into the area, since currently, it allows the duplicated sequence number code to be added 7. Click on 'Export questions to CSV'. The questions should be saved to the local system in a file of CSV format. 1. Login to expertiza as 'instructor6' (Username: instructor6 Password:password) 2. Select 'Questionnaire' Tab under Manage Content. 3. Click on any one of the Review tab (For eg: Review, Metareview, Author Feedback) 4. Click on edit button of a questionnaire which is owned by instructor6 5. Click on edit advice button. This should redirect to a page containing the advice for that questionnaire. 1. Login to expertiza as 'instructor6' (Username: instructor6 Password:password) 2. Select 'Questionnaire' Tab under Manage Content 3. Click on any one of the Review tab (For eg: Review, Metareview, Author Feedback) 4. Click on edit button of a questionnaire which is owned by instructor6 5. Click on 'save and redisplay' button. This should reload the same page with the edited advice.","Good job of explaining the changes made, the automated and manual tests.  My only reservation is that some of the longer code snippets should have had more explanation of the changes that were made.","Dear Student, 

I appreciate your efforts in putting together this comprehensive work on updates and modifications for the software application, Expertiza. Your understanding of the software and the specific changes you made to improve its functionality are quite clear. The technical depth with which you've gone into your work and the detailed examples you've provided are commendable. 

Here are a few areas I would like to point out for improvement:

1. Structure: Although your assignment has been laid out in detail, it seems a bit jumbled. I would recommend using headings and subheadings to structure your content. This will make reading your report easier and will improve the overall presentation.

2. Clarity: At several points, it was challenging to identify the problem you were addressing, the actions you took, and the outcomes you achieved. It would be beneficial to provide a brief summary at the start of each point to orient the reader.

3. Repetition: Ensure that you avoid repeating the same points. For example, you've mentioned changes multiple times. Elaborate once, comprehensively, but concisely.

4. Visual aids: Include screenshots or diagrams where possible. This can vastly improve the comprehensibility of your arguments and the changes you are proposing.

5. Code Formatting: Make sure to correctly format your code using backticks in markdown, this makes it easier for anyone reviewing your work to identify and understand them.

6. Testing: You've done a great job in outlining the test cases, however, I suggest including expected and actual outcomes for a more complete description. 

7. Conclusion: It would be advantageous to end with a conclusion summarizing the main points of your work, the overall implications and future possible enhancements.

As a general note, I suggest proof-reading your assignment as there are a few typographical errors. Remember that clear and concise communication is vital while presenting complex technical information. Good job overall. Keep learning and improving!"
198,E1776,"Expertiza is an open-source web application devloped on the Ruby on Rails platform that helps students create reusable learning objects through peer review, and also supports document submission and team projects. Expertiza includes several variations of import functionality, and allows instructors to import following data: 1. A list of users. 2. A list of participants for an existing assignment. 3. A list of participants for an existing course. 4. A list of teams for an existing assignment 5. A list of teams for an existing course. 6. A list of reviewers (reviewing contributors to assignments). 7. A list of meta-reviewers (reviewing reviewers). 8. A list of topics for an existing assignment. These imports are done by uploading a file containing rows of data, with each individual value of a row separated by a given delimiter. Expertiza allows four specifications for delimiters: 1. Comma 2. Space 3. Tab 4. Other (any custom delimiter provided by the user as text) All of these import functions are routed through the Import File Controller, which is responsible for parsing file data and delegating the import process to the appropriate model. The following is an Expertiza-based OSS project which deals primarily with the Import File Controller. This project is associated with fixing <link> , detailed on the Expertiza Github. A significant problem with the existing import functions is that they are not implemented consistently, and there are rigid restrictions placed on how the columns should be ordered in the given import files. In the current implementation, rows are taken is arrays, with the column numbers of specific fields hard-coded into the helper methods for different imports. The aim of this project is to improve the import functionality as well as provide a flexible and user-friendly interface so that users can easily and reliably take advantage of Expertiza's various import functions. To resolve these issue, we have enhanced the interface and the import process, keeping the core methods of import intact, but expanding its functionality to increase its reliability, robustness, and ease-of-use. In the new interface, the system will display what will be imported in an easy-to-read grid before the import is finalized, letting the user verify the correctness of the data and, if necessary, choose from a dropdown menu which columns need to be rearranged. The default ordering is the same as what is currently required by Expertiza, unless a specific order is provided by the user as a header in the import file. In our implementation of the import method, we have made the use of hash data structure. During the import process, we create an array of hashes, in which each row of the array corresponds to a row of the original import file. In each hash, keys refer to the field name, and values refer to the actual value of that field that will be saved to the database. This greatly improved the flexibility of the import process, since the order of the data in the import files is no longer required to be in one specific order only. In this project we have made the import process more reliable, robust, and easy to use. As stated in the previous section, the previous import functions required that files have a specific order to there columns. We have lifted this restriction, allowing users to import files with the columns given in any order and. If a file has a header, the new import function will use the column names defined in the header to ensure that information is saved in the proper field of the model. If a file does not have a header, the user is given options to specify which columns refer to which fields. We will work through the User import process as an example. The general flow of the original import process is as follows: 1. The user navigates to the ""Import Users"" link. 2. The link forwards the user to the start view for import_file , and passes User in a variable called @model . 3. The user selects a file and clicks ""Import"". 4. This submits a form, which calls the import method of the import_file_controller . 5. The import method calls a secondary importFile method, which parses the file and returns a 2D array representing the data. 6. The importFile method then dispatches actions of saving to the database to the self.import method of the User model, based on the previously-populated @model variable. 7. The self.import method makes use of methods in the import_file_helper to create or update the users listed in the file appropriately. However, this process was brittle for a number of reasons, the main one being demonstrated by the code below: <code> This was the reason why columns were required to be in such a restrictive order. In our approach, we divide the rows of data provided in import files into hashes. Accessing data from hashes is flexible as we just need the keys to access certain values, which we specify during our import process. Following is a snippet from the updated self.import method from user.rb to demonstrate our usage of hash. <code> In order to achieve the flexibility afforded by hashes, we created several protected methods in the import_file_controller to change the ""intermediary"" data structure used during import. Previously, data would be represented as a 2D array, with the first ""row"" being the header (if the file had a header). As an aside, another problem with the original code is how it checked for headers. Previous Expertiza developers had left several comments in the importFile method of import_file_controller warning of these problems. We decided to give users the option to specify whether or not their file had a header, rather than rely on the brittle existing methodology. We also split the importFile functionality, which was originally responsible for reading from a file, parsing the data of the file, and calling the appropriate self.import method for the given model. File upload and parsing is now achieved through several protected methods we wrote, and a new method we wrote called import_from_hash is now responsible for delegating import calls to respective models. Below is an example of the previous ""intermediary"" data structure: <code> Under our new implementation, the ""intermediary"" data structure would be: <code> In addition to theses changes, we have added several options that a user can select during the import process, and have also created a new import_file_controller action show , along with corresponding views, so that a user can view and amend the data to be imported before it is finalized and saved to the database. Detail concerning these additional features are outlined in the screencasts and sections below. In order to address the specifications laid out in the project description, we needed to make significant changes to the Expertiza code base, which had cascading effects to all models with import methods, all of which we needed to address in order to preserve the exiting import functions. As such, several of the existing specs were not suited to the new code. We have adapted the appropriate unit tests in spec/models/course_participant_spec.rb to pass with the existing code. We have commented out integration tests in spec/features/instructor_interface_spec.rb and spec/controllers/airbrake_exception_errors_controller_tests_spec.rb per the instructor's advice, and have added comments above these tests describing how they will need to be adapted to our new code in the future. All other tests defined in the spec directory are passing, as evidenced by the Travis CI pass on our pull request. We have thoroughly tested our new import implementations for all models involved, for each of the permutations of options available. A few of these permutations are outlined in the video demonstrations below, but the videos are not exhaustive. <link> This video demonstrates the enhanced import features for the User model with several varying examples, and also demonstrates that the original error messaging system is preserved with our new implementation. <link> This video demonstrates the enhanced import features for the Assignment Participant and Course Participant models with several varying examples. <link> This video demonstrates the enhanced import features for the Review Response Map and Metareview Response Map models with several varying examples. <link> This video demonstrates the enhanced import features for the Sign Up Topic model with several varying examples. Improvements: 1. Added descriptive title 2. Fixed form alignment 3. Added ""Header"" radio button 4. Changed ""Expected Columns"" to be more legible <image> Old User Import View <image> New User Import View. NOTE: Course Participant changes are identical. Improvements: 1. Added descriptive title 2. Fixed form alignment 3. Added ""Header"" radio button 4. Changed ""Expected Columns"" to be more legible <image> Old Assignment Participant Import View <image> New Assignment Participant Import View. Improvements: 1. Added descriptive title 2. Fixed form alignment 3. Added ""Header"" radio button 4. Added ""Contributor"" radio button 5. Changed ""Expected Columns"" to be more legible <image> Old Reviewer Import View <image> New Reviewer Import View. Improvements: 1. Added descriptive title 2. Fixed form alignment 3. Added ""Header"" radio button 4. Added ""Contributor and Reviewer"" radio button 5. Changed ""Expected Columns"" to be more legible <image> Old Metareviewer Import View <image> New Metareviewer Import View. Improvements: 1. Added descriptive title 2. Fixed form alignment 3. Added ""Header"" radio button 4. Added ""Optional Columns"" checkbox list 5. Fixed bug where ""Expected Columns"" would not display if an assignment had no prior topics set up 6. Changed ""Expected Columns"" to be more legible <image> Old Topic Import View <image> New Topic Import View. <image> An example of the new User Import view when the given file contains a header. <image> An example of the new User Import view when the given file does not contain a header. NOTE: The new view for Course Participant is identical. <image> An example of the new Assignment Participant Import view when the given file contains a header. <image> An example of the new Assignment Participant Import view when the given file does not contain a header. NOTE: As shown in the video demonstrations, the notice on this page is changed according to the order of columns specified in the previous import step. <image> An example of the new Reviewer Import view. NOTE: As shown in the video demonstrations, the notice on this page is changed according to the order of columns specified in the previous import step. <image> An example of the new Metareviewer Import view. <image> An example of the new Topic Import view when the given file contains a header. <image> An example of the new Topic Import view when the given file does not contain a header. 1. app/asstes/javascripts/shared.js 1.1. NEW: checkForFile() 1.2. NEW: checkIfUserColumnDuplicate() 1.3. NEW: checkForParticipantColumnDuplicate() 1.4. NEW: checkTopicForDuplicatesAndRequiredColumns(optional_count) The methods above were written to address pre-existing file-import bugs, and prevent users from importing files improperly under the new implementation. 1. config/routes.rb Routes were added to accommodate the new controller action and view written for the enhanced import process. 1. app/controllers/import_file_controller.rb 1.1. NEW: show 1.2. NEW: import_from_hash 1.3. NEW: hash_rows_with_headers 1.4. NEW: parse_to_hash 1.5. NEW: parse_to_grid 1.6. EDITED: import The new controller action was written to enable the review and editing of the import data before finalization. The methods above were written to facilitate the new hash-based data structure used for import, and to separate different functionality from the old importFile into distinct methods. The old import method was changed to use our new import_from_hash method. 1. app/helpers/import_file_helper.rb 1.1. EDITED: self.define_attributes 1. app/helpers/import_topics_helper.rb 1.1. EDITED: self.define_attributes The methods above were adapted to use the new hash-based data structure used for import. 1. app/models/assignment_participant.rb 1.1. EDITED: self.import Adapted to use the new hash-based data structure used for import. 1. app/models/course_participant.rb 1.1. EDITED: self.import Adapted to use the new hash-based data structure used for import. 1. app/models/course_team.rb 1.1. EDITED: add_member Fixed a pre-existing bug caused by a mismatch of arguments during import. 1. app/models/metareview_response_map.rb 1.1. EDITED: self.import Adapted to use the new hash-based data structure used for import. 1. app/models/review_response_map.rb 1.1. EDITED: self.import Adapted to use the new hash-based data structure used for import. 1. app/models/sign_up_topic.rb 1.1. EDITED: self.import Adapted to use the new hash-based data structure used for import. 1. app/models/team.rb 1.1. EDITED: import_team_members 1.2. EDITED: self.import Adapted to use the new hash-based data structure used for import. 1. app/models/user.rb 1.1. EDITED: self.import Adapted to use the new hash-based data structure used for import. 1. spec/controllers/airbrake_exception_errors_controller_tests_spec.rb 1.1. COMMENTED OUT: it 'will catch the error info if the tempfile cannot be obtained from params[:file]' This spec is no longer suited to the new import methodology. See the comments included above the tests in the source code for more detail. 1. spec/features/instructor_interface_spec.rb 1.1. COMMENTED OUT: it 'should be valid file with 3 columns' 1.2. COMMENTED OUT: it 'should be valid file with 3 or more columns' 1.3. COMMENTED OUT: it 'should be a invalid csv file' 1.4. COMMENTED OUT: it 'should be a random text file' These specs are no longer suited to the new import methodology. See the comments included above the tests in the source code for more detail. 1. spec/models/course_participant_spec.rb 1.1. EDITED: it 'raise error if record does not have enough items' 1.2. EDITED: it 'raise error if course with id not found' 1.3. EDITED: it 'creates course participant form record' These specs were adapted to accurately test the new import methodology. 1. EDITED: app/views/course_participant/list.html.erb 2. EDITED: app/views/participants/list.html.erb 3. EDITED: app/views/review_mapping/_list_review_mappings.html.erb 4. EDITED: app/views/review_mapping/list_sortable.html.erb 5. EDITED: app/views/sign_up_sheet/add_topics.html.erb 6. EDITED: app/views/teams/list.html.erb 7. EDITED: app/views/users/list.html.erb The above files were edited to promote readability of the expected columns message, and in the case of topics to address a pre-existing bug where this information was not displayed properly. 1. EDITED: app/views/import_file/start.html.erb The above file was edited to provide new options to the user during the import process, based on the model being imported. Various other cosmetic changes were made, as described in the appropriate Wiki section. 1. NEW: app/views/import_file/show.html.erb The above file was created to accommodate the new controller action made for the improved import process. 1. NEW: app/views/import_file/_metareviewer.html.erb 2. NEW: app/views/import_file/_participant.html.erb 3. NEW: app/views/import_file/_reviewer.html.erb 4. NEW: app/views/import_file/_sign_up_topic.html.erb 5. NEW: app/views/import_file/_team.html.erb 6. NEW: app/views/import_file/_user.html.erb The above files are partials rendered in the show.html.erb view based on the appropriate model. To begin the User import process, first select the ""User"" link from the ""Manage"" drop-down menu. <image> Manage Users Next, scroll to the bottom of the page and click the ""Import Users"" link. <image> Import Users You will then be redirected to the User import page. To begin the Assignment Participant import process, first select the ""Assignments"" link from the ""Manage"" drop-down menu. <image> Manage Assignments Make sure that ""Assignments"" is highlighted on the ""Manage content"" page, then locate the appropriate assignment and click the ""Add Participants"" button. <image> Add Assignment Participant Finally, scroll to the bottom of the page and click the ""Import assignment participants"" link. <image> You will then be redirected to the Assignment Participant import page. To begin the Course Participant import process, first select the ""Courses"" link from the ""Manage"" drop-down menu. <image> Manage Courses Make sure that ""Courses"" is highlighted on the ""Manage content"" page, then locate the appropriate course and click the ""Add Participants"" button. <image> Add Course Participant Finally, scroll to the bottom of the page and click the ""Import course participants"" link. <image> Import Course Participant You will then be redirected to the Course Participant import page. To begin the Reviewer and Metareviewer import process, first select the ""Assignments"" link from the ""Manage"" drop-down menu. <image> Make sure that ""Assignments"" is highlighted on the ""Manage content"" page, then locate the appropriate assignment and click the ""Assign reviewers"" button. <image> Finally, scroll to the bottom of the page, and click either the ""Import reviewer mappings"" link or the ""Import meta reviewer mappings"" link. <image> <image> You will then be redirected to either the Reviewer import page or the Metareviewer import page. To begin the Topic import process, first select the ""Assignments"" link from the ""Manage"" drop-down menu. <image> Manage Assignments Make sure that ""Assignments"" is highlighted on the ""Manage content"" page, then locate the appropriate assignment and click the ""Edit"" button. <image> Edit Assignment Next, select the ""Topics"" tab, scroll to the bottom of the page and click the ""Import topics"" link. <image> Import Topics If topics have not been set up yet on the given assignment, you will receive an alert that will need to be accepted before continuing. <image> Topic Alert You will then be redirected to the Topic import page.","The writeup is very detailed and clear what changes were done. The formating is also done carefully. well done!  It would be helpful to add some prose description between the screenshots showing old & new views of various features ... say, describing what had changed in the views. Also, the filenames are in a giant font size.","Dear Student,

Thank you for your comprehensive and detailed assignment submission on enhancing the import functionality for the Expertiza platform. This project demonstrates a significant understanding and application of web application development, particularly with the Ruby on Rails platform.

I appreciate your considerable effort in explaining the implementation of various import functions, defining the roles of controllers, and describing your precise approach in improving import process limitations and enhancing their flexibility and usability. The demonstration of the application of hash data structure and intermediary data structure evidences your strong grasp of data handling and representation, crucial to algorithm efficiency.

The design changes made in user-interface showed a thoughtful addition that improved the overall experience for users. A similar approach is encouraged in future work.

To improve even further, consider giving more attention to editing and proofreading. Despite the technical accuracy of the content, there are minor grammatical errors in your submission which can create some confusion for readers. 

Overall, this assignment strongly exhibits your capabilities in problem-solving, innovation, and user-centric design improvement. Continue to apply these exceptional attributes to future projects and keep up the excellent work!

Best Regards,
[Your Name]"
199,E1789,"In expertiza, review report page and summary page give the information for instructors to view the overall review result. Also, they are the place where instructors grade the reviews. Review report page can be accessed via Manager -> Assignment, then click the “View review report” button (the one which has a spyglass and two people). The summary can be accessed through Review Page by clicking “summary” button of a particular student. The appearances of the two pages are shown below: <image> <image> For now, there are several defects need to be fixed to optimize the grade procedure: 1. Metrics column is not intuitive enough. 2. The layout of “Review Report Form” in “Summary Page” is unreasonable. 3. Reviewers don’t need to re-review the submissions which are not updated, so there should be a checking mechanism. Therefore, our tasks are: 1. Visualize Metrics column. 2. Reasonably reorganize the “Review Report Form” in “Summary Page”. 3. Check updates of submissions for reviewers to help them decide if they need to review aga. Metrics column, which is in “Review Report Form”, displays statistic data of words used in particular student’s reviews. This helps graders to value how the student compares with the average student. For now, it displays numerical data in the literal way which is not intuitive. It would be better to have a bar or column chart showing this. Ultimately, we may be showing several metrics in this column, so the bars or charts should be resizable. <image>. <image> <image> We compare the 1st round and the 2nd round review with their average separately, then compare the overall (Total) with the average. In this way, it will be pretty clear for the grader to checkout how the student performs in the reviews. <image> 1. There is no header saying what course, assignment, or student this relates to. 2. The team name and student names are listed on separate rows. With the large amounts of whitespace, this makes the table too sparse vertically. It also takes up too much space as the other columns usually contain more information. 3. Text is too close to the cell boundaries. <image> 1. For checkbox questions, comments are not possible, but still a blank cell is displayed. 2. Checkbox questions could be displayed more compactly, better in a visually appealing manner like the review is shown to the author. It will be more reasonable if there is a header in the page. The information of the header will include course name, project name and student number as below: <image> For example, the header will show as “CSC 517 OSS PROJECT : Student 666”. We totally redesign the form in order to arrange the space more properly. The form looks as below： <image> Firstly, we lay the reviewees on the top with its student details, then we just repeat reviewees’ team name in each question. Meantime, we fix the top row when we scroll down the page, so that we could always refer the student details whenever we like. In this way, we solve the problem 2 mentioned above. Now the reviewees don’t take up too much space and it looks more concise. Secondly, for questions that require score and comment, we show the score at the beginning, then the text follows. This is consistent with the way that review is shown to the author. Thirdly, for the checkbox, it becomes clearer. The result will show as ✔ or ✘ which replaces the previous manner of using 0 or 1. We also removes the previous comment column which is not needed for checkbox. Finally, we redesign the style of the form with keeping the style consistent with other places in Expertiza. <image> In the review report, each team that has been reviewed is color-code. Text in red indicates that the review is not yet completed; text in blue indicates that the review grade is not assigned or updated. So if an instructor sees a name in red , the student should not be given credit for the review. If text is in blue , the instructor should grade it now. But another common case is after the reviewer has reviewed the work, the author didn’t update it. So the reviewer doesn't need to re-review the work. These reviews should be coded with another color (perhaps green ). Therefore, it should be checked whether the author has submitted new files or links since the previous review, even the content pointed to by pre-existing links. To learn whether submission has been updated since the previous review, we need to get the latest updated time then compare it with the latest review time. In expertiza, one submission contains two types of content -- link and file. Both two types should be considered. For file, we just need to look at the last modification time. For link, you need to consider more: the link string itself, and the content that the link points to. In expertiza, there is a SubmissionRecord class that stores the records of each submission. Thus, for the file and the link string, we could simply get the update time from the records. For link-to content, situation becomes much more complicated. The types of the links are various, and how to get update times from them is what we need to focus on. Actually, Many HTTP responses return a Last-Modified header. It contains the date and time at which the origin server believes the resource was last modified. Sometimes we could use this time as our latest update time. In other cases, we can’t get Last-Modified header from the URL. Like the GitHub Enterprise, generally it requires you to login to access the resources. Even you have logged in, the Last-Modified time is not equal to the latest commit time which is what we want. In these cases, we need to call APIs of the link-to website. As the GitHub and Google Doc should be the most common websites, we will handle these two special types of links. After we got the status of submission(updated or not), we could simply mark the not updated reviews green to indicate that it doesn't need to be re-reviewed. Since the main task is about UI design, most of tests executed manually. For the checking updates function, several test code is needed. Test case 1: Manually open Review Report Page, see if the chart is displayed properly in the Metrics column, including the numerical data and the appearance, ensuring that they are corresponding to the data which should be shown. Also check if the size is resizable. Test case 2: Manually open Summary Page, see if the chart is displayed as it is designed, including the numerical data and the appearance, check if the checkbox and those save button can respond correctly. Test case 3: Write unit tests to ensure the last update time gotten from SubmissionRecord is right and can be correctly shown. Test case 4： Write unit tests to ensure the last update time gotten from link-to website is correct. Test case 5: Manually open Review Report Page, see if the color of ‘submissions’ words are green if they are not updated.","Basically good; you did what we asked you to.  There is room for improvement.  Test plan is a bit sparse; you say ""correct"" in several places, but don't say exactly what you would check to determine if it's correct.  A number of reviewers said you didn't provide many design details and, indeed, you didn't identify what parts of the code you would change.  Also, the screenshots are often so large that you would need to zoom out to see them.","Dear student,

Thank you for your assignment. I am impressed with your comprehensive detailed analysis of the review report and summary page of Expertiza. 

The proposed enhancements are noteworthy and well explained. I especially appreciate your consideration of usability and the difficulties that may arise from differences in perceptions of numerical data and visualized data. Providing a detailed plan including illustrations aids in the understanding of your concept.

The steps you outlined for collecting information and data to manage reviews are plausible and practical, particularly your attention to the importance of texts' color-coding.

However, it would be beneficial if you explained more succinctly and clearly your solutions for the issues with file and link updates. As well, consider emphasizing important points in your text so that readers can easily identify the key takeaways. 

Your manual test cases are well considered, but remember that automated testing should also be included wherever possible to reduce human error. Additionally, outlining the expected results for the test cases could help clarify your intent and make it easier in the later implementation stages.

Overall, you have demonstrated a solid understanding of the problems at hand and have provided detailed and focused solutions. With a bit more focus on clarity and succinctness, you will greatly improve the accessibility and user-friendliness of your text. 

Keep up the good work!

Best regards,
[Your Name]"
200,E1793.1,"Expertiza is a Ruby on Rails based Open Source project. It is a collaboration tool which lets users with different roles (student, instructor, teaching assistant) to collaborate on a course in an institution. A collaboration could be for an assignment where students teams up for an assignment and instructors grades them on the basis of their submission. Students could review other's works and give feedback as well. 1. <link>. 1. <link>. 1. <link>. 1. For team-based assignments, it always takes time to find suitable team members. 1. We already have bidding, which could help you to join a team with other team members hold similar bidding preferences. However, a student may not be satisfied with automated team formation and want to switch to another team. 1. In this project, we will build a new feature to help students find teams to join. Currently, there are 2 ways to find other students to join your team: 1. If your team is not full, you could invite people by inputting his/her UnityID. It will send an invitation to a certain user. If s/he accepts your invitation,s/he will leave the original team and join your team. 1. You could create an advisement by clicking “Your team” link and then clicking “Create” link under “Advertisement for teammates” section. Then your advertisement will appear the last column of the signup sheet page with a horn icon. In this way, all classmates could see your advisement. Someone could send a request to join your team. If you accept their request, s/he will leave original team and join in your team. Below screenshots represents the description above. Student: Advertisement icon doesn't appear in Chrome browser. <image> Instructor: Advertisement icon doesn't appear in Chrome browser. <image> Advertisement icon appears in Mozilla browser but not in the cell it should appear rather it is visible under ""Actions"" column. <image> Change Request requirements: 1. Students whose team is not full yet to be able to see a list of students who don’t already have teams. 2. Students should have an option of inviting other students to join their teams. 3. Instructors should be able to view a list of students who don't have teams. Fix the second way to find other students to join your team. Currently, after you create ​an​ ​advertisement,​ ​the​ ​horn​ ​icon​ ​does​ ​not​ ​appear​ ​in the​ ​the​ ​last​ ​column​ ​of​ ​the​ ​signup​ ​sheet. We found out that the problem was due to the name of horn icon. Certain ad blockers block any element with name ad or advertisement and horn icon was named as ad.png. We renamed it to ad_horn.png and it resolved the issue. We also found out that the issue was also due to some complex table cell population. When the assignment was not in finished stage, actions were put into a td cell and displayed, which was adding an extra row, but this was only for users who had signed up some topic. In other cases, the cell was not created every time, forcing table row to have lesser columns. We removed the conditional td creation, and added all conditional checks inside a parent td, ensured that even if a user has no action to display, at least a td will be created. For​ ​student​ ​end: Display​ ​a​ ​list​ ​of​ ​​students​ ​who​ ​do​ ​not​ ​have​ ​a​ ​team​ ​with​ ​invitation​ ​links​ ​in student_teams#view​ ​page. You​ ​could​ ​invite​ ​students​ ​to​ ​your​ ​team​ ​by​ ​clicking​ ​invitation​ ​links.​ ​If​ ​s/he​ ​accepts your​ ​invitation,s/he​ ​will​ ​leave​ the original​ ​team​ ​and​ ​join​ ​in​ ​your​ ​team.​ ​It​ ​will​ ​be​ ​more straightforward​ ​than​ ​typing​ ​UnityID. For​ ​instructor​ ​end: Display​ ​a​ ​list​ ​of​ ​​students​ ​who​ ​do​ ​not​ ​have​ ​team​ ​with​ ​invitation​ ​links​ ​in​ ​teams#list page. This has solution step for CR2 and CR3. We created a helper method to fetch all participants from the database who did not have a team or whose teams have only one member(themselves). We used Join queries to join tables participants, team_users, and teams to extract participants associated with the assignment with or without teams and then filtered out participants with team size > 1. def extract_assignment_participants(assignment_id, excluded_id = nil) Above method was defined in app/helpers/assignment_helper.rb. The second parameter was required to exclude current student's id to be excluded to be returned for student whereas, for an Instructor, all students without teams or with single-member team had to be returned. More changes could be found here: <link> The method was made generic enough to be used by both app/controllers/student_teams_controller.rb (for student) and app/controllers/teams_controller.rb (for instructors). <link> <link> For student, we checked if student can actually send invites or not, and based on that we fetched the participant list. We considered cases enlisted below for verifying if a student can send invite or not: 1. Student can't send invite if student doesn\’t have a team 2. Student can't send invite if current team size is 1 and assignment\’s allowed team size is also 1 3. Student can send invite if assignment\’s allowed team size is >1 and current team size is less than allowed team size 4. Student can't send invite if current team size is equal to allowed team size 5. Student can't send invite if assignment is in finished stage 6. Student can send invite if assignment is not in finished state The table containing the list of students to send an invite to was created/not created based on above criteria only. For Instructor, there were no such criteria to be considered. 1)Conrollers:- 1. app/controllers/student_teams_controller.rb 2. app/controllers/teams_controller.rb 2)Helper:- 1. app/helpers/assignment_helper.rb 3)Views:- 1. app/views/join_team_requests/_list_not_initiated.html.erb 2. app/views/join_team_requests/_list_received.html.erb 3. app/views/join_team_requests/_list_sent.html.erb 4. app/views/sign_up_sheet/_add_signup_topics.html.erb 5. app/views/sign_up_sheet/_table_line.html.erb 6. app/views/sign_up_sheet/list.html.erb 7. app/views/student_teams/view.html.erb 8. app/views/teams/list.html.erb 4)Tests:- 1. spec/controllers/student_teams_controller_spec.rb 2. spec/features/team_invitation_spec.rb. We have written automated tests to check if the changes made are working correctly. For that, we considered the following scenarios Testing invitation criteria:- 1. Scenario 1 - Student can't see list of students to invite if student doesn't have a team 2. Scenario 2 - Student can't see list of students to invite if current team size is 1 and assignment’s allowed team size is also 1 3. Scenario 3 - Student can see list of students to invite if assignment’s allowed team size is >1 and current team size is less than allowed team size 4. Scenario 4 - Student can't see list of students to invite if current team size is equal to allowed team size 5. Scenario 5 - Student can't see list of students to invite if assignment is in finished stage 6. Scenario 6 - Student can see list of students to invite if assignment is not in finished state 7. Scenario 7 - The list of students contains only those students who don't have a team yet or whose team is not yet complete and who have not created an advertisement link. 8. Scenario 8 - A student can create an invitation link only if his team is not yet full. 9. Scenario 9 - The same student who accepted the invitation link actually gets added to the team. 10. Scenario 10 - A student won't be able to send the invitation to himself as he is already a member of that team. 11. Scenario 11 - An instructor sees only the list of the students who do not have teams with invitation link. All tests could be found here: <link> <link>. Horn icon appearing in correct column in signup sheet table. <image> All students whose teams are not complete would see list of other students without teams on their ""your team"" view so that they could invite them by an easy ""Invite"" link as displayed below: <image>. 1. <link>.","I had a little trouble following the sequence of actions to be followed in adding students to teams.  The design doc describes it, but it's easy to miss.  And there are seemingly no instructions given to a user on what that ""Invite team mates"" (should be ""teammates"") invitation is about.  It should be said, perhaps in a tooltip, that these students in the class have no team yet.","Dear Student,

Thank you for your detailed work on this project assignment. It is apparent from your response that you have a thorough understanding of the Expertiza system and its functionalities. Your approach, methodology, and the level of detail with which you have addressed the problems is commendable.

I appreciate the time and effort you took to troubleshoot and identify the underlying issues with the system, particularly with the advertisement icon and team formation. Your discovery of the ad-blockers leading you to rename the horn icon shows your ability to think outside the box.

Your solution to fixing the team formation issue appears promising. The criterion you have set up to determine if a student can send an invite to other students is thorough and seems to cover all relevant scenarios effectively. 

Great job on codifying these complex features, it indicates your understanding of the related concepts and your ability to implement them in practice. The effort you put into testing and validating your changes to ensure accurate results is notable. This practice not only ensures the software works as expected, but it also shows your careful and diligent approach to your work.

Just a note, it would be helpful if, in future assignments, consider explaining more about how you arrived at your solutions in addition to what the solution is, it would give an even deeper insight into your problem-solving process.

Overall, excellent work on this project. The solution you have devised seems highly effective and well tested. Well done and keep it up!

Best regards,
[Instructor Name]"
201,E1601,"This wiki is for the open source refactoring project E1601: Refactor methods related to submitted_hyperlinks for the course ECE/CSC 517. The reviewers may use the below student and instructor logins for the purpose of reviewing and testing the functionality. These students belong to the same team and work on an assignment created by the below instructor: 1. Instructor login: username -> instructor6, password -> password 2. Student login: username -> student5884, password -> password 3. Student login: username -> student6420, password -> password Please note : Please do not delete the above users or their team. If you wish to do so, please add them back so as to aid other reviewers. Also note that the option to submit hyperlinks in the UI will be displayed to the enrolled students only if assignment deadline is in future and the assignment is not in ""Finish"" state. Expertiza is an open source web application which enhances the student's learning through peer reviews. The students can form teams and work on assignments given by course instructors. The peers can review the submissions and give feedback. The students also get to review the reviewers!. Before : When a student submitted files and hyperlinks for an assignment, that content was submitted on behalf of his team, and not individually (even if there is only one person in the team i.e a student working on an assignment cannot be without a team even if he is working alone). Some of the previous contributors had worked on a project which made this change and associated all the submitted content to teams instead of the individual participants: the submitted_hyperlinks and dirctory_num fields were moved to teams table. All the hyperlinks were now recorded in one submitted_hyperlinks field in the team model instead of being present in all the participants of the team. All the submitted files similarly were uploaded to the common file space and in the “course_folder/assignment_folder/team_folder” path. What was wrong with that : There are multiple methods in assignment_participant.rb which still give the impression that the author is submitting the hyperlinks on behalf of himself and not the team even though the relevant fields have been moved to teams model. These methods are to be moved to assignment_teams.rb for improving the clarity and the efficiency of code. What refactoring we have done to improve the code : Task1:: Removed “hyperlinks_array” method and “hyperlinks” method from assignment_participant.rb. Created “hyperlinks” method in assignment_team.rb. Task2:: Removed “submit_hyperlink” and “remove_hyperlink” from assignment_pariticpant.rb and created equivalent methods in assignment_team.rb. Task3:: Removed “has_submissions?” from assginment_participant.rb and created the equivalent method in assignment_team.rb. Task4:: All the calls to the above methods were refactored to call the appropriate method's functions. Task5:: Refactored some of the logic of controller methods. Task6:: Tests for submitting and removing submitted hyperlinks and files. Model Files: 1. assignment_participant.rb 2. assignment_team.rb 3. student_task.rb View Files: 1. submitted_content/_hyperlink.html.erb 2. assignments/edit/_calibration.html.erb 3. assignments/list_submissions.html.erb 4. submitted_content/_main.html.erb Controller Files: 1. sign_up_sheet_controller.rb 2. submitted_content_controller.rb Files with major modifications: 1. The model: assignment_participant.rb 2. The model: assignment_team.rb 3. The controller: submitted_content_controller.rb. Four methods hyperlinks , has_submissions? , submit_hyperlink and remove_hyperlink were moved from the assignment_participant.rb model to assignment_team.rb, and the hyperlinks_array method was removed. Task1:: The below methods hyperlinks_array and hyperlinks were removed from the assignment_participant.rb. The hyperlinks method which existed here seemed suspect as there was no hyperlinks method in the AssignmentTeam/Team models so the try would always fail and return an empty array. Also the hyperlinks_array method retrieved the hyperlinks from the submitted_hyperlinks field of the team model so in moving to AssignmentTeam model we just had to remove the .team quantifier. <code> <code> They are both merged into a new single hyperlinks method in assignment_team.rb. All callers of both methods were refactored to use hyperlinks method of AssignmentTeam. <code> Task2:: Earlier, the following method submit_hyperlink was in assignment_participant.rb: <code> It has been now moved to assignment_team.rb as below. Again, as the method was moved to AssignmentTeam model, it obviated the need to invoke the team method. <code> A similar refactoring was done for remove_hyperlinks method in assignment_participant.rb. Task3:: The methods has_submissions? earlier existed both in AssignmentTeam model and AssignmentParticipant model. In assignment_team.rb <code> In assignment_participant.rb <code> What was happening earlier was that has_submissions? (AssignmentTeam method) used to call has_submissions? for each of the AssignmentParticipants in the team. This was redundant as the submitted_files and submitted_hyperlinks fields had been moved from the participant to the team model in earlier projects. So the participant objects again ended up again going to the team for retrieving these fields. So we removed has_submissions? from the AssignmentParticipant and refactored the one already present in AssignmentTeam to the simple code below: In assignment_team.rb <code> Task4:: Most importantly, at all the places in the Expertiza code, where there were calls to the above mentioned methods in assignment_participant.rb, they were refactored appropriately to call the newly created methods in assignment_team.rb. Sample example : <code> This was refactored as <code> In refactoring the call points, we used the existing team method of AssignmentParticipant to get the AssignmentTeam object associated with the particular participant and then invoked the equivalent methods on the team object. Task5 :: Refactoring some of controller code. In submitted_content_controller, remove_hyperlink method used to cycle through all the participants belonging to the team of current participant, and for each participant call the remove_hyperlink method of the AssignmentParticipant Model to delete the instance of input hyperlink. Since all the required hyperlink methods and fields are now in AssignmentTeam this would be redundant and waste cycles. So we refactored it to directly call the AssignmentTeam remove_hyperlink method. Earlier in submitted_content_controller.rb <code> Refactored: <code>. RSpec is a testing framework for Rails, and is a Behavioral-Driven Development tool. It is a domain specific language(DSL). There were no existing tests for the hyperlinks related methods. We used RSpec to write test cases using TTD approach. The assignment_team_spec.rb in the spec folder will have these tests. All the tests can be executed by rspec spec command, or can also be executed individually using the command ""rspec spec/models/assignment_team_spec.rb"". We have used Factory Girl for creating Assignment and Team objects to be used for testing. Factory Girl is a replacement for fixtures. Fixtures have to be updated whenever we change a data model whereas adding and removing fields is much easier in Factory Girl. Fixture definitions are global whereas Factories can be local, so isolated cases can be tested. Factories are defined to create objects for testing. Below code has to be added to the gemfile <code>. Below is the code to create object of team class. <code>. We have written unit tests for each of the methods we have re-factored in this project. Here's a unit test example contained in spec/model/assignment_team_spec.rb: <code>. <code>. Following are some of the steps which we performed to test this code from the User interface. Before the test:: Have two students in an assignment team (say student1 and student2, you can also use the student logins listed in this wiki) for an active assignment. Active assignment simply means that the due date is in future and the assignment is not in ""Finish"" state. You can use an instructor login (example username: instructor6 password: password) to create a new assignment or update the due dates of some previous assignment and assign the team to it. Test1: Login as student1. Submit a hyperlink (say : linkA) as student1. Expected: Submit should go through. The hyperlink should be visible when you login as student2. Test2: Now as student2, submit another hyperlink (say linkB). Expected: Submit should go through. Now both hyperlinks should be visible from both student1 and student2. Test3: As student1, try submitting linkB. Expected: As linkB already exists in team's hyperlinks the submit should not go through. Test4: Remove a hyperlink (say linkA). Expected: Remove goes through. Now only linkB should be visible from both student accounts. Test5: Remove all hyperlinks. Expected: Hyperlinks list is empty for team and this can be seen from both student accounts. Test6: Submit some hyperlink. Try dropping topic after submitting. Expected: You are not allowed to drop if you have submitted some work. Only if you remove the submitted work it is possible for you to drop. Test7: Submit some hyperlink. Do a review of the team after logging in as a student in another team. The assignment should be in review stage for this to be possible, you can move the due dates via instructor login to achieve this. Expected: Peer review should show the links submitted by the other team. Review should be submitted successfully.","""It starts out with a synopsis of Expertiza (unnecessary) and a fairly unreadable explanation of what is wrong.
But after that, it describes the changes very well.""","This assignment is quite comprehensive and detailed. The systematic approach with which your team tackled each task reflects your clear understanding of the project objectives. I am pleased with the refactoring you made in the code and how you shifted methods between models to improve clarity and efficiency. Your detailed explanations make it easier to follow the changes made and their impact on the whole system.

However, testing was only briefly covered towards the end of the assignment. While you mentioned using RSpec and the TDD approach, providing more detail on the actual tests would have been beneficial. It would have helped illuminate how you ensured the refactored code's stability and correctness. In your future assignments, providing more information on the testing strategies used, why they were chosen, and how they were implemented would be beneficial.

Your overall submission suggests you did thoroughly execute the assignment while using reliable coding practices. I also appreciate your inclusion of the step-by-step testing process, and detailed information regarding Factory Girl.

Well done! I look forward to seeing more of your work in the future as you continue refining your problem-solving and technical skills."
202,E1654,"<link> is a <link> application made by the joint contribution of Professors and Students of <link> . It is used by the Professor ,Teaching Assistants and students of a particular course to manage their respective responsibilities with respect to that course. Professor can enlist a new assignment or project, set/update the deadline to submit it , grant publishing rights to a user and more. The Teaching Assistants can including other things update the review scores of the students, view the submissions etc. The students can view information about all the assignments due and submitted.Students can form teams in Expertiza to work on various projects and assignments.Students can also review other students' submissions and the performance of their teammates. Expertiza supports submissions across various document types, including the URLs and wiki pages. The <link> allows the instructor to set deadlines for the assignments and peer reviews. 1) The current date-picker doesn't let you change dates easily. When you try to edit a deadline, Unless you spell it out to the minute, it changes the deadline to the current time. 2) While testing, the instructors very often want to test an assignment in, say, the submission or review phase, even after the assignment is complete. In order to do this, we need to change several due dates from the User Interface. This process needs to be simplified. 1) Fix the date time picker bug in _due_dates.html.erb. 2) Find a more user-friendly <link> <link> that supports time zones and allow users to define deadline by date and time (hour), if the bug is not fixed in the existing implementation. 3) <link> should be automatically picked from users timezone preference. 4) Allow users to set all due dates ahead by x days, and the algorithm calculates the exact date and time. Problem 1: In the previous implementation for Expertiza, the professors observed that when they wanted to change the date for submission or review deadline for any project or assignment, Expertiza was not able to handle it properly. As in, when the professor tries to change the date - a calendar pops out but then the calendar should point at the date already in the text box.But this was not implemented as it was picking the date of the system and the professor had to go through a cumbersome process to change the date. And even when any date was not selected the field used to get updated by current date and time. Reason: In the back end , the date picker used was not able to read the date properly from the text box because of date format mismatch. We observed that if we resolve the mismatch in the date formats , this problem could be solved. <image> <image> Problem 2: When there is a requirement which asks for the professor to change the due dates of assignments or projects, (s)he had to change several dates from the front end one by one which was a very time-consuming and ineffective method. Reason: In the previous implementation , there was no functionality which allowed the professor to change dates for multiple projects,assignments without manually entering a new date in each text box or selecting each date using the date picker. We observed that we need to add a functionality where the professor can simply select the assignments/projects for which (s)he wants to update the deadline and input the number of days he wants to extend the deadline and by a click of a single button (s)he can change multiple deadlines. <image> <image>. We made two major changes. Change 1 - We have changed the date picker implementation. As stated, the date picker was not functioning properly. If, while changing the date in the text box , no changes were made, the picker defaulted to the system date instead of the previous date in the text box. The reason for this was a mismatch in the date formats. We made corrections to the code and resolved this mismatch. Now, the date picker is working as per the requirement. It is able to read the date in the text box and there is no mismatch in the date formats. The code below formats the date in a format which datepicker expects. Which removes the Bug in the system which was causing wierd behavior of the Datepicker <code> Change 2 - We simplified the process of changing the due dates of submissions for multiple projects/assignments. It was accomplished by adding check box in front of each assignment. Suppose there are 5 submissions on the page. And the professor wants to adjust the due dates of assignments 1,3 and 5 by 4 days. Then, he will check the check boxes for submissions 1,3 and 5 and increase from 0 to 4 in the number of days. On clicking save, the dates of all the 3 submissions 1,3 and 5 will be increased by 4. While coding , we have checked for the adjustment in the months and years as well keeping in mind some months have 28,29,30 or 31 days with an year being a <link> or not. <image> <image> The Code below contains jQuery Functions which are called on click of ""Show/Hide Date Updater"", ""+"", and ""-"" button. <code> <image> <image> The Function Below is a generic Function which can be used to Increment/Decrement Days and Months written in jQuery <code> <image>. The changes made by us in the code can be tested using the below tests : 1. Navigate to Manage Tab, Assignments, Edit (Pencil Icon) page after logging in with the following URL: <link> ( Project successfully deployed ) <code> 2. After logging in as an instructor, Perform the following: change the due dates for an assignment. Go to the text field to change the dates, and without changing the date click on any whitespace. In the current production version of expertiza, the second action resulted in the current date and time being filled in the date and time section. <code> 3. For incrementing/decrementing the number of days allotted for an assignment, click on the show/hide date updater button to reveal the updater widget. check mark all those assignments that need to be updated and enter the number of days in the text field. Press Plus to increase and Minus to decrease the number of days allotted for the assignments. <code> 4. The complete functionality of our project is well described in the <link> . This will help in testing as well. Here is our <link> . In the link you can see all the changes made in the back end made to fix the date picker bug and implement additional functionalities to update deadlines. 1 <link> 2 <link> 3 <link>.","problems and implementations are clearly shown with screenshots. the description of the mismatch in the date formats, and what was the correct format should be written using a human language, not a copy paste of code!","The work you have done is commendable. Your attention to both minor details as well as the major functions is excellent. Debugging the date-picker was crucial for maintaining a user-friendly interface, and your detailed explanation of the issues shows your deep understanding. Your commitment to improving the convenience of both students and teachers is evident in the changes you made to ease the process of modifying multiple due dates.

The screenshots you included in your report help in understanding the processes in action and the code snippets help me – and other developers or users – understand the solution you put forth. I commend you on this wonderful illustration of your troubleshooting steps and solutions with relevant examples and code.

However, you need more clarity in your language and format, as some sections were a bit difficult to understand. I encourage you to proofread your work for typographical errors and to ensure your sentences are clear, concise, and easy to understand. Another point is that the large blocks of text can be daunting for readers. You could consider adding subheadings to break your content into sections.

The final part of your submission, in which you described how the changes to the code can be tested, is both detailed and exhaustive. This will make it easier to maintain the system in the future and provides a solid foundation for continued testing and development.

In conclusion, your understanding of the system is impressive, and the innovative solutions you proposed show your potential as a developer. Remember to express your thoughts clearly and concisely in your future assignments for the benefit of your readers. Great job on this one!"
203,E1815,"This project aims to enhance the review report and summary page, and display more information necessary for grading. The goal is to help the instructors by making the process of grading reviews easier and more accurate. There are some issues with the current review report page with regards to the Metrics column. 1.1. Metrics are displayed as plain text. 1.2. No comparison on how this student compares with other students. 1.3. If more metrics are added, showing multiple lines of text for each metric can make the column cluttered and difficult to read. Showing a bar chart for the metric rather than just text would improve the user experience. The bar chart can also depict the average for all students for this metric, so the grader can see how this student compares with other students. Also, if several metrics are shown in the column, the bar chart can be made resizable to accommodate multiple bars. <image>. To view this page you click the summary in the row for any student. This page summarizes the peer Reviews given to the Author. They are basically separated into three columns i.e reviewee, score and comments. 1. The first issue in this view is that there is no header saying what course, assignment, or student this relates to. 2. Secondly, The field that lists the team members is wider than the rest of the columns combined. The comments column needs more space it will contain more information 3. Finally, For questions answered with check-boxes, comments are not necessary, but still a blank cell is displayed. <image>. Currently, in review report, each team reviewed is color coded as, red indicating that the review is not yet completed and blue indicating that the review grade is not assigned or updated. So if an instructor sees a name in red, the student should not be given credit for the review. If text is in blue, then the student has not been graded for the review, so the instructor should grade it now. But there is caveat here. If the reviewer has reviewed the work but the author did not resubmit, the reviewer has nothing new to review in the latest round and should not be downgraded for not re-reviewing the work. This issue needs to be addressed. <image> This is what the current color scheme looks like. The text in blue indicates that the student has not been graded, while the text in red indicates the student should not be given credits. 1. app/assets/stylesheets/redbox.scss 2. app/helpers/review_mapping_helper.rb 3. app/views/review_mapping/_review_report.html.erb 4. app/views/popup/view_review_scores_popup.html.erb 5. config/application.rb. We replaced the text given in the Metrics column with a bar chart, as shown below. The bar chart depicts the overall average of all students for this metric, the average of this student for this metric (based on each round) and the metric values for each round for this student. 1. File: app/helpers/review_mapping_helper.rb The following methods were added to calculate average for this metric for all students and for calculating maximum value for this metric. The maximum is needed for constructing bar chart. The second method was added to construct the x-axis labels in the format ""0|50|100|...|max"" for the bar chart. <image> 1. File: app/helpers/review_mapping_helper.rb The following method constructs the bar chart. <image> 1. File: app/views/review_mapping/_review_report.html.erb The following code is added to get the average metric, maximum value of metric and x-axis value from controller. <image> 1. File: app/views/review_mapping/_review_report.html.erb The following code includes the bar chart in the review report page. <image>. <image>. We have spanned the question text to all three columns instead of it being one, also the width of the first column containing the reviewee information is reduced appropriately. Checkbox Questions are displayed more compactly by including Question to the left and automatically adjusting the width of the reviews to right. A green tick is added if the reviewer selected the checkbox and a red cross mark is added if the reviewer did not select the checkbox. The file modified is app/views/popup/view_review_scores_popup.html.erb In the code, we identified whether a question is Checkbox question or not and changed the row to include the question on the left and auto adjusting the response from the reviewer's on right. <image> The page looks as follows <image>. To address the caveat mentioned above, we have used green color to distinguish reviewers who have nothing new to review as the authors have not made any changes. This is what the end result looks like, <image> For doing this, we are getting the last modified date/time of the wiki links and comparing it with the last review submission deadline. If the last modified date/time of the wiki links is before the last review submission deadline, there is nothing new to review and hence green should be used instead of blue to display the author's name. To ensure this check we have added the is_submission_updated_for_last_round function to the /app/helpers/review_mapping_helper.rb, <code>. 1) Log in as an instructor 2) Navigate to review grader by doing this (Manage > Assignments) 3) Click on the “View review report” icon (the one with the spyglass and two people) 4) Check if the visualizations are appearing in the review report. 1) Log in as an instructor 2) Navigate to review grader by doing this (Manage > Assignments) 3) Click on the “View review report” icon (the one with the spyglass and two people) 4) In the review report click on the “summary” in the row for any student. 5) Check if the changes are appearing in the page as mentioned in the proposed solution. 1) Log in as an instructor 2) Navigate to review grader by doing this (Manage > Assignments) 3) Click on the “View review report” icon (the one with the spyglass and two people). 1. <link>. Expertiza 1. <link> Expertiza Github 1. <link> Expertiza Documentation 1. <link>.","Clear organization, and good explanation of the changes that have been made.  The screenshots in Issue 1 show how the changes have been implemented.  The code in Issue 2 is less clear, and there is no description of how it works.  The test plan is OK except for saying what is supposed to happen when the code is tested; that is very vague.","Hi there,

Thank you for your thorough and detailed assignment submission. I appreciate the time you took to clearly document the problems you identified with the review report page, your process for addressing those issues, and the solutions you implemented. The specificity and clarity in your process are commendable.

From your assignment, it's clear that you have a good grasp of designing intuitive and user-friendly UI. You made some excellent observations about the previous system design and the improvements you proposed were well thought out.

I especially liked how you recognized the need for visuals in the form of bar charts to replace plain text metrics. This is a great idea that truly enhances the user experience and makes data visualization much easier.

The newly introduced color codes and your modification to account for situations where the reviewer had nothing new to review was another effective solution you implemented, aiding in script interpretability and usability.

Also, your approach to making the comments column wider was a much-needed change. This shows your understanding of functional UI design and your ability to identify areas for improvement.

I also appreciate the in-depth instructions you provided for testing the changes and verifying the new features. This is a great practice that enhances the reviewability of your changes.

One suggestion I have for future projects is to include more testing details. You provided instructions for how to view and verify your changes, but didn't include much information about how you tested these changes during development.

Overall, your work is excellent and you've demonstrated clear understanding of application development and UX design principles. Keep up the great work!

Best,
[Your Name]"
204,E1569,"<link> is an <link> software tool developed at NC State University. It is used to facilitate assignment and course management. It is primarily intended to facilitate assignments being peer reviewed. It is written as a <link> application, thus functioning natively in a web environment. It can be cloned from <link> . <link> is a process designed to change code without modifying the functionality. Refactoring can improve the readability and the logical design of the software, making sure everything is in the right place and has the right name. This allows code to be understood more quickly by a developer, which shortens the time it takes to develop new features. Ensure that MySQL is already setup on your system. If you are using an Ubuntu system, the following commands can be used to install MySQL: <code>. In your local directory, clone the updated GitHub repository. <code> Visit <link> for getting more information on setting up git. Go to the local expertiza directory: <code>. From the expertiza directory, run the following command: <code>. The ReviewMappingController file in this application (review_mapping_controller.rb) is responsible for setting up mappings between reviewers and reviewees. It essentially connects a reviewer to an assignment. However, it is a fairly bloated file since it has to handle functionality for five different kinds of maps (review response, author feedback, teammate review, meta-review, and quiz response). It is a prime choice for refactoring because the refactoring can clarify the intent of the different methods in the file. According to the problem statement<ref> <link> </ref>, there were 11 tasks involved in refactoring the ReviewMappingController : 1. Method delete_rofreviewer should do the same thing as delete_metareviewer 2. Method delete_participant is not used 3. Method list_sortable is not used 4. Method automatic_review_mapping_strategy is too long 5. Method review_report has SQL-like code 6. Method add_user_to_assignment should not be in this controller 7. Method get_team_from_submission should not be in this controller 8. Method delete_all_reviewers doesn’t actually delete all the reviewers, but just the outstanding review response maps. We want to keep this functionality 9. Method delete_participant should not be in this controller 10. Method name release_reservation doesn’t describe the functionality well 11. Method delete_review is not used. In the process of refactoring, we have actively followed the Ruby coding guidelines <ref> <link> </ref>. We have also followed some design pattern rules like Single Responsibility Principle <ref> <link> </ref>, which state that every class should have responsibility over a single part of functionality provided by software and that responsibility should be entirely encapsulated by the class. All the services and operations within the class should be aligned with that responsibility. This function has duplicate functionality to another function, delete_metareviewer, and the other function is named much better. The method delete_rofreviewer was removed. This function was confirmed to not being used, since there is no other function in the application that calls it. Therefore, it was removed. This function was confirmed to not being used, since there is no other function in the application that calls it. Therefore, it was removed. This function was originally too long. Hence, we modularised it by moving the part of the code that loops over all teams and creates the ReviewResponseMap into a new function. To make this code easier to read for a pure Ruby developer, the SQL-like code was rewritten with ActiveRecord. This method does not belong in this controller, and it is only ever called by participants_helper. Therefore, the method should go into participants_controller, which is where it was moved. Since the only problem with this method is that the name does not describe the actual or intended functionality, we replaced all instances of “delete_all_reviewers” with “delete_outstanding_reviewers”. This function was confirmed to not be used, since there is no other function in the application that calls it. Therefore, it was removed. Since the method name does not accurately describe the functionality within, all instances of “release_reservation” were replaced with “release_mapping”. This function was confirmed to not be used, since there is no other function in the application that calls it. Therefore, it was removed. <link> is a Behavior-driven development for Ruby programming language widely used for Test Driven Development. It has its own mocking framework based upon JMock. <ref> <link> </ref>. <code>. <code>. <code>. <code>. <code>. View Response Report <image> View Response Report by name Search for Reviewer's name ""523, student"" <image> View Feedback Response Map <image>. By refactoring ReviewMappingController , extraneous and unused code was removed, readability was increased, and tests confirm that its functionality remained intact. Users will experience incrementally better performance, and developers will have an easier time getting up to speed on the software, resulting in heightened developer efficiency and faster turnaround times for new features. 1. <link> 2. <link> 3. <link>. <references/>.",Good job on writeup!,"You've done a commendable job with this assignment. The thorough presentation of the problem, the detailed explanation of the analyses, and the display of the refactoring tasks display a deep understanding and control of the assignment. 

Your knowledge of expertiza and the use-cases for different concepts in the tool is impressive. Also, your approach to refactoring was thoughtful and meticulously detailed, abiding to best practices like the Single Responsibility Principle which is commendable. Ensuring to confirm unused methods before removing them was an appropriate step to take. 

Although your descriptions were satisfactory, try to include more detailed justifications for why some methods don't belong in certain controllers to enrich your explanations. 

The report would benefit from having the methods you analyzed and the corrections you made clearly distinguished. Some sections were hard to follow mainly because your insights on changes were merged with the existing structural details of the controllers. This could potentially confuse readers who are not familiar with the software.

Lastly, in terms of academic writing, remember to apply proper referencing format for your sources. Ensuring that references used have matched citations in the body of your assignment enhances your credibility and the quality of your work.

Great job! Keep it up!"
205,E1937,"Peer-review systems like Expertiza utilize a lot of students’ input to determine each other’s performance. At the same time, we hope students learn from the reviews they receive to improve their own performance. In order to make this happen, we would like to have everyone give quality reviews instead of generic ones. Currently we have a few classifiers that can detect useful features of review comments, such as how many suggestions they contain. The suggestion-detection algorithm has been coded as a web service, and other detection algorithms will be so coded in the future. In order to make the API call, the response_controller.rb will be responsible for sending a JSON input to the web service. The input will contain the review comment submitted by the user in the following format: Below is a sample input <code> Once the request is send, we expect the output to be in the following format: <code> The output (which is a JSON) will be parsed and the suggestion metrics such as the tone and presence of suggestion will be extracted so the user will be able to view a summarized result of how well their review comments were. In addition, an average score will be computed based on the scores they received for each comment section, and the result will be presented in a colorful format to the user after they hit the submit button. <link> 1. They had a functional suggestion detection API call that successfully communicated with the PeerLogic Server and retrieved the output. 2. They included their API call in response.html.erb using JavaScript. 3. They were able to display the output for each review beside the review. They displayed all of the information returned from the endpoint, which can look clunky. 4. Since the code is added in the views, they performed manual testing in the views. More information about the suggestion detection service can be found at <link> <image>. <image>. 1. Move API calls of suggestion-detection algorithm from view to response_controller.rb 2. Change default review view from displaying analysis for each comment to summarized analysis for all comments 1.1. Do not include comment text in analysis view 1.2. Focus on sentiment_score, suggestions, suggestions_chances returned from API 3. Include displaying analysis for each review as a ""debug"" option 4. Ensure that CORS does not need to be enabled for API call to work 5. Write unit tests for our method(s) in response_controller.rb 6. Fix grammar issues in response.html.erb 7. Evaluate how much time this API is taking and, if possible, work a way out to improve it. 1. app/views/response/response.html.erb - Refactored and reworked JS methods for the autosave and form submits, added a new hidden button to the response form 2. app/controllers/response_controller.rb - Refactored and reworked methods for the autosave and form submits, added an API method to pass to view 3. app/helpers/review_mapping_helper.rb - Adjusted the bar thickness according to desired specifications 4. config/routes.rb - Added another route to support the new review confirmation page listed below. 1. app/models/metric.rb - New ActiveRecord model added to act as a template for future API usage 2. db/migrate/20190425194052_create_metrics.rb - New table added for permanent storage of the Metric class 3. app/views/response/show_confirmation_page.erb - The new page added for review confirmation 4. test/fixtures/metrics.yml - In support of the new ActiveRecord model called Metric 5. test/models/metric_test.rb - In support of the new ActiveRecord model called Metric 6. app/assets/images/lightbulb.png - Lightbulb picture for the new review confirmation page 7. app/assets/images/music_note.png - A music note picture for the new review confirmation page. Lines 359 and 360 are where we will retrieve the input from each review comment found in the form. 1. The Answer model represents the review provided by the reviewer. 2. On line 360, answer: v[:score] is the review comment from a given textarea HTML element 3. params[:responses] stores the aggregate review data provided by the user <image>. The program flow is as follows: 1. After the reviewer has filled out their review, they have 2 choices: See an analysis of their review or Save the review. 2. The reviewer selects to view their analysis by clicking on ""Confirm Submission"" button 3. The program directs the reviewer to the new confirmation page which displays an analysis of their review. 4. The reviewer has 2 options in the confirmation page: Submit the review or go back and modify their review. 5. If the reviewer decides to Submit their review, the program directs them back to where they started (Create or edit review). The image below shows the above steps in a visual depiction. <image>. Below we showcase the available information from the API if a reviewer is curious to find more details <image> <image> <image>. To make the interface more user-friendly, we used conditional formatting to color our text. For the suggestions metrics, anything >50% means suggestions are present while anything <50% means suggestions are absent. Our conditional formatting is set so ""Yes (>50%)"" is green, 50% is yellow, and ""No (<50%)"" is red. The formatting is the same for the class average of suggestions metrics. For tone, there are three options in the API: positive, neutral, and negative. We created conditional formatting in our view file so positive is green text, neutral is yellow text, and negative is red text. Since we changed the controller and UI in our project to add the redirect view, the current Travis CI test build is failing. 1. For TESTFOLDER=features, in the response.hmtl.erb view, we changed the submit button text from ""Submit"" to ""Confirm Submission"" in order to accurately reflect the new redirect page. 2. For TESTFOLDER=controllers, we modified the save method inside response_controller.rb to redirect according to logic defined above. 1. We tested the new model added i.e. Metric model in metric.rb. 2. The RSpec file is added to the rspec/models folder with the name metric_spec.rb. 3. The testing tests the calculation of the average of suggestions chances from each response for a particular assignment. 4. This also tests the output text of the sentiment that is received based on an input numerical value. We have... 1. Manually tested response.html.erb to verify the Review page outputs the correct message 2. Provided sample inputs and shown expected outputs using screenshots. 1. <link> 2. <link> 3. <link>.","I think this design doc would have been more effective if you described more of the code.  You did say what was done in Lines 359 and 360 of the response_controller, but you didn't explain any of the other changes.  This is important for giving programmers who follow you an idea of why the code is structured as it is.","Hello,

Thank you for the comprehensive submission. Your attention to detail and the clarity of your included code is impressive. It's also clear that you have given extensive thought to the user experience and how to improve it.

However, there are a few areas for improvement:

1. You mentioned that issues have arisen due to the changes you made to the controller and UI, namely the Travis CI build failing. It's crucial to resolve these issues before proceeding further. Also, make sure you are writing tests for all new methods and functionality. Proper testing helps to catch bugs and other issues early, preventing software malfunctions.

2. There are a number of places in your post where you need to provide more context or explanation. For example, you mentioned an issue with CORS. What precisely is the issue, and what obstacles might it cause for the API call?

3. In terms of testing, you mentioned providing visualizations of your sample inputs and expected outputs, as well as some manual tests. I encourage you to employ a more rigorous automated testing methodology to ensure your software can withstand real-world scenarios.

4. Regarding the analysis information, it's mentioned that the results are color-coded. Ensure that color isn't the only indicator, to maintain accessibility for colorblind users.

5. The organization of your document can be improved. It seems you tried to cover a vast amount of information; while it is excellent to be comprehensive, it is equally important to maintain readability and flow. 

6. Lastly, please pay careful attention to grammar and punctuation. There are a few places where sentences are not properly constructed, which can be a bit disruptive for the reader.

Overall, your submission reflects your hard work and understanding. Keep up the great work! 

Best regards, 
[Your Name]
"
206,E1962,"In Expertiza, students and instructors are notified of various events by e-mail, e.g., creation of a new account, submission of a review on their work, or updating of work that they have reviewed. Students receives email whenever their account is created in system. New users on Expertiza can be created by instructors directly from Users page or new user can also get created when added as an assignment participant but does not already exist in the system. After creating an assignment, the instructor can add participants to it by two ways 1. Picking participants by their usernames OR By importing a csv file which lists the participants If a user does not already exist in the system, then a new Expertiza account is created for the user and then added as a participant on the assignment. An email notification of account creation along with the user-ID and password must be sent to the user. The following issue was identified in the current system 1. When students' accounts are created by importing a CSV file on the Users page, they receive e-mails with their user-ID and password. However, if an account is created by adding them as participants to an assignment when they don't already have an account, e-mail notification is not being sent. You can find the issue marked on github <link> . File: app/models/assignment_participant.rb The code in the below snippet previously had the flow as follows: If user does not already exist in the system, then create new user account(if there is sufficient information about the user to create a new Expertiza account) Add this user to the assignment as a participant. If user already exists in the system, do nothing. If the user is already a participant on the assignment, do nothing. The issue here was that an already existing user in the system will not get added as a participant on the assignment. The code has been modified to facilitate the following flow: If the user does not exist in the system, create new user account (if there is sufficient information about the user to create a new Expertiza account) If the user already exists as a participant on the assignment, do nothing Add the user to the assignment as a participant; otherwise. This way, the user(whether newly created or already an Expertiza user) gets added on the assignment as a participant. <image> File: app/models/assignment_participant.rb Now that we have enabled the email functionality irrespective of where a new user is created from, we don't need to explicitly call the mailer from each location where new user is created. Hence we disabled one such part of code where mailer was being called particularly at this location in the original implementation. <image> File: app/models/user.rb Here, we enabled the email functionality by adding the .deliver_now method This method invokes the mailer to deliver an email immediately. <image>. Unit testing is not mentioned here because proposed implementation uses already existing mailer functionality for which test cases are already written. Below given file shows test cases for integration testing of this improvement. File: spec/models/assignment_participant_spec.rb While uploading participant list via a csv, for each new user created on expertiza, an email notification should be sent out. This is a test case which checks the count of email after a new user has been created. The email count should be 1 in the case that a new valid user is created. <image> <image> File: spec/models/participant_spec.rb Initially, on being added to an assignment, the user would receive an email. However, no email notification was sent on new account creation. Hence the total number of emails sent out was one, as per previous implementation. Now that the email functionality has been added on account creation too, a total of two emails will be sent to new users added as participants - one for account creation and one for addition to assignment. We modified the expected email count to accommodate this change. <image>. Follow these steps:- (You can also watch the demonstration of the implementation <link> ) 1. First, make a CSV file on your local system using the following format. You may skip the header. <image> 2. Follow <link> to the deployed application 3. Login with username 'instructor6' and password 'password' <image> 4. Navigate to Manage -> Assignments <image> 5. Click on 'Assignments' <image> 6. For an assignment, select the action 'Add participants' <image> 7. Click on import assignment participants <image> 8. Upload the csv file created above <image> 9. Confirm the participant list <image> TIP: To test fully, ensure that you have access to at least one of the email-ids mentioned in users listed in the csv. This way you can affirm the changes work when you receive an email notification as shown below. In course of working on the issues listed in the scope of this project, we identified another bug in the system. Issue: If a user already exists in the system and appears in the csv file while importing participants, then the code only checks that the user exists and moves ahead. However, the user is not added as a participant on that assignment. Participants are being added to the assignment only when user does not exist in the system already and user is newly getting created. To view the issue on github, <link> To visit our forked repo, <link> To test the implementation, <link> To view our pull request, <link> To watch a demo of the implementation, <link>.","Although I disagree with some of the design decisions, the changes are very well documented.

Using the Github diff view is an excellent way to show your changes.

Unfortunately, many of the changes are to comment out code.  Code that is no longer needed should be deleted.

Explanation of the assignment_participant changes was very terse.  More complete explanation would save the next person considerable time.

It is not a good idea to email students whenever they are added to an assignment.  I don't know of any other class where students are emailed every time work is assigned.  Students may want to opt out of this, and there is no way to do so at present.

Team found another bug, which I will report to Github.","Dear Student,

Good job! Your assignment shows a robust understanding of the Expertiza system and the nuances involved in modifying already existing functionalities. 

Your explanation on the identified issues with the current system, your approach to addressing these and the subsequent changes made were detailed and evident. The way you structured the process into systematic steps showcasing the prior and post-implementation scenarios was very insightful and gives the reader a clear understanding of problem and solution alike.

The use of images at appropriate places helped visualize what you were addressing at each point. It's great to see you thoroughly working on the bugs and testing their implementation rigorously. 

It's commendable that you have thought of testing the new functionality using an existing participant email, and have clearly highlighted this testing process with suitable steps. 

However, keep in mind that your technical communication could be improved by incorporating more concision and precision in your language. This would make your work more accessible to readers who may not be as well-versed in the system you are describing. 

Also, adding a brief synopsis of the project at the beginning might give the readers a general outline of the whole implementation, thus making it more understandable. 

Lastly, as an improvement for future projects, consider adding comments in your code to make it more readable and easier for others to understand, especially when collaborating on software development projects.

Keep up with your great efforts!

Best,
[Your Name]"
207,E1930,"The Expertiza application running on Ruby on Rails is used for a variety of purposes by students and faculty members. There are many pages that display information about students, assignments, rubrics and reviews. The information is displayed with attributes like name, ID, due date etc. This project works on improving the search facility by adding search criteria in existing search bars, making it look elegant and adding search bars if not present. 1. An instructor or administrator can search for a user by name, user-ID, or other characteristics. 2. An instructor should be able to search for assignments by name, due date, or other characteristics. 3. An instructor should be able to search for rubrics (or other questionnaires) by name, or by the courses or assignments they have been used in. 1.1. For the instructor, there also needs to be a way to quickly find rubrics (and other questionnaires) that have been used in a single course. It should be possible to search or click somewhere to bring up a list of questionnaires used in the course, expanding only the applicable questionnaires in the list of questionnaires. 1.2. One should also be able to search for questionnaires by words used in questions that belong to the questionnaires. 4. There should be a way to search all reviews of a particular team’s work for particular scores or text strings. Reviews should be able to be filtered by score, text comment length, reviewer and reviewee. 5. An instructor or administrator should be able to search for all the assignments that a particular user has participated in. 6. If more than one criteria needs to be specified, there should be an 'Advanced Search' button. In the current system workflow the user is able to search for a particular user by entering a partial or a complete text that matches with the user name. In the proposed workflow searching by name, searching by User ID will also be supported. The user will be able to apply multiple filters at a time and the output of the query will match all filter applied. If no results are found an empty list will be returned. Steps to reproduce the proposed workflow: 1.1. Log in to expertiza to view the home page 1.2. Go to Manage > Users 1.3. Type the name of the user in the search box available below the ‘Users’ tab 1.4. In the dropdown list that opens up, click on the ‘Advanced Search’ button if you wish to apply more filters. 1.5. All the entries that match the given criteria will be returned. In the current system implementation, searching via the name of the assignment is supported. In the proposed system, the user will be able to search for an assignment using additional filters such as date created, date updated. The user will be able to apply multiple filters at a time and the output of the query will match all filter applied. If no results are found an empty list will be returned. To search for an assignment by creation date, the user can enter a time duration within which the assignment was created. All assignments that were created within this date range and which match other filters will be returned. The procedure is same for searching by date of update. Steps to reproduce the proposed workflow: 1.1. Log in to expertiza to view the home page 1.2. Go to Manage > Assignments 1.3. Type the name of the assignment in the search box available below the ‘Assignments’ tab 1.4. In the dropdown list that opens up, click on the ‘Advanced Search’ button if you wish to apply more filters ( date of creation, date updated). 1.5. All the entries that match the given criteria will be returned. The existing system does not have a search functionality under Questionnaires. The proposed system will implement a search functionality for searching via the name of the questionnaire, the text in the question within a questionnaire, date of creation, date updated. The user will be able to apply multiple filters at a time and the output of the query will match all filter applied. If no results are found an empty list will be returned. To search for a course by creation date, the user can enter a time duration within which the course was created. All courses that were created within this date range and which match other filters will be returned. The procedure is same for searching by date of update. The questionnaires will be grouped on the basis of their courses and will be expanded when clicked. All the above will be available under Manage > Questionnaires. The existing system does not have a search functionality under Reviews. The proposed system will implement a search functionality for searching using the attributes like team name, score, reviewer, comment etc. <image>. We though about 2 ways of adding the search functionality in the system 1.1. Adding a search controller to the system 1.2. Adding search functionality to individual models. If we followed this approach the search query would be like 1. localhost:port/search/user?name=<> 2. localhost:port/search/assignment?name=<> This would mean that we are thinking of search as a resource on the system which to us looked as a wrong approach. If we followed this approach the search query would be like 1.1. localhost:port/user/search?name=<> 1.2. localhost:port/assignment/search?name=<> On discussions we concluded that that the latter was a more RESTFul design For most of the cases we have tried to minimize the changes required in the respective model by reuse We propose to add search methods in each model for corresponding changes. Therefore in order to perform search every entity required changes in all the three layers 1. View : Changes in view are changes added to UI, and it is used to pass search parameters to controller 2. Controller : Parses the changes from UI, essentially takes params[] hash. 3. Model : Bulk of search logic is implemented here, once the model gets the parameters for the search ( hash ), the query is incrementally built using all the params and then executed to get the list of objects. User changes have been handled differently than for Questionnaire, Assignments and Review because Users follows the traditional RoR scheme, where as others user React for UI. React based View changes are in app/assets/javascripts/tree_display.jsx. 1. Also, placeholders are removed from the search text bars in advanced search because it looked ugly. Also, labels for each search text box has been added directly above it so that the user can easily identify what parameter that text field contains. 2. Also, code has been refactored because it was a lot of bad jumble in all the cases. 3. Comments have been extensively added throughout the code which are informative and helpful 4. Search functionality for Courses has been added as well. 1. Search fields 1.1. username 1.2. name 1.3. email 1. Modified files: 1.1. app/views/users/list.html.erb 1.2. app/controllers/users_controller.rb 1.3. app/models/user.rb 1. Modified functions 1.1. UsersController#list : Parses the username, name and email from the params hash. 1.2. User#get_user_list : Model returns list of users to the view, changes in this function uses regex to filter out the entries that do not match search params. 1. Search fields 1.1. name 1.2. assignee_username 1.3. assignee_name 1.4. due_date_before 1.5. due_date_after 1.6. created_before 1.7. created_after 1. Modified files 1.1. app/assets/javascripts/tree_display.jsx 1.2. app/controllers/tree_display_controller.rb 1.3. app/models/assignment_node.rb 1. Modified functions 1.1. TreeDisplayController#initialize_fnode_update_children 1.2. TreeDisplayController#update_fnode_children 1.3. AssignmentNode.get. 1. Search fields 1.1. name 1.2. text 1.3. course 1.4. assignment 1. Modified files 1.1. app/assets/javascripts/tree_display.jsx 1.2. app/controllers/tree_display_controller.rb 1.3. app/models/questionnaire_node.rb 1. Modified functions 1.1. TreeDisplayController#get_tmp_res 1.2. QuestionnaireNode.get. 1. Search fields 1.1. team 1.2. text 1.3. min_score 1.4. max_score 1. Modified files 1.1. app/views/review_mapping/_searchbox.html.erb 1.2. app/controllers/review_mapping_controller.rb 1.3. app/helpers/summary_helper.rb 1. Modified functions 1.1. ReviewMappingController#response_report 1.2. SummaryHelper#summarize_reviews_by_reviewees. 1. Search fields 1.1. Name. <image> 1. As seen in the image, the advanced search is closed at the start. When it is clicked on, it pops up as shown in the image below. 2. There is also an option of hiding the advanced search bar. <image> 1. Important changes made in the pop-up of advanced search bar context was that, before when we tested the functionality it was found that if you had searched something prior in the advanced search bar, then if you hide the advanced search bar, the data remains persistent until it is removed manually. 2. Hence, if you search again now, it will take the prior advanced search criteria into consideration as well. 3. But now, the functionality has been changes to completely erase the data from the text boxes once it is hidden. So unwanted parameters are not included in the search. The simplified version of ER Diagram depicts relationships between the entity sets that are used in the system. Many-to-many relationships are identified by named-diamonds - teams_users, assignment_questionnaires, which are implemented as tables. <image>. <image> <image>. We plan to two types of testing 1. User Interface manual testing 1.1. As extensive as these tests were, everything was found to be working correctly. 1.2. Feedback was taken as to where changes needed to be made and respective changes were made where necessary. 2. Automated RSpec testing 1.1. Tests were included for all the code refactoring done (making new subroutines and moving code.) 1.2. Also, there were extensive tests written for the search functionality which was dependent on the user that was logged in. 1.3. Basically, super admin were to be tested on different data than, TAs and instructors. 1.4. As an example:- <code>. <link>. <link>.","Very good coverage of the design. Your screenshots are very effective in showing the changes, and they are motivated well. You did a good job of showing changes made to the db. But the doc was not updated to say which code was changed. That is one of the most important needs for teams that follow after you.","This is an excellent, detailed, and well-thought out assignment. It is evident from your submission that you have done due diligence to the given task. Your aim to enhance search capabilities in the Expertiza application is very impressive. The systematic way you propose changing the current system to a more sophisticated and user-friendly one is noteworthy. Your proposed workflows for different aspects are detailed and well explained.

Your focus on not just building functionality, but also integrating it into the user interface is documentation of careful and thorough planning. The thought put behind maintaining an aesthetically pleasing UI while incorporating advanced functionality is appreciated. I like how you drew on the system workflow to propose changes that do not complicate usage for the users of the application. You clearly specify the changes in the system layer.

Your decision to add search methods in each model while minimizing changes in the model is very wise as it reduces the possibilities of errors or bugs in the system. Your explanation on the different types of searches that can be implemented, as well as your decision to make the design RESTFul are both strong design choices.

Also, your detailed projection on the changes to be made on the user interface is very helpful. I appreciate your idea of erasing the data from text boxes in the search, preventing unwanted persistence of search parameters. This not only shows your strong understanding of user experience, but also your focus on producing a clean interface.

However, there are a few sections in your assignment where screenshots or diagrams are mentioned, but not included. Make sure to always include these resources in your submissions as they help to better understand your plans and projections.

Finally, good job on implementing the testing stage - both User Interface Manual Testing and Automated Rspec Testing. These measures ensure that your codebase is robust and efficient, giving you and your team confidence in the system's integrity.

In conclusion, a beautifully detailed and astutely planned assignment. I encourage your ingenuity and thoughtful design process. Well done! Looking forward to see how these changes will influence the user experience of the Expertiza application."
208,E1965,"Expertiza<ref> <link> </ref> is an open-source web application to create re-usable learning objects through peer-reviews to facilitate incremental learning. Students can submit learning objects such as articles, wiki pages, repository links and with the help of peer reviews, improve them. The project has been developed using the Ruby on Rails<ref> <link> </ref> framework and is supported by the <link> . Expertiza assignments are based on a peer review system where the instructor creates rubrics for an assignment through questionnaires which students use to review other students' submissions. The author of the submission is given an opportunity to provide feedback about these reviews. Expertiza displays reviews (i) to the team who was reviewed, and (ii) to the reviewer. A student user can see all the reviews of his/her team’s project. The instructor can see all the reviews of everyone’s project. The instructor also has access to a Review report, which shows, for each reviewer, all the reviews that (s)he wrote. The score report and review report use different code so UI is non-orthogonal, it would be great if we can follow same UI structure for score and review report which also reduce the DRY problems. 1. Currently Review report uses its own code to display reviews. This a pretty basic view, and it does not interpret HTML codes. It should be changed so that it calls the usual code that is used for displaying reviews, that gives the circle with the score inside. Currently, if you pull up a review report, and then click on one of the teams reviewed, e.g., the first one, you get a report that looks like this: <image> We need to change the views to existing templates in view_my_scores pages. For student view the UI is consistent in displaying reviews they have done and reviews they have received but for instructor's view the review report follows different UI and have different code. To make the UI consistent we have decided to choose the UI design of student view as the base and modify the UI design for review report in instructor's view. This will allow us to use the same code in both views, thereby following DRY principle. Updated View: <image> Our changes can shown more apparently in the following video.<ref> <link> </ref>. 1. app/view/pop_up/team_users_popup.html.haml 2. app/view/pop_up/team_users_popup.html.erb 3. app/assets/stylesheets/grades.scss. The specific changes can be seemed in the comments of code. Review report view is rendered in app/views/popup/team_users_popup.html.haml. First, we changed it to regular erb file. And fix some bugs between auto-change. <code> We replace the above code by code below. Just simply convert haml to erb. <code> Then we change the row and col layout and css style of this view. The previous tables can be listed as below. <code> After we change the lay out, it can be listed as below. <code> We also fixed some small bug about the checkbox questions and index of the questions. We fixed the if-else logic question, in order that checkbox questions can be showed properly. <code> We also changed the outlook of score and make it to be a circle. <code> And the css is in grades.scss <code> We added the ""index"" in this view, in order to show the proper sequence of review's question. <code> At last, we add the css style ""warning"" and ""info"" for the table and review score. So that it looks more beautiful. <code>. Our test plan are mostly manual. There are two reasons why we choose UI testing: 1. As we only change the layout of several views. We can only test them from UI testing. 2. The existing templates view_my_score are also tested with UI, without any Rspec testing. There are two test cases for UI testing. 1. To Test UI for student View 1.1. Log-in as Student. 1.2. Go to Assignment 1.3. Click Your scores 1.4. Click show reviews 1. To Test UI for instructor View 1.1. Log-in as Instructor. 1.2. Go to Manage Assignments 1.3. Click on review report of a particular assignment Expected result: <image>. <references/>. 1. <link> 2. <link> 3. <link>.",The code changes are hard to follow when you paste in successive versions of the code.  Github diff view would have more clearly shown the changes.  It would be very useful if your narrative described how the code worked.,"The assignment is well-detailed and it's clear that you put a significant amount of effort into it. The explanation of the Expertiza platform was clearly detailed, which sets a strong context for your assignment. You were also able to demonstrate a good understanding of the problem with the current system and what needs to be done to improve the overall functionality. The explained modifications and expected improvements are appropriate and fully relevant.

You included code snippets which adds a lot to the comprehensibility of the assignment, visual elements like images and videos you plan to add would undoubtedly serve as beneficial supplements, ensuring that your findings are easily understood. Kindly do well to include the actual images or videos next time. Moreover, remember to correctly format your hyperlinks for full accessibility of all resources mentioned in your paper.

The step-by-step test plans could be a little more specific, however, they gave a detailed overview of the procedure and expectations. It's commendable that you included valid justification for your approach to testing the system.

In the future, include citations to any resources used for the assignment, this is essential for ethical reporting and allowing others to further read on the subject should they wish to. You should also insert the references into the <references/> tag to have it correctly formatted. 

Overall, a fine effort. This report is a good example of how detailed and informative technical writing should be. You should be commended for your meticulousness in addressing the task. Keep it up!"
209,E17A2.2,"<link> <link> <link> <link>. The goal of this project is to create a simple badging system for Expertiza, allowing students to earn badges when they meet certain predefined criteria while using the platform. The full E17A2 project topic description can be found <link> Per the full project topic description, the badges will be designed using <link> . Previous work on this project topic revealed that any text included on the badges is too small to read, so all text should be removed from the badges and instead appear when the badges are hovered over. This project is concerned with two preliminary badges — ""Good Reviewer"" and ""Good Teammate"" — but the design will be such that the badging system can be easily extended to include more badges in the future. The ""Good Reviewer"" badge will be awarded to students who receive very high review grades. The ""Good Teammate"" badge will be awarded to team members who receive very high teammate review scores. By default, the ""threshold"" for earning these badges will be set to a score of 95, but this value will be configurable on a per-assignment basis by the instructor. A new ""Badges"" tab will be added for instructors on the ""Edit Assignment"" page where instructors can add badges and configure the badge criteria for a given assignment. Badges a student has earned can be seen when they view their ""Task List"" page, and an instructor will be able to view all badges earned by students when they view the ""Participants List"" page. Please refer to the sections below for further detail. 1. Create badges using Credly (do not include text) 1.1. Create the ""Good Reviewer"" Badge 1.2. Create the ""Good Teammate"" Badge 1.3. Store these badge images in the app/assets/images/badges directory 2. Create tables for the badging system 2.1. Create a table named badges with the following attributes 2.1.1. id — primary key 2.1.2. name — varchar 2.1.3. description — varchar 2.2. Create a mapping table named assignment_badges with the following attributes 2.2.1 id — primary key 2.2.2 badge_id — foreign key 2.2.3 assignment_id — foreign key 2.2.4 threshold — int 2.3. Create a mapping table named awarded_badges with the following attributes 2.3.1. id — primary key 2.3.2. badge_id — foreign key 2.3.3. participant_id — foreign key 3. Change the UI so that instructors can add, configure, and view badges, and so that students can view their badges 3.1. Add a new ""Badges"" tab to the assignments/edit page for instructors to add and configure badges 3.2. Add badge icons to the participants/list page for instructors to view badges 3.3. Add badge icons to the student_task/list page for students to view badges 4. Write feature tests to verify the modifications 4.1. Include tests in the a new badge_system_spec.rb file in the spec/features directory. The following Credly badge will be awarded to students who meet the ""Good Reviewer"" criterion for a given assignment: <image> Good Reviewer Badge The following Credly badge will be awarded to team members who meet the ""Good Teammate"" criterion for a given assignment: <image> Good Teammate Badge. The following is an example of mock data in the badges table: <table> The following is an example of mock data in the assignment_badges mapping table: <table> The first row represents that the badge with badge_id 1 (""Good Reviewer"") has been activated for assignment with assignment_id 1 with the default threshold of 95 . The second row represents that the badge with badge_id 2 (""Good Teammate"") has been activated for assignment with assignment_id 1 with the default threshold of 95 . The third row represents that the badge with badge_id 1 (""Good Reviewer"") has been activated for assignment with assignment_id 2 with a customized threshold of 90 . The fourth row represents that the badge with badge_id 2 (""Good Teammate"") has been activated for assignment with assignment_id 2 with a customized threshold of 85 . The fifth row represents that the badge with badge_id 1 (""Good Reviewer"") has been activated for assignment with assignment_id 3 with a customized threshold of 80 . The following is an example of mock data in the awarded_badges mapping table: <table> The first row represents that the assignment participant with participant_id 1 has earned the badge with badge_id 1 (""Good Reviewer"") for the given assignment. The second row represents that the assignment participant with participant_id 1 has earned the badge with badge_id 2 (""Good Teammate"") for the given assignment. The third row represents that the assignment participant with participant_id 2 has earned the badge with badge_id 1 (""Good Reviewer"") for the given assignment. The fourth row represents that the assignment participant with participant_id 3 has earned the badge with badge_id 2 (""Good Teammate"") for the given assignment. The following screenshots show a comparison of the existing ""Assignments Edit"" page, alongside a mockup incorporating the new badging system where instructors can add and configure badges for a given assignment. <image> The original ""Assignments Edit"" page. <image> The modified ""Assignments Edit"" page. The following screenshots show a comparison of the existing ""Participants List"" page, alongside a mockup incorporating the new badging system where instructors can view all awarded badges for a given assignment. <image> The original ""Participants List"" page. <image> The modified ""Participants List"" page. The following screenshots show a comparison of the existing ""Student Task List"" page, alongside a mockup incorporating the new badging system where students can view all of the badges they have earned. <image> The original ""Student Task List"" page. <image> The modified ""Student Task List"" page. A new badge_system_spec.rb file will be created in the spec/features folder, and will include feature tests that verify the modifications made for the project. The following will be our test plan for this project: <code> <code> <code> <code>. Please click the image below to watch the video demonstration for this project, which demonstrates that: 1.1. Newly-created assignments are automatically added to the assignment_badges table (one entry for each badge) with default threshold values of 95 1.2. Updating a student's reviewer score appropriately awards or revokes the Good Reviewer badge 1.3. Updating the Good Reviewer badge threshold appropriately awards or revokes the Good Reviewer badge 1.4. Updating a student's teammate review score appropriately awards or revokes the Good Teammate badge 1.5. Updating the Good Teammate badge threshold appropriately awards or revokes the Good Teammate badge <image>. • app/assets/images/badges A new directory created to house the new badge image files. • app/assets/images/badges/Badge-Good-Reviewer.png The image used for the new ""Good Reviewer"" badge. • app/assets/images/badges/Badge-Good-Teammate.png The image used for the new ""Good Teammate"" badge. • app/views/assignments/edit/_badges.html.erb • spec/features/badge_system_spec.rb The file holding the new tests written for the badging system. • db/migrate/20171115222415_create_badges.rb The migration for the new badges table. • db/migrate/20171115224048_create_assignment_badges.rb The migration for the new assignment_badges table. • db/migrate/20171115230007_create_awarded_badges.rb The migration for the new awarded_badges table. • app/models/badge.rb The model associated with the new badges table. • app/models/assignment_badge.rb The model associated with the new assignment_badges table. • app/models/awarded_badge.rb The model associated with the new awarded_badges table. • test/fixtures/assignment_badges.yml • test/fixtures/awarded_badges.yml • test/fixtures/badges.yml • test/models/assignment_badge_test.rb • test/models/awarded_badge_test.rb • test/models/badge_test.rb. • app/controllers/assignment_badges_controller.rb • app/controllers/assignments_controller.rb • app/controllers/response_controller.rb • app/controllers/review_mapping_controller.rb • app/models/assignment_form.rb • app/models/review_response_map.rb The file in which the code for the ""Good Reviewer"" badge will be inserted. NOTE: More detail will be provided as the project progresses. • app/models/teammate_review_response_map.rb The file in which the code for the ""Good Teammate"" badge will be inserted. NOTE: More detail will be provided as the project progresses. • app/views/assignments/edit.html.erb The UI changes allowing instructors to add and calibrate badges for a given assignment. • app/views/assignments/edit/_badges.html.erb • app/views/participants/list.html.erb The UI changes allowing instructors to view badges for the participants of a given assignment. • app/views/participants/_participant.html.erb • spec/factories/factories.rb • app/views/shared_scripts/_user_list.html.erb • app/views/student_task/list.html.erb The UI changes allowing students to view their badges for all of their assignments. • db/schema.rb Incorporating schema changes for the three new badges , assignment_badges , and awarded_badges tables. Videos summarizing the previous team's work on this project topic can be found <link> .","There's little prose in this document.  It is mostly a collection of lists, which might make it easy to look up information, but not to learn about the project by reading end to end.  The test plan merely consists of the test code.  The purpose of the document is to describe the functionality, not to present the code by itself.","Dear Student,

Firstly, I would like to applaud you for your rigorous work and the meticulous details you've provided in your project. It appears that you have a solid understanding of the task and your systematic and highly elaborative manner of presenting the plans shows diligent thinking. Each step seems appropriately prudently planned, demonstrating a clear pathway to manage the project.

Here are a few feedback points:

1. Excellent Project Description: The broad outline of the project, with each individual description leading to your final product, shows careful planning and dedicated study. The clear distinction of each task and sub-task outlines a good project progression.

2. Good Use of Resources: Employing Credly for badge creation is an intelligent approach. If not already done, ensure that you fully understand their permission policies and usability rules to avoid any future discrepancies.

3. User Interface Changes: It was apt to identify where and how the UI needed to change to accommodate badges. Make sure to keep the UI simple but intuitive for the users.

4. Detailed Table Descriptions: Well done on the detailed explanation about the database design. This shows a good understanding of data management, and moreover, you have well-narrated how every information will be stored and utilized.

5. Badge Monitoring: Kudos for your thoughtful consideration about instructors and students being able to see the badges and their respective scores.

Things that could be improved:

1. Aesthetics of Badges: I appreciate your initiative to create different badges, but the visual appeal of badges also plays an important role. Enhanced design of badges could incentivize students to earn them.

2. Feature Testing: You've outlined your plans to write feature tests for the modifications. It is also important to incorporate stress and usability tests to validate the overall functionality of your system in different scenarios.

3. Code Review: The code part was missed out. Always a good practice to include some snippets or briefly explain the core logic that will be involved in each task. 

4. Explain Potential Challenges: While it's clear what you plan to do, addressing potential roadblocks and how you might overcome them, could show your project's robustness.

5. User Roles: In the implementation part, you may want to discuss how you plan to handle different user roles (e.g., instructors, students).

I'm looking forward to seeing the progress of this project. Keep up the great work!
"
210,E1740,"The purpose of this project is to implement several different “badges” that will be achievable for students by reaching a set of criteria. These badges will be “1st Submission”, “Dream Team”, and “Good Reviewer”. The images for the badges have previously been created, but must be re-worked to remove text that was too small to read. The logic for earning these badges must be implemented in Expertiza as well as how they display for both students and instructors. Expertiza project is a software to create reusable learning objects through peer review. It is an open source project based on Ruby on Rails framework. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. It allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. The main goal of Expertiza as a whole is to have a platform for instructors to create or assign topics and students to submit their work related to the assigned topics. Credly provides an universal way for people to earn and showcase their achievements and badges. We use Credly to design the badges. We are tasked with designing three badges - namely, Top Scores, Dream Team, and Good Reviewer. We store these badges as images for use in our project and can always add, remove or modify the existing badges in the future. The end goal of this project is to have the earned badges appear on the student’s task view as well as the instructor’s participants view. When the user hovers their cursor over an image a brief description of the badge will appear. The student’s task view appears as shown in the below screenshot, as per the current implementation. Students can see the list of tasks/assignments and the topics, grades and deadlines for each of those assignments. <image> The participants view in the current implementation (i.e, prior to the proposed changes). The instructors can see the list of students, their details, and the details related to that particular task. <image>. The student’s task view after our changes should appear as shown in the below screenshot, as per the current implementation. Students can see the badges earned along with the list of tasks/assignments and the topics, grades and deadlines for each of those assignments. Hovering over the badges would give you a brief description of the badge earned. <image> The participants view after the proposed implementation would be changed as shown below. The instructors can see the badges earned by the student next to the student's name along with the existing details. <image>. Use Case Diagram : <image>. Use Case 1: First Submission Badge for Student The student here will be able to view the first submission badge in their view (student_task/list) page, if the badge computer component in the system can determine the submission made by the team of the student is the first submission of the assignment. Use Case 2: Dream Team Badge for Student The student here will be able to view the dream team badge in their view (student_task/list) page, if the badge computer component in the system computes the aggregate scores of all the teammate reviews to be greater than 95. Use Case 3: Good Reviewer Badge for Student The student here will be able to view the good reviewer badge in their view (student_task/list) page, if the badge computer component in the system determines the review grade for the student to be greater than 95. Here, the system needs to wait for the grade score from the teaching staff to display this badge. Use Case 4: First Submission Badge for Participants The instructor here will be able to view the first submission badge for participants in their view (participants/list) page, if the badge computer component in the system can determine the submissions made by teams of each participants (in the list) are the first submissions of different assignments. Use Case 5: Dream Team Badge for Participants The instructor here will be able to view the dream team badge for participants in their view (student_task/list) page, if the badge computer component in the system computes the aggregate scores of all the teammate reviews for each participant to be greater than 95. Use Case 6: Good Reviewer Badge for Participants The instructor here will be able to view the good reviewer badge for participants in their view (student_task/list) page, if the badge computer component in the system determines the review grade for the each participant to be greater than 95. Here, the system needs to wait for the grade score from the teaching staff for each participant to display this badge. To achieve the goal of this project we will work on four aspects. TASK 1 - creating the badge images and implementing them as a model in Expertiza 1. This will involve using Credly to create the badges and, 2. Making changes to student_task/list and participants/list to show them TASK 2 - Implement the 1 st Submission badge 1. To do this we will need to check the submission times of each assignment through the db teams table 2. The team with the earliest submission time will have each member earn the 1 st Submission badge 3. The logic for this badge will be written in the team.rb file. TASK 3 - Implement the Dream Team badge 1. This badge will be given to a team when all of their members receive an aggregate teammate review score of 95 or above 2. To check for this, we will average the teammate review scores for each individual member and then check to see if each member had an average of 95 or above 3. If the team accomplishes this, each member will be awarded the Dream Team badge 4. If any member of the team does not have an average of 95 or above then none of the team members will be awarded the badge 5. The logic for this badge will be written in the teammate_review_response_map.rb file TASK 4 - Implement the Good Reviewer badge 1. This badge will be given to a student if they receive a review grade average of 95 or above from the teaching staff 2. In order to calculate this score we will have to get each individual grade the student received on their reviews and average it out 3. If that average is at 95 or above they will receive the badge, if not they will not be given this award 4. The logic for this badge will be written in review_response_map.rb On completing the tasks the badge system will be functional. As verified with the mentor, the scope for testing in this project will be limited to majorly UI testing. The following steps need to followed to test implementation manually. 1. Log in as an instructor and identify the top scorer for a particular assignment and later later impersonate the students of that team and make sure that all the team members have received the 'top score' badge. 2. Log in as an instructor and identify the team which received an average score greater than or equal to 95% and later later impersonate the students of that team and make sure that all the team members have received the 'dream team' badge. 3. Log in as an instructor and give review scores for two students (one more that 95% and one less than 95% for the other) and later later impersonate the students to make sure that the student who received more than 95% review grade received the 'good reviewer' badge and the other student does not. 4. Log in as an instructor and check if the students tested above has the badges reflected in the participant_list/list view page. The page shows all the assignment specific badges (Top score, Dream team and Good reviewer badge). NOTE: The details about the badge should appear when we hover the mouse pointer above the badge. The following are a list of files that has been identified, which would be modified for the proposed implementation. 1. app/models/team.rb 2. app/models/teammate_review_response_map.rb 3. app/models/review_response_map.rb. 1. app/views/participants/list.html.erb 2. app/views/student_task/list.html.reb. 1. app/controllers/participants_controller.rb 2. app/controllers/student_task_controller.rb. Link to Github repository : <link>. 1. <link> 2. <link> 3. <link>.","Generally good flow, explains most of the items well.  Except for three mentions of files to be modified, there is no indication of how the code will be changed to allow for badges.  This should be described in more detail.","Dear Student,

Thank you for your hard work on this project. You have demonstrated a comprehensive understanding of the project specification, provided a clear and detailed explanation of your implementation and have thoroughly outlined your approach to implementing the “badges” in Expertiza. Your outlined steps for testing and your inclusion of the specific files you will modify for the proposed implementation demonstrate a deep understanding of the system.

Given your thoroughness, I only have a few minor suggestions and points of clarification:

1. You've explained how to create the badges using Credly and also mentioned the need to rework some badge images due to small, illegible text. However, you didn't actually clarify how you plan on improving these images. Please provide some details on your approach to making the text more legible.

2. You've specified that for the Dream Team badge, every team member should have an average score above 95 to receive it. However, there's a potential interpretation where if one team member scores exactly 95, the team would be excluded from earning the badge. It would be helpful to clarify whether a score of 95 is considered above 95 in your implementation.

3. While you've done an excellent job outlining the system's primary functionality and providing detailed use cases, it may be beneficial to also include more discussion about fail-safes and potential error handling. What will happen if there's a problem with the badge computer component in the system? How would the system respond to an exception?

4. The manual testing steps are clearly defined. However, it would be beneficial to incorporate some automation testing approaches as well.

5. Lastly, please make sure to include all relevant links to your Github repository so we can view your full codes and conduct a more detailed review of your implementation.

Overall, your submission is exceptionally well-thought-out with a attention to detail. I'm extremely impressed with your work and am looking forward to seeing your implemented badge system. Keep up the great work!

Best Regards,

[Your Name]"
211,E1637,"<link> is an educational web application built on <link> framework. It provides functionality for the instructor to create assignments for a specific course. The students can sign up for a list of topics created by the instructor. Expertiza allows students to form teams and work together. Students can provide feedback to assignments and projects submitted by other students. The students can also provide reviews about each individual member in their team as well. The numerous functionalities provided by expertiza makes the process of assignment submission, feedback and management much simpler and for the students and the instructors. This project deals with LatePoliciesController and PenaltyHelper files. It focuses on calculating a penalty which would be deducted from the total score obtained by the student if the student submits the assignment or review past the specified deadline. The goal of our project is to make the task of calculating and deducting penalties function perfectly and also refactor the code to make it more intuitive and modular. The files modified for the penalty functionality to work are as follows,. This controller contains the functions to create, update and delete a late policy. The instructor can create a late policy for any assignment, where in the instructor can specify the points per unit and the maximum penalty that can be applied for a particular assignment. The create and the update functions in this module were very long and it had to be refactored so that the code was modular. In grades controller, the total penalty was not getting deducted from the total score due to the mismatch of conditions. The conditions were modified in this controller for the penalty to be deducted from the total score obtained. This helper file has functions to calculate submission, review and metareview penalties. This function was not returning the values of the calculated penalty as required and modifications were made so that the correct penalty values are returned. In the current implementation, the penalty deducted is not displayed when a student views scores. The views were modified so that the deducted penalties and total score are displayed appropriately. The list of views modified are as follows, 1. _participant.html.erb 2. _participant_charts.html.erb 3. _participant_title.html.erb. Rspec tests were written to test the functionality of the LatePolicy model. The tests ensure that the attributes in the model obtain the correct value. In addition, the tests also ensure that none of the fields are empty and ensures the maximum penalty and penalty per unit is a positive number which lies in a specified range. 1. T1: Refactor the create function in LatePoliciesController to make the code more modular 2. T2: Refactor the update function in LatePoliciesController to make the code more modular 3. T3: Modify the PenaltyHelper to calculate and return the correct penalty value 4. T4: Modify the GradesController to deduct the total penalty from the total score 5. T5: Modify the ViewScores page to display the penalties deducted 6. T6: Test the working of the LatePolicy model by writing necessary RSpec tests. The create function performed various checks on the parameters passed from the form instead of calling appropriate functions to do them. The same checks were performed by the update function. This violated the DRY principle. To overcome this discrepancy, two functions were created namely, validate_penalty_unit and validate_duplicate_policy which perform the required checks. This function checks that the penalty per unit is less than the maximum penalty. If this function returns fall, the LatePolicy will not be created. <code>. This function checks that another policy with the same name created by a different instructor does not exist. Duplicate policy names are permissable if created by the same instructor. <code>. The update function performs the same checks as the create function. The check statements are replaced by the appropriate calls to validate_penalty_unit and validate_duplicate_policy. In addition, when the late policy is updated, the corresponding penalty calculations have to be updated for students enrolled in assignments using the corresponding late policy. So a new function called values_update is introduced which performs the necessary task. <code>. The helper function penalty_helper.rb aides in calculating associated penalties with a late submission. In the original implementation, penalties were not calculated and returned. Minor modifications were made in the penalty_helper.rb file to return the value of calculated penalty. The controller grades_controller.rb performs all the necessary functions involved with calculating scores. In the original implementation, the calculated penalties were not subtracted from the total score when a late submission was made. This controller is now modified such that based on the time of submission (if late) penalty points would be deducted from the total obtained score. When a student clicks on view scores link for an assignment he/she can view the scores obtained for that assignment. In the original implementation, the students could not view the penalty deductions obtained for the assignment. To enable this, additional code was added to /app/views/grades/_participant.html.erb, /app/views/grades/_participant_charts.html.erb and /app/views/grades/_participant_title.html.erb. Now when the student clicks on the view scores link, he/she can see all the penalty deductions in addition to the total score obtained. While creating a late policy many constraints have to be kept in mind like the policy name should not be blank or empty, every late policy should have an instructor associated with it, the maximum penalty and penalty per unit should be a positive number and the penalty unit should always be set (seconds/minutes/hours). We have ensured that these constraints function effectively by writing the necessary rspec tests. The rspec test can be located in /spec/models/late_policy_spec.rb. <code>. As mentioned earlier, rspec tests are written to test the proper functioning of the LatePolicy model. The rspec tests can be found in /spec/models/late_policy_spec.rb file. The create and the update code was refactored and modularized in the LatePoliciesController. The following steps can be followed from the Web UI to ensure that the refactoring did not affect the functionality of LatePoliciesController. 1. Login as instructor 2. Create an assignment in course 3. In the due dates tab in create assignment check the ""Apply Late Policy"" box 4. Select ""New Late Policy"" link 5. Fill in the form with necessary details and submit 6. The newly created late policy will be displayed in the list of all late policies 7. Select the ""Edit"" option for the created late policy 8. Change the required fields and save the changes 9. The updated late policy is displayed in the list of late policies 10. Edit the assignment/create a new assignment 11. In the due dates tab, the newly created late policy will be displayed in the dropdown. Changes were made in the Penalty Helper file and Grades Controller to calculate the correct penalty value and deduct it from the total scores obtained. Changes were made in so that the View Scores option would display the penalties in addition to the total score. The following steps can be followed to ensure that the penalties get deducted appropriately from the total score and are visible to the student. 1. Login as instructor 2. Create an assignment in course along with a late policy 3. Create a team of 2-3 students for the created assignment 4. Login as a student 5. Make a submission for the assignment past the mentioned deadline 6. Go to view scores and the deducted penalty will be displayed. The demo for testing this functionality can be viewed at <link> . Please do turn on closed captions while viewing the video to obtain a better understanding. While the late penalty has been implemented, there are few aspects of this project that can be improved. 1. Currently the review penalty is not being calculated because submission of review is not allowed after the mentioned deadline. If the review for an assignment is submitted after the mentioned deadline no points get deducted even after enabling late review. This will require code changes in assignment and other controllers.","The writeup is generally pretty good.  There is no point in including the whole late_policy_spec.rb, but other than that, the changes are explained and shown with code snippets of reasonable length.  There is a good explanation of  how to test.","The feedback to the student's assignment would look something like this:

Thank you for your submission. Your report on Expertiza and it’s LatePoliciesController and PenaltyHelper features was comprehensive and detailed. The narrative displayed a clear understanding of the work you set out to accomplish and you described this in a coherent, step-by-step manner. 

Your writing style is good as you have presented the details of the project in an understandable way. The demonstration of the issues associated with the existing functions, and how you addressed those issues through your code, was portrayed well.

Here are a couple of areas you could consider for improvement:

  1. While you’ve mentioned that you have introduced specific functions to simplify long functions and to adhere to DRY principle, it would be beneficial if code snippets were supplied to show the implementations of validate_penalty_unit, validate_duplicate_policy, and values_update functions. 

  2. It is commendable that you’ve already identified areas of improvement for your work. It would be further beneficial to present clear and concise next steps, that is, what specifically needs to be done to implement these improvements. 

  3. Let's ensure that the submission follows the general guideline of code comments. Code is much easier to understand when it's accompanied by comments providing context and rationale for the given implementation decisions.

Overall, excellent work. The time and thought you’ve put into this project is evident. Keep it up!"
212,E1662,"Expertiza is an open source web application developed by students and faculty members of North Carolina State University. This portal is being used by both faculty members and students in order to carry out assignments. Typically following is the workflow of the system: 1. Faculty member adds students to a particular course. He also adds an assignment for the class. 2. Assignment has a specific deadline, review period and final submission. 3. Faculty members upload list of topics for the assignment. 4. Students have to bid for the topic or they can suggest their own topic. 5. At the end of the bidding process, students get a specific topic for the assignment. 6. Students can form the teams by sending out invitations to other students. 7. Students start working on the assignment and submit the assignment work before the initial submission date. 8. Every student then gets to review work submitted by at least one team. Student submit their feedback in the review. 9. Students then make the necessary changes as suggested by reviewer and submit the assignment before the final submission date. 10. Students are graded on the basis of their work and reviews. The main objective this project is to fix the issues in the current system. The current system has following issues: 1. Historically courses were created without providing Institution ID. Since data warehouse is now storing Institution ID for a particular course, this application should do support this function. 2. If an assignment is completed, no one can sign up for topics or drop topics. Yet a completely blank ""Actions"" column on the signup sheet still appears. It would be better if the column did not appear. 3. Currently when admin/instructor tries to delete an assignment, there is no alert/confirmation shown. This is risky. We need to add a confirmation step to avoid losing data. Capturing Institution ID Institution and Course has One-to-Many relationship where in one institution may have many courses associated with it. In current system while creating new course user does not have to choose which institution the course belongs to. Hence we need to fix this issue. Following basic changes are required in order to fix this issue. 1. Ensure that relationship exists between Course and Institution model classes. <code> 1. In app/views/course/_course.html.erb , add a drop-down list so that user can select institution from the available options. <code> 1. Ensure that the id for the selected institution is sent as a parameter along with other parameters back to controller. 2. Once we receive all the data in controller Institution ID should be saved in course table. Thus in app/controllers/course_controller.rb , add arguments to the Create method. <code>. 1. User should login to expertiza using Instructor's credentials. 2. Go to Manage Courses and click on New Course button so as to open form for it. 3. Fill up the form. you can see new field added as Institution Name. This is a drop down list which has list of Institutions. 4. User has to select one of these institutions. If user tries to go ahead without selecting this then he will get an alert flash saying this is a required field. 5. Once an institution is selected user can click on Create button to submit the form (with other fields completed). 6. Institution ID would be saved in database record against this particular entry of course in Course table. User can verify this by accessing Course table in the database. When student open sign up sheet for the Finished projects, he should not be able to take any actions for that assignment and hence Actions column should be hidden to him. For fixing this bug, we had to make following changes into app/views/sign_up_sheet/_table_header.html.erb . <code>. 1. Login to expertiza using student credentials 2. Go to assignment tab and look for the assignments which have current stage as ""Finished"" 3. Go to that assignment and open sign-up sheet. 4. You should not be able to see column Activities, which means the work is successful. When instructor clicks on delete button to delete assignment, It gets deleted without confirming it. System should ask for confirmation whether to go ahead with deletion or not. To post a confirmation to users, we used the flash method to put the message on the screen. When user is going to delete an assignment, he will firstly use the delete action in assignment model with parameter force=nil . Thus in app/models/assignment.rb , we added an condition in the beginning of the method to check whether it is the first attempt to delete the assignment. If it is, an exception will be raised. <code> The exception will be caught in the assignment controller. Then corresponding messages are passed by flash method to be shown on the page. <code>. 1. Login to Expertiza as an Instructor. 2. Go to manage assignment page. 3. Try deleting an assignment by clicking on an image from the activities column. 4. When delete button is clicked, system should ask for confirmation message whether you really want to delete or not. 5. If you select yes then that assignment should be deleted. Otherwise if selected no then that assignment should not be deleted. 1. <link> - Github link for original repository 2. <link> - Github Repository code for the updated code.","The documentation does not mention that they skipped Issue #256. However, it is nicely structured thus it's easy to find information. however the solution presented are mostly just copy paste of the code. It should be described in a narrative, rather than a list of bullet points.","Hello,

You have done a commendable job in analyzing the issues with the Expertiza web application and proposing specific changes and modifications to improve its functionality. Your understanding of the workflow, knowledge of the system’s models, and your ability to trace and amend the application’s logic are evident throughout your work. 

However, there are a few areas where you could improve upon.

1. While you have described the problems and detailed your intended solutions, you've not provided a comprehensive discussion of your testing methodology. Including specific details about how you tested your changes — including the data you used, the scenarios you tested, and whether you performed any negative testing — would strengthen your report.

2. It would also be helpful to include screenshots or other visual aids to illustrate the changes you made. This would make it much easier for others to understand what you did and why.

3. Make sure you double-check the format of your text before submission, there are some stray `<code>` tags left in the text which indicate that code is missing or incorrectly formatted.

4. It is beneficial to include some discussions on possible limitations or potential issues of your modifications, or how the system can further be improved in the future.

Keep up the good work and keep striving to improve even further.

Best Regards,"
213,E1814.1,"Our task for this project is to test the collusion_cycle.rb model with the collusion_cycle_spec.rb test to achieve at least ninety percent coverage. Expertiza is an open source project that can be used by instructors to create assignments and assign them to students. Students can manage teams for the assignment and submit work for each of the assignments. After the students have submitted their work they can review other student's work to facilitate grading. The project is based on the <link> framework. You can find our <link> as well as our <link> to view our work. The collusion cycle model is used to handle situations where a cycle is created when students are reviewing each other's work. The cycles in the review relationships are common since each assignment to review is randomly selected. The collusion cycle model calculates the assignment scores from the reviewers as well as other statistics such as similarity and difference between each score. The model is built to handle two, three, and four node cycles where each node represents a student. Achieving good coverage with quality tests is part of a good development process. The collusion_cycle.rb class is used to calculate the grade received based on the reviews from other students as well as handle cases where the reviewer is also reviewed by the reviewee effectively creating a cycle. We want to test this class to achieve good coverage in order to catch possible bugs in the program and ensure that it works correctly. 1. Test Two-Node Cycle 1.1. When the reviewers of the current reviewer (ap) do not include the current assignment participant it should skip this reviewer (ap) and return the corresponding collusion cycle 1.2. When the reviewers of the current reviewer (ap) include the current assignment participant and the assignment participant is not reviewed by the current reviewer it should skip the reviewer (ap) and return the corresponding collusion cycle. 1.3. When the reviewers of the current reviewer (ap) include the current assignment participant and when the current assignment participant was reviewed by the current reviewer (ap) it should insert the related information and return the corresponding collusion cycle. 1.4. When the reviewers of the current reviewer (ap) include the current assignment participant and the assignment participant did not submit a review of the current reviewer (ap) it should skip the current reviewer (ap) and return the corresponding collusion cycle. 1.5. When the reviewers of the current reviewer (ap) include the current assignment participant and the assignment participant did submit a review of the current reviewer (ap) it should skip the current reviewer (ap) and return the corresponding collusion cycle. 2. Test Three-Node Cycle 1.1. When the reviewers of the current reviewer (ap2) do not include the current assignment participant it should skip the current reviewer (ap2) and return the corresponding collusion cycle. 1.2. When the reviewers of the current reviewer (ap2) include the current assignment participant and the current assignment participant did not receive a review from the current reviewee (ap1) it should skip the current reviewer (ap2) and return the corresponding collusion cycle. 1.3. When the reviewers of the current reviewer (ap2) include the current assignment participant and the current assignment participant received a review from the current reviewee (ap1) it should insert the related information and return the corresponding collusion cycle. 1.4. When the reviewers of the current reviewer (ap2) include the current assignment participant and the current reviewee (ap1) received a review from the current reviewer (ap2) it should insert the related information and return the corresponding collusion cycle. 1.5. When the reviewers of the current reviewer (ap2) include the current assignment participant and the current reviewer (ap2) received a review from the current assignment participant it should insert the related information and return the corresponding collusion cycle. 1.6. When the reviewers of the current reviewer (ap2) include the current assignment participant and the current reviewer (ap2) did not receive a review from the current assignment participant it should skip the current reviewer (ap2) and return the corresponding collusion cycle. 1.7. When the reviewers of the current reviewer (ap2) include the current assignment participant and the current reviewee (ap1) did not receive a review from the current reviewer (ap2) it should skip the current reviewer (ap2) and return the corresponding collusion cycle. 1. Test Four-Node Cycle 1.1. When the reviewers of the current reviewer (ap3) do not include current assignment participant it should skip the current reviewer (ap3) and return the corresponding collusion cycle. 1.2. When the reviewers of the current reviewer (ap3) include the current assignment participant and the current assignment participant received a review from the reviewee of the current reviewee (ap1) it should insert the related information into the collusion cycle and return results. 1.3. When the reviewers of the current reviewer (ap3) include the current assignment participant and the reviewee of the current reviewee (ap1) received a review from the current reviewee (ap2) it should insert the related information into the collusion cycle and return results. 1.4. When the reviewers of the current reviewer (ap3) include the current assignment participant and the current reviewee (ap2) received a review from the current reviewer (ap3) it should insert the related information into the collusion cycle and return the results. 1.5. When the reviewers of the current reviewer (ap3) include the current assignment participant and the current reviewer (ap3) received a review from the current assignment participant it should insert the related information into the collusion cycle and return the results. 1.6. When the reviewers of the current reviewer (ap3) include the current assignment participant and the current assignment participant did not receive a review from the reviewee of the current reviewee (ap1) it should skip the current reviewer (ap3) and return the corresponding collusion cycle. 1.7. When the reviewers of the current reviewer (ap3) include the current assignment participant and the reviewee of the current reviewee (ap1) did not receive a review from the current reviewee (ap2) it should skip the current reviewer (ap3) and return the corresponding collusion cycle. 1.8. When the reviewers of the current reviewer (ap3) include the current assignment participant and the current reviewee (ap2) did not receive a review from the current reviewer (ap3) it should skip the current reviewer (ap3) and return the corresponding collusion cycle. 1.9. When the reviewers of the current reviewer (ap3) include the current assignment participant and the current reviewer (ap3) did not receive a review from the current assignment participant it should skip the current reviewer (ap3) and return the corresponding collusion cycle. 1. Test Cycle Similarity Score 1.1. When the collusion cycle has been calculated it should return a similarity score that is equal to the average difference between all of the scores in a two-node cycle. 1.2. When the collusion cycle has been calculated it should return a similarity score that is equal to the average difference between all of the scores in a three-node cycle. 1.3. When the collusion cycle has been calculated it should return a similarity score that is equal to the average difference between all of the scores in a four-node cycle. 2. Test Cycle Deviation Score 1.1. When the collusion cycle has been calculated it should return a deviation score based on the appropriate values in a two-node cycle. 1.2. When the collusion cycle has been calculated it should return a deviation score based on the appropriate values in a three-node cycle. 1.3. When the collusion cycle has been calculated it should return a deviation score based on the appropriate values in a four-node cycle. Each of the tests are very similar in the way they are tested. With the addition of each node in the cycle, the underlying process remains the same. This means that only the number of branches increases, which is the only reason there are more tests in the Four-Node Cycle section then there are in the Two-Node Cycle section. To test the cycles we used stubs to create the relationships between each of the assignment participants in a before-each block before each cycle tests. Then we applied the changes specified to test each branch. To break up the code more easily we separated the testing of each branch into a context block that provided additional information about the test itself as well as making the code look much neater. The Similarity and Deviation tests use calculations to determine the similarity and the deviation of each of the scores. We can verify these results by creating a mock data set of reviews and participants and calculating the scores by hand then checking to make sure the collusion cycle methods got the same answer. Since these sections only involved calculations there were not many various branches to test other than making sure that scoring methods worked with two, three, and four node cycles. 1. When a test case states that it inserts the 'related information' into the collusion cycle it means that it inserts the review score as well as the appropriate participant into a two-dimensional array. Since we were tasked to write test cases rather than programming design cannot be done in the same way one would design a system. Instead, our design revolved more around the use of RSpec syntax to allow for good self-documentation. In addition to self-documentation, we also wanted an easy way to translate the test write-ups that cover every possible branch of the code into actual test code. To do this we made frequent use of the 'context' statement in ruby. The context statement allows us to nest code in the same way that branches are nested while also allowing a direct correlation of test plan writeup to test plan code. Here is our original skeleton of the test plan <code> Here is the actual snippet of implementation code <code>. Currently, we have already found one bug, which was a missing parameter in the collusion_cycle.rb file with each of the node_cycle methods (two_node_cycle, three_node_cycle, four_node_cycle) which needed an assignment participant parameter to be passed in for the function to even work. In addition the obvious benefit of adding more coverage you a better assurance that the code works well. Of course, testing does not guarantee that the code works, but can only be used to find where the code does not work. To run the test files you need to clone the repository in an Expertiza environment <link> . Instructions for creating an appropriate Expertiza environment can be found in the README file in the Expertiza GitHub repository. Once you have the Expertiza repository setup make sure you are in the root directory of the app and run `rspec spec/models/collusion_cycle_spec.rb` For a demonstration and you can check out this <link> on YouTube. Because the scope of this addition is relatively small, and we have tested all possible branches within the code there is not much future work to do other than possibly refactor the code with a more efficient tool. Test coverage through quality tests consistently added throughout the development of the Expertiza project should be the future work of the project.","Good prose descriptions of what is going on.  Diagrams would probably be a more concise way to show the information flow, but I can't fault the way you described it in words.","Your assignment shows a clear understanding of the task and exhibits detailed planning and implementation. Good work on following the testing process and ensuring maximum coverage. Your explanations on how each node in a collusion cycle is tested are thorough and accurate, showcasing your understanding of the project's requirements. 

The layout of the different test cases for the two, three, and four-node cycles were well explained and differentiation between each case was clear. 

The details you provided about each test case related to every involved branch enhance your report, making it easier to understand your testing process. Also, your explanation on how to verify the results of the similarity and deviation tests using a mock data set was insightful.

You integrated a comprehensive methodology in your testing, making use of context blocks to improve code readability and organization. Your usage of different test cases for two, three, and four-node cycles, and description of each case shows in-depth analysis and planning.

Nevertheless, there are a few improvements you could consider. First, make sure you remove the placeholders for the links (`<link>`) and replace them with the actual URL to guide your readers directly to the resource.

Moreover, you could provide further elaboration on the discovered bug. This would help readers to understand what went wrong, how the bug was discovered, and the steps you undertook to rectify it.

Lastly, consider explaining your debugging and troubleshooting process in more detail. These aspects are just as important as writing the original code, and understanding your approach in solving issues would be insightful.

Overall, you have done a great job in testing and providing comprehensive coverage of multiple scenarios within this assignment. Good work and keep it up!"
214,E2009,"<link> is an open source web application project based on Ruby on rails framework. Expertiza allows instructors to add assignments and students to upload their submissions. The assignment.rb model file consists of some basic CRUD operations along with some methods which help calculate scores and export details etc. The goal of the project is to refactor assignment.rb file to follow good coding practices. Assignments is the most important base class in expertiza. It enables students to submit their assignments. also aiding TA's and profs to access and grade the assignments. It also gives support for peer reviews. This model is used for all the backend operations and DB querying related to Assignments. Assignments can be submitted, reviewed by other peers and scores assigned and accessed, keeping in mind the deadline constraints too. Some of the coding issues with the assignment.rb file are 1) Methods performing more than one tasks, resulting in long methods 2) Methods with multiple conditions and loops resulting in increased cyclomatic and cognitive complexity 3) Large number of methods in one file. 4) No proper naming conventions in some places. The approach we took to refactor this file, is to go through the issues generated by <link> and fix the smaller issues first. This gave us an idea about what the code is doing and gave us a head start to fix bigger issues. 69 issues were found on code climate and through this project, 30-35 issues have been resolved. Few of the issues that were resolved was detected by rubocop. Code climate gives different metrics that indicates the code quality. Some of the metrics the code climate gives are 1) Assignment Branch Condition (ABC) size - It is computed by counting the number of assignments, branches and conditions in a section of code. Specifically ABC size = sqrt(A*A + B*B + C*C), where A - number of assignments, B - number of branches, C - number of conditions. 2) Cyclomatic complexity - It is a quantitative measure of the number of linearly independent paths through a program's source code (or a method). It gives a measure of how difficult a code is to test. Higher the number of branches in a method, higher the number of independent paths and hence higher the cyclomatic complexity. An if statement (or unless or ?:) increases the complexity by one. An else branch does not, since it doesn't add a decision point. The && operator (or keyword 'and') can be converted to a nested if statement, and ||/or is shorthand for a sequence of ifs, so they also add one. Loops can be said to have an exit condition, so they add one. 3) Cognitive complexity - It is a measure of how difficult a unit of code is to intuitively understand. Generally methods with higher cyclomatic complexity will have higher cognitive complexity also. 4) Perceived complexity - It is a complexity score that's a measure of the complexity the reader experiences when looking at a method. In contrast to the Cyclomatic Complexity, this metric considers `else` nodes as adding complexity. All the metrics are quite interlinked, so aiming to reduce one complexity will also reduce other metrics. The longer methods are refactored mostly by extracting a method out which performs an independent task. Longer methods generally has higher Assignment Branch Size and higher complexity metrics. The methods refactored using Extract method are scores, review_questionnaire_id and response_map_to_metareview. The scores method is one of the biggest methods in assignment.rb file. The code climate gives the Assignment Branch Condition size as 131.2/15, number of lines of code as 48 and cyclomatic complexity of 8/6. The scores method computes and returns the scores of participants and teams as a hash. The participant scores are directly got by calling a method in Participant class. The logic to compute the scores of teams has an outer each loop with one if-else block inside and 2 each loops inside the if block. This resulted in 3 levels of nesting and many lines of code inside the each loop. Two methods are extracted out of this method. Below is the screenshot for diff after refactoring (left is refactored code) <image> Hence after refactoring the number of lines of code in the method reduced to 17 . This method as the name implies returns the review questionnaire ID. It first gets all the assignment questionnaire ids whose type is 'ReviewQuestionnaire'. This part is extracted as a separate method. Also renamed the variable rev_q_ids. Following is the diff after refactoring <image>. This method returns the best review to meta-review map if meta-review exists for a review. It has a sequence of similar operations like sorting the review_respone_map and rejecting certain entries in the review_reponse_map based on certain criteria. We found the same lines repeated in two places, so we extracted that part as one method. In one place the method includes a logic to get the reviewers in a map. Even though that task is performed in one place, it is performing a distinct task. Hence that part is also extracted out as a method. Following is the diff after refactoring <image>. 1) Refactoring export_details_fields The export_details_fields has many if statements as can be seen below. Each if statement increases the cyclomatic complexity by 1. It is refactored by adding constant EXPORT_DETAILS_FIELDS with all the fields to export. Then this list is iterated using each loop. <image> 2) Refactoring delete method The delete method has the following lines of code. Each line has a call to each method. This is also refactored by using list to hold all the instances to delete and then iterating through the list and deleting. <image>. 1) Three methods in assignment.rb file has the following check <code> Each predicate in if condition count towards one decision point and hence increase in cyclomatic complexity. Also the same condition check is done in 3 to 4 places. Hence we can write a separate method like below and call in all places the conditions self.staggered_deadline and topic_id.nil? are checked together. <code> 2) Similarly the method valid_num_review has if condition with 3 predicates as can be seen below Before Refactoring <code> Here the 2 if conditions are quite similar. Also both are checking 3 conditions. Hence the condition check part can written as a separate function as below After Refactoring <code> <code> By this way, it is both reducing cyclomatic complexity and improving code reuse. 1. Removing unused variables 2. Changing variable/function names Before Refactoring <code> After Refactoring <code> 3. Avoiding multi-line ternary operators <image> 4. Using Guard Clause instead of wrapping the code inside a conditional expression. A guard clause is simply a check that immediately exits the function, either with a return statement or an exception. <image> 5. Converted simple if-else statements with ternary operator in some places. <image>. Our test plan includes rspec tests and testing the GUI in the browser. The rspec tests for the assignment.rb file is pretty much complete with tests written for all the methods called from outside the file. Two rspec tests were failing before we started the refactoring. Those were fixed. The methods added as part of refactoring are given a private scope and are added in assignment.rb since it is not called from outside. Testing the public methods implicitly tests these private methods. Below is a screenshot our rspec test results. Here is the link to the <link> running. <image> We launched expertiza in browser and tested as thorough as possible. On testing the GUI's Assignment page completely, we found that ""View Scores"" is breaking only for ""Project 1"" due to a NoMethodError in the Grades#view. ""View Scores"" of all other projects work as expected. There was also a Routing Error for viewing the survey responses. These errors existed in the base code before we started the refactoring. Since these errors do not pertain to assignment.rb, they have not been fixed. Other than these errors everthing related to assignments works fine. The assignment.rb file has too many methods in one file. It maybe a better idea to move some of the methods which are only used with the views to assignment_helper.rb file.","The wiki page includes screenshots from the IDE.  Although they are a bit blurry, they show very well the code changes that have been made.  The prose descriptions are also quite readable. Their test plan mentions that they have done exhastive testing on the UI but does not mention the scenarios. Their automated testing section mentions that they have fixed two previously failing tests but does not mention which ones either. ","Dear student,

Great job on the detailed analysis and refactoring of the assignment.rb file! Your approach to initially focus on resolving smaller issues to gain a deeper understanding for larger issues is effective and can be used in real-world scenarios. Your clear understanding and application of coding metrics such as ABC size, cyclomatic complexity, and cognitive complexity is commendable. 

The methods you have extracted and illustrated (scores, review_questionnaire_id, response_map_to_metareview) are well chosen and the screenshots provided are helpful for understanding your changes. It was good to see your effort in reducing the cyclomatic complexity and improving code reusability. Your use of guard clauses, ternary operators and constant EXPORT_DETAILS_FIELDS is well-justified and demonstrates good coding practices.

I appreciate the effort you put into not only providing explanations of the code changes made but testing those changes thoroughly as well. The use of rspec tests and in-browser testing in your test plan is impressive. 

However, moving forward, it would be beneficial for you to analyse the methods that can be moved to a helper file for better organization and maintainability, especially given the large number of methods in assignment.rb file. This is something you have already identified in your conclusion, which is good.

Overall, very impressive work demonstrating a deep understanding of refactoring and applying solid principles in coding. Your attention to detail, carefully explained steps and well thought out strategies all contribute to a commendable project. Keep up the good work!

Best,
[Your Name]"
215,E1712,"This project is part of an educational web application called Expertiza. This wiki gives the details on the refactoring tasks undertaken as part of continuous improvement of Expertiza. <link> is an open source project managed by the faculty and students of NCSU. It is a web application which offers a platform for assignments and allows learning through peer reviews. In the existing code the InvitationController and the JoinTeamRequestsController do the expected task but the there is a lot of redundancy and duplicity in the code, and the comments in the code are few and sparse. The aim of our project was to reduce the complexity of the controller by removing redundant code adding comments so that the code is easy to understand and all the variables used in the code are clearly explained. Invitations controller handles the functions required to send invitations out to potential teammates for a project. Once a student decides to invite someone into his assignment team the controller performs some checks before sending out the invitations. These checks are performed in the create function. The current implementation has a lot of redundant code and many nested if statements. The ABC size of the method is also very high. The controller also has functions which take care of cases where an invitee accepts/declines an invitation. There is also an option to retract a sent invitation which is handled by the cancel function in the controller. 1. Rename to invitations_controller.rb, in accordance with current naming convention. 2. The ABC size for create method is too high and needs to be refactored along by removing other nested if's in create and update_join_team_request methods. 3. Use find_by instead of find_by_name and find_by_user_id_and_assignment_id. 4. Add comments explaining what each method does, and comments on how important variables are used. 5. Pending invitations needs to be displayed in the same format as other tables. 6. Feature tests need to be written for the controller. The tasks identified above were implemented and the details are given below. 1. A new private function check_users was added which performs some basic checks before the create function is called. In the original implementation, there were a lot of nested if conditions which checked if a user is valid, is a participant in the project, and if the team has slots available. All these checks were the cause of the nested if statements because they needed to be checked before an invitation is sent out to a student. The nested if's were removed by moving all these checks into the private function thereby reducing the ABC size of the create method. 2. Nested if statements in the update_join_team_request were removed by breaking the nested statements into separate conditions and using return when the condition fails. For example, when checking if the user is valid, instead of using a nested condition to check validity, if the user is not valid then we throw an error message and return from the function. 3. Call to the method find_by_user_id_and_assignment_id has been replaced by find_by and passing the user_id and assignment_id as arguments to find_by. The code snippet showing the change made is shown below. Before refactoring <code> After refactoring <code> 1. Styling was added to the pending invitations table in accordance with the existing tables so that the view is uniform across the entire page. 2. The name of the controller was changed in accordance with the current naming convention and comments were added explaining why some important variables were used and also giving more clarity to whoever wants to modify the code in the future. There were very few comments earlier and they did not explain much about what was going on in the functions. The below test cases written can be found at spec/features/invitation_check_spec.rb. A student is initialised and an assignment is assigned to the student. This serves as a base for testing. <code>. <code>. <code>. <code>. Some of the possible test cases which can be used for the controllers are given below. 1. Test for create method in invitations controller: Before sending out an invitation to another student there a lot of checks that need to be performed such as checking if the invitee is a valid user, if the student is a participant in the project etc. All these scenarios are tested and finally, we make sure that a new invitation has been created in the database. The image below gives a visual representation of all the checks performed before sending out an invitation. <image> 1. Test for create method in join teams request controller: Similar to the create method in the invitations controller we need to do a lot of checks before sending out a new join team request. The below flow chart explains all the checks that need to be asserted before sending out a new request. <image> 1. Test for cancel method: The cancel method is called when the student who sends out an invitation wishes to retract the sent invitation. In this scenario the invitation is destroyed from the database and we assert that change by checking the change in the count of the database. The below diagram is attached for further clarity. <image> 1. Test for decline method: In this test, we assert the change of reply_status to 'D' in the database. Further improvements to this project would be to write feature tests for the scenarios discussed above. VCL is used to host the project remotely. The login credentials as an instructor are ""instructor6"" with password ""password"". To log in as a student, you can use 'student5425' with password 'password' <link>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.",check_users is a bad method name (what are they being checked for?).  Should be something like eligible_to_join.  Ditto for check_team.  Why isn't cancel called retract?  Good documentation of testing scenarios.,"Thank you for your submission. Your refactoring task seems comprehensive and thorough. I appreciate the clear explanation of the issues at hand and the step-by-step breakdown of your approach to improve the current setup. Your suggested solutions to code redundancy and nested statements, along with the use of efficient functions, are commendable.

However, there are a few improvements to consider:

1. Innovativeness: Try to incorporate innovative solutions or features to make the existing code more efficient rather than just addressing the existing issues.

2. Explanation: While your flow of thought is coherent, you could elaborate in certain areas. For instance, explain why 'find_by' was chosen over 'find by name' and 'find by user id and assignment id.' Is it more efficient or faster? Knowing the reasons would provide better context.

3.Sorting out content: It would be easier to understand if the work is broken up into sections such as Overview, Problem Identification, Solution Approach, Test Cases, Future Enhancements, and References.

4. Formatting is a serious concern. The text is clumped without spacing in between which makes it hard to read. Bullet points, numerals and paragraphs would make it easier for the reader to follow.

5. Code snippets: You mentioned only ""Before and After Refactoring"" without showing any actual code. Including specific examples can help verify the work undertaken. 

6. Test cases: You've given in-depth detail about what each test will confirm, which is great. However, actual code snippets for the tests could provide clarity and demonstrate your understanding.

7. Apply professional tone: Avoid using informal phrasing in certain sections. For instance, 'the student is initialized and an assignment is assigned' can be replaced by 'an instance of student is created and an assignment is associated with the student.'

Your hard work is obvious. Please make these improvements and resubmit your assignment for further feedback.
"
216,E1747,"Expertiza is a web application where students can form their teams, submit their projects, peer-review other's work, view their grades and so on. Expertiza is open-source, maintained by students and faculty in NC State university. Code Refactoring is the process of restructuring existing computer code—changing the factoring—without changing its external behavior. Refactoring improves nonfunctional attributes of the software. Advantages include improved code readability and reduced complexity; these can improve source-code maintainability and create a more expressive internal architecture or object model to improve extensibility. Typically, refactoring applies a series of standardised basic micro-refactorings, each of which is (usually) a tiny change in a computer program's source code that either preserves the behaviour of the software, or at least does not modify its conformance to functional requirements. Many development environments provide automated support for performing the mechanical aspects of these basic refactorings. If done extremely well, code refactoring may also resolve hidden, dormant, or undiscovered bugs or vulnerabilities in the system by simplifying the underlying logic and eliminating unnecessary levels of complexity. If done poorly it may fail the requirement that external functionality not be changed, introduce new bugs, or both. Test last development is a traditional and most common approach of testing where testing is done only after implementation code has been written. But test driven development, test first coding or TDD is a relatively new concept where test cases are written before writing the implementation code. RSpec is a 'Domain Specific Language' (DSL) testing tool written in Ruby to test Ruby code. It is a behavior-driven development (BDD) framework which is extensively used in the production applications. The basic idea behind this concept is that of Test Driven Development(TDD) where the tests are written first and the development is based on writing just enough code that will fulfill those tests followed by refactoring. It contains its own mocking framework that is fully integrated into the framework based upon JMock. The simplicity in the RSpec syntax makes it one of the popular testing tools for Ruby applications. The RSpec tool can be used by installing the rspec gem which consists of 3 other gems namely rspec-core , rspec-expectation and rspec-mock. sign_up_sheet_controller.rb is the controller to handle topic assignment. sign_up_sheet_controller.rb is a fairly complex file. It contains a lot of methods that are long and hard to understand. These method need to be broken down into simpler and more specific methods that are easier to read or understand. Also, the few instances of code duplication that exist should be removed. 1. Refactor ""list"", ""save_topic_deadlines"" method 1.1. 1.Split into several simpler methods and assign reasonable names 1.2. 2.Extract duplicated code into separate methods 2. Use find_by instead of dynamic method 3. Complete the pending tests in sign_up_sheet_controller_spec.rb, and write integration tests for newly-created methods. Refactor corresponding methods, and only then finish pending tests. Refactor ""list"" method The 'list' method is a long method which is fairly complex and hard to read. It is not following ""good Ruby and Rails coding practices"". In ""list"" method we found that ""signed_up_topics"" occurred too many times, here we split it into three different methods, named as ""find_signed_up_topics"" ,""find_selected_topics"" and ""list"". The changes are showed below. Previous Code: <code> Modified Code: <code> <code> <code> Refactor ""save_topic_deadlines"" method We found the ""save_topic_deadlines"" method is not hard to read, but it's a little bit long and some of the codes can be reused. Here The ""save_topic_deadlines"" method is modified and two new methods were created, named as ""get_instance_variable_assignment"" and ""get_instance_variable_topic"". Previous Code: <code> Modified Code: <code> <code> <code>. 1.Complete pending test in sign_up_sheet_controller_spec.rb. 2.Write integration test for newly created methods. 3.Write test for refactor methods. The most important two tests are about ""list"" method and ""save_topic_deadlines"" method. Here we wrote 27 examples of test and all of them are passed. <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code>. <link> video about Refactor <link> video about test.","Most of the narrative is in providing background (e.g., about Expertiza and RSpec) that most readers would already know.  There are paragraph-long descriptions of two refactorings, but for the rest, the code is just pasted in.  That is not helpful; it's easier to read the code on Github, where you can see what was added, deleted, and sometimes, moved.","Thank you for your detailed presentation on Expertiza and the explanations on code refactoring and testing. Here are my comments:

1. You have put forth a good definition and explanation of what Code Refactoring is and the benefits derived from it. You've also touched on potential pitfalls which was insightful. Remember to always back your points with practical examples where possible.

2. Your explanation of Test Driven Development (TDD) and Behavior Driven Development (BDD) was up to the point and you did a wonderful job explaining how RSpec fits into this.

3. Your recognition of code redundancies and complexities in the sign_up_sheet_controller.rb file indicates good analytical skills. 

4. The steps provided to refactor 'list' and 'save_topic_deadlines' methods are clear which is commendable. Remember, it's always best to include your actual code in the submission rather than placeholders like '<code>' for an accurate review.

5. An excellent initiative to write tests for the methods you've refactored. Creating new tests is crucial in maintaining the software quality as the code evolves.

6. Good job on providing a video about code refactoring and tests. However, make sure you provide the actual link next time.

For the next assignments, in addition to what you have done here, try to enhance your presentation skills by working on having a smoother transition between different sections. Also, make sure to include actual code when you're talking about code you're working on.

Good work overall! Keep it up!"
217,E1850.2,"Expertiza is an open source web based on peer review system developed and maintained by students and faculty members at North Carolina State University. It enables students who enrolled in a particular course to form online teams, complete assignments, review other's work and receive feedbacks of their works. Review_response_map.rb is used to prepare data for peer review. But there are no unit tests for it. 1. Create a new file named review_response_map_spec.rb under spec/models folder 2. Write RSpec unit tests to make the path coverage above 90%. 3. Coverage edge cases. 4. Achieve high branch coverage. Use the mutant-rspec gem to measure test thoroughness and fault-finding capability of tests. 1. spec/models/review_response_map_spec.rb. Follow the instruction on <link>. To better test the methods, we read the whole review response map model and understand the functionalities of what we want to test. 1.1. Questionnaire: find the specific questionnaire. 1.1. Get title: set the title. 1.1. Delete: delete the feedback response map and metareview response map. 1.1. Export fields: set the fields of export. 1.1. Export: export the review response map. 1.1. Import: import the review response map from local. 1.1. Show feedback: show the feedback via html. 1.1. Metareview response maps: fetch all the metareview response map and return. 1.1. Get responses for team round: get the responses for given round. 1.1. Final versions from reviewer: return the final review version from reviewers. 1.1. Review response report: find the reviewers for a given assignment. 1.1. Email: send an email to the members in a team. 1.1. Prepare final review versions: prepare the final review versions for an assignment. 1.1. Prepare review response: return the review responses id for an assignment. We mock the necessary instances for the test in the beginning of test file. <code>. Write test for the methods in review_response_map.rb. Questionnaire method returns a questionnaire associated with an assignment. <code>. Get_title method returns the title. <code>. Delete method deletes the feedback_response_map and metareview_response_map and return review_response_map. <code>. Export_fields method which shows the title of export csv file, ""contributor"" and ""reviewed by"". <code>. Export method exports the name of reviewer and reviewee and return the map. <code>. Import method allows user to import the csv file and check it. After that, it returns the name of reviewers. <code> When reviewee user = nil <code> When reviewee user exists but reviewee user is not a participant in this assignment. <code> When reviewee user exists and reviewee user is a participant in this assignment. <code> When reviewer user doesn't exist. <code> When reviewer user exists. <code> When reviewer user is not a participant in this assignment. <code> When reviewer user is a participant in this assignment. <code> When reviewee_team = nil <code>. Show_feedback method returns the html associated with response. <code>. Metareview_response_maps method returns metareview_list associated with responses. <code>. Final_versions_from_reviewer method returns the questionnaire and response ids associated with reviewer. <code>. Review_response_report method returns the participants associated with assignment. <code> When review user exists. <code> When review user doesn't exists. <code>. Email method can successfully send an email. <code>. Prepare_final_review_versions method returns the final review versions. <code> When round exists. <code> When round = nil. <code>. Prepare_review_response method returns the response id associated with assignment. <code>. The tests can be run on the terminal from inside the expertiza folder using following commands: <code>. app/models/review_response_map.rb 100.0 % covered 102 relevant lines. 102 lines covered and 0 lines missed. Full video for this test can be found at <link>. <link>.","The ""necessary instances"" built at the beginning should be described.  For the other tests, their outcomes should be described (why they pass or fail).  It would also be good to motivate why the tests are listed in the order that they are.","Dear student,

Great work on your assignment! I commend the level of detail and depth you have put into preparing the tasks. You have shown clear understanding of various methods within the Expertiza peer-review system with illustrated use cases. Your approach to achieving high coverage while emphasizing the importance of edge cases is good practice in unit testing. Well done!

However, as this is a technical assignment, it is crucial to avoid ambiguity. You mentioned writing tests but didn't include any concrete examples. So for future assignments, include Test Suite/Cases or pseudocode to give a better idea of how you are structuring your tests.

Moreover, in the midst of so many points and methods, it became somewhat confusing. Please work on organizing your thoughts in the future. One idea might be to discuss each method individually before moving to the next one.

Lastly, mentioned are a couple of scenarios such as 'reviewee user exists but is not a participant in this assignment' or 'round exists'. For your final code submission, make sure to write effective tests that would accurately capture these scenarios.

Keep up the good work on learning and implementing unit testing. It's a valuable tool for any software developer. I look forward to seeing your improved assignment and viewing your videowalkthrough.

Best regards,
[Your Name]"
218,E1665,"<link> is a web application which enables students to choose a topic in an assignment, submit assignments and peer review others' work. This application also allows the instructors to add assignments to a course, and create multiple topics with varying rubrics and different deadlines for an assignment.The Expertiza project is developed on Open Source Software (OSS) and is supported by the National Science Foundation. <link> is a behavior-driven development tool for Ruby programmers which helps write human readable specifications that direct and validate the development of an application. RSpec is composed of multiple libraries which can be used together or independently with other testing tools like Capybara and Cucumber. There are four parts of RSpec. They are: 1. rspec-core 2. rspec-expectations 3. rspec-mocks 4. rspec-rails. <link> is a web-based test automation software that simulates scenarios for user stories. It can automate web application testing for behavior-driven software development (BDD). It is a gem that can be used on top of a web-based driver. It offers a user-friendly domain specific language to describe a sequence of actions executed by the web driver. It is a part of the Cucumber testing framework. It is supported by the following web-based drivers: 1. RackTest 2. Selenium 3. Capybara-webkit. <link> is a type of black-box testing used in quality assurance, Functional tests are done by feeding the inputs and checking the outputs giving least importance to the internal structure of the program. It describes what the system does. Functional testing verifies a program by checking it against the specification documents. There are different types of functional testing: 1. Smoke testing 2. Sanity testing 3. Regression testing 4. Usability testing. Staggered deadline means having different deadlines for different topics under the same assignment. This is a relatively new feature of Expertiza. Deadline of different topics under the same assignment may need to be different for reasons like dependency of one topic on another. The aim of this project is to write RSpec tests to test the functionality of staggered deadline using Capybara. According to the instruction, we design 3 test cases: Initial state: Two students with different topics submit their work before the assignment's submission deadline in round 1. Scenario 1: Change deadline of topic 1 to bring it into review stage in round 1, check if the student assigned with topic 1 can review others' work, check if the rubrics are right for round 1. Scenario 2: Change the deadlines of both the topics to bring them into review stage in round 2, check if the students assigned with these topics can review each other's work, check if the rubrics are right for round 2. Scenario 3: Change the deadline of both the topic to bring them into finish stage in round 2, check that the students assigned with these topics are unable to review each other. Our test plan is divided into the following steps: 1. Create an assignment: Create an assignment with topic with varying rubric by round feature. 2. Add participants to newly created assignment. 3. Submit a Topic: Impersonate each participant, choose a topic and submit something. 4. Change topic Deadline: Change deadline of each topic and let each topic be in different stages (like submission round 1, review round 1, submission round 2 and review round 2) 5. View topic stage: Impersonate each participant and check their topic’s current stage on student_task#list view. 6. Submit reviews: Participant with topic in review stage can review other participant’s work, ensuring that right rubrics are used for different topics.The reviewers can fill in the rubrics, save and submit their reviews successfully. In order to test using the UI, type the following commands to start the server: <code> Once the Expertiza website is up, test the following: 1. Login as instructor 'instructor6' 2. Click on 'Create public assignment'. 3. Fill in the textboxes with assignment name, and assignment directory and other necessary details. 4. Click the 'Create' button. 5. Click on the link 'Rubrics'. 6. Check the box 'Review rubric varies by round?'. 7. Click on 'Save'. 8. Click the link 'Topics'. 9. Click on 'New topic' 10. Fill in the Topic id, Topic name,Topic category and Number of slots. 11. Click 'Create'. After returning, the assignment created is listed under 'Assignments' tab. 1. Create a new assignment 'Assignment1665' using factories, with two review rounds and Staggered Deadline enabled. 2. Added three participants to the newly created assignment using factories. 1. Create a stub to Impersonate the student 'student2064'. 2. Click on 'Assignment1665' from the task list. 3. Click on ‘Your Work’. 4. Fill in the textbox with the submission link. 5. Click on ‘upload link’ On clicking the 'upload' button, the submitted link is displayed on the page. 1. Create an assignment 'Assignment1665' using factories, with two rounds of reviews, and the staggered deadline functionality enabled. 2. Create different types of deadlines with names 'submission', 'review', 'metareview', 'drop_topic', 'signup' and 'team_formation'. 3. Create two topics 'Topic_1' and 'Topic_2' under 'Assignment1665' using factories. 4. Create assignment due dates for 'submission' and 'review' for two rounds using factories. 5. Set the topic due dates to corresponding assignment due dates using factories. 6. Change the different deadlines of one topic to different dates. On returning, click on 'Assignments' tab, and click on 'Edit' under 'Actions'. Click on the 'Topics' tab and then click the link 'Show start/due dates'. The instructor should be able to see the changed due dates for each of the topics. 1. Change the deadline date of topic assigned to 'student2064' to a past date and change deadline date of topic assigned to 'student2065' to a future date. 2. Impersonate a participant 'student2064' using a stub. 3. Click on 'Assignments' tab on top of the page. 4. The page should display the current stage of 'Assignment1665' as 'Review' 5. Impersonate 'student2065' using a stub. 6. Click on 'Assignments' tab on top of the page. 7. The page should display the current stage of 'Assignment1665' as 'Submission'. 1. Impersonate 'student2064' using a stub. 2. Click on the link 'Assignment1665'. 3. Click on the link 'Others' work'. 4. Select a topic to be reviewed. 5. Click on the link 'Begin'. 6. The student can see 'Questionnare1' for the review round 1. 7. Fill in the response checkboxes. 8. Click the button 'Save Review'. On returning, the reviewer should be able to see the 'View' option for the reviews done. The test file we added is 'staggered_deadline_spec.rb'. Once the server is running, open a new terminal, navigate the cloned 'expertiza' folder. The tests can be run in the terminal using the command: rspec /spec/features/staggered_deadline_spec.rb Here is the result: <image>. 1. <link> 2. <link> 3. <link> 4. <link>.","I question whether the tests are really exhaustive because only a couple of different combos of deadlines and rights are checked;; suppose someone tries to review a topic too early, for example?  But as far as the writeup is concerned, the tests are well described, but the code should also be shown, so that the reader could easily verify what is being tested.","Dear [Student's name],

This is an incredibly thorough and detailed showcase of your understanding of writing RSpec tests for a specific functionality using Capybara. Your understanding of different test strategies and application of behavior-driven development (BDD) are commendable.

I appreciate the detailed step-by-step strategy you laid out for testing the staggered deadline functionality. This clear approach to setting up, executing, and validating test cases makes the testing process reproducible, which is a critical aspect of successful testing.

You have also demonstrated a good grasp of the Expertiza platform, different functional testing types, the RSpec tool and libraries, and Capybara functionalities. Your descriptions about the four parts of RSpec are insightful, as are your explanations about different functional testing types and Capybara’s capabilities.

One area where you can improve further is in your documentation. While it is detailed, it would be more beneficial to specify the expected outcomes against each test case. That way, anyone who runs the tests can immediately spot any deviations from the expected behavior. 

Another point to consider is the layout of the document which seems a bit cluttered. A distinction of sections like introduction, purpose, test design, execution process and results could make it more readable.

I'd encourage you to continue with your meticulous approach to testing and practice writing clear, concise, and comprehensive reports. Great work!

Best regards,

[Instructor's Name]"
219,E1824,"The way Expertiza is set up right now is that only peers can review your work. However, there are cases when the course staff (Instructor/ TAs) would want to submit reviews as well. This project aims to implement this feature by allowing course staff to review the project on the same metrics as other students who review the project. Peer review is a great way for students to learn about how well they have developed their application. However there are some problems with this: 1. Sometimes, the peer reviews may not be thorough and the team/person's work reviewed might not reflect the actual status of the development. 2. The reviewer might not know how well they are reviewing the peers work. They might not entirely know as to what tone to use or what suggestions to put forward. By letting course staff perform reviews as well, the reviewer and the reviewee are both benefited, which can improve the overall learning experience. This is how some of the pages we are concerned with, currently look. <image>. <image>. We performed the following changes to let staff perform reviews as well: Step 1: Add a way for the instructors to perform a review. To do this, we added links for performing/viewing/editing/updating a review in the assignment submissions view. When the instructor/TA reviews a work for the first time, he is added as a participant and a review response mapping is created. Files edited: 1. View: app/views/assignments/list_submissions.html.erb - To add links in the instructor view 2. Controller: app/controllers/review_mapping_controller.rb - Method: add_instructor_as_reviewer Code snippet from the controller: <code> <image> In the second case, we can see a 'Perform review' link. This is the initial state when instructor review has not been added to the submission. Once the instructor adds a review and submits it, we can see the 'View review'. In case he just saves the review, an 'Edit review' link will appear. If the review deadline of one round is passed, the 'Edit review' link becomes 'Update review' link. This follows in line with what the student sees while performing a review. However, the course staff will be allowed to perform a review even if the deadline for reviewing has passed. Step 2: Add the instructor review in Your Scores table in case he has reviewed your work. Provide a highlight/way to make it look distinct. Files edited: 1. Assets: app/assets/stylesheets/grades.scss - To make an instructor performed review distinct from other reviews 2. View: app/views/grades/view_team.html.erb - Modified the ""Others work"" page to include the instructor review as well as ensure the score is not used. 3. Models: 1.1. app/models/answer.rb - Method: compute_scores | Modification in logic to ensure instructor review scores are not counted in the overall score of the student. 1.2. app/models/vm_question_response_score_cell.rb - Included a new variable called 'is_instructor_review' to identify an instructor review 1.3. app/models/vm_question_response_row.rb - Change in average_score_for_row method to not include an instructor review score 1.4. app/models/vm_question_response.rb - Modified the add_answer method to include the is_instructor_review to each row_score object Code snippet from the add_answer method: <code> <image> A student should be able to make out if an instructor has reviewed his/his team's work. In case the instructor performs a review on the team's work, it will highlight the instructor's review with a golden border as seen in the round two score table along with explicitly stating that it is an 'Instructor review'. The average peer review score for the team has been modified to exclude the instructor's scores. Same has been taken into account for the average score calculated for each row. Additional Files modified: 1. Controllers: 1.1. app/controllers/response_controller.rb - Change in re-directions in case of an instructor taking him back to the submissions page. 2. Models: 1.1. app/models/assignment.rb - Method: number_of_current_round_for_instructor | To allow an instructor to review an assignment even after the due date 1.2. app/models/course.rb - Method: is_ta_or_instructor? | To identify whether the user is a TA or an instructor of the current course Code snippet from the model: <code>. Features testing: Many of our changes are reflected on views (user interface). Following is the list of tests that are conducted with rspec/capybara. 1. it ""should let instructor/TAs perform a review for the submission of latest finished round if instructor/TAs has not started a review for the submission yet"" 2. it ""should let instructor/TAs save a review"" 3. it ""should let instructor/TAs review a previously saved review"" 4. it ""should let instructor/TAs edit a previously saved review"" 5. it ""should allow instructor/TAs perform a review after the deadline for reviewing has passed"" <code> Controllers testing: review_mapping_controller#add_instructor_as_reviewer <code> More testing: 1. it ""should let instructor/TAs update a review for the submission of latest finished round if instructor/TAs performed and saved a review for the previous round"" 2. it ""should show ""Instructor review"" when a student views feedback on his/her submission if an instructor/TA has reviewed his/his team's work"" 3. it ""should exclude the instructor's/TA's review score when calculating the average peer review score for the team"" 4. it ""should exclude the instructor's/TA's review score when calculating the average score for each question in the review"". 1. Forked Repository: <link> 2. Pull Request: <link> 3. Deployment: <link> 4. Screencast Demo Link: <link>. Expertiza 1. <link> Expertiza Github 1. <link> Expertiza Documentation 1. <link>.","The description is generally clear, but the organization is not.  The Problem Statement evidently consists only of a Current Scenario, which is subdivided into two parts.  The Proposed Solutions and Implementation are much longer, but are not divided at all.  The Test Plan is mostly pasted code, with minimal descriptions; it would be better just to refer the reader to the Github repo.","Good job on your assignment! Your comprehensive and detailed explanations are commendable. You managed to clearly define the motives of this new feature in Expertiza system, and also covered the problem this aims to solve. 

There are, however, few things you might consider to further improve your assignment:

1. You have mentioned the specific file changes, but providing the before-and-after code snippets would make your explanations clearer and more illustrative.
2. On testing, I noticed your descriptions of the tests conducted with rspec/capybara cover the cases where instructors/TA are allowed to take actions. It would be beneficial to cover the negative cases as well, where instructors/TA should not be able to take certain actions in specific circumstances.
3. Apart from testing, you should also specify the challenges and difficulties that occurred during coding and how they were overcome. This will showcase your problem-solving skills and could benefit others who may come across the same or similar issues.
4. Lastly, providing screenshots for demonstrating the implemented changes in the UI along with the shared links could be useful for better understanding and visualization.

Overall, your assignment is comprehensive. You clearly understand the implications of your changes and have taken the feature from concept to implementation with a clear focus on improving the Expertiza system. Remember, completeness and relevance of your work is as important as your coding skills. Well done!"
220,E1871,"Contents 1.1. <link> 1.2. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.3. <link> 1.4. <link> 1.5. <link> 1.1.1. <link> 1.1.2. <link> 1.6. <link> 1.1.1. <link> 1.1.2. <link> 1.7. <link> 1.1.1. <link> 1.1.2. <link>. For this project, our task was to create a view which consolidates information related to each assignment for each student in a course in a single page. The objective was to ease the way in which final grades could be viewed, and to provide holistic insight into the performance of each student in a class. Our fork and branch can be found here. <link>. Our pull request can be found here. <link>. This feature was requested by Dr. Gehringer in order to ease the process of collecting student grades for a course for reporting at the end of the semester. This process took nearly an entire day last semester, and the time savings given by a consolidated view containing all this information could be immense. Dr. Gehringer mentioned believing that this information had been previously available under the 360 Assessment tab in the Manage Courses menu, but that functionality had since been broken by an update. The current view indicates that one_course_all_assignments should be available from the 360 Assessment menu, and this appears to have provided similar but less complete information to what Dr. Gehringer has requested in this project. Looking through the commit history, we determined that 360 Assessment had been removed intentionally in commit <link> for unknown reasons, then added back when Zhewei needed to count the total reviews done by each student in a semester in commit <link> . It was then removed again when <link> the committer determined that the functionality the page was providing could be gained by accessing View Aggregated Teammate and Meta-Reviews from the Manage Courses page. This is the procedure for accessing the Grade Summary by Student view. It's not too complicated, but our reviewers really wanted some sweet UML action. <image>. 1. 1.1. app/assets/javascripts/tree_display.jsx 1.2. app/controllers/assessment360_controller.rb 1.3. config/routes.rb 1.4. app/assets/stylesheets/table_sorter.scss 1.5. app/controllers/grades_controller.rb 1.6. app/models/sign_up_topic.rb 1.7. app/helpers/grades_helper.rb. 1. 1.1. app/views/assessment360/course_student_grade_summary.html.erb 1.2. spec/controllers/assessment360_controller_spec.rb 1.3. spec/features/course_student_grade_summary_spec.rb. Getting the data we need to populate this view is a little more complicated than expected. Here is an explanation of what we need and why: 1. 1.1. We start by getting a course with a course_id. 1.2. Once we have a course, it is straightforward to gets the assignments and course_participants. 1.3. For each course participant and for each assignment, we then conduct the rest of the procedure. 1.4. We get the user id from the course participant. 1.5. We use the user id to get an assignment_participant object from the assignment. 1.6. We use the assignment and user ids to get a topic id from the SignedUpTeam model. 1.7. Once we have the topic id we can add the name to the list for the UI. 1.8. Use the assignment id and user id to get a team id from the TeamsUser class. 1.9. Use the team id to get a team object. 1.10. Get a grade_for_submission from the team object. 1.11. Get questionnaires from the assignment. 1.12. For each questionnaire in an assignment, use AssignmentQuestionnare model to get rounds. 1.13. For each round, get questions. 1.14. Once you have all questions, call score on participants while passing questions as argument. The view for Grade Summary by Student must contain the following information, according to the requirements document and consultation with Dr. Gehringer. 1. 1.1. Each student's name and id in a course. 1.2. Each assignment given to each student. 1.3. The topic name for each assignment. 1.4. The topic id for each assignment. 1.5. The grade for each assignment. 1.6. The peer review score for each assignment. 1.7. The total score of each student over all of their assignments. From the Manage Courses page in Expertiza, we intend to place our view behind the 360 Assessment icon for each course. Being able to view every student's complete grades for each assignment constitutes a 360 degree view of every student's performance in a course, and no functionality exists behind the icon currently, so this seems to be a logical choice for placement. <image> The following image shows our initial LoFi sketch of the desired page. It shows our intention to list each student in a row, and to have each column be their assignments. We wanted to contain all the information about their assignment within the column, but did not decided on columns-within-columns until reviewing with Dr. Gehringer. <image> We took Dr. Gehringer's feedback and have created the following rough prototype for the view. The data is absent, but this uses Expertiza's color scheme and style conventions. In this case, Topic Name and Topic Id are space-holders for real values, and Aggregate Score will not have sub-fields in the final draft. We are contemplating putting dividers between the columns, so it is easier to parse where each assignment begins and ends. We are also working on a way for the columns to be sorted by student and by grades. <image>. All of the information required in this view is present in the system: the controller for this view will simply need to make the appropriate queries to the models and database. We intend to create a hash of students given the particular course id, and then use the course id and the student id to retrieve the specific information about the assignments. All changes were made in the file assessment370controller.rb. Because the primary attraction of this feature is a view, the typical unit testing is not as practical as it would be if we were making changes to underlying models. Similarly, there aren't any interactive elements in the view we're testing. As a result, we plan to test the controller and the feature in general as best we can. Here are videos of each set of tests running successfully. <link> <link>. The controller we test is the assessment360_controller.rb, particularly the course_student_grade_summary function. Controller tests are tricky to write, as they can't be sensitive to the model's implementation or how the information will be displayed. As such, we intend to test that each of the instance variables provided to the view is instantiated, but not concern ourselves too much with what the values are (these would be tested by the unit tests for the manu models we query in this method.) This is identified as a best practice for controller tests in <link> . Here is an image of part of our Controller tests, showing how we handle the case where a course doesn't have any students. <image> Here is an image of all of the objects which must be mocked in order to properly test the controller function. <image> Here is an image of some of the tests which verify that the controller instantiates the view's instance variables. <image>. To verify that our view is correct, we'll implement some simple feature tests. Given some dummy students with dummy assignments with dummy fields, we expect that our view's page should display certain information. We'll check that upon navigation to our view, each element of data is present using the Rspec expectation 'to have_content'. In this way, we will verify that our view is performing its job. Here is an image of all of the objects which must be mocked in order to properly test the feature. <image> Here is an image of some of the content-check tests for this feature. <image>.","This design doc has uneven depth.  The testing code is described in great detail, but the implementation code is only described in outline form (though the outline is quite readable).  There is a mockup of a screen, but not a screenshot from the final version, which would have been more useful.","Dear Student,

I appreciate the amount of effort you have put into this project. Your detailed explanation and provision of evidence through images and links clearly shows the depth of your involvement in the task. 

However, your submission is a bit confusing. There seem to be some instances of redundancy, particularly in your use of sections where links have been mentioned, making it difficult to clearly understand the structure of your report. A clearer separation of sections and a more concise presentation could greatly improve the readability of your work. 

It's also impressive to see your extensive procedure on getting the data required for your project and how to access the Grade Summary by Student view, among other explanations. You've given a thorough account of your thought processes and execution, which is good practice in programming work.

Your thorough anticipation and explanation of testing methods is commendable. This shows that you've given extensive thought to the robustness of your software and provides a rigorous set of guidelines with which to test your project.

Your inclusion of what went into the view for Grade Summary by Student and your plans to bolster its features further was very enlightening. Continue to focus not only on the functionality but also on the user-friendly aspect of your tool as this is where the true value lies for the end user.

While you have done well tackling this project, I would recommend refining your presentation and focusing on clarity to make your work more understandable, which would also make it more impactful to your audience. Keep up the good work and continue honing your skills.

Best regards,
[Your Name]"
221,E1558,"This page provides a description of the modifications and improvements made to the Expertiza project’s source code as part of an Expertiza based Open Source Software project. Expertiza is a web based application which allows students to submit and peer-review classmates’ work, including written articles and development projects. The specific changes made during the course of this project were to the ReviewResponseMap.rb file, with additional changes made to other related files in support of refactoring ReviewResponseMap.rb. ReviewResponseMap is the model class used to manage the relationship between contributors, reviewers, and assignments. The intent of the changes were to refactor the code for better readability and adherence to Ruby coding standards and best practices. Primarily these changes involved the refactoring of overly complex methods, renaming methods for better readability, and the addition of missing unit tests. Project Requirements: 1. Code Climate<ref name=""Code Climate""> <link> </ref> shows import method is complex, because of lots of checks. This method can be fixed by adding private methods for raising import error. 2. Get_assessments_round_for method can be renamed to get_team_responses_for_round. Team_id private variable is not needed. 3. metareview_response_maps rename, refactoring can be done. No need to do second iteration. 4. write missing unit tests for existing methods. As part of our project, we refactored the model to follow the Single Responsibility and Don't Repeat Yourself (DRY) Principles. Both of the principles focus on reducing code repetition and increasing the cohesion of the individual methods in the class. The Single Responsibility Principle states that each class and method should have sole responsibility over one single part of the functionality of the system<ref> <link> </ref>. The DRY principle states that whenever the same types of logic and functionality are being performed in a class the duplicated logic should be extracted into a new method that can be called in place of the repeated lines of code <ref> <link> </ref>. A prime example of a method that initially violated these principles was the import method, which in addition to performing the core import processes also performed a number of checks that would be more properly extracted into private methods. CodeClimate reports showed the import method to be overly complex, with a number of checks being included within the import method itself. The resolution for this problem was to refactor the import method, creating private methods to perform the null checks and throw import errors. Prior to refactoring, all null checks were performed within the import method. After refactoring, the import method adheres to the single responsibility principle, performing only key import tasks while making calls to private methods for any necessary validation. The size of the import method was reduced by doing this and counts for better readability of the code. Also, this method is a very important one and care was taken so that any existing functionality did not break. Before refactoring: <code> After refactoring: <code> Private methods added: <code> <code> <code> <code>. The get_assessments_round_for method’s name failed to provide a clear idea of the method’s purpose and functionality. This is why it was renamed to get_team_responses_for_round, the new name of the method provides a clearer idea of its purpose. Additionally, there was a private variable, team_id, introduced in the method that was unnecessary and could be replaced by using the id property of the team parameter directly. We also removed the return statement at the end of the method. Before refactoring: <code> After refactoring: <code> The change in method name also required changes to the following files that referenced it: /app/models/assignment.rb:436: <code> ./app/models/assignment_participant.rb:268: <code>. The metareview_response_maps method was unnecessarily complex. It contained an unneeded private variable and an unnecessary nested loop. Originally, it added each metareview map individually in the nested loop. We decided to remove the nested loop and use the concat method for readability and maintainability. These changes allowed us to remove the private variable ""metareview_list"" and only maintain the ""metareview_response_maps"" variable. We also renamed the metareview_response_maps method to get_metareview_response_maps method to be more descriptive about the intent of the method. Before refactoring: <code> After refactoring: <code> The change from this renaming also requires changes in the following files: app/models/assignment.rb:361: <code> app/models/assignment.rb:362: <code> app/ models/assignment.rb:363: <code> app/models/assignment.rb:377: <code> app/models/assignment.rb:378: <code> app/models/assignment.rb:379: <code> app/models/assignment_participant.rb:73: <code> app/models/response.rb:4: <code>. The export method contained mappings.sort! { |a, b| a.reviewee.name <=> b.reviewee.name }. We could not get past this when running tests, we kept getting a message saying, ""sort! was not a method for an ActiveRecord_Relation"". But, ActiveRecord_Relation does allow the use of sort. So we changed that line of code to mappings = mappings.sort { |a, b| a.reviewee.name <=> b.reviewee.name } Before refactoring: <code> After refactoring: <code>. The final_versions_from_reviewer method was too long and repetitive. We removed common functionality from within the if and else statement and put it in a private method final_versions_from_reviewer. Then we created the get_responses method to find the responses based on the arguments values. These private methods make the class more readable for other programmers. Before refactoring: <code> After refactoring: <code> Private methods added: <code> <code>. We removed the return statement from the get_title, export_fields, and show_feedback methods because return statements are unnecessary in Ruby. We added comments to all of the methods in the ReviewResponseMap.rb file and corrected instances where CodeClimate Identified opportunities for code improvement. One issue flagged by CodeClimate that we did not change was to use the find_by method instead of where().first method. The where().first method occurs in the import, get_assignment_participant, and create_response_map methods. It is not always appropriate to use the find_by method, as documented in this github post: <link> . In instances where ordering by id is the desired behavior, where().first will order by default, but in Rails 4+ find_by does not honor that default behavior. For this reason we left the instances of where().first unchanged. This refactoring was to improve readability and follow as many good Rubyist coding practices as possible without breaking the functionality of existing code. We used CodeClimate of the master branch code as a reference. We took the suggestions we got from CodeClimate and improved our code based on that. We also made some of the methods shorter by removing redundant functionality and adding private methods to methods with a lot internal functionality. We also added private methods in places where we saw repeated patterns to make the code DRYer . At the end of our refactoring, we managed to improve the rating on CodeClimate from a C to a B . Further improvements meant reducing the size of the entire class which required a much more significant refactoring in multiple files and folders. We focused on refactoring the existing model, ReviewResponseMap . The previous unit tests had syntactical and run time errors. We were not able to get the previous unit tests to run without errors. Because of this we rewrote all of the unit tests for the ReviewResponseModel . It is important to have working unit tests so that when internal changes are made to functions the external output remains the same. We added a test_helper file to the main test folder that requires a needed configuration file and needed gems. We also added 8 fixtures that were needed for data to run the unit tests. The following fixture files were added: 1. assignment_questionnaires.yml 2. assignments.yml 3. participants.yml 4. questionnaires.yml 5. response_maps.yml 6. responses.yml 7. teams.yml 8. users.yml There is at least one unit test for every public method within the ReviewResponseModel . The test naming convention used is ""method_<name of method that is being tested>"". For example, the unit test for the export method is ""method_export"". If there are multiple test for one method the name of the test will include the test case after the normal naming convention. For example, one of the unit tests for the import method checks for an invalid assignment. The name of this method is ""method_import_invalid_assignment"". The following are the unit tests we created: 1. method_export 2. method_get_metareview_response_maps 3. method_get_team_response_for_round 4. method_final_versions_from_reviewer 5. method_import 6. method_import_invalid_reviewee 7. method_import_invalid_reviewer 8. method_import_invalid_assignment 9. method_delete 10. method_delete_no _force 11. method_show_feedback 12. method_get_title 13. method_export_fields 14. method_questionnaire 15. method_add_reviewer. To run the unit tests, follow these steps: 1. Download the master branch of the repo. 2. Setup the Databases for the test environment (we have used Zhewei's scrubbed expertiza DB ) 1.1. Run the "" rake db:create RAILS_ENV=test "" command 1.2. Run the "" rake db:reset RAILS_ENV=test "" command 1.3. Scrub the DB using "" mysql -u root expertiza_development < expertiza-scrubbed.sql"" 1.4. Run the "" rake db:migrate "" 3. Run "" rake test test/unit/review_response_map_test.rb "" in the ""expertiza/"" directory. 1.1. If you run into a mysql log in error go into config/database.yml and edit the mysql credentials for the test section so that it matches the local environment's mysql configuration 4. Check if tests passed or failed. In order to test the changes made to the ReviewResponseMap, bring up <link> and log in as an administrator. Once logged in, proceed with the following steps: 1. Go to impersonate user when logged in as instructor6 and type in student559 (or) just log in as student559 . All passwords are password . 2. Pick any assignment to view. 3. Navigate to Other's work . 4. Check the different reviews and metareviews. Whether they are being displayed correctly or not. 5. Go to Edit or Give feedback and submit a feedback. 6. Go back and check if the feedback given is displayed correctly or not. 7. Check if author's feedback is correct or not. 8. Go to the Temp assignment and see if the page is being displayed correctly or not (since there is no assignment submission content or reviews for that). NOTE: Since this was a refactoring of the code and methods, the existing functionality was supposed to remain the same and not break for the changes we've made. <references/>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.","Good job of explaining changes; however, there are clearer ways to show code changes (side by side, or with github's red & green bkgrds. for code removed & added).","The assignment provided is thorough and detailed, from the detailed code analysis to the set-by-step guide on how to run and test it. Your code refactoring efforts in terms of adherence to the Single Responsibility and Don't Repeat Yourself (DRY) principles are commendable. The test cases you've constructed for ensuring the integrity of the refactored code are logical, sound, and sufficient. 

However, you could have enhanced the readability and understanding of your assignment by providing some code snippets or examples, specifically for the 'before and after' refactoring phases to illustrate your methodology. In addition, you could have enriched the assignment by discussing some of the challenges or difficulties you faced during the process and how you overcame them.

I would like to highlight that you've adopted commendable practices like referring to CodeClimate to analyze the quality of your code and make necessary improvements. The fact that you were able to improve the CodeClimate rating from C to B indicates a significant improvement.

Another aspect I appreciate is how you retained the existing functionality while improving the readability and efficiency of the code. The detailed process that you outlined for running and testing the changes to the ReviewResponseMap is very helpful. Your approach towards creating various unit tests for the methods you worked with aids in validating the correct functionality of the code.

In conclusion, your project is commendable in terms its depth, organization, and the effective code improvement techniques you've implemented. However, as stated earlier, providing real code examples and discussing about challenges faced would have increased the richness of your assignment. Keep up the good work and continue to leverage tools like CodeClimate for continuous code improvement."
222,E1906,"<link> is a web application developed using Ruby on Rails Framework whose creation and maintenance is taken care of by students as well as the faculty of NCSU.It's code is available on Github <link> .Expertiza allows the instructor to create and edit new as well as existing assignments.This also includes creating a wide range of topics under each assignment which students can sign up for.They can also publish surveys and reviews,view statistical results, set deadlines for assignments and make announcements.It provides a platform for students to signup for topics,form teams,view and submit assignments and give peer reviews and feedback. An assignment in Expertiza has many deadlines possible: deadlines for submission and review in each round,deadlines for signing up and dropping topics,submitting meta-reviews,etc.Depending on what the next deadline is,an Expertiza assignment is said to be in a particular kind of what is called ""stage"".For example,if the next deadline(after the current time) is a submission deadline which is a DueDate object,then the assignment is said to be in a ""submission"" phase. <image> Depending on which stage an assignment is in, certain activities may be permissible or impermissible.For example, the default for a submission stage is to allow submission but not review,and in a review stage,the default is to allow review but not submission.These defaults may be changed by checking the relevant boxes on the Due Dates tab of assignment creation or editing.In the figure below it can be seen the ""Other's work"" link is grayed out as review is not permissible during submission phase. <image>. <link> <link> <link>. E1906 is an Expertiza based OSS project which deals basically with refactoring stage deadlines in assignment.rb file.Class assignment.rb has several methods for checking what kind of stage an assignment is in at the current time.These are: 1. current_stage_name(topic_id = nil) 2. find_current_stage(topic_id = nil) 3. get_current_stage(topic_id = nil) 4. link_for_current_stage(topic_id = nil) 5. stage_deadline(topic_id = nil) The goal of the project focuses on refactoring some of the above more complex methods, modifying some of the language to make it more Ruby friendly, removing some redundant code. This project is basically an attempt to make this part of the application easier to read and maintain. 1. assignment.rb 2. assignment_spec.rb. Multiple functions in the code were calling DueDate.get_next_due_date(self.id, topic_id). A new private function next_due_date was added. Other calls to the DueDate.get_next_due_date were replaced. <code> 1. One example of refactoring <image>. The above five methods were being used at various places to check if the assignment is 'Finished' which made the code very redundant. Assignment is said to be finished if the next_due_date is nil. We have created a new method ""finished?"" that checks if the next_due_date is nil (which means that the assignment is ""finished""). <code> We have called this method at all the places where previously different methods were being used to check the same thing. 1. Signup sheet table uses assignment finished? method instead of current_stage_name <image> 1. Use assignment finished? method where only a comparison to ""Finished"" was being done using get_current_stage and find_current_stage <image> <image>. The check for a topic_id to be nil when it is a staggered assignment and return 'Unknown' when it is true was being done at many places.This was not following Ruby and Rails rules. To make the code DRY and more easy to understand,we have created a new private method ""topic_missing?"" to check if the topic_id is nil in case of staggered assignment. <code> 1. Refactoring with new method topic_missing? <image> 1. stage_deadline( topic_id = nil) changed according to the modifications done <code>. find_current_stage(topic_id=nil) method is being used only locally in the assignment.rb and once in the student_teams controller to check to check whether to display or not the reviews option for team members.This method was calling another function to get the next_due_date for an assignment that was like nesting of calls and not very Ruby standard. We have removed this function and replaced it with finished? method in the student_teams controller(shown in screenshot above in Problem 2) and with DueDate.get_next_due_date where the next due date was required. <code>. get_current_stage method is returning the stage name which the assignment is in at current time.This is not very clear from the name of the method. We have changed the method name to current_stage_name(topic_id=nil) to make it more clear to understand. <code> 1. Refactored get_current_stage with current_stage_name <image>. current_stage_name(topic_id=nil)[This is the initial one] method was implementing things which was already being done by other methods and thus this method was redundant. The initial code given was: <code> First thing we noticed was that due_date.deadline_name was always nil because there was no field to enter the deadline name on the form, and therefore, the statement <code> was never getting executed. This method was checking for the due_date.deadline_name which was always nil. After removing the dead code, we get: <code> Looking at the current_stage_name(topic_id=nil)[New one] method shown below and comparing it to what we have above, this code was surely redundant.That is why we removed this code and made appropriate changes wherever required within assignment.rb. 1. Below is the current_stage_name method for reference <code> The associated rspec tests that tested the old current_stage_name method were also no longer needed. link_for_current_stage function served no purpose. The function checked to see if any given due date had a link (presumably web URL) and would return it. The database had no values and there is no where in the application this URL could be provided. There doesn't appear to be any use for having a separate URL for each stage. Removed function. <image> Removed test related to the function. Removed the one call to this function. <image>. We have created and modified the tests as per the changes done in our project.We have added the tests to the file <link> and they are passing 100%. The current version of expertiza did not have any tests for get_current_stage(topic_id=nil) method.Now as we have changed it to current_stage_name(topic_id=nil),we have added its tests as well. <code>. We have added tests for the new method that we have added finished?. <code> As topic_missing? method is made private,there was no need to test this. We also have corrected the tests for stage_deadline according to the modifications done(It is using finished? and topic_missing? methods). <code>.",Great job!  Good documentation of changes made for each issue. There are no deficiencies that I can find.,"You have demonstrated a solid understanding of Ruby on Rails and the Expertiza system in this assignment. Your in-depth analysis and comprehensive refactoring of the assignment.rb file reflect your strong technical skills.

Here are a few areas you did well:
1. You've thoroughly explained the function of each method within Expertiza and have clearly identified the redundancies and problematic aspects within the code. This level of problem identification and explanation is commendable.
2. Your focus on making the code more Ruby friendly and removing redundant code will likely improve the application's efficiency and readability significantly.
3. The creation of new methods like 'finished?' and 'topic_missing?' have reduced the complexity of the system and made the code more understandable. This was a smart approach.
4. Implementing and modifying tests according to the changes is a very commendable practice and shows your understanding of TDD(Test-Driven Development) principles.

However, for future assignments, here are some recommendations to improve:

1. Make sure to clearly state the problem you identify before you dive into the solution. This will make your work even more understandable to others reading it.
2. Alongside the code snippets, provide a brief explanation of what exactly the code does and how the changes have improved it functionally.
3. In places where you’ve simply posted an image of the code, try including the actual code, as the image may not be as clear and easy to understand.

Overall, your work is impressive and shows a high level of understanding and ability to effectively refactor code. Keep up the great work!"
223,E1953,"<link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. The following tasks were accomplished in this project: 1. If tagging is enabled, number of total tags per round is shown on student's score page 2. Implemented feature which shows number of tags student have entered 3. Implemented feature to show number of tags entered and total number of tags in Assignment page. 4. Implemented feature to show tagging counts dynamically when student change tagging type in score page 5. Added RSPEC testcases for testing changes done for tagging. Expertiza has a feature of peer review where other teams can provide feedback on student's work. There is also another feature of ""Tags"", where a student can answer if the feedback provided were helpful or not. Tags can vary from assignment to assignment but the main motive of it is to provide information on whether the feedback provides helpful information for student's assignment. The picture below shows an example of tags. <image>. For a particular assignment, there may be a lot of questions and hence multiple feedback. Students might miss a few tags and they might go unanswered. This feature will provide students to keep track of answered tags and show them how many tags have they answered out of total tags on the page. For counting, we are primarily concerned with two numbers: the number of possible tags for an assignment and the number of completed tags for an assignment. The latter is easy to calculate as it's directly stored as AnswerTags. The former is more difficult: possible tags are stored as TagPromptDeployments which do not have a 1:1 correspondence to the number of prompts the user sees on their page. <image> The green classes are used to count the number of tags done, the red classes are used to count the number of tags possible, and the yellow classes are used to calculate both counts. All classes help to narrow the scope to a specific user and assignment. On clicking of particular Assignment, student can see his/her teams, work, scores, etc. There is no feature which allows student to show how many of the review tags has he/she answered on this page. This task implements this feature where student can see answered tags with respect to total tags in Assignment page. app/controllers/student_task_controller.rb - The following code counts the number of Tags present in an assignment and total number of answered tags in that particular assignment. <code>. On clicking of particular Assignment>Your Scores> student can see his/her score. Student can also see all the reviews per rounds in particular assignment. This new feature will allow student to see number of answered tags per round with respect to number of total tags present in particular round. app/controllers/grades_controller.rb - The following code counts the number of Tags present in a round and total number of answered tags in that particular round. <code>. If a user changes their tags, the page formerly needed to be refreshed in order to display the correct counts. This functionality ensures that the tag counts always accurately reflect the results on the page. app/assets/javascripts/answer_tags.js - The following code correctly increments/decrements the tag count on the page based on the user's action. <code>. <image>. Please find below RSpec Test cases for this feature. Follow the below steps to Verify the fix for this issue: Test Case 1 <code> Test Case 2 <code>. Follow the below steps to Verify the fix for this issue: Test Case 1 <code> Test Case 2 <code>. Since new changes were added to existing function, we ran the existing tests to ensure none of them were failing. We needed to check if the feature implemented were resulting the expected behavior. To test this we followed following steps:- 1. Login as a student 2. Select Assignment for Assignment Home Page Test Case 1 This page should show number of tags completed and total tags present including all the rounds in that particular assignment. ✓ Test Case 2 On selecting Your Scores on Student Task page, Each round should show Review Tagged Column. ✓ Test Case 3 Review Tagged Column should consist of tags completed and total tags count for that particular round. ✓ Test Case 4 Review Tagged Column should not consist of tags completed in all rounds and total tags count. ✓ Test Case 5 Review Tagged Column should dynamically increase or decrease tag count when user change their tagging. ✓. Below are instructions for navigating through expertiza to see the review tags in action. 1. Go to <link> and log in as {username: student7552 password: password}. 2. After you log in if you are not at the assignments landing page (152.46.18.192:8080//student_task/list) click on Assignments to navigate there. 3. Click on ""Final project (and design doc)"" from the list of assignments in the table at the bottom of the page. 4. Behold the tag counter next to the bullet labeled ""Your scores"". It reads (You have tagged the available tags completed / total available reviews). <image> 5 . Further, click on ""Your scores"". On the next page that shows up, click on a row in the table to see the tags. Notice in the last column of the header of the table is a cell containing the available tags completed / total available tags. <image> 6. After clicking on a row to reveal tags drag the blue square towards 'No,' 'Yes,' or the middle. Observe that the tags left / total tags has updated. 7. To observe the new per round tagging capabilities log out and then log in as {username: student8115 password: password}. 8. Select the first Program 2 from the list of assignments. In the next page click on ""Your scores"" as in step 4 above. Scroll down and behold tagging statistics for each round in the last column of the table headers. <image>. 1. <link> 2. <link> 3. <link>.","The ""Problem Statement"" section is not really a problem statement; it is a list of what was accomplished.  It should be later on in the report.
Tagging is about more than helpfulness; it can be used to identify whether or not a review comment has any characteristic.  If someone was unfamiliar with tagging, this explanation would not be of much help in understanding it.
The design diagram is quite useful.  So is the process diagram.
The code for all the tasks should include comments!  There are comments only for Task 3.
The test cases not explained at all, beyond a listing of the code. There should be an explanation of what the test does, and why it verifies that the new functionality works.
When it says, You have tagged x of y reviews, shouldn't it say, You have tagged x of y review comments?  In the example, there are only 17 reviews, but it says that there were 25 reviews to tag.
So, the visuals on this wiki are very good, but the prose needs improvement."," Dear Student,

I appreciate your extensive explanation of the Expertiza system and the enhancements you made to it during your project. Demonstrating your understanding of the underlying system is truly commendable. I can see a clear understanding of system programming, proper code implementation and modification from your report. The tasks you performed, particularly enhancing the tagging systems to increase user engagement, show great initiative and technical skill.

The detailed approach to testing your implementation is also worth mentioning. Your write-up shows a good understanding of developing test cases to verify new features. I appreciate the user instructions you have provided. They help in providing a proper user-experience to a new user.  

However, I didn't see a detailed explanation of your problem-solving approach and the challengers you faced while tackling the problem. It's important to highlight these aspects in project updates because it helps to draw a clearer image of your thought process and inform future maintenance of your work. 

Do remember to not share your password publicly. Even in documentation, you shouldn’t include sensitive information. The next time you want to demonstrate such a system, consider recorded video demonstrations or provide guest credentials which don't have elevated privileges.

You have shown a good understanding of the system you have worked with and your ability to contribute to it positively. Your testing and implementation strategy seems solid and you seem to possess a good understanding of programming overall. Keep up the good work!

Best regards,
[Your Name]"
224,E1823,"users_controller.rb is a file under app/controllers that manages different kinds of methods related to users. This project is to write integration tests for users_controller.rb by using rspec, so our goal is to create a file named users_controller_spec.rb under spec/controllers folder and write integration tests to make the path coverage of users_controller.rb more than 90% and achieve the highest possible branch coverage. All methods used in this file that can render or redirect to one or more user-related views will be thoroughly tested.(16 in total) We do not need to test private or protected methods directly because these methods should be tested when testing other public methods in the same file. Newly-created file: <code> Tested file: <code> Related view files: <code>. 1. <link>. 1. index This method is used to list users in the database. A permissions check is done first to verify that the current user has permission to view the list of users. If the user is a student, he is redirected away from the page. All other user roles have access to the page. 2. auto_complete_for_user_name The method finds all users who have names similar to the one being typed and displays only those that have a lower role than the current user. The page is rendered again showing all these suggestions. 3. set_anonymized_view This method is used to anonymize the usernames in the views for demo purposes. 4. list This method calls the get_user_list method in the user model which returns a list of users according to the role of the user that calls the method. This list is stored in the @users instance variable which is used by the view. 5. list_pending_requested This method is called to show all the requests which need to be reviewed. It first obtains all the request users and the roles. Then It will show those request_users who is under review and their details with a selection window--""status"" which is used to determine if this request will be approved or rejected. 6. show_selection This method is used to show the users. It first detects if this user is valid or not. if this user is nil, it will redirect to the ""list"" page. If this user is valid, it will call the get_role method to get the role information of this user. and then use the role information to determine if this user is available for editing. For users available for editing, this method will render show ""page"", otherwise, this method will redirect to ""list"" page. In summary, this method will direct to ""show"" page, when the user is able to be edited, otherwise, it will go to ""list"" page. 7. show This method is used to show the details of a user. It first detect is the user is valid. There two condition for an invalid user: 1) the id of user is nil; 2) current user role is not student and the session id doesn't equal to the user id. Otherwise this user is valid. For a valid user, it will show his/her detailed information including name, email, password, prefs, institution and self_introduction. 8. new This method is called when method create is used to create a new user. <image> (This image will be helpful for the next 4 methods) 9. request_new This method is called when a TA or instructor requests an Expertiza account. To register to use the Expertiza, one needs to be either a course TA or Instructor and then sends a request to Expertiza administrator to get approved. This function only serves TAs and instructors, and the students account will be created by instructors or TAs. 10. create This method is called when the user wants to create accounts. 11. create_requested_user_record This method is called after the guest sending a request for the account to Expertiza administrator. After the guest sending a request for the account using request_new method, this method will store the request in the database and list all the requests on the pending_request page waiting for the administrator to operate. 12. create_approved_user This method is called when the Expertiza administrator deals with the guests' pending requests. By this method, the administrator can approve or decline the pending requests. 13. edit ""resources :users"" in routing rule maps /users/1/edit (assuming user's id is 1) to edit action in UsersController. Thus, this edit method is called when accessing user's edit page and will pull the relevant user out of the database via user's id that stored in params[:id]. 14. update ""resources :users"" in routing rule makes update action get called when the form in user's edit page is submitted. This method will first find the relevant user by user's id that stored in params[:id] and then updates the user's information in the database based on the submitted params hash. If the update is successful it shows a success flash and redirects to user's show page otherwise it renders user's edit page. 15. destroy ""resources :users"" in routing rule makes destroy action response to the delete method and thus accomplishing the user deletion. When this method is called, it will first find the relevant user via user's id that stored in params[:id] and then delete related AssignmentParticipant, TeamsUser and AssignmentQuestionnaire models if any (These models are found through their foregin key: user_id). Finally, the user is deleted from the database and it will show a success flash. If any of the above steps fails, it will throw an error flash. 16. keys ""get :keys"" under the collection block of ""resources :users"" will enable Rails to recognize paths such as /users/keys with GET, and route to the key action of UsersController. When this method is called, if no current user or current user is a student but is not the user stored in session, it will redirect to home page of the user stored in session. Otherwise generate_keys (a method of user model) will be called on the current user and the return value will be assigned to an instance variable @private_key defined in UsersController. This project aims to writing an integration test for users_controller.rb. There is no this Rspec file exist for this test, so a new test file shall be created and built from scratch. And before writing this test file, some prerequisites must be done. 1. Download and set the Expertiza environment 2. Determine which methods should be tested 3. Define all the conditions needed to be tested for each method The methods have already been introduced on above, here are the test plan for each method: 1. index 1.1 ""If the user is student, we check if proper redirection is taking place"" 1.2 ""Else, the appropriate list of users should be rendered according to the role of the current user"" 2. auto_complete_for_user_name 2.1 ""The page should render suggestions only of those user names that are similar to the one being typed and not all user names"" 3. set_anonymized_view 3.1 ""The method should add the session ip to the list of anonymized ip's and redirect to the previous page "" 4. list 4.1 ""The @users instance variable should contain all the users that are permitted to be viewed by the current user. This is tested by the same test for index"" 5. list_pending_requested 5.1 ""check if it will render users/list_pending_requested page"" 6. show_selection 6.1 ""check if the user is nil, will the page redirect to users/list page"" 6.2 ""check if the user is not available for editing, will it redirect to users/list page"" 6.3 ""check if the user is available for editing, will it render users/show page"" 7. show 7.1 ""check if the user id is nil or if the role is student and session id equals to id, will it redirect to home"" 7.2 ""if the user is valid, check the return value"" 8. new 8.1 ""check if this will render users/new page"" 9. request_new 9.1 ""Here isn't any conditional sentence. So only need to check whether the return value is expected."" 10. create 10.1 ""Is the name new? If yes, good. Otherwise, register the user by email address."" 10.2 ""Is the user's information valid? If yes, good. Otherwise, fail"" 11. create_requested_user_record 11.1 ""does the user belong to any institution? If yes, good. Otherwise, set a new institution."" 11.2 ""is the user already existed and valid? If both yes, good. If the user already exist, send notification. If the information is not valid, fail."" 12. create_approved_user 12.1 ""does the request have one status? if yes and the parameters of the request are completed, good. Otherwise, submit a status, approve or reject."" 12.2 ""is the status Approved or Rejected?"" 12.2.1 ""if the status is Approved, is the information valid? if yes, good. Otherwise fail"" 12.2.2 ""if the status is Rejected, is the processing correctly? if yes, reject successfully. Otherwise, error processing request."" 13. edit 13.1 ""Here isn't any conditional sentence, so we just need to check if it renders users#edit page."" 14. update 14.1 ""When user is updated successfully, it shows correct flash and redirects to users/show page. 14.2 ""When user is not updated successfully, it redirects to users/edit page."" 15. destroy 15.1 ""When user is not deleted successfully, it shows an error and redirects to users/list page."" (This also covers the condition that user is deleted successfully.) 16. keys 16.1 ""When params[:id] is not nil, @private_key gets correct value."" 16.2 ""When params[:id] is nil, it redirects to /tree_display/drill page."". Coverage percentage: <image>.","This document reads too much like a reference model and not enough like a narrative.  It appears that the test descriptions have been changed in some ways, but it's still hard to determine what some of them do, e.g., """"does the user belong to any institution? If yes, good. Otherwise, set a new institution.""""  Shouldn't it really prompt the user for a new institution, instead of just setting it?","Dear Student,

You have taken a very thorough approach to this challenging assignment, covering all the important aspects and methods that are needed for an integration test for the users_controller.rb file. 

Your understanding of different controller methods and how they interact with views and models is demonstrated very well. I appreciate your detailing of all the test plan for each method - including the test conditions and expected outcomes. This indicates a good grasp of the controller actions and how they should function under various scenarios.

Furthermore, your test plan shows a thoughtful approach to testing all user paths and actions, which effectively targets coverage of over 90% as required in the assignment. 

However, do ensure to keep the following points in mind while writing the tests:

1. Make sure your tests are not too tied up with the implementation, as that might limit the refactoring capabilities in the future and make them too brittle.
2. Always think about edge cases and negative scenarios along with the positive ones that you have covered here extensively.
3. Remember to check your tests pass and provide useful feedback if they fail before submitting them.

In conclusion, I would say that the assignment is well done and shows promising work. Good luck with the coding!
"
225,E1876,"A key component of Expertiza is peer reviews, which provide feedback to authors so that they can improve their work. Expertiza also supports grading of these reviews to ensure students write quality reviews, helping them learn more about the assignment by looking at their peers' work. In addition, Expertiza allows for metareviews, which are reviews the authors of the original work write for the reviews of their original work. This author feedback is useful for grading the reviews because it indicates how helpful this review was to the authors of the original work. The objective of this project is to add metareview or author feedback information to the review report page, which shows a summary of all the reviews written by the students for an assignment. The aim of this project is to build this into the system. We need an additional column in the 'Review Report' page for reviews which shows the calculation of the author feedback. This will help instructor's to know how the reviews proved useful to the authors/team. The aim of this project is to integrate the author feedback column in the summary page. In the page ""Review report for Design exercise"" (Log in as an instructor then go to Manage -> Assignments -> View review report.), we are planning to add one more column to show the average ratings for the author feedback for a student's review of a particular assignment. The logic for calculating the average score for the metareviews would be similar to already implemented logic for the ""Score Awarded/Average Score"" column. Below is the page we are planning to edit. <image>. The following method shows the code logic we are planning to write for calculating the average scores for the feedback given by authors for the reviews of their work. <code>. The following are the table structures we will need for this feature. First, the questions table has all the questions based on the questionnaire. We will be only concerned with the questions in the feedback questionnaire. The answers for each question in the feedback questionnaire are saved in the Answers table below based on the Question ID. Now, in order to know if the answer is a feedback by team members or a review by reviewer, the mapping for the Answers table is done by the response_id which is a foreign key to the Response table. This Response table gives us the map_id which maps to a response map table. Now, the response map table gives us information on the reviewer_id, reviewee_id, reviewed_object_id (which is the ID for the assignment being reviewed) and the type (whether it's a teammate review, author feedback, a regular review, etc.). We will have to fetch the answers from the Answer table based on response_id because in our case, the response is from a previous reviewee and not a reviewer. So, we will fetch those answers whose response type is FeedbackResponseMap and calculate scores for those questions for the corresponding ReviewScores table. Below are excerpts from the <link> which describe the database tables relevant to our design. <table>. <table>. <table>. <table>. <image>. 1. To calculate the average author feedback score: <link> 2. To populate the average author feedback score for the view: <link> 3. To add a field in the view: <link> 4. To add a field in the partial : <link> 5. To add a field in the partial: <link>. We added functionality in the on_the_fly_calc.rb file in Models. The methods in consideration are: 1. compute_author_feedback_scores 2. calc_avg_feedback_score(response) 3. calc_feedback_scores_sum The first method fetches the Feedback Response from ResponseMaps table based on the responses given earlier. Responses means the reviews given. Each feedback is saved to ResponseMap table with type = 'FeedbackResponseMap'. The feedback is fetched according to the assignment id, the reviewer who gave the review for that assignment and the reviews in each round. For each feedback response, we get the weight of the answer(feedback) submitted by author from Answer table and the weight of each answer from Questions table for the FeedbackQuestionnaire in consideration which we fetched from Questionnaire table. We calculate by taking an average of all feedbacks given by all team members to the reviews that they got. Following is the code snippet: <code> <code> <code>. We added another column to show the average author feedback score for each student who reviewed and for each team the student reviewed. <code>. We plan to test the response report page (/review_mapping/response_report?id={:assignmentID}) to make sure the new field (average author feedback) exists. Using <link> we will add a test case to review_mapping_controller_spec.rb. <code> We also plan to manually test the response report page to make sure the new field is aligning well in the UI in the expected place. We will attach the screenshot of the UI as the test result. We will test the cases of one and multiple reviews by a reviewer and verify the number and average scores of the metareviews for those reviews are rendered correctly. Below is the screenshot of review report page which now shows a new column for Author Feedback Score. <image>. We added a rspec test in on_the_fly_calc_spec.rb which tests our method: 'compute_author_feedback_scores' that calculates the average feedback score. Below is the snippet: <code>. <link>. 1. <link> 2. <link> 3. <link>.","This is a concise summary of what the project does.  I would prefer that steps in the Relevant Database Tables and Implementation section be itemized; I think that would make it more readable, but overall, the authors have done a good job explaining how their project works.","Your assignment is quite detailed and comprehensive. Good job on clearly laying out the needs of the project, the goals of your work, and a detailed plan of how you expect to achieve it. I appreciate the depth of your understanding as well as the thorough explanation of data table mapping and calculation logic.

Ensure that your images and links are inserted properly and are well-connected to your explanation to improve reader comprehension. Moreover, the method presented seems to well align with your project's objectives. However, without being able to see the coding specifics, it's a bit hard to review its actual functionality. You should ensure thorough testing of the program to catch any errors or bugs. 

You’ve done an excellent task explaining your approach to testing, both manual and automated. Merge testing and quality assurance is an essential part of any software development project, and it's pleasing to see the thought you've put into it.

Overall, your methodology is very well presented. If implemented as described, we should be able to see a substantial enhancement in the Expertiza system's capabilities. As you move forward, ensure you stick to your timetable and guidelines as closely as possible to make sure you achieve all your goals. Proper documentation is also vital in this process. Your future updates should focus on any challenges encountered, how they were resolved, and any potential improvements to the process.

Good luck with your project implementation."
226,E1954,"Expertiza is an educational web application created and maintained by the joint efforts of the students and the faculty at NCSU. It’s an open-source project developed on Ruby on Rails platform and its code is available on Github. It allows students to review each other’s work and improve their work upon this feedback. The following states the needs/issues with the current Expertiza project. Whenever an instructor/TA adds a new Assignment with the name of already existing assignment in the same course, then the newly created assignment is stored in the same directory as that of the previously created assignment which creates a conflict. Thus, need of a check that should be added to prevent two assignments in the same course from having the same name. Two assignments can currently be stored in the same directory. Thus, need of a check to stop two assignments from sharing the same directory. The directory name is not auto-generated from the assignment name. Hence, auto generation is required. The following is an Expertiza based OSS project which deals primarily with the AssignmentsController and AssignmentsView - _general.html.erb. Here is the details description of the project: The directory name is auto-generated from the assignment name. The instructor is allowed to edit It is done by changing spaces in the names to underscores. E.g., the directory for Program 1 is by default ""Program_1"". The special characters like '/','\','$' etc are to be removed from the auto-generated submission directory name. A check is added to prevent two assignments in the same course from having the same name. A check is made to stop two assignments from sharing the same directory. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link>. A controllera, helper file and spec were modified for this project namely: 1. AssignmentsController 2. AssignmentsView - _general.html.erb 3. AssignemntsController - assignments_controller_spec.rb </br>. This is a controller that helps instructors create, modify, copy new assignments. Each assignment can be associated with specific Rubrics, Review Strategy and Due dates. This the View for creating the new assignments and editing the existing assignments. This view also handles specifications of Rubrics, Review Strategy and Dates. We worked on the following work items(WIs) WI1: Created exist_assignment and exist_directory to check if the assignment name and directory name already exists in the current course. If any of those are already present then flash the respective error, else save the assignment. Here is the create method of controller -> assignments_controller.rb: <code> WI2: Auto-generate the Submission directory name based on the assignment name. Allow, the Submission Directory name field to be explicitly editable by the instructor. Here is the javascript function introduced in views -> assignments -> edit -> _general.html.erb <code> <code> WI3: Earlier the assignment was getting generated even if the instructor was not giving it any name or submission directory path, now both of these fields have been made mandatory. Testing plan is divided into two - Rspec testing and UI testing. As the controller code has been changed now, which does not allows two assignment files to be stored with same name. Thus, in the spec file for assignments controller, a test case has been added for the same. <code>. Following Steps needs to be performed to test the project from UI:- Step 1: Login as Instructor (Username - instructor6, Password - password). Create an assignment under any of the existing courses with name as ""test assignment"". <image> Step 2: Check if the Submission directory field is automatically getting populated based on the assignment name (replacing spaces with underscores and removing special characters). <image> Step 3: Fill in the details for Rubrics and Review Strategy. <image> Step 4: Click on create. You should be able to see the assignment you created in the list. <image> <br Step 5: Now, try to create another assignment with the same name in the same course. Also, try to change the submission directory name to any of the existing assignment or same the assignment created in Step 2, Check if the system flashes an error in the creation of this assignment. <image>.","Wiki lists the code changes, but there are not many comments, and the approach is not described in prose.  Probably would not help a reader learn what was done.
They have added screenshots for changes and the test case they added.
Similarly, there is little prose to explain what the tests are doing.  There are screenshots, but they are huge, relatively speaking, and the reader would need to zoom out to read them.
","Dear student,

Thank you for your detailed and thoughtful work on this assignment. You have clearly identified the key issues in the Expertiza application, including the necessity for a check for duplicate assignment names, and the need to prevent two assignments from sharing the same directory. Your approach to solving these issues, outlined clearly and methodically in your assignment, demonstrates your understanding of the codebase and your problem-solving abilities.

Your proposed updates to the AssignmentController, including checks for existing assignment names and directories, are well thought out. It's great to see how you utilized the model-view-controller (MVC) pattern in your proposed solution by creating a helper method in the controller that checks for a unique name and segregates the assignment logic and presentation. 

With respect to the naming convention of directories, your method for auto-generating a name is resourceful. Sure enough, the option to allow manual overrides is a thoughtful addition.

However, in your code snippets, you didn't actually provide the code, you only mentioned where the code would go. In the future, please include the actual code block instead of the placeholder <code> so that we can better understand and analyze your approach.

Your testing plan is thorough and outlines clear step-by-step instructions both for UI and RSpec testing. Including specific expected outcomes would make your testing plan even more robust. 

I look forward to seeing your next steps and how they impact the overall functionality of the Expertiza system. Keep up the good work!

Best regards,
[Your Name]"
227,E1625,"<link> is a web application developed using the <link> framework as a combined effort of students and faculty. The main advantage of using Expertiza, in an educational environment, is for the instructor to introduce peer reviewing among the students. The instructors can create and customize assignments, create a list of topics the students can sign up for, have students work on teams and then review each other's assignments at the end. Expertiza supports submission of almost any document type, including the URLs and wiki pages. Expertiza is supported by National Science Foundation under Grant No. 0536558. Additional funding from the <link> <link> (LITRE) program, the NCSU <link> , the NCSU <link> Initiative, and the Center for Advanced Computing and Communication. Confidence ratings are meant to provide objective value to student assigned peer review scores. Students select from a list of tasks to be performed and then prepare their work and submit it to a peer-review system. The work is then reviewed by other students who offer comments/graded feedback to help the submitters improve their work. During the peer review period it is important to determine which reviews are more accurate and show higher quality. Reputation is one way to achieve this goal; it is a quantization measurement to judge which peer reviewers are more reliable. Peer reviewers can use expertiza to score an author. If Expertiza shows a confidence ratings for grades based upon the reviewers reputation then authors can more easily determine the legitimacy of the peer assigned score. In addition, the teaching staff can examine the quality of each peer review based on reputation values and, potentially, crowd-source a significant portion of the grading function. <image> <link> There are two algorithms intended for use in calculation of the reputation values for participants. There is a <link> (the link accessible only to the instructors) available which serves a JSON response containing the reputation value based on the seed provided in the form of the last known reputation value which we store in the participants table. An instructor can specify which algorithm to use for a particular assignment to calculate the confidence rating. As the <link> on reputation system by observes, “the Hamer-peer algorithm has the lowest maximum absolute bias and the Lauw-peer algorithm has the lowest overall bias.This indicates, from the instructor’s perspective, if there are further assignments of this kind, expert grading may not be necessary.” Reputation range of Hamer’s algorithm is red value < 0.5 yellow value is >= 0.5 and <= 1 orange value is > 1 and <= 1.5 light green value is > 1.5 and <= 2 green value is > 2 The main difference between the Hamer-peer and the Lauw-peer algorithm is that the Lauw-peer algorithm keeps track of the reviewer's leniency (“bias”), which can be either positive or negative. A positive leniency indicates the reviewer tends to give higher scores than average. This project determines reputation by subtracting the absolute value of the leniency from 1. Additionally, the range for Hamer’s algorithm is (0,∞) while for Lauw’s algorithm it is [0,1]. Reputation range of Lauw’s algorithm is red value is < 0.2 yellow value is >= 0.2 and <= 0.4 orange value is > 0.4 and <= 0.6 light green value is > 0.6 and <= 0.8 green value is > 0.8 The instructor can choose to show results from Hamer’s algorithm or Lauw’s algorithm. The default algorithm should be Lauw’s algorithm. A Sample of the webpage displaying reputations with Lauw's algorithm is given below. <image>. In an <link> , a software application is divided into three major components : Model, View and Controller. This allows separation of internal representations of information from the information that needs to be presented to the user. Model - Maintains the data, logic and the relationships between objects and the database. It also handles validations, associations and transactions. View - Displays data received from the controller in the User Interface. Controller - Accepts input from client and converts it into actionable items for the model or the view. Its responsibilities include querying models and organizing data into a structure that is displayed by the view. All the documentation for the Expertiza system can be found in the following links: <link> , <link>. participant. grades/view.html.erb grades/view_my_scores.html.erb grades/_review_table.html.erb assignment_form.rb, edit/_general.html.erb. Reputation_web_service_controller.rb. reputation_web_service_controller_spec.rb assignment_creation_spec.rb grades_spec.rb. All our code follows the <link> on Ruby style. 1. Write a migration to add reputation field in participant table. (The default value of this field is 1, set any nil to 1) 2. Change the send_post_request method in <link> to obtain initial reputation values from DB instead of hard-coded. 3. Write a new method in <link> to extract reputation values from JSON response and insert into DB. 4. On view_my_score (student-end) and view_scores (instructor-end) pages: use different font color on students’ names to distinguish different level of reputation values. We will be using the existing test suite used by gem to test any new code modification. We will be writing new test cases for any new public method exposed by existing classes.Our priority is to add functional tests associated with reputation for instructor, assignment and student controller. For example, One test workflow would be Testcase 1 1) Instructor selects type of reputation algorithm 2) Chooses the assignment and the round for which the reputation needs to calculated 3) Receives the json response 4) Check if the response is in the right format and the that the reputation for each student is stored in the database. Testcase 2 1) Student logs in to Expertiza. 2) Selects a particular assignment. 3) Clicks on 'View My Scores'. 4) Student should be able to see his/her reputation value along with the scores. 1. <link> 2. <link>.","Lauw is a boolean in db in assignments table, which is not correct. We may have more repu. algorithms
limited testing done.","Hello,

Thank you for turning in the assignment. Overall, it's clear you have an understanding of the concepts and technologies as well as your ability to explain them, however, there are a few areas that need improvement.

The introduction of your assignment is well-structured. You manage to give an overall context of Expertiza and its practical advantages. Still, I recommend summarizing its operation briefly before diving into its intricate details.

The latter part of your essay is very detailed and shows a thorough understanding of the Expertiza's structure as an MVC app. However, I noticed some sections are a bit disorganized. It got hard to follow your points when you started discussing the algorithms and their reputation ranges. Try using sub-headings or bullet points to break down these topics into smaller, more digestible sections.

There's also a lack of clarity on the purpose of the algorithms. While you have explained how they work and their differences, you have not really provided any context as to why instructors would want to use one over the other. Additional context will help in understanding the overall relevance and real-world application of these algorithms.

Your explanation of the MVC model is excellent and clearly outlines its respective roles. The documentation part you provided works perfectly as a summary and it validates your understanding of the use of Expertiza.

In regards to the coding tasks, you've outlined a comprehensive plan. But, it would be helpful to see how you're thinking in terms of dividing these tasks and prioritizing them. Perhaps consider providing more justification for why you've ordered the tasks as you have.

Finally, the test cases show good understanding of the interaction with Expertiza. However, outlining what you hypothesize the issues may arise with this workflow and how you will manage fixing them would enhance this section.

Overall, keep up the great work, and be sure to implement these suggestions when working on future assignments as they will help you improve your assignment organization and clarity.

Best Regards"
228,E1670,"This wiki page is for the description of changes made under E1670 OSS assignment for Fall 2016, CSC/ECE 517. Mocks and factories are used in the unit tests so they can't be tested by UI. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.6. <link> 1.1.7. <link> 1.1.8. <link> 1.1.9. <link>. Expertiza is an Open Source web application developed on Ruby On Rails platform. It is a platform which allows students to access assignments posted by the course instructor. Expertiza also allows students to select assignment topics, form teams and submit their work. It also allows them to review other students' submissions and improve their work based on the feedback provided. The instructor can look at the feedback provided by students and rate the student based on feedback provided for others work. It helps organize and upload assignments and reducing the manual review process and helps students provide a peer feedback and also learn from reviewed work. Teams can be chosen by the student or can be assigned automatically based on a priority list inputted alongside each topic available for the assignment. In Expertiza, each questionnaire contains many questions, those question may have different types (e.g. checkbox, criterion, etc). When a user fills in a rubric, the responses for each question will become an answer record. The responses of rubrics are stored in answers table in DB. The answer.rb is the model for the answers table in the Database. The Answer.rb model does not have any test cases corresponding to it and the aim of the project is to write fast, effective and flexible unit test cases that offer maximum code coverage. As a part of the project the files mentioned below were the ones, created/modified as needed. 1. answer_spec.rb (path /spec/models/answer_spec.rb) 2. factories.rb (path /spec/factory/). RSpec is a testing framework for Ruby for behavior-driven development (BDD) licensed under MIT. It is inspired by JBehave and contains fully integrated JMock based framework which has a very rich and powerful DSL (domain-specific language) which resembles a natural language specification. Composed of multiple libraries structured to work together, RSpec provides encapsulated testing via the describe block to specify the behavior of the class and the context for the unit test case. RSpec is easy to learn and implement and can be used with other testing tools like Cucumber and Minitest independently. It is extremely powerful for testing states with complicated setup and also helps in tearing down complex code to access the objects required for testing RSpec semantics encourage agile thinking and practice and it structures the tests in a more intuitive way. Listed below are the functionalities and the Rspec unit tests corresponding to the function names along with a list of scenarios tested. Function Name : Compute_scores Compute_scores is a function in model answer.rb which gives the average, maximum and minimum scores obtained in a series a responses/assessments. It has two input parameters: List of assessments and questions. The function iterates over each assessment to get the total score of that assessment. If the response or review is invalid, that assessment won’t be considered in the calculation of the score average. After iterating over all assessments, Max score, and Min scores are calculated along with the average score based on the number of valid assessments. Their scores are returned by the function. Rspec Unit Test : Compute_scores Following scenarios are tested: 1. To return scores as nil if the input list of assessments is nil. This is to make sure no Null Pointer exceptions are thrown by the code 2. To return a particular score when a single valid assessment is given as an input. 3. To return a particular score when multiple valid assessments are given as an input. This is to test the looping functionality of the method. 4. To return a particular score when invalid assessments are given as an input. The validity and total scores are returned by a mock and not by the actual functions. This is to make the test cases less rigid so that failure of dependent functions do not disrupt the functionality of interface level tests. 5. To return a particular score when invalid flag is nil. Invalid flag can either be 0,1 or nil. Nil situation is tested to prevent NullPointer Exceptions 6. To check if the method get_total_score is called with the right parameters. This unit test uses a stub and returns a mock value. <code> This is to eliminate tight coupling between compute_scores and get_total_scores. Failure in get_total_scores wouldn't break the compute_scores test cases. Function Name : Get_total_scores This function is called by the Compute_scores method of the answer.rb model to compute the total score of an assessment. The input consists of assessment for which the total score is being calculated and the list of questions being evaluated in the assessment. The method uses questionnaire id from the questions and response id to obtain a score view questionnaire data. This score view is a read-only record. The questionnaire data mainly consists of q1_max_question_score, sum_of_weights and weighted_score. Before calculating the score, the function performs two crucial tasks. 1. Checks if the answer for a scored question is nil. If it is nil or unanswered, the question will be ignored and not counted towards the score of this response. 2. Calls the submission_valid function by passing the response record to set the @invalid flag based on the validity of the response. The total score is calculated using the below formula <code> Any edge cases would return -1 indicating no score Rspec Unit Test : Get_total_scores Following scenarios are tested: 1. To return an anticipated total score of a single response without any edge cases. Since this function will be called only on one response at a time, there is no need to test for multiple responses at the same time. 2. To return an anticipated total score of a response where nil answer is for a scored question. This is to check if its weight gets removed from the sum_of_weights. 3. To return -1 when the sum of weights becomes 0. This can happen when all the scored questions are unanswered. Return value of -1 is checked at the calling function to ensure if a score is returned or not. 4. To return -1 when weighted_score of questionnaireData is nil 5. To check if submission_valid is called. This method is called to set invalid flag to indicate whether the response entered is valid or not. The validity criteria is explained in the submission_valid? Function. This unit test uses two stubs and returns mock results <code> <code> This is to reduce the outcome of the test to depend on DB calls. For example, in case the connection to DB fails, this unit test would still pass making it less rigid. Function Name : submission_valid? This purpose of this function is to verify the validity of a review based on a deadline. This function obtains a list of AssignmentDueDate objects in descending order which is then compared against the current time to determine which deadlines are valid and which ones are not. The flag variable is used to represent whether or not a deadline was available in the previous iteration of the loop. If the flag is set to TRUE and the deadline is less than the current date, then latest_review_phase_start_time is set to this deadline. A list of ResubmissionTime objects is also retrieved from the controller. These objects are then compared against the then latest_review_phase_start_time variable to determine a response. Observations: The current implementation of the function is bugged. It retrieves a list of sorted AssignmentDueDate objects and proceeds to check if this list is empty. However, instead of exiting if the function if the list is empty, it carries on execution and raises an exception on hitting the for loop. 1. Checks if a review is valid or not by comparing its date with a list of deadlines. 2. Returns 1 or 0 depending on validity 3. Current implementation is bugged. Throws an exception if no AssignmentDueDate objects are passed, returns nil if any objects are passed. Rspec Unit Test : submission_valid? Following scenarios are tested: 1. Passing valid AssignmentDueDate objects 2. Not passing any AssignmentDueDate objects When valid AssignmentDueDate objects are passed, stubs are used to create fake AssignmentDueDate Objects and ResubmissionTime objects. These objects are then populated with valid deadline dates and deadline_type values. These values are then supplied when requested by the submission_valid? Function rather than actually calling the function. The current implementation of this test case expects the program to throw an error when it reaches the for loop. Once this bug is fixed, this test case may be re-written to test a more legitimate test case. In case an empty list of AssignmentDueDate objects is passed back to the submission_valid?() method. This would cause the function to return nil. When this function is fixed, the following test case may be re-written to test for a more legitimate test-case. This unit test uses two stubs and returns mock results <code> The above stub returns two AssignmentDueDate objects whenever the where() and order() method are chained on AssignmentDueDate. <code> The above stub returns two ResubmissionTime objects whenever the where() and order() method are chained on ResubmissionTime. <code> This stub is used in the second test case to return nil objects. the stub_chain method can be used to create stubs where chained methods are expected. Function Name : answers_by_question, answers_by_question_for_reviewee,answers_by_question_for_reviewee_in_round These three functions are sql queries that hit the DB to get an output record after a series of selections and joins. SQL queries that hit DB often do not have a high priority when it comes to testing, so the project does not aggressively test these functions. However, these functions are tested to make sure the queries are able to find the right column names and tables successfully. Any change in the table schema would be detected in these test cases. The functionality of these queries are not tested but instead the existence of an output is tested. This ensures that answer.rb is able to make a successful db connection and is sync with the latest db schema. Since the function actually hits the DB, mocks can no longer be used, instead active records were created and saved in test db using FactoryGirl gem from the factories.rb. These records are cleared after every test case. Following factories were used to create records in the table 1. question 2. response_record 3. response_map 4. answer Rspec Unit Test : answers_by_question, answers_by_question_for_reviewee,answers_by_question_for_reviewee_in_round The factories are created such a way that the query would return an output and the tests will pass if the query returns a non nil record. The functionality of these functions would be tested by the integration tests of the controller <code> Validation and Dependency Rspec Test Apart from testing functions, the models are also tested for validations and external dependencies. Model answer.rb does not have any validations but does have a dependency on question.rb. Answer belongs_to question and this was tested using a simple dependency rspec test. <code>. 1. To run the test suite for a particular file only( answer_spec.rb): <code> 1. To run the entire suite of test cases: <code>. <code>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. <link> 8. <link>.","The intros to Expertiza and Rspec are really not needed, as anyone reading this writeup would already be familiar with them.  It might be appropriate to link to descriptions of them, but no more.  The descriptions of the test cases is very good.  I wonder why more of the descriptions are not backed up by showing the code.","Overall, your assignment is very comprehensive and demonstrates a strong understanding of the topics covered in CSC/ECE 517. However, there are a few areas that could be improved upon:

1. **Structure and Clarity:** The presentation of your assignment could be clearer. While the content is informative and well-detailed, it is also quite dense and can be difficult to follow at times. Try paragraphing more clearly and consistently to help break up your information more effectively. This would make your work easier to read and understand.

2. **Links:** The various `<link>` placeholders within your content are distracting. If these are supposed to be links to additional resources or references, including the actual URLs might be more helpful for the reader. On the other hand, if these links are not relevant, consider removing these placeholders entirely.

3. **RSpec Testing:** You have done a good job explaining the concept, scenarios tested, and the purpose of each function. However, you might need to provide more specific examples on how the tests are implemented, possibly through small snippets of real scripts.

4. **Code Snippets:** The use of `<code>` tags in your assignment is unclear. If intended to introduce code snippets, please ensure the snippets are related to the content and accurately represent the code you are discussing.

5. **AssignmentDueDate and ResubmissionTime:** If it is within the scope of the assignment, consider providing a solution or workaround for the current implementation issue that throws an exception when no AssignmentDueDate objects are returned.

6. **References:** I notice placeholders indicating references at the end of your assignment, remember to fill these in with your actual sources.

7. **Conclusion:** It would be useful to have a short conclusion summarising what you have covered in the assignment, and discussing the implications of your findings.

Overall, your work shows depth and a clear understanding of the subject matter. It's evident that you've put in significant effort. With the above improvements, your assignment will not only demonstrate your knowledge but will also be easier to follow for readers. Continue the good work!"
229,E1707,"Expertiza is an open source web platform that enables students and instructors indulge in an enhanced and accelerated peer based learning milieu. It is aided by facilities like submissions of project work and reviews according to instructor approved deadlines, teaming up with other peers for various projects, reviewing other teams' and teammates' work and personalization of a project submission according to the best suited requirements. All these factors make Expertiza a valuable asset for an instructor to guide his students through the course with much more effectual results. Expertiza source code is built using Ruby on Rails and is available on github with public access enabled repository. Currently, before the start of an assignment, students can be asked to form teams on their own or teams can be assigned by the instructor. As the main motive is guide students via peer based learning, thus more number of peers the student works with, better learning. So, to enable students find different people for the assignments rather than just team up with same people for every assignment in the current course, students can ask for a team to be randomly allocated by not choosing the team members before hand. After the bidding for the project topics is over, the student is allocated a team. Here, in this case it may be possible that the student is allocated a team member they have previously worked with before. Hence, to enable student circumvent this situation in case he/she prefers different people for the particular, we need to provide an option for the students to choose if they prefer different team members for the assignment before the bidding for the project topics happens. The main objective is to give students an option to choose whether or not they want to team up with their previous team members for a particular assignment in the current course. If they choose the option, then when a student is added to the team, a check is performed if he/she has worked with the student before. If such is the case, then the student is swapped with some other student who hasn't worked with the same person before. Another point to note is that if the student chooses some person to be on the team who he/she has worked with before, choosing this option would still allow the person to remain in the team. To implement top trading cycle algorithm, we would be utilizing the web service that is hosted at <link> . The students, and student history would be provided to the web service and the response from the web service would be utilized to update the teams. The web service is expected to respond back with new team after swapping the team members that have teamed up before. As part of the changes, a new flag would be introduced in the teams model. The teams do not want to be changed (swapped) would have to unset the flag. If the flag is unset, the teams would not be send to the web service for the swap operation. Only the instructor would see the option of utilizing this feature from the view. The feature would not be present for the students. As part of the changes a new method would be added in the lottery controller to implement this functionality. The new method would have the responsibility to utilize the webserver and update the teams according to the web service. A new button would be added in the instructor view for the assignments for invoking this new method. A new checkbox would be added in the students view for selecting/un-selecting the option of swap. <image>. <image>. • The first step is to include a checkbox to provide student with an option to select if he/she want to be assigned new people who were not previously team up with the student. • An additional flag has to be introduced in the teams table that represents the value of the checkbox. The following flow chart diagram describes this scenario at the front end: <image> • After instructor initiates the team creation process, first check is to know whether the team members have already been chosen by the student. If yes, then the team is created as it is with the chosen members. • If, the student doesn't have all/some team members already selected, a team is created for the student by calling the create teams method in the top trading cycle service. • After a team is created, the flag is checked if the student wanted new team members for the assignment who were not team up before. • Then for each team member selected to be on the team, it is checked if the he/she has been teamed up with before. If no, then we move on to the next member. • If the team member has been teamed up with before, we call the swap method in the top trading cycle service and pass the student's team history. • Using that information, he/she is swapped with some other team member who hasn't been on the team. • This process repeats for each member, until we cover all the team members. At the end, we have our team ready. The following flow chart diagram describes this scenario at the back end: <image>. 1. app/views/assignments/_reserve_topic.html.erb 2. app/controllers/sign_up_sheet_controller.rb 3. app/views/sign_up_sheet/list.html.erb 4. app/controllers/lottery_controller.rb. 1. ""To check if team creation will create teams with students having put up with the teammates previously teamed up with"" 1.1. Set max number of students per team to 3. 1.2. Manually make change in DB to make 3 students previously team up with 3 other students. 1.3. Have 6 students bid for a topic. 1.4. Call the team creation method 1.5. Check if any student is paired with a student they had already teamed up with. If no, then this test is a success. 2. ""To check if the new team creation algorithm does not allocate more than the max number of people per team"" 1.1. Set max number of students per team to 2. 1.2. Have 6 students bid for a topic. 1.3. Call the team creation method. 1.4. Check if any team has more than 2 students. 3. ""To check if students who have chosen their own team members are not swapped even though they might have worked together before"" 1.1. Make 2 students teammates. For convenience, let the students be 'A' and 'B'. 1.2. Set max number of students per team to 3. 1.3. Have a total of 6 students choose topics. 1.4. Check that in the team containing the 'A', 'B' is also present. 4. ""To check if the new_members flag is not set, then the team members should be the same for that particular assignment"" 1.1. Make four students, A,B,C and D. 1.2. Two teams where created, team A containing A and B, and team B containing C and D for an assignment with maximum team size 2. 1.3. Each team had unset the new_members option. 1.4. After running the method run_intelligent_assignment, the teams where checked to see if they are still the same. 5. ""To verify if the student team history is returned correct: The teamed_students method is invoked there are no previous teammates"" 1.1. Verify that the returned hash is empty 6. ""To verify if the student team history is returned correct: The teamed_students method is invoked when the student has team mates."" 1.1. The teamed_students method is invoked with name_required set to true. 1.2. Verify that the names of the previous teammates are returned. 7. ""To verify if the student team history is returned correct: The teamed_students method is invoked when the student has team mates."" 1.1. The teamed_students method is invoked with name_required set to false. 1.2. Verify that the user ids of the previous teammates are returned. 8. ""To verify if the student team history is returned correct: The teamed_students method is invoked when the student has team mates."" 1.1. The teamed_students method is invoked with exclude_assignment_id set to the current assignment id. 1.2. Verify that the user ids of team mates in the current assignment ids are not returned. 9. ""To verify if the student team history is returned correct: The teamed_students method is invoked when the student has team mates."" 1.1. The teamed_students method is invoked with include_assignment_id set to the current assignment id. 1.2. Verify that the user ids of team mates in the current assignment ids are only returned. 10. ""To verify if the top trading cycles is working correctly"" 1.1. An assignment is created which implements the intelligent bidding. 1.2. 4 students are created, of which 2 have an history of an assignment with the other 2(these are mutually exclusive) 1.3. The students are added to the assignment. 1.4. The students set the preference to be paired with new teammates. 1.5. The students prioritize topics. This is the bidding process. 1.6. The intelligent assignment is run for this particular assignment. 1.7. We expect that the student who have history together not be paired again, even if they have the same priority for the topics.","The document says what is to be done, but provides very little detail on how it is to be accomplished.  For example, how are you going to refactor the code?  The purpose of the workflow diagram is unclear.  The top part looks like a plan for refactoring, the bottom half is a plan for an integration test.","This is an impressively detailed and comprehensive piece of work, demonstrating your deep understanding of the subject area and your excellent command of technical language. Your explanation is logical and clear, readers can follow through your methods easily.

I appreciate how you laid out the process in a methodical sequence and included all the essential steps. Your mention of the top trading cycle algorithm and how to implement it shows your understanding of complex concepts. You have outlined your approach involving a mix of manual and automated processes clearly, especially with your inclusion of control flows and debug tips.

Furthermore, your suggestion for the toggle feature to allow for student choice is noteworthy as it places the control in their hands and respects their preferences. However, I would love to see an elaboration on the measures put in place to ensure fairness and balance in case some students consistently prefer to work with the same set of peers.

On a smaller note, whilst your explanation is solid, you should ensure your grammar and sentence structure is consistently correct to improve the readability of your assignment. For instance, phrases like ""All these factors make Expertiza a valuable asset for an instructor to guide his students through the course with much more effectual results."" could stand some improvements. ""All these features make Expertiza a valuable tool that instructors can use to guide their students with more effective results."" would have a better readability.

Overall, excellent work on the assignment. Be sure to work on these minor areas as you proceed. Your analytical thinking and comprehensive presentation are commendable. Well done!"
230,E1752,"Expertiza is an open source webapp built on Ruby on Rails stack. It provides a platform to students with various features like peer-reviewing projects, submitting work, form teams, viewing grades etc. The project is being built and maintained by students and faculty at NCSU. The file assignments_controller.rb handles the logic behind Expertiza assignments and enables the creation and managements of assignments by instructional staff. Besides regular CRUD operations, it also integrates multiple parts of the expertiza components, such as users of different authorizations and priorities, corresponding courses associated with the assignment, due date and so on. Therefore, further unit and integration tests are required to guarantee that these operations work as expected. And also refactoring on the code in this controller is needed to make it more readable and reduce the complexity at the same time. Our tasks are based on the motivations above. Software testing is a process of examining a program or application with the intent of finding the software bugs. In software developemnt, it is usually defined as the process of validating and verifying that a software program or application or product meets the specified business and technical requirements. Additionaly, software is tested to: 1. Detect and rectify and errors made during the development phase, 2. Ensure customer satisfaction in the application, 3. Ensure the quality of the software product and 4. Optimize the performance of the system. Our project is guided by the Test-First Development principle. We write passing and failing tests for use cases of the assignment controller, and then turn to refactor the code. During the project, we implement the tests and refactor in Agile methodology with our mentor Zhewei through weekly delivery. RSpec is a 'Domain Specific Language' (DSL) testing tool written in Ruby to test Ruby code. It is a behavior-driven development (BDD) framework which is extensively used in the production applications. The basic idea behind this concept is that of Test Driven Development(TDD) where the tests are written first and the development is based on writing just enough code that will fulfill those tests followed by refactoring. The Expertiza project makes extensive use of RSpec to test the various components of the application. Tests of our tasks are in the code file: spec/controllers/assignments_controller_spec.rb. 1. Creating new tests for each method, 2. Testing the each method and making sure the tests pass. All 22 tests were passed with zero failure on the final version of project code. Please refer to our detail project demo to see the testing in action. Refactoring of computer software or code is the process of restructuring existing software code without changing its external behavior or performance of the software application. Refactoring improves nonfunctional attributes of the software. Refactoring aids in code readability and keeps the code well maintained and easy to understand. 1. Replace magic numbers in deadline_type_id by constants with reasonable names; 2. Formatting the code for readability and convention; 3. Split large chunks of code in to smaller manageable chunks; 4. Extract simpler and specific methods out of blocks of codes to remove code duplications using DRY principle; 5. Rename existing methods with meaningful names for better readability without change on external functionality. Actions: code block split, method extraction and add meaningful constants Original <code> After refactoring <code> Here we first grouped the blocks of code according to their similarity of functions. Then we extracted simpler methods from each code block to make it more readable and reduce the complexity and coupling. It is obvious that after refactoring, this part is simpler and easier to maintain. In addition, we also replaced the magic numbers by constants according to the deadline type. Actions: split long code block and extract specific methods Original <code> After refactoring <code> The update method was refactored in the similar way to reduce the size of codes and improve readability. The definitions of those helper methods were placed at the bottom of the assignments_controller.rb. Actions: rename for consistent Ruby code style <code> After each refactoring procedure, we perform the testing to ensure the expected functionality in Rspec. For more cases, please check our GitHub project repo. The files we make change on are: app/controllers/assignments_controller.rb and app/helpers/deadline_helper.rb. <link> <link> <link>. <link> <link> <link> <link>.","First, it shouldn't be necessary to give background on software testing, refactoring, etc.  It would be good to have considerably more discussion of how methods had been refactored.  The revised version of the edit method is much shorter than the original version because much code has been factored out, but the factored-out code is not shown.  Ditto for update.  The tests are not included or described in the writeup. Moreover, it's not too useful having a copy of the code in the Wiki. it should be simplified with pseudocode so it's much faster to read.","Dear Student,

Thank you for submitting your assignment. It is evident that you have carried out this assignment with diligence and a thorough understanding of the topic. I am appreciative of the detailed explanation you have given regarding Expertiza, its functions, and the need for further testing. 

Your explicit awareness of the Test-First Development principle and its application in your project demonstrates your practical understanding of software development methodologies. Your inclusion of Agile project management as a means of executing your project further highlights your comprehension and ability to apply development principles.

Furthermore, your grasp of tools such as RSpec and their significance in testing is commendable. It was an inspired decision to exemplify the process undertaken to simplify the code and make it more maintainable.

I encourage you to continue such detailed application of theory and tools in practical scenarios. These are skills that are valuable not only academically, but also professionally. 

However, there is some room for improvement in clarity and formatting of your submission. For instance, you could provide the actual code, or snippets of it, that you refactored for a more illustrative demonstration of your work.

Additionally, next time endeavor to organize your work in readable sections or use bullet points for better readability. Lastly, incorporate hyperlinks in your text for easier access to your resources.

Overall, a commendable job. Keep up the good work! 

Best,
[Your Name]"
231,E1677,"This project will facilitate few text metrics to evaluate student's peer reviews. The text metrics will provide a result about the textual content, the nature of the review, whether it contains any sort of offensive or improper language, and quantify the sincerity of the review in general. The tasks that have to be completed as part of this project can be identified as follows: 1. Create DB table [review_metrics] to record all the metrics of volume, presence of suggestions, errors/problems pointed out by the reviewer and offensive words used in the review text if any. 2. Add a pop-up dialog or a label for both students (student_review/list) and for instructors by adding content in review_mapping/response_report page metrics column 3. Make sure the code works for both assignments with and without ""vary rubric by rounds"" selected. 4. Make sure the code updates the review text metrics table when the peer reviews are updated. 5. Sort the reviews based on the text metrics on the “Your scores” pages of students’ view 6. Create tests to make sure the test coverage increases. Currently, after completion of reviews, the reviewers can view their responses as shown in the screenshot below: Instructors can see the response of the reviewers. However, in order to analyze the quality of review given by the students, the instructors have to manually go through all the reviews given by every student one at a time. This could be a time-consuming process, and the reviewers may not be properly assessed. In order to ease the process of evaluating the reviewers, metrics that can analyze the text written by the reviewers can be added. This will give more information about the reviews given by the reviewers to the instructors evaluating them. The picture below shows the present implementation. The reviews do not show the metrics of the review, which could provide a quick summary of how the review is written/perceived. This picture shows how the reviews are displayed in the current implementation in Expertiza. The reviews are not sorted <image>. The UML diagram below shows the MVC design proposed as part of the project and the relationships between the different elements. The users being students and instructors, a single model called review metric need to be defined with its own controller review_metrics_controller which will have all the metric-based methods defined in it. The controller will update the attribute values in the review metrics table when a review is created or updated. This will then be visible in the views. <image>. TASK 1 - we will be adding a new model Review_metrics . This model will include all the metrics as follows: 1. response_id → int(11) → foreign key 2. volume → int(11) → # of [different] words 3. suggestion → tinyint(1) → if suggestion is given in the peer-review 4. problem → tinyint(1) → if problems or errors in the artifact are pointed out in the peer-review 5. offensive_term → tinyint(1) → if the peer-review contains any offensive terms There will be a consequent review_metric_controller which will include all the necessary CRUD operations for review metrics such as add, remove and update review metrics. We will be dealing with the following View files: 1. student_review/list.html.erb - for the student 2. review_mapping/response_report.html.erb - for the instructor TASK 2 - For each peer review , we will be defining the following metrics, which the reviewer/instructor will be able to view after hovering the mouse over over the respective icons (it will either be a pop-up or a label text) 1. Number of words average - Integer 2. Number of words for all the reviews in this assignment in this round if suggestion is given- Integer 3. The percentage of the peer-reviews which offer suggestions in this assignment in this round - Integer 4. If problems or errors are pointed out - Boolean 5. The percentage of the peer-reviews which point out problems in this assignment in this round - Boolean 6. If the peer-review contains offensive language - Boolean 7. The percentages of the peer-reviews which contain offensive language - Integer The picture below shows how the proposed design will look to the user. The icons from left to right, will be indicative of the following metrics. (NOTE: The icon images are not subject to any copyright rules) 1. Icon 1 -> Number of reviews 2. Icon 2 -> Indicative of Vulgar content 3. Icon 3 -> Indicative of Similarity of reviews 4. Icon 4 -> Indicative of Problems or Errors in the peer review 5. Icon 5 -> Indicative of Suggestions made <image> The code snippet below shows where the view will be updated when the icons will be added - review_mapping/list.html.erb <code> TASK 3 - When the instructor checks the condition 'Vary rubric by rounds' the new code should work either way. This will be done checking the boolean method is_varying_rubric_by_rounds and then proceeding to update the review_metrics table. TASK 4 - We will be defining an RSpec file in review_metrics_controller which will check that the metrics table is updated when a review is updated. TASK 5 - We will be sorting and displaying the reviews in the file list.html.erb which is part of views/review_mapping based on the number of words metric received from the review_metrics table. Updating a review will effect a change in the review metrics table, therefore this will dynamically change the order if the metric has changed. NOTE: Code snippets have not been shown for Task 3, 4 and 5 because present code does not exist. We need to create new view and new rspec test cases for the same. Iterator pattern is used as the design pattern. This pattern is used in order to allow us to iterate over the elements of a collection regardless of their implementation. In our case, the collection is the different responses given by a reviewer in one single feedback. Since we will be iterating over the different responses in a given feedback by a reviewer (where the different responses in a given feedback are the elements of the collection) in order to collect the text metrics, the design pattern used will be an iterator pattern. This will provide a standard interface for starting an iteration and moving to the next element, regardless of the implementation of the collection. Added label or pop up which will indicate the metrics as icons, as shown below. These icons will directly summarize the review in terms of predefined metrics. The reviews will be sorted according to the text metrics and will be displayed to the student on the 'Your Scores' page. This project provides us the opportunity to use the Ruby-NLP gem which has specific methods for analyzing language with predefined patterns. We will be entering a filter for a tentative list of foul words, which when detect will populate as a metric. Gem - ruby-nlp Gem - Automated Metareview The Automated Metareview has been used in parts in the present expertiza codebase but has not been implemented. We have take inspiration from the set of phrases such as NEGATIVE_DESCRIPTORS< SUGGESTIVE_WORDS which are some of the constants as part of the gem documentation. Features like Word Count, Text summarization, Language detection, Text similarity, parsers are all part of this gem file which has been taken as baseline while implemneting few of the features. 1. When an instructor views all Assignments and clicks on the Review Report, this is the view that pops up <image> 2. When an instructor clicks on View Review Metrics, the popup containing the Metrics for all the responses done by the particular reviewer are displayed in a tabular format. <image>. 1. When a student clicks on Other's Work after clicking on a specific Assignment, this is the view that pops up, containing a View Text Metrics for each review that the student has done. <image> 2. When the student clicks on View Review Metrics, the popup opens which displays the metrics for the specific review. <image>. As verified with the instructor, the scope for testing in this project will be limited to majorly UI testing. For user/reviewer, the steps will be as follows 1. Login to Expertiza with your credentials 2. Open the Assignments , click on Other Work 3. For every review entered, hover the mouse on the icons beside the review 4. The review will be summarised by caption texts on the icon like ""Good Content"" or ""Obscene Word usage"" or ""200 words reveiw"" 5. View the metrics for each review. Few of the Test cases added to the test file for Review Metric. <image> For the instructor, the steps will be as follows 1. Login to Expertiza with instructor credentials 2. Open Manage Assignments 3. Select the Assignment. Click on the icon 'View Reviews' 4. Depending on the stage of the assignment , the reviews will be listed in the order they were filled. 5. Metrics will be displayed on hovering the mouse over each icon. 1. ReviewMetric.rb 2. Response.rb. 1. popup_controller.rb 2. review_metric_controller.rb. 1. student_review/list.html 2. review_mapping/review_report.html.erb 3. popup/view_review_metrics 4. popup/view_student_review_metrics. Link to Github repository : <link> Link to Pull request : <link>. 1. <link> 2. <link> 3. <link> 4. <link>.","No relevent information in document. Document only consist of images and code samples, no information about design of project
Josh: Documentation is a concatenation of diagrams and code snippets, with almost no prose.
","This is indeed a comprehensive assignment, showing clear understanding of the problem and a well-thought-out solution. The thoroughness with which each task has been explained is commendable. The use of UML diagrams and markup language to denote the implementation and coding part is appreciated. 

Your in-depth explanation of the metrics to be considered and how the database schema would look like is excellent. However, careful consideration should be given to the potential false positives and negatives that could arise from the offensive term detection process, as some words might have different connotations depending on the context. 

It's excellent that you have broken down the work into specific tasks, this will definitely help in executing the project without any hassles. Also, the instructions provided for user-reviewer and instructors are complete with images highlighting the functionality, which will help users understand and use the system effectively.

One recommendation would be to add test-cases for the cases where an error may occur. Also, incorporating details on handling edge cases would be beneficial. 

I also recommend adding comments to the provided code-blocks, which describe what the code accomplishes, to make the project more understandable to people not involved in the project's development.

Overall, great work on the presentation of content, efforts in detailing the features/functionality, and breaking them down into manageable tasks. The project shows a lot of potential with a clean and easy to follow plan and a clear presentation style."
232,E1688,"Expertiza is an open source software to create reusable learning objects through peer reviewing of team projects and submission of project design documents. In the final project, there are two major changes that will help in improving user experience. The purpose of this project is: This feature will help expertiza users to achieve faster resolution to the problems they face. A new UI support needs to be given to enable them to directly send the issues they face to expertiza support through email. The purpose of this enhancement is to reduce the wastage of space on the Manage Assignments page. The current implementation of expertiza does not provide any feature for users to send feedback in case they face any problem. This new feature allows a user to send a complaint or feedback to expertiza support via email. Captcha needs to be implemented so as to prevent the abuse of the this feature. Currently the data to be displayed for each assignment takes 2 lines whereas the “actions” icons are taking up 3 or 4 lines for display. This is a wastage of space on the screen. <image>. This design unit includes following tasks: 1. Provide ‘Expertiza Support’ button on top of website. 2. Create a feedback support form page which should be available to all the users including unauthenticated users. 3. The form page should have fields for email Id for fetching email id of the user facing issue, a description input box where user can describe the steps for reproducing the issue. 4. This form should have field email auto filled with email on user profile if the user has logged in. 5. This form should provide random captcha to prevent abuse of this feature. 6. Submitting this feedback form page should trigger email to “ <link> ”. 7. The project should provide User with an acknowledgment saying email has been seen and Expertiza Support will try to fix the issue as soon as possible. To eliminate the extra space on Manage Assignments page because of less data and more “actions” icons, we will replace all the “actions” icons with a single “actions” icon embedded with a pop up panel. So when a user clicks on this new “actions” icon, it will throw a pop up containing all these previous “actions” icons and the user can select one of them to invoke one of these actions (edit, delete, add participant, create teams, etc...). An error occurred while attempting to extract the child content. 1. Input: User clicks on Expertiza Support and issue description and captcha as input. The email id is auto-filled from the user profile. 2. Type of Input: Feedback Form 3. Source of Input: User interface 4. Processing: Validate input fields and form submit 5. Outputs: Email sent to Expertiza support and acknowledgement displayed to user. <image>. Provide a new icon in “actions” on tree display, then when you click on this new icon a new popup appears. This popup has all the previous “actions” 1. Input: User clicks on new icon 2. Description: new popup appears with all actions in it 3. Type of Input: Click on the new icon 4. Source of Input: User interface 5. Processing: Create popup 6. Outputs: Pop up Panel displaying all the previous “actions” icons for the user to choose from. Model : send_sync_message method with expertiza_support_helper(new helper class defining the body of email) will be responsible for sending email to expertiza support. Controller : Feedback form submission should call MailerHelper’s send_sync_message method with the appropriate parameters specifying that an expertiza user is facing some issue. View : A new expertiza contact support form to be created with fields email id, description of issue, captcha and submit button. <image>. A UI change replacing displaying tree with an icon. On click event will create a pop up panel. User selection will trigger the appropriate action(this functionality will not be changed). View : Instead of displaying all the ""actions"" icons, we will replace this code to display a single ""actions"" icon with an embedded pop up panel. <image> <image>. 1. T.1: Contact Support’ button should be seen to all the users (even unauthenticated). 2. T.2: For unauthenticated users, clicking on ‘Contact Support’ should redirect to feedback support form page with blank email id field, description and captcha 3. T.3: For authenticated users, clicking on ‘Contact Support’ should redirect to feedback support form page with email id auto-filled with email on their profile, description and captcha. 4. T.4: Before form submission, none of the fields should be blank. Appropriate blank error message should be shown otherwise. 5. T.5: Captcha should be random on every page load. Error message saying ‘incorrect captcha’ should be shown in case user fails to provide the same text of captcha. 6. T.6: Email should be received to Expertiza support “expertiza-support@lists.ncsu.edu” on the form submission and the user should get an acknowledgement of email received. 1. T.1: Ensure that when a user click on the new “actions” icon, it throws a pop up panel with all the old “actions” icons. 2. T.2: Ensure that Edit icon redirects the user to edit assignment view. 3. T.3: Ensure that Delete icon deletes the assignment. 4. T.4: Ensure that Add TA icon redirects the user to Add TA view. 5. T.5: Ensure that Add Participant icon redirects the user to Add Participant view. 6. T.6: Ensure that Create Teams icon redirects the user to Create Teams view. 7. T.7: Ensure that Create Assignment icon redirects the user to Create Assignment view. 8. T.8: Ensure that 360 assessment dashboard icon redirect user to One_course_all_assignments page of assessment360 view. 9. T.9: Ensure that Copy icon redirects user to Edit course page. 10. T.10: Ensure that Make public icon redirects user to the tree display page.","The document shows UI mockups, but it doesn't explain anything about how the implementation will be done.  It lists ""files to be considered,"" but doesn't say how they are going to be modified.  It is thus too ""early innings"" to be a good synopsis of the design.","Dear Student,

Great job on this assignment! I can tell you put a lot of thought into developing this project. You clearly pointed out the shortcomings in the existing Expertiza system and developed concrete steps to rectify them.

I appreciated your use of diagrams to visually illustrate the changes you recommended, and your decision to implement Captcha to prevent abuse of the system shows you're thinking strategically about how new features can be exploited.

I'm also impressed with your detailed delineation of the required tasks, with your comprehensive input, processing, and output descriptions, and how you have thought about the user interface and the changes required to improve user experience.

However, there are a few areas for improvement:

1. Clarity: The explanation and enhancement process can appear disorganized and hard to follow in places. It might benefit from use of headings or bullet points to divide your text into manageable sections.

2. Presentation: Your writing could be more concise and to the point. Lengthy text might make it difficult for the user to follow along.

3. Explanation to Non-Tech Savvy Users: The detailed technical description of tasks can be overwhelming for non-technical personnel. Including a simple summary or overview of tasks can help a wider range of users understand your proposal.

4. Hypertext Links: Mention of ""<image>"" and ""<link>"" suggest that you intended to include links that were ultimately missing. Check your work for such oversights.

5. Testing: More details could be included on the testing process particularly on how to validate correct functioning of the new features.

Overall, you've done a good job of identifying important issues and coming up with solutions to address them. With a bit more attention to presentation and accessibility for all users, I'm sure you could do even better. Keep up the good work!

Best Regards,
[Your Name]"
233,E1700,"Expertiza is an educational web application created and maintained by the joint efforts of the students and the faculty at NCSU. It’s an open source project developed on Ruby on Rails platform and it’s code is available on Github. Using Expertiza students can bid for a particular project topic and the faculty assigns the same to different groups. Students can track their grades for previous projects and make new submissions for current projects. It also allows students to review each other’s work and improve their work upon this feedback. Currently the instructor creates rubrics for an assignment through questionnaires which students use to review other students' submissions. The only way reviewers can suggest some more changes to the author is by using the 'additional comments' section in the review form which is not very helpful. In this project we will be looking towards improving this functionality by adding an extra medium through which multiple reviewers can collectively comment on the author's work and collaborate their answers in a constructive way. We are planning to achieve this by enabling alert messages to the authors and the reviewers who will use the newly created Google document links embedded into Expertiza. For every Assignment created, the Instructors have been given a new criteria to make the review comments as anonymous. Depending on the criteria set, the Authors will be provided with notifications on two things: the permission setting of the Google Doc(Allow users with link to comment only) and to make reviewer comments anonymous. The Author of every Assignment will then need to create a Google doc based on these notifications. The links once submitted can be accessed by reviewers to submit their reviews. The reviewers also get notifications if they need to review the Assignments anonymously. If the anonymous setting is enabled, the reviewers will need to log out from all their Google accounts before opening the Google doc. Once on the Google doc, the reviewer's comments will be posted anonymously, the reviewer's comment will be anonymous to both, other fellow reviewers as well as the author. This feature will help the author to better understand where is his work exactly lacking and how exactly should the changes be worked upon based on the comments received. The reviewers will just need the Google doc link to post comments and it wouldn't be required to login into Expertiza or any google account for using this feature. 1. The alert message should only pop up when the Faculty has indicated to do so (alert messages only whe Google Doc hyperlinks are uploaded, and when Anonymous commenting is Enabled ) 2. The Google Doc link needs to be added on the Assignment submissions page by the Author of the project 3. The settings for the Google Doc should be set to ""Anyone with the link can comment"" by the Author 4. A Peer Reviewer needs be directed not to login to any Google account to comment on the doc, and all Peer Reviewer comments shall be anonymous 5. Multiple commenting at a specific instance is taken care of by the Google Document settings and it will be placed one below the other. The first phase of our project aimed at embedding a Google document which enables the project Author to automatically generate a Google document with specified permissions for the reviews such that when a reviewer makes a comment it appears without his identity. We succeeded in authorizing the user to the Google documents by using the google-client-API (aouth + signet) credentials and the API console also showed positive results for the ""request"" sent over to the client and created a google document but to access that particular binary file we had to set the permission rights of the service account for which the google document is created which is different from the credentials account. We also tried hard coding and giving all access rights to anyone who wanted to open the file but it seems practically impossible to get those rights. The second half of the project aimed at creating a flash box which directs the author to set the comment rights on the review google document as decided by the professor subject to the condition and complexity of the project. This will happen on the go and the author is notified to ""enable commenting rights only"" only if the faculty checks the option for that particular project. On the other side whenever the reviewers click on the google document link attached to the project for reviewing or commenting on a project they will get a notification alert to log out of all google accounts in order to assure the anonymity of the reviewer. This is done because google documents does not support complete anonymity. In this the assumption is that the google doc is created in the same manner as the other hyperlinks are added. 1. When an instructor will create a new assignment, he should be able to select a checkbox if he wants to enable anonymous commenting for google docs. 2. If the instructor selects this then the authors will not be able to identify the individuals commenting on the doc. 3. The below image shows how we aim to create a checkbox about the same for the instructor. <image>. 1. The authors need to create a Google doc, input their assignment content for Review and submit the hyperlink as shown below. <image> 1. We will try to create an alert message whenever the author submits a google doc link. 2. The alert message will ask the author to change the sharing settings of the doc to 'Anyone with the link can comment'. 3. This message should be thrown only when the author submits a google doc link and not any other link. 4. The below image shows the desirable alert message when author tries to submit a google doc link. <image>. 1. If the instructor has enabled anonymous commenting on google docs then the reviewer should see an alert message which will ask the reviewer to log out from all google accounts before opening the google doc link. 2. The reviewer will need to logout because google allows anonymous commenting on a doc only if the user is currently not logged into any google account. 3. The below image shows the desirable alert message when a reviewer tries to review a project which has google docs in its submission and anonymous commenting is enabled. <image>. 1. As explained above, once every author creates a Google document for their assignment, they can input their content for reviewal. (For example, their wikipedia article) 2. On following the above permission settings and security points, authors can upload the shareable link for commenting 3. One reviewers anonymously comment on the doc, this doc would look like the below image: <image>. As mentioned in the requirement document, there are 2 security risks associated with this project, they are: 1. A situation where the peer reviewer forgets to logout would result in his/ her name being added to the history of document edits which will reveal the identity. 2. Possible security violations like an user with access to the link deletes all the content on that doc. Proposed solution to mitigate the risk: 1. When a reviewer goes on the page of submitted contents, he'll be shown an alert message to logout from google accounts if there exists a google docs link in the submitted content and instructor has enabled anonymous commenting. 2. The authors of the project will be shown an alert to modify the settings of their google doc to 'Anyone with the link can comment' when they submit a google doc link. <image> <link> ScreenShot of google document settings 1. As it can be seen, Google doc has 3 access levels and the 'can comment' option will allow the users only to add more comments on the Google doc. They won't be able to edit or delete previously entered comments. 1. The new outcome will involve accessing the database table 'assignments' and we will make a change to the schema of the table by adding a column 'allow_anonymous_commenting' of the type 'Boolean' to indicate whether the professor has asked the project developers to have a review document created with the rights of anonymous comments. 2. To incorporate the database changes we will generate a migration file in the ""db"" migrate named: '_add_allow_anonymous_commenting_to_assignemnnts.rb' 3. The 'factories' file in the spec will have a variable added with the default value set as 'FALSE' 4. '_genral.html.erb' page in the edit assignments view will have a 'check box' and a label added to it. 5. A function will be added in the 'assignments_form' model which sets the visibility to false/ true depending on the input 6. Newly added Google doc hyperlinks will be saved with other assignment hyperlinks in the 'submitted_hyperlinks' column of 'teams' table. This UI enhancement will be tested to check whether the following required functionalities are implemented successfully: i. Any user having the doc link should only be able to comment on the Google doc ii. Alert should be shown to the authors only while submitting a google doc link iii. Users need not login to comment in the Google doc iv. Alert should be shown to the reviewers only if the submissions contain a google doc link and anonymous commenting is enabled v. Multiple comments made at the same time should not lead to any conflicts. 1. <link> 2. <link> 3. <link>.","Problem 1-4 should be requirement 1-4 (use standard term in software development). A workflow / interactioan diagram would've been nice to get an overview of how you solve the problem (list of files changed is not useful, it can be obtained from github). ","Dear student, 

Excellent work. You have developed a thorough and well-structured document, detailing all aspects of the project, from context to execution and testing. Your idea of embedding Google docs into Expertiza to facilitate anonymous and collective commenting is innovative and will be beneficial in improving the project's review system.

You presented the project with clear explanations, making it easy to understand your objectives, how you accomplished them, the challenges you encountered, and how you addressed them. 

Also, I appreciate your preliminary attention to potential security risks and how you mitigated them. It shows your ability to foresee potential problems and initiative to solve them proactively, which is a crucial skill in software development.

However, you might want to be more precise in explaining your usage of Google-client-API, including the documentation of obtaining the API Key and how you implemented it in Expertiza. Also, while mentioning that you used Ruby on Rails for the project, listing your dependencies or the gems you utilized would be helpful.

There are also a few areas you might want to improve on:
- At times, the text seemed repetitive; for example, you have mentioned the use of an alert message and anonymous commenting numerous times in different sections. Ensure your work is concise and avoid redundancy.
- You mentioned images and links, but they are not included. Please make sure to attach them for better comprehension.
- Please include specific codes or pseudocodes you used in implementing some of the critical features for those who might want to learn or understand better.

Overall, you did a good job of providing comprehensive documentation for your work. I am looking forward to seeing the code and your submission for future projects. Good job!"
234,E1914,"Expertiza is a web application where students can submit and peer-review learning objects (articles, code, web sites, etc). It is used in select courses at NC State and by professors at several other colleges and universities. This document contains the description of the changes that we made to users_controller, how we refactored it, our testing results and some design decisions that we took while making these changes. Problem : The users_controller.rb file included the standard CRUD methods for a User model along with methods for other workflows. The users_controller.rb file also handled the creation and management of a RequestedUser object in addition to handling the user object. Solution : Earlier, there was no controllers for a RequestedUser object and these were handled by the Users controller itself. We separated the RequestedUser workflow from the Users and we renamed the RequestedUser model to AccountRequest. As a part of this refactoring activity, we created a new controller called the account_requests_controller to handle the workflow of an AccountRequest. The following methods were moved from users_controller to account_requests_controller. 1) created_approved_user 2) list_pending_requested 3) request_new 4) created_requested_user_record 5) roles_for_request_sign_up 6) requested_user_params. Problem : The users_controller included a few methods which lacked documentation. Solution: 1) What the method does: This method is used to find the list of roles the current user can embody. 2) Where the method is used: Used to display a drop-down selection of roles for the current user in the views. 1) What the method does: show(): If the current user is a student, they should only be able to see information about themselves. All other people should be able to see information about themselves or other students. If the request to show() passes these checks, then they are shown the view 'show'. Otherwise, they are redirected to the home page. show_selection(): If the role of a user's parent is less than the current user or if the current user is requesting to see itself or if user's parent_id does not exist then the show() method is called. All these conditions boil down to whether the current user of the system is authorized to see/edit the information about the user specified in the params. If the requested user does not exist or if the current user is not authorized to see the requested user, then the current user is redirected back to the list page. 2) Scenarios in which show_selection is called: in users/list.html.erb, a list of users is shown. On top of the list there is a functionality to search the list. When a person searches for a particular student, and selects that student, the show_selection method is called. If the person is allowed to see that student, the user is directed to the show() method. Otherwise the person stays on the list view. 3) Scenarios in which show() is called: From the edit.html.erb, if the person wants to see the information instead of editing it. From show_selection() as described above. Problem : Methods in the Users_controller were not named to convey exactly what they did. Solution: The get_role method was named more like it would be in Java. It was renamed to 'role' because that is how it would be named in ruby. We chose to keep the method in the controller instead of moving it to the model because it does not alter the data structure and it also has selection logic. Problem : The forms that come after ""Request Account"" button is clicked need to be changed. Solution : Only instructor accounts can be created, so the drop-down was removed. All form labels were bold-faced. The “Self Introduction” label was re-named to “Self-Introduction”. The text-box for the self-introduction field now includes a useful hint of what is expected in the text-box. The hint is ""Please include a website name"". <image>. <image>. Problem : When a list of all users are shown, the list is not paginated. So the instructors see a list of all users that have enrolled for a course over all the years that they have offered the course. Solution : The existing project does not have the feature of pagination for the user list. So, currently, all the users are shown to the instructor. The paginate_list method is supposed to paginate the list of users. The method was not called anywhere and also the method logic was incorrect. With the latest implementation, the pagination is added with dropdown option - ""25"", ""50"", ""100"" and ""ALL"". The method ""paginate_list"" is corrected and called at right place. The default option is kept to ""25"" to reduce the web-page loading time. <image>. <image> As can be clearly seen, different pagination options are now provided at the lower part of the view. Problem : Since we created a new controller, tests for this controller did not exist. All those tests were written in the users_controller since that was where the methods were located earlier. Solution: We moved the tests from the users_controller_spec.rb file to the newly created accounts_request_controller.rb file. We also changed some tests in account_request_controller to route to their appropriate tests. It can be seen that all 11 test cases passed for account_request_controller. <image>. Problem: The pagination for users_controller was not tested correctly in the previous implementation. We fixed this issue by writing a test for this. Solution: It can now be seen that all 18 test cases pass for users_controller. <image>. The <link> to our project instance. 1) To view pending account requests: Login as the administrator. Username = administrator5 Password = password Navigate to Manage(in the horizontal tab at the top of the page) -> Pending Requests. You will be able to see all the pending requests. The method that serves this view is in the newly created controller. So this is one way to test if the controller we wrote and the routes we configured are working. 2) To test the changes in the form for Account Requests: Go to the login page. But do not log in. Click the Request Account button. You will be able to see the labels in bold and a hint of what should be entered in the last textbox. 3) To test the pagination: Login as an instructor. username: instructor6 password : password Navigate to Manage(in the horizontal tab at the top of the page) -> users. You will be able to see a list of users and page numbers where the list ends. You will also be able to select the number of users to show on each page using a dropdown at the top of the list. 4) Other changes: To check if the build passed or not, <link> is the repository which we forked from expertiza. If you navigate to this and scroll down to the README, you should be able to see the build status and test case coverage statistics. You should also be ble to see the build status and all checks at the end of the pull request. The other changes we made like renaming methods and documenting code are not so visible in the GUI and will have to be seen in the code. During the second round review, we discovered that we had not synced the Main Expertiza beta branch with our forked beta branch, so we have synced our branch with the main Expertiza branch and made some commits to fix issues in Travis CI builds. Eventually, the Travis CI builds pass and can be seen in our pull request. 1) Partial Views : There are some partial views which are related to displaying forms to create/edit a user in the Users view. The same partials were earlier being used for displaying forms for requesting a new account. Now that we separated the two controllers, we had the following options to deal with these duplicated partials. Option 1: Keep accessing the partials in the users view from the newly created Accounts_request view. This would make the code DRY but harder to understand. Option 2: Duplicate the partials in the accounts request view.This would make some render partial statements hard to read but would make the code DRY. Option 3: Create partial files in the views folder. Have Users_controller, Account_requests_controller access these partials. The code becomes DRY and also readable. We decided to go with the second option. Even though these forms contain the same code right now, due to changing requirements in the future, these views may need to be changed which would allow us to add more functionality in the future. This option gives some flexibility to the accounts_controller to modify the form without affecting the User's form. This design decision was taken after discussions with our mentor. The partials that are now duplicated are: _email, _name, _institution, _password, and _prefs which can be found in user and account_request views. 2) Refactoring variable names : We refactored the variables names from requested_users to account_requests (in views, controller actions, etc.) since requested_users is a bad naming choice for our variable. As we are referring to AccountRequest model in our controllers, such renaming makes sense here. For example: <code> makes more sense than <code>. 1. Expertiza Documentation: <link> 2. To show our design changes, we have hosted our implementation on VCL. The link is: <link> 3. Link to the pull request <link>.","On the micro level, every change made was well described.  On the macro level, it's not clear why you listed the changes in the order that you did.  More structure would've been helpful.","The feedback:

Dear Student,

Thank you for your detailed write-up of the comprehensive work you have done in implementing changes and refining the functionalities of Expertiza web application. There are several areas where your work is commendable. The orderly subdivision of your report into problem and respective solution makes it very easy to follow. I am especially pleased with the rigorous code refactoring you conducted, ensuring your code adheres to the first principles of programming.

Foremost, the steps you took to separate the RequestedUser workflow from the user's controller and the subsequent renaming it to AccountRequest is an excellent design decision that makes the overall functionality more effective and specialized. This change, alongside the distinctive testing and verification, signifies the great understanding you have of the functionalities and how they interact. 

I also appreciate the depth of thought applied in your refactoring activities. Your choice to rename the 'get_role' method to 'role' based on Ruby naming conventions and your concerns about not altering the data structure represent a keen attention to detail and knowledge of the programming language. The same applies to your clear and detailed documentation, which goes a long way in enhancing the readability and maintainability of the code.

Your solution to the pagination problem was a welcome improvement. The added feature to select the number of users to display each page is a neat touch. It will give users much greater control over their interaction with the application.

In the future, it might be helpful to add more context, i.e., the underlying reasons, when noting the problem statements. While your solutions are exceptional, understanding the issues with the initial state in greater depth would provide relevant background and give your work even more merit.

Nonetheless, it's great to see you taking initiatives to ensure your tests are moved and functioning correctly with the new controller and that all test cases are passing. Remember, the testing phase is vital and your input here shows a clear understanding of this.

Lastly, I admire your decision to go with option 2 during the second round review. Thoughtful design decisions make for great user experience and your reasoning shows a forward-thinking approach.

Overall, a very well done job! You have showcased a deep understanding of both the subject matter and the best practices of software development and inclusive design. Your thoughtfulness in problem-solving is commendable. I encourage you to continue applying this level of analysis and problem-solving in future projects. Keep up the great work!

Kind regards,
[Your Name]"
257,E1998,"Expertiza is an open source project which can be used by instructors for a multitude of use cases such as creating assignments of various types, creating rubrics, questionnaires, allowing teams to be created (for group assignments) etc. It also allows grading of the assignments created, and provides the ability to let students peer review other students' work. Background and Problem Statement The questionnaire/rubric creation feature of Expertiza also allows weights to be added to the questions being created, thereby allowing an instructor to create a questionnaire with relative ordering among the questions from a grading standpoint i.e., correctly answering a question with a higher weight will fetch more marks as compared to correctly answering a question with a lower weight. However, the same functionality is not present for quiz questionnaires. Quiz questionnaires are essentially a way to ensure that students review others' work genuinely. When an assignment has quizzes enabled, each student gets an option to create a quiz for each of his/her reviewers after the initial submission is done and a review round has occurred. The flow which is followed from quiz creation to score evaluation is as follows: <image> While creating this quiz, a student is supposed to ask questions related to his/her work which ideally a reviewer must be able to answer. Once it is created, reviewers are able to answer these quizzes and the corresponding scores are evaluated for each quiz separately. Ideally, each question should have a weight associated with it which a student creating the quiz should be able to specify, which in turn should be used while calculating scores for those taking these quizzes. However, currently, there is no way to specify weights for individual questions while creating quizzes and hence scores are being calculated by giving each question equal weightage. Goal of the Project The goal of this project is to understand the cause of the aforementioned issue and to ensure that the weights associated with questions are taken into consideration when grading all types of questionnaires involving weights. Our main focus will be to implement weights for quiz questionnaires, To achieve this, first we will have to introduce a way for a student creating a quiz to be able to enter weights for individual questions. Once weights for each question are being successfully stored, we can proceed to change how scores for each reviewer(for a particular quiz) are being calculated such that these newly added weights are also being taken into consideration. Expertiza allows multiple questionnaires to be associated with an assignment. For instance, an assignment may have 3 questionnaires - one each for reviewing teammates, one for reviewing others' work, and one for giving feedback to the reviews received. There are various questions that can be created for each type of questionnaire but they can be broadly classified into two types - weighted and non-weighted. The user-submitted responses to these questions can be accessed via a view called score_view which extracts results from three different tables - questions, questionnaires, and answers. This view has a column named question_weight which is populated by the user entered weights for weighted questions and is set to null for non-weighted questions. This is the view which the code uses for calculating grades for a particular assignment. Currently, for questionnaires other than quiz questionnaires, an instructor creates a rubric for the questionnaire where he/she can specify weights for each weighted question that exists for that questionnaire. However, the way it is implemented is that the instructor first has to create a question without specifying any weight. The weight for this newly created question is set to 1 by default. After this is done, the instructor has to edit that question to trigger a way to enter a weight for that question. This method for specifying weights is non-intuitive and cumbersome. For quiz questionnaires on the other hand, there is no way to enter weights for newly added questions at all. The weights are set to 1 by default for all the weighted questions and are not modified henceforth. As a result, scores are calculated for each quiz for a particular reviewer by giving equal weightage for each question. This calls for a complete overhaul of how scores for quiz questionnaires are being calculated to include weights which will need to be accepted from the student creating the quiz. We have utilied the Facade Design Pattern to hide the complexity of quiz score calculation and provided a single method quiz_score to calculate and return the score of the quiz considering weights on each question. The method makes the query call which gets the question, the weight, the corresponding answer score obtained by the student. Then it converts the values into a total and calculates the final percent score obtained by the student in the quiz. The method encapsulates the entire logic and returns the total weighted score for the corresponding quiz instance. The following files were modified to accomplish the aforementioned changes: 1. questionnaires_controller.rb add_new_questions The weights were being hard coded earlier, which have now been replaced by the user specified weights via the UI. This method creates new questions when creating questions in questionnaires of types such as review questionnaire, author feedback questionnaire, teammate review questionnaire, etc. save_new_questions This method saves questions when a student creates a quiz questionnaire. There was no way to associate weights with questions in quiz questionnaire earlier, we've made changes to allow adding weights to questions in a quiz questionnaire. The corresponding changes are present in this method. 1. _new_question_template.html.erb The input field for adding question weights at the time of creation of questions in a quiz has been added to this file. This functionality was not present earlier, all questions in a quiz were associated with a default weight of 1. The weights entered in this input field are used by the save_new_questions method in questionnaires_controller.rb 1. _questionnaire.html.erb The input field for adding question weights at the time of creation of scored questions for questionnaires of all types except quiz questionnaire has been added in this file. This functionality was not present earlier, as questions had to be created first and then edited to change the default weight (1) associated with it. The weights entered in this input field are used by the add_new_questions method in questionnaires_controller.rb 1. _question_weight.html.erb This file contains the JavaScript code which handles the conditional display of the field to input weights depending on the type of question the user wants to create in the above view. This code ensures that the field is displayed only if the user is trying to created a question with which weights can be associated - questions of type Criterion and Scale. 1. edit.html.erb This files was had to be modified to include the above partial which contains the JavaScript for conditional display of the input field for entering question weight. 1. quiz_response_map.rb quiz_score This method has been modified to include the logic for calculation of quiz scores. The added logic incorporates the weights which the user can now input corresponding to questions when creating quizzes. 1. score_view.rb readonly This method has been modified to allow factories of this class to be created for testing. The following file was modified to included automated tests for creation and grading of a quiz questionnaire: 1. quiz_spec.rb This file contains the necessary changes for testing the entire flow, right from creating a quiz to submitting it, and finally scoring it. The test has been created to check all the modifications we've made to the above files. Also, some of the existing tests had to be modified to incorporate the changes in the way the score is calculated using the new logic. 1. quiz_factory.rb This file contains the factory for score_views which is used by quiz_score to compute the grade by taking weights into consideration. As a part of creation of RSpec tests, we created an example in quiz_spec.rb file which sets up the necessary actions before a student A can create a quiz questionnaire. We then proceed with quiz questionnaire creation and associate weights with questions created. We create all three types of questions that can be created in a quiz questionnaire - True/False questions, Multiple Choice Radio questions and Multiple Choice Checkbox questions. Further, we login as student B who has reviewed student A's work and take the quiz. Finally, we submit the quiz and ensure the that the quiz is scored after taking the weights associated with the questions into consideration. Please follow the following steps to test our changes and/or reproduce the functionality implemented by us: 1. Find an assignment and find some participants for the assignment using add participant option corresponding to the assignment in the assignment page. 2. Enable the has quiz option for the corresponding assignment if it is not already enabled. 3. An input field will appear at the right of the has quiz checkbox, please enter the number of questions in the quiz in that checkbox. 4. Now, modify the submission deadline of assignment to some date in the near future. 5. Also, select yes for the stage in which you wish to allow students to take quizzes in the due dates tab. 6. Login as one of the participants (or impersonate one) say A, submit something in the your work section for the assignment. 7. This will enable the create quiz link in the your works section, please go ahead and create a quiz. 8. Now, modify the submission deadline of assignment to some date in the past, so that the assignment is now in review stage. 9. Now login as another assignment participant say B, review A's work. 10. Click on the take quizzes link, a radio button with the quiz created by participant A should appear, go ahead and take the quiz. 11. The quiz will be graded taking into consideration the weights you used for creating the questions in the quiz as participant A. 1. Video Walk-through Link: <link> 2. Forked Repository Link: <link> 3. Pull Request Link: <link> 4. Demo Link: <link>.","Well-written report, with good descripitions of the changes that were made. Tests should be a separate section, though.  Automated testing should be addressed in a separate section.","Your assignment submission is well-articulated, detailed, and enlightening. You have done a fantastic job explaining the Expertiza system, identifying the problem, and planning a solution. Your exploration of the issue with the quiz scoring system is thorough, and your proposed remedy illustrates a deep understanding of the system's architecture and functionality.

Your application of the Facade Design Pattern to hide the complexity of quiz score calculation and provided a single centralized method for calculating weights showcases your sophistication and skill as a developer.

Your detailed list of modified files and thorough explanation of modifications made, including those aimed at testing changes, helps in understanding the whole procedure used to solve the problem. It is also noteworthy that you have addressed necessary changes in tests as well in the solution.

The step-by-step process for testing the changes along with the links provided will be highly beneficial for understandability and for future reference.

I appreciate your thoroughness and insight, your submission demonstrates that you have done an excellent job understanding the codebase, assessing the problem, and developing a reasonable solution.

However, I have a few suggestions for improvement:

- There could be a better segmentation of sections, like problem statement, proposed solution, files modified etc., for better readability.
- Avoid usage of long sentences crammed with information. Split it into smaller ones to enhance readability.
- The use of bullet points or numbered lists could improve readability and comprehension of your solution steps.

Overall, this is a very comprehensive submission. Well done!"
258,E1967,"Find our PR here : <link> Team members : 1. Bin Patel (bpatel24) 2. Omkar Kulkarni (oskulkar) 3. Pranav Gaikwad (pmgaikwa) Mentor : Mohit Jain To test our code in a real Expertiza environment, please see instructions on <link> page (Expires Nov 9, 2019). In Summary report for assignment (grades/view_team?id=xxxx) for instructors, the author feedback section list a different set of users than the reviewers. It should list the team's feedback to all its reviewers to this particular assignment. Currently, the Author Feedback section for a team shows the feedback the team received from other Authors they reviewed earlier. The Author Feedback section, however, should display the feedback the team gave to their reviewers. To explain these ideas in more detail, let's consider the following scenario : Team 22 has two members in the team : Team Member 1 , and Team Member 2 . This team reviewed assignments of Team 29 and Team 30 . Currently, the author feedback section displays feedback given by Team 29 and Team 30 to Team 22 . See following figure. <image> Now, consider that the Team 22's assignment was reviewed by members from Team 23 and Team 24 . Then, the Author Feedback section should display the feedback Team 22 gave to the members of Team 23 and Team 24 . <image>. List of files with code relevant to this issue : 1. Controller : <link> 1. View : <link> 1. Model : <link> 1. Helpers : <link> <link> method in grades_helper.rb is responsible for providing information about reviews, metareviews, author feedbacks, etc. For the purpose of this issue, we only need VmQuestionResponse data structure defined in this file. We do not need to make changes in this file. 'Author Feedback' tab in the UI contains tables for each team member with detailed breakdown of their feedback. The method <link> is called before the review table is rendered in the view. This method does different things based on which tab we are on. In this function, we only have to change the if block for 'Author Feedback' tab. Apart from these, we need to change the heatgrid view in the UI. Current view cannot be used for Author Feedback for following reasons : 1. The heatgrid is configured to use Reviewer id as column title. In case of Author Feedback, we want Reviewee id as column title instead. <image> 1. The row title in detailed scores is not appropriate for Author Feedback. We need Reviewee Id there. <image> 1. Logic to show total number of feedbacks in the title row doesn't work. <image>. 1. File : <link> 1. Line Numbers : #61-#70 We only need to change the if block responsible for Author Feedback tab. Logic : 1. Get the list of all FeedbackResponseMaps where current Participant is a reviewer. The participant id is already passed to the add_reviews() method. 2. For each FeedbackResponseMap obtained above, find out all the most recent Response objects. We only need most recent responses since Participants may have edited their responses. The old responses are not deleted from Responses table. 3. Pass the list of Responses to the heatgrid view. def add_reviews(participant, team, vary) <code> end. 1. File : <link> 2. Line Numbers : #117-#119, #185-#189 As discussed in the previous section, we need to change UI elements specific to Author Feedback tab. First, we change the title of each column to show Reviewee Id instead of Reviewer Id . To achieve that, we only add a simple if condition in the view to check whether the current tab is 'Author Feedback'. We change the title to use 'reviewee_id' whenever the current tab is Author Feedback. <code> Secondly, we change the Title of each row in the detailed score view (when the dropdown of review is opened). Currently, it shows name of the Review. Here, we need the Id of the reviewee. <code> 1. File : <link> 2. Line Numbers : #6 At last, we need to change the count of Feedbacks displayed at the top of each row as shown in the figure. <code>. The code we changed is very specific and only applies to cases where 'Author Feedback' is to be shown. Therefore, we do not expect other parts of the application to get affected by our code. Continue reading for more information on tests. File : <link> 1. There is a fundamental change in how Author Feedback is tested. In existing implementation, we test for the feedback received by a participant. However, in the new implementation, we are interested in testing feedback left by current participant to other team members. Therefore, variable @list_of_reviews should contain the list of reviews (feedbacks) left by current participant. <code> 1. To view the deployed Expertiza associated with this assignment, use the following credentials : Instructor Login: username -> instructor6, password -> password. 1. Login to expertiza using the above credentials. 2. Impersonate as student7189 and for assignment Madeup Problem, click on Alternate View, then click on show reviews and save any review. 3. Follow the step2 for student7452. 4. Then as an instructor, click on Assignments under Manage Notifications Tab. 5. Click on View Scores under Madeup Problem Assignment. 6. expand Madeup problem_Team22. 7. click on tab ""Author Feedback"" and you will see all reviews made by that authors(all participant of Team22). To test our code in a real Expertiza environment, please see instructions on <link> page (Expires Nov 9, 2019).","1. Explained their task and solution well.
2. I'm confused when you say, ""This team reviewed assignments of Team 29 and Team 30."".  In Expertiza, teams don't review submissions; users do.  Looking at the diagram clarifies that you only consider the submissions reviewed by the first member of the team.  The prose should be changed to reflect that.
3. I assume that your diagrams are ""before"" and ""after"" you have changed the behavior.  But the wiki doesn't identify them as old and new.
4, Created mock test data and explained how to test from UI.
5. No code is shown for automated tests, only a single sentence that overflows a text box.  The test plan needs to be much better defined.  How do you know that the right reviews appear on the right user's heatgrid?




","This is a well-composed and extensively detailed assignment. Your ability to explain the concepts of your work is commendable. You've effectively used a problem-solving approach by defining the scenario, identifying the problem, and providing a solution. 

However, some areas require minor revisions:

1. Carefully number your points. It seems in multiple sections, the numbering restarts from '1.' Maintain consistency throughout.

2. Slightly ambiguous instructions. While the detailed narrative you've provided is informative, there are moments when the instructions are a bit hard to follow.  Providing simpler instructions can help in better understanding. 

3. Not all the pictures or links that you're referencing are included in this document. You may have forgotten to insert them. Ensure these are included so readers can better understand your examples.

4. Grammar and punctuation. There are some instances where either a word might be missing or punctuation is off. Proofreading before submission could help to catch these small errors.

In spite of these points, you have shown good understanding and logical thinking in problem-solving. Good job! Please revise based on the feedback and re-submit for further review."
260,E1845,"In order to test all functionality, a super-administrator account is needed. The following account can be used in a standard Expertiza deployment: - Super_administrator2 : password Following the installation and setup of the Expertiza system with the scrubbed database, testing of the project functionality can be done as follows. A. User Deletion 1. Sign in as a Super-Administrator (see above for sample account) 2. Navigate to Administration>Show>Instructors i. Select one of the instructor accounts ii. On the account page, click the delete link at the bottom iii. Assuming the instructor account is not tied to any assignments or other associations, the account will be gone from the list. If there is an issue, an error will be displayed at the top of the page. 3. Navigate to Administration>Show>Administrators i. Select one of the administrator accounts ii. On the account page, click the delete link at the bottom iii. Assuming the administrator account is not tied to any assignments or other associations, the account will be gone from the list. If there is an issue, an error will be displayed at the top of the page. 4. Errors may appear on the page when an account to be deleted still has relations to other assignments, teams, etc. The content and quality of these error messages is outside the scope of this project; some may show an English error, others may return an SQL error. This is the intended functionality as of the time this project was written - this project only concerns successful deletion in situations where deletion should be working. B. Role Creation 1. Sign in as a Super-Administrator 2. Navigate to Administration>Setup>Roles 3. Ensure that there is no link on the page to create a new role 4. Ensure that manually navigating to /roles/new results in an error message on the page. The majority of the project was related to solving issues regarding the deletion of Administrator and Instructor accounts. Administrator and Instructor are both account types that inherit behavior from User but are handled and deleted in different codepaths. Furthermore, properties are used on a User that aren't on an Administrator, such as team ids or course associations. The first step towards fixing the deletion functionality was to sort out the routing issues. No listing in the routing table existed for administrator deletion, and no controller method existed for neither administrator nor instructor deletion. With both of those in place, the only issue left was the deletion functionality. Because of the varying properties on Users and Administrators, and due to some database table migrations that were put into effect earlier, the rails system was unable to find user_id columns in the Users table when trying to delete the Administrator and Instructor accounts. The earlier migration had renamed it to team_id when team functionality was changed, but since Administrator and Instructor don't join teams, that id was invalid. A new migration was created to re-add the user_id column to the table as a blank column just used for SQL matching. In order to maintain DRY principles and support future code maintenance, a helper method was created for use with deleting Users, Administrator, and Instructor. By using a static class method, both UserController and AdminController could use the same underlying functionality for deleting User objects while customizing the flash message and the redirect url. The changes made to both controllers is visible in the UML diagram below and the before and after code segments. The code segments only show the destroy method for the users controller, as the code is nearly identical in the administrator controller for both Instructor and Administrator deletion, with the only changes being to the name of the position being passed and the redirect_to path after the deletion. <image> Before: (users_controller.rb) <code> After: (users_controller.rb) <code>. In Expertiza, each user has a role in the system which dictates the availability of functionality to the user. The current roles in the system are Administrator, Instructor, Student, Super-Administrator, Teaching Assistant, and Unregistered User. The other focus of this project was to remove the ability to add new roles to the system. The functionality was previously available only to Super Administrators, but the functionality was deemed unnecessary and a potential issue to keep around. The solution simply involved removing the New button from the Roles list view and preventing any new functionality in the Role controller. Before: (roles_controller.rb) <code> In the controller, the above was changed to the following in order to prevent the functionality on the GUI side. After: (roles_controller.rb) <code>. In order to develop test cases for the functionality added and removed in this project, both an admin_controller_spec.rb and a roles_controller_spec.rb file were created and added to the RSpec test environment. The admin tests include building and deleting both Administrator and Instructor accounts using Capybara for testing the front-end web functionality. To test the role creation, Capybara was again used to check that the web page did not have any button for ""New Role"" and that navigating to the page manually resulted in an error.","The write-up is short but precise. it has pretty much everything needed for understanding the issues and what they have done. It will be  better if they could show the code for test and include some UI screenshot. Also, they wrote their implemented solutions in ""Changes"" and even in ""Background"" and it would be easier for reviewers to find them if they are seperated in a new subsection.","Dear Student,

Thank you for your detailed analysis and explanation of your project. Your clear step-by-step guidance on how to execute administrator account deletion and role creation restrictions shows a deep understanding of both the project requirements and the Expertiza system. The focus you've placed on these issues and their respective resolutions suggests that you have a strong handle on navigating throughout the software and problem-solving.

Your examination of the challenges related to the deletion functionality of administrator and instructor accounts is comprehensive. The solution you implemented demonstrates a clear understanding of the principles required for the application’s improvement. Good job on maintaining DRY principles and ensuring code is reusable and maintainable.

As for the role creation restriction, your rationale for removing the ability to add new roles is sound and demonstrates a good understanding of system security. It's logical to limit unnecessary functionality expansion that could potentially lead to issues.

It would, however, be beneficial to include the final working code and UML diagrams to illustrate the changes you've made visually, as they are not included in your paper. Additionally, further elaboration on the specific test cases developed would be advantageous.

Overall, excellent work! Looking forward to more of your future submissions. Keep up the good work!

Best Regards,
[Your Name]"
261,E1810,"<link> is a web based open source peer reviewing tool developed and maintained by current and past students of <link> . Peer review is a great way for a student to learn how to approach a project and get ideas for their own projects. Currently, there is no way for a student to view another student's work, unless they are reviewing the other student's work. The objective of this project is to: 1. Add a feature to allow teams to publish their work for other students to see. 2. Add a feature for a student to view sample submissions for a given assignment made available by other students: 1.1. In the same assignment, available after deadline. 1.2. In an old assignment, selected by the instructor from sample submissions made in an old assignment. 3. Add a feature for instructor to select a previous assignment to show sample submissions for a new assignment. The proposed features will involve two kinds of users : Students and Instructors. Students will use the application to make their submissions public and view published reviews. <image> Instructors will use the application to make submissions from a previous assignment available as sample submissions for a current assignment. Only those submissions will be visible which were previously made public by the students. <image>. The tasks that need to be completed as part of this project can be listed as follows: 1. Add checkbox against each assignment in student_tasks/list view to allow student to publish their work 2. Add column make_public to table teams for storing user permission (published or not) for each project. 3. Add controller for Sample submissions and implement corresponding methods. 4. Add views for sample submissions 5. Make changes to page student_task/view which would have link to sample submissions for each project. 6. Add drop down in assignments/edit/_general view. 7. Add controller code for the drop down. 8. Add column sample_assignment_id to table assignment. 9. Add test scripts for all the functionality. All tasks mentioned in Project tasks are completed. 1. Add checkbox against each assignment in student_tasks/list view to allow student to publish their work <code> 2. Add column make_public to table teams for storing user permission (published or not) for each project. <code> 3. Add controller for Sample submissions and implement corresponding methods. <code> 4. Add views for sample submissions <code> 5. Make changes to page student_task/view which would have link to sample submissions for each project. <code> 6. Add drop down in assignments/edit/_general view. <code> 7. Add controller code for the drop down. <code> 8. Add column sample_assignment_id to table assignment. <code> 9. Add test scripts for all the functionality. <code>. 1. The first screenshot of the application is taken when the deadline for the current assignment has not crossed and the instructor also has not given any sample assignment for this assignment. <image> 2. The second screenshot of the application is taken when the deadline for the current assignment has not crossed but the instructor has selected a sample assignment for viewing against this assignment. <image> 3. The third screenshot of the application is taken when both the deadline for the current assignment has crossed and the instructor has selected a sample assignment for viewing. <image>. Many of our changes are reflected on views (user interface). So we build tests with rspec/capybara. Following is the list of tests that conduct: 1. it ""is able to make an assignment public"" 2. it ""is able to view sample submissions page"" 3. it ""should not see current assignment submissions if deadline is not met"" 4. it ""should see current assignment submissions if deadline is met"" 5. it ""should not see instructor selected submissions if instructor has not selected them"" 6. it ""should see instructor selected submissions if instructor has selected them"" <code>. 1. Publishing sample reviews made by students: This feature will require students to allow their review to be published as a sample review. This can then be made available to future students. 1. link to forked repository <link> 2. link to the git pull request <link> 3. link to the deployed application <link>. 1. Link to expertiza website: <link>.",Very good job of describing the functionality and presenting the code.,"Hello,

Your assignment is well-structured, logical, and shows a good understanding of the peer reviewing tool functionality and how to enhance it. Your objectives are clear and your explanation maintains clarity throughout the document.

Good job on successfully completing all the tasks required, down to creating test scripts to ensure the feature functionality. Your attention to detail and implementation of user interfaces and data storage indicates a good handle of the assignment.

However, there are a few areas where more detail or clarity might be useful:

1. Explain the reasoning for your features more. While it's mentioned that these features would be beneficial, slightly more context or detail into what led you to these specific features would help enhance understanding.

2. Illustrations/images mentioned do not appear in the assignment. It would be good to include them as they will strengthen the understanding of your project.

3. While code implementation is mentioned, it would be better to detail more on how the code works in case it's needed for future reference.

4. The testing strategy appears comprehensive, but try to explain a bit more about how the tests will validate whether functionality meets the requirements.

Overall, you’ve done an excellent job and demonstrated good capability in understanding, enhancing, and testing software tools. Keep working on enhancing your assignment presentation with the suggested points in mind, and you'll continue doing great work! Keep it up!
"
262,E1960,"Expertiza is an open-source project based on Ruby on Rails framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. E1960. Create new late policy successfully and fixing ""Back"" link. An instructor can create late policies for any assignment, wherein the instructor can specify the points per unit and the maximum penalty that can be applied for any assignment submission. If an instructor while creating a policy, clicks on “Create” (Step 5), following error message is displayed on the top of the page “The following error occurred while saving the penalty policy:” and the policy is not created and added to the list of policies. If an instructor, while creating a policy, clicks on ""Back"" link (Step 6) and wants to go back to the previous page, (s)he is directed to the list of policies instead of “Due Date” tab of assignment edit page (Step 2 above). The create button on the new page of late_policy is not working. Whenever the data for the form is filled and submitted by clicking on the Create button, an error message is shown saying “The following error occurred while saving the penalty policy:” and the policy is not created and added to the list of policies. An instructor can choose to go back to the previous page from the create new policy page. When the Back button on the create new late policy is clicked, it should be redirected to the Due Date tab of the assignment it came from but it is redirected to the index page of late policies. Solution There was no provision to handle the validations of the form in the new late_policy page. A new late policy would not be created if any of the validations fail and the user would be notified of the errors by a flash error message. Updated File: app/views/late_policies/new.html.erb <code> A new Rspec File has been written to carry out the automatic testing. All the test cases have been mentioned in the Test Plan subsection. A new late policy must not be created if any of these validations fail. File created: spec/models/late_policy_spec.rb <code>. An instructor can choose to go back to the previous page from the create new policy page. When Back button on the create new late policy is clicked, it should be redirected to the Due Date tab of the assignment it came from but it is redirected to the list of late policies page Solution We tried to store the assignment id of the page from where the create new policy was clicked. This way when we have to redirect after the back button, we can send it to this particular assignment with the help of assignment id. This session variable gets overwritten every time whenever an edit page for the new assignment is opened. So the bug in the back link is fixed. update method at app/controllers/assignments_controller.rb <code> app/views/late_policies/new.html.erb <code>. For users intending to view the deployed Expertiza associated with this assignment, the credentials are below: Instructor Login: username -> instructor6, password -> password. <image>. <image>. <image>. <image>. <image>. 1. Login to expertiza using the above credentials. 2. Click on Assignments under Manage Notifications. 3. Click on Edit icon under any of the Assignments. 4. Navigate to Due Dates Tab. 5. Scroll Down and click on ""New Late Policy"". 6. Create/test new Late Policy!. A new late policy must not be created if any of these validations fail. 1. Late Policy Name 1.1. Late Policy Name must not be blank 1.2. Late Policy must be unique 2. Penalty Points per unit 1.1. Penalty points must not be blank 1.2. Penalty points must be a number 1.3. penalty points must be less than total penalty points 3. Maximum Penalty 1.1. Maximum Penalty must not be blank 1.2. Maximum Penalty must be less than 50 All these test cases have been automatically tested by writing a new RSpec file: spec/models/late_policy_spec.rb. <image>. There are three different cases covered under the back link testing on the new late policy page. Flow: Assignments -> Edit Button -> Due Dates Tab -> New Late Policy -> Back. It is redirected to the due dates tab of that assignment. Flow: Assignments -> Edit Button -> Due Dates Tab -> New Late Policy -> Click on create without Entering values -> Back. An error message is shown regarding the validations when the create button is clicked. When the Back button is clicked at this stage, it is redirected to the due dates tab of that assignment. Flow: Assignments -> Edit Button -> Due Dates Tab -> New Late Policy -> Submit a policy -> Create New policy -> Back Once a policy is created we are redirected to the index page of the policies which lists all the policies available. Now if we try to create a new policy from here and click on the Back button after that, we are redirected to the due dates tab of that assignment. Following tasks were accomplished in this project: 1. Corrected the code for the late_policies controller and new late_policy page. 2. Improved the code for the Back button inside the new late_policy page. 3. Added RSPEC test cases for testing changes done in late_policies Controller. 27.125%. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7.Clean Code: A handbook of agile software craftsmanship. Author: Robert C Martin.","The description of the problems is separated from the solution.  Would have been better to just list the problems (in one line), and then juxtapose the problem description with the solution.
The code in spec/models/late_policy_spec.rb should have been explained, like the changes in other files were. 
The automated test cases were just listed.  Ideally, the test code should have been shown, and the tests explained.  Actually, this was done for the tests for the back link, but not for testing the creation of penalty policies.","You have prepared a comprehensive review of the project, discussing issues and solutions in great detail. I appreciate your deep understanding of the topic, and your articulate presentation skills. However, several areas need further improvement. First off, you failed to include the proper end tags within the ""<code>"" sections and I was unable to view the codes you used to solve various issues. Your work would have been easier to understand if you had included this detail. Moreover, your presentation and interpretation of the project could have been better. While explaining your code, you used system terminologies heavily which might make it difficult for the audience without any basic understanding of the system to understand.

You might want to include more visuals or diagrams in the future to illustrate some of your points or provide step-by-step guidance. Also, when citing references, ensure you provide full and proper citations. For example, your citation of Robert C Martin's work is incomplete. Furthermore, I noticed some redundancies. Avoid repeating sentences or phrases, rather aim to be succinct and straight to the point.

Lastly, it will be helpful if you could explain how the results of your assignment contribute to the overall functionality of the Expertiza system, how it would impact users and overall system efficiency. 

However, you have shown considerable effort and competencies in tackling the assignment, keep it up!"
263,E1842,"<link> is an open source project developed using Ruby on Rails framework.Expertiza allows the instructor to create new assignments and customize new or existing assignments.The application allows students to submit and peer-review learning objects (articles, code, web sites, etc)[1].Expertiza supports submission across various document types, including the URLs and wiki pages. In Expertiza, an instructor is responsible for adding a participant to his course or assignment. This makes the course material available to the participant (or student per se). Since the instructor has admin rights, he is capable of impersonating the participant. This creates a few problems. This project addresses those issues. Issues as described by the problem statement: Once the instructor impersonates the participant, he/she is capable of accessing all of participant’s work, irrespective of the course or the assignment. This raises serious security concerns. Suggested solution is to restrict the instructor to view only his coursework. After adding a participant, the page has to be manually refreshed to show the name of the participant on the list. This creates a bad user experience and needs to be fixed. 1) app/controllers/auth_controller.rb 2) app/controllers/impersonate_controller.rb 3) app/controllers/student_task_controller.rb 4) app/views/participants/add.js.erb 5) app/views/participants/_participant.html.erb 6) app/views/shared_scripts/_user_list.html.erb. Once the instructor or teaching assistant impersonates the participant, he/she is capable of accessing all the assignments of this participant irrespective of the course and this raises serious security concerns. Ideally, when this happened, the system should have displayed only those assignments to which he/she is assigned as an instructor or teaching assistant. This issue has been fixed by modifying the current implementations of data filtering and session/role handling features. 1. Impersonation and Session Handling: Setting and resetting of all the session data associated with impersonation are handled in auth_controller.rb file. i] After login, session[:impersonate] value is set to false by default. <code> ii] Once the Instructor tries to impersonate any student, the following actions are performed. a) Assign the instructor/TA data to a session variable and use this data when instructor/TA tries to switch back to their original role. <code> b) Impersonate flag is set to true and the session's user variable is set to the user data of impersonated student. <code> iii] All the session data is cleared off when the user logs out. <code> 2. Data Filtering: Logged in user's role data and impersonation status is used to filter the data for populating the assignments list. This is implemented in student_task_controller.rb file: <code> <code> Why this approach? We wanted some way to maintain the details of the logged in user to be available throughout the session and across all the controllers. So, we have used session variables to store the user data and impersonation flag. Then, we use this impersonation flag and user data (role details) to decide whether to return whole or filtered results. The user (instructor, TA or admin) has to click the Add button on the course or assignment page to add a new participant to the course or assignment. On click of the button, the browser initiates an AJAX request and gets a response HTML representing success or failure of the action. The failure case was already handled - an error message appears at the top of the page. On success, it was observed that, though the HTML for a new table row (representing the just added participant) was part of the response, it was not being appended properly to the page's DOM. This is fixed by giving an id to the table HTML element, and appending the new row to its tbody element. Why this approach? Since we are appending to a html <tbody> element, we need a way to identify it. We could select the table body or the table itself. However, it looks more optimal to provide an id to the <table> that contains this <tbody> element, since this provides a way to edit other parts of this table in future. After appending, we must also ensure that the ""Submit"" button which is part of the new HTML must be functional. So, an onchange listener is added to the button element (in the file add.js.erb). <code>. 1) Login as Instructor4 . Add a new assignment Assignment_Instructor4 under the course Course 617, Spring 2016 . 2) Make student6400 as the participant of that assignment and logout. 3) Login as Instructor6 . Add a new assignment Assignment_Instructor6 under the course Course 517, Spring 2016 . 4) Make student6400 as the participant of that assignment and logout. 5) Click on Manage -> Impersonate User and enter student6400 as the user to be impersonated. 6) After impersonation, Instructor6 will be able to see only his/her assignment details and not of any other instructors. 7) We need to login as Instructor4 and verify that Instructor4 is not able to see other assignment details of the other instructors. 8) Login as Instructor4 . Click on Manage -> Impersonate user. Enter student6400 as the user to be impersonated. 9) After impersonation, Instructor4 will be able to see only his/her assignment details and not of any other instructors. 10) Login as TeachingAssistant1274 who is a TA for the Course 517, Spring 2016, who is a TA under Instructor6. 11) Create an assignment TA_Assignment and make student6400 as a participant. 12) Click on Manage->Impersonate user and enter student6400 as the student to be impersonated. 13) After impersonation, TeachingAssistant1274 will be able to see all the assignment details of all courses for which (s)he is the TA and not the details of the other assignments. 14) Now suppose Instructor6 logs in and impersonates the student student6400 , he will be able to see all the assignment details under his/her course i.e. all the details of the assignment that was created by Instructor6 himself as well as the assignments created by his TA's. 15) Next, login as student6400 and click on assignments. The student will be able to see all the assignments of all the courses to which he/she is assigned to. 16) This verifies that the bugs have been fixed. 1) Login as an Instructor or Admin or Super-Admin or TA . 2) Click on Manage -> Assignments. In the Actions column click on Add Participant . 3) After the list of all the participants you will be able to see Enter a user login text box. 4) Enter the user login in the text box (Ex: student9000) and click on Add button. 5) After clicking on the Add button, you will see the participant added at end of the list. 6) This verifies the bug has been fixed. 1) Login as Instructor4 . Add a new assignment Assignment_Instructor4 under the course Course 617, Spring 2016 . <image> 2) Make student6400 as the participant of that assignment and logout. <image> 3) Login as Instructor6 . Add a new assignment Assignment_Instructor6 under the course Course 517, Spring 2016 . <image> 4) Make student6400 as the participant of that assignment and logout. 5) Click on Manage -> Impersonate User and enter student6400 as the user to be impersonated. <image> 6) After impersonation, Instructor6 will be able to see only his/her assignment details and not of any other instructors. <image> 7) We need to login as Instructor4 and verify that Instructor4 is not able to see other assignment details of the other instructors. 8) Login as Instructor4 . Click on Manage -> Impersonate user. Enter student6400 as the user to be impersonated. <image> 9) After impersonation, Instructor4 will be able to see only his/her assignment details and not of any other instructors. <image> 10) Login as TeachingAssistant1274 who is a TA for the Course 517, Spring 2016, who is a TA under Instructor6. 11) Create an assignment TA_Assignment and make student6400 as a participant. <image> 12) Click on Manage->Impersonate user and enter student6400 as the student to be impersonated. <image> 13) After impersonation, TeachingAssistant1274 will be able to see all the assignment details of all courses for which (s)he is the TA and not the details of the other assignments. <image> 14) Next, login as student6400 and click on assignments. The student will be able to see all the assignments of all the courses to which he/she is assigned to. 15) This verifies that the bugs have been fixed. 1) Login as an Instructor or Admin or Super-Admin or TA . 2) Click on Manage -> Assignments. In the Actions column click on Add Participant . 3) After the list of all the participants you will be able to see Enter a user login text box. 4) Enter the user login in the text box (Ex: student9000) and click on Add button. <image> 5) After clicking on the Add button, you will see the participant added at end of the list. <image> 6) This verifies the bug has been fixed. 1. Git pull link: <link> 1. <link> 2. <link> 3. <link>.",The wiki document is detailed. It would have been helpful if they explained how they have used the variable related to impersonation and an overall view of how they solved this problem.I wish they had added screenshots while explaining how they fixed the issues. The format of the document is not very intuitive.,"First of all, the depth and breadth of your work is commendable. You've detailed every step and process clearly and correctly, thus making your project easy to understand. Additionally, your ability to resolve the security issues within the Expertiza platform is impressive.

However, there're several aspects to your work that you can improve upon. Consider the following feedback:

1. **Clarity of Instructions**: While you've done a great job detailing the steps involved, the instructions tend to get a bit verbose and confusing at times. You might want to break it down in shorter, simpler sentences, making it easier for those applying your work to follow.

2. **Use of Visuals**: Including <image> placeholders in your assignment suggests that you intend to provide visual guidance, like screenshots for example. This will indeed help a lot in making your instructions even more understandable. Please make sure to provide these images in your final submission.

3. **Code Snippets**: You've made reference to <code> snippets but haven't included them. For the sake of completeness, please include these in your final submission as well. Code snippets will give a much clearer idea about the changes you're proposing and how they should be implemented.

4. **Explanation of your Approaches**: It is evident that you've given thought to your approaches. However, the rationale behind adopting these could be expanded a bit more. This would help others understand why your solutions are effective and how they address the problem at hand. This is particularly important for those who might be less familiar with Ruby on Rails or the specific frameworks and systems you're working with.

5. **References and Supporting Links**: It's good to see links included in your work, but I noticed they're just mentioned as '<link>'. Make sure to provide the correct URLs in your final submission.

6. **Proofreading**: There're a few instances of textual errors in your assignment. Proofreading your work thoroughly before submission can eliminate these minor issues.

Great work overall! With the improvements suggested, you'll be offering very well-composed, comprehensive, and accessible solutions that users can easily follow and implement. Keep it up!"
264,E1817,"Expertiza contains Peer-Review where in all students are asked to review the work done by their fellow classmates. The rubric for the same are created by instructors. These Rubrics contain questions that are related to the submitted topics. But sometimes students have questions which may or may not be related to the work other students are working on. So there is no option currently available to ask these questions to their peers. This project (E1817) aims to solve this problem by allowing students to add questions to the standard instructor generated rubric so that they can get specific feedback on from the reviewers. In order to solve the above problem, we intend to add Supplementary Review Questions to the existing Review Questions already added by the instructor. These “extra” questions will not be graded. However, they will increase the benefit that each person gets because they can get feedback that is specific to their project. The rest of this document describes the design and approach for project E1817. In Expertiza, all rubrics and surveys are subclasses of Questionnaire. A Questionnaire has “questions” that make use of checkboxes, dropdowns, text boxes, etc. We want to add a new subclass of Questionnaire called SupplementaryReviewQuestionnaire to help us implement this project. The flowcharts below describes the design that we chose to implement for this project. 1. When a student wants to create/edit Supplementary Review Questionnaire 1.1. If the instructor has enabled a particular assignment to have supplementary review questionnaire only then a student can create a supplementary review questionnaire. A student can click on the ""Your Work"" tab and see a link to the add/edit Supplementary Review Questionnaire. This link directs the student to the create review questionnaire(same as instructor). 1.2. When a student creates a Supplementary Review Questionnaire (SRQ), the entry in the SRQ column added to the Teams table will contain the questionnaire id to link the SRQ with the team that generated it. If the SRQ column of a team is empty it means no supplementary review questionnaire was created. If its not empty, it will indicate that a supplementary review questionnaire was created. <image> <image> 1. When Reviewer wants to access the Review Questions. 1.1. When a reviewer requests for a review, first the entry of the SRQ column in the Teams table is checked to see if supplementary review questionnaire was added. If the field is not empty, the supplementary review questionnaire is appended to the existing review questionnaire created by the instructor. Otherwise the reviewer only sees the default review questionnaire. <image> 1. When responses of questionnaire need to be displayed 1.1. When the responses of the reviewer is recorded, the student can click on ""View Scores"" tab for a particular assignment which contains the responses of the reviewer. This view should contain the responses for both the default review questions as well the supplementary review questions added by the student. So if the entry of the SRQ column in the Teams table is not empty the responses of the supplementary review questions is appended to the responses of the default review questions. NOTE : The responses of the Supplementary Review Questions will not be added to the review scores of the project. It will just be shown to the team that has asked these questions so that they can see what suggestions does the reviewer has for the questions. <image>. The following changes need to be made to the User Interface. 1. Assignment Page 1.1. An assignment will have a checkbox that the instructor can ‘check’ to enable a student to add supplementary review rubric. Once ‘checked’ a button or link will appear in the student's ""Your Work"" section. This link will redirect the student to the same page that an instructor lands on when creating a new rubric, which will allow the student to create a review rubric just like an instructor does. <image> 1. A link called ""Supplemantary Review Questionnaire"" will appear in the student's ""Your Work"" section when the Instructor has allowed students to create supplementary review questions. So when a student clicks the link he/she can add the desired questions. <image> 1. The page where student will be directed to when he/she clicks the Supplementary Review Questionnaire link. Students can add Questions to the created Supplementary Review questionnaire here. <image> 1. Review Page 1.1. When a reviewer fills out a rubric, the ResponseController will display a set of rubrics, in order, on the same page. This set would normally consist of just a review rubric, which is a Response object. However, the set would now have a review rubric and a supplementary review rubric (two items in the set instead of one) if the Supplementary Review rubric has been added. Thus, now the reviewer will be able to see the Supplementary Review questions along with the existing review questions. <image> <image> 1. Review Results Page 1.1. The “View” function for a rubric will display answers submitted for the SupplementaryReviewQuestionnaire as well as the ReviewQuestionnaire. NOTE :The student-generated questions (Supplementary Review Questions) should not be graded to avoid encouraging students to ask “easy” questions so that their reviewers would give them a high scores. In order to do that, the students must explicitly set the weight of these questions to 0 while creating the supplementary review questionnaire. <image>. Firstly, we need to add tests for the following: 1. To check the link for ""Supplementary Review Questionnaire"" appears in the ""Your Work"" section of a student. 2. To check if the link for ""Supplementary Review Questionnaire"" redirects to page which allows to create questionnaire. 3. To check if the reviewers can see the supplementary questions that were added by the team as part of the review questions. 4. To check if the responses of the Supplementary Review Questions have been added to the responses of the existing review questions. Supplementary Review Questionnaire Testing : supplementary_review_rubric_spec.rb : In this test, we are testing the addition and editing of the supplementary questionnaire. Furthermore, we are also checking whether the questionnaire is being displayed or not to the reviewer. Also a test has been added to check if the questionnaire gets added to the model. <code> Topic Helper : topic_helper.rb : This file is included in the helper folder inside spec/features. This helper is used because the given methods are used in more than one place and to keep the code ""DRY"". In the first method we are stubbing the user so that that user signs up for an assignment. In the second method more testing is being performed to test the upload link. <code>. 1. app/models/supplementary_review_questionnaire.rb 1. Added a migration to create a subclass ""SupplementaryReviewQuestionnaire"". <code> 2. db/migrate/20180419210958_add_srq_id_to_teams.rb 1. Added a migration which will add the Supplementary Review Questionnaire id column to the ""Teams"" table. This is to link the team which created the supplementary review questionnaire to the created questionnaire. <code> 3. config/routes.rb 4. app/controllers/response_controller.rb 1. Obtained supplementary review questionnaire from the questionnaires table for new response. <code> 1. Obtained answers for the supplementary review questionnaire from the responses. <code> 1. Appended responses of the supplementary review questionnaire in the edit method. <code> 1. Append questions of supplementary review questionnaire in create method and set content method. <code> <code> 5. app/controllers/grades_controller.rb Added supplementary review responses to ""Your Scores"" section. <code> 6. app/views/assignments/edit/_rubrics.html.erb 1. Add a checkbox called ""Allow students to create supplementary review questionnaire"". <code> 7. app/views/submitted_content/_main.html.erb 1. Created a link "" Create Supplementary Review Questionnaire"" to appear in the student's ""Your Work"" section if the instructor has enabled student generated Questions for this assignment. <code> 8. app/controllers/questionnaires_controller 1. Added a method to create Supplementary Review Questionnaire. <code> 9. app/models/questionnaire.rb 1. Added ""SupplementaryReviewQuestionnaire"" to QUESTIONNAIRE_TYPES. 10. app/models/response.rb 1. Added supplementary review responses to be visible in the ""Show Review"" section. <code> 11. app/models/team.rb 1. Added a method to obtain srq_id of a team. <code> 12. app/views/response/response.html.erb 1. Added the following code section to append supplementary review to existing review. <code> 13. db/migrate/20180428233726_add_srq_to_assignments.rb 1. . Added a migration to add a column ""srq"" to the ""assignments"" table. <code>. 1. Expertiza on Github: <link> 2. Pull Request: <link> 3. Expertiza YouTube channel: <link>.","This is a good step-by-step description of how supplementary questions would be used.  It should also describe how they are implemented, and it does not.  Many of the code files are pasted into the documentation.  They show up in monochrome, and in general, are not easy to read.  I would have preferred prose descriptions of what they do.  In the test plan, it doesn't seem that the included code tests for the 4 items listed as tests.","The comprehensiveness and detail in your assignment are commendable. You've done a great job structuring your project and systematically addressing every aspect of the proposal, from the problem to the solution and its implementation. 

The proposed solution of adding Supplementary Review Questionnaire seems practical and thoughtful. The usage of diagrams to make your ideas more understandable is excellent. Incorporating both new and existing functionality and reviewing how it can be used in combination is a good approach.

However, Do take note that the placement of '<image>' is a bit confusing, please ensure you replace these placeholders with the actual images or diagrams to further aid in the understanding of your content.

The extent to which you've evaluated user interaction and the revisions needed in the user interface shows excellent foresight. I commend your thorough assessment of the necessary additions and changes to the codebase.

Your presentation of the test requirements was very articulate and orderly, outlining the need for supplementary_review_rubric_spec.rb and topic_helper.rb was astute. However, it would be helpful if you could incorporate specific examples for testing the functionalities to ensure they are working as expected.

As for the code segments marked '<code>', those should ideally be replaced with actual code snippets for a detailed analysis. Failure to include these may result in confusion about your implementation approach and design decisions.

Finally, it's very good that you've provided links to your Github repository and pull requests so that your changes can be reviewed in detail. I'd recommend that you include a summary of your changes in your commit messages to make them more informative.

Overall, your assignment was well crafted, incredibly detailed, and indicative of a thorough understanding of the system. Excellent work!"
266,E1603,"This page provides details about the changes made to Expertiza under project E1603. Refactor user, course_participant and assignment_participant model. Expertiza is an educational web application built on top of Ruby on Rails. The project is open source with code available on Github and maintained by both the students and faculty of the NC State University. The application allows instructors to manage courses and assignments. The students can choose a topic from the list for an assignment, form a team, submit their work and do multiple reviews on other's work. The application helps instructors and teaching assistants in scoring and maintaining the grades for the assignment. The users of the expertiza are modeled using the user model. A participant signs up for courses and assignments. A user can have multiple participants and all participants belong to a user. The participant model is inherited by the course and assignment participant model. Our work involves refactoring functions defined in these models. Some methods were moved to places with better fit and some methods were improvised with better implementations. The further sections in the document will explain the changes complement and how it will impact the overall usage of expertiza. 1. Moved the export_fields method to the User model from CourseParticipant model to remove redudancy. 2. Added attr_accessible modifier to CourseParticipant to improve security. 3. Refactored the get_user_list method into smaller methods, one method for each if condition in User model. 4. Moved the ‘files’ method from AssignmentParticipant model which was duplicate and used in assignment_team.rb as well to a common place (FileHelper module). 5. Refactored the average_question_score method by using sql summation to find values for sum_of_scores and number_of_scores variables in AssignmentParticipant model. The user model stores details of the user like name,email,role,timezone and his preferences on how expertiza should behave to him. A user can have many roles like student, instructor or administrator. The user model is used for logging in, participating in courses, assignments and creating teams. The user model maintains parent child relationship, a user will have one parent and can have many children. Expertiza uses a participant abstraction for modeling the participance of a user in any of the activities like courses and assignments. A participant belongs to a user and it represents a connection between a user and an activity. Assignment_participant, which is a child class of participant models the association between users and assignments. This association also needs to be mapped to other activities performed by a user related to the assignment. These activities include reviews, quiz, response to reviews, teammate reviews etc.. The assignment_participant model is related to models which is responsible for all the mentioned activities. The course_participant is a child class of the participant abstraction and it represents the association between a user and a course. The model also stores fields required for the association and supports bulk importing and exporting. This method exports the headers of the csv file to be downloaded. The method export_fields occurs in various models with different implementations. However, the implementation for this method had been duplicated in course_participant and user models. This led to the disadvantage of having redundant code in the system and an inefficient coding practice. User model represents the base class and other models inherit from this class. Hence, deleting the method from User model made little sense. The refactoring invoked the User models export_fields method from within the export_fields of course_participant. Since the export_file controller calls this method on the course_participant object, there wasn't a choice to delete the method completely. This refactoring has the advantage that code is reused and the proper object is tied to the header fields instead of just the generic User object. This method contained a lot of if-else statements that executed different codes depending on the type of user. The refactoring broke the large method into smaller methods, one for each user type. This improved the modularity of the code. It made the code more manageable and understandable from maintenance point of view (separation of responsibilities). The average of the score for a question in the review given by all other students who reviewed an assignment needs to be calculated in the average_question_score method in assignment participant model. This was originally implemented by using two for loops and fetching all the answers given by all the reviewers and then filtering using an if statement. This method consumes more CPU cycles and impacts the performance of the application server. It also consumes more bandwidth since the application fetches all the data from the database but returns only one value to the user. This was reimplemented to use the SQL summation inside the database and returns the only desired value to the application. This method also takes advantage of the database indexing and fetches only values required instead of filtering in the application. The course_participant model has a number of instance variables like can_submit, can_review, user_id, parent_id, submitted_at, permission_granted, penalty_accumulated, grade, type, handle, time_stamp, digital_signature, duty, can_take_quiz. Earlier, these variables were less secure and hence susceptible to tampering with URLs or forms from malicious users. In general, elements are filled based on the data sent as a hash from the view. This happens as mass assignment where any matching key in the hash will be set. To protect this mass assignment from malicious attacks, a good design is to add attr_accessible macro. Adding this keyword to instance variables ensures that only the specified attributes in the list of attr_accessible are allowed for mass assignment. This ensures that developers can carefully consider which attributes should be allowed to do mass assignment. This way, the refactoring is done. attr_accessible :can_submit, :can_review, :user_id, :parent_id, :submitted_at, :permission_granted, :penalty_accumulated, :grade, :type, :handle, :time_stamp, :digital_signature, :duty, :can_take_quiz. In participant.rb model, there is a method topic_name. However, this method doesn't seem to be required here. A course participant cannot have a topic. If it is an assignment participant object, we can find which team that participant is in first, then find which topic is this team holding. In fact, there is a topic_name field in SignedUpTeam class. On thorough investigation, we found that the method has no caller, which is the right implementation in any case. Hence, the refactoring involved deleting this method altogether. The refactoring was verified by the fact that none of the existing test cases failed. Expertiza mainly uses RSpec for testing and has a comprehensive set of test cases overall. However, there are some models that do not have the required rspecs. We have included test cases for all the refactoring that we have done. We also ensured that the existing test cases do not fail. The earlier version of Expertiza did not have an rspec for the CourseParticipant model. We added an rspec named course_participant_spec.rb as the rspec for this model covering tests for the refactorings done in this project. The attr_accessible improves security by allowing only those fields that are in the list of attr_accessible macro for mass assignment. We test this by using “should allow_mass_assignment_of” and “should_not allow_mass_assignment_of”. Those attributes that are not in the list of attr_accessible will pass the test only when tested as “should_not allow_mass_assignment_of” and the attributes that are in the list of attr_accessible will pass the test only when tested as “should allow_mass_assignment_of”. The following is the code snippet of the test case. <code>. This refactoring was done in the CourseParticipant model. The duplication is removed and the export_fields method is kept only in the User model and a call to the User model is made from CourseParticipant. To test this method, we test the functionality of this method as there is no test case for this method in the previous version. The export_fields method takes an argument of options which is a list of all the fields that the end user wants to export as course participant data and it returns the corresponding fields by making a call to User model. The ideal test case will test only the export_fields in the course_participant model and not the one in user model. This is in line with the strategy of testing incoming query messages by making assertions about what they send back. Therefore, for a given set of options, only the required right set of fields are to be returned. We expect that the returned list of fields will match the ones the method asked using the options field. Below is a sample test snippet. <code>. In order to test get_user_list, we create a dummy object of User and set its role as instructor and fetch the user list of that instructor which returns the list of participants of that instructor’s course. The list could be empty or non empty depending on the user object. <code>. The files method takes an argument of a directory path and returns all the files present in that directory. In the original repository, there was no test case for this method. We have added a test for this method in the file_helper_spec.rb file. The test case takes an example directory like /tmp/expertiza1603/ and returns the files present in that directory. Since the test cases can be run in any environment, the result of the test case is dependent on the presence of such a directory structure. We have created a sample directory with two files on the VCL environment(152.7.99.160). If such a directory is not present, it is important to create a directory by that name. <code>. 1. Login as super_administrator2 or administrator5 with password as ""password"" 2. Click on ""Manage..."""" and click on ""Courses"" 3. On the ""Actions"" tab, click on ""Add Participants"" 4. On the page that opens up, go to the bottom and select ""Export course participants"" 5. Click on ""Export"" button and a csv file should download with the selected radio button fields. 1. Login as super_administrator2 or administrator5 with password as ""password"" 2. Click on ""Manage..."""" and click on ""Users"" 3. You should see all the users on the page. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. <link>.",Basically a good job.  Would have been nice to see a few more short code sequences,"Dear Student, 

Good job on your submission! Your documentation is detailed and insightful, showing a deep level of understanding of the Expertiza system and the Ruby on Rails platform it is built on. The step-by-step breakdown of your refactoring process effectively demonstrates your logical approach towards programming.

Your explanation of the reasons behind the various modifications you made to the methods in the User, CourseParticipant, and AssignmentParticipant models are well-articulated. I'm glad to see you taking performance, security, and maintainability into serious consideration while doing your revisions. 

Your explicit documentation of the test cases incorporate various edge cases, which is a good indicator of your thorough approach. Further, I appreciate your points on reducing CPU cycles, improving code maintainability, and security augmentation through attr_accessible macro use.

I would suggest further practice on clean code principles such as DRY (Don't Repeat Yourself). For instance, your documentation states that the method export_fields had multiple implementations including redundant code. Great catch on that!

There are a few ambiguous parts in your submission where you refer to `<code>` and `<link>`. It would be great if you can provide those in your next assignment. 

Also, consider linking your modifications to improved user experience or functionality since ultimately, it's the application's users who mostly benefit from your work. 

Overall, this is an excellent assignment. Your presentation and awareness towards issues in the original code make this a high-quality contribution to the project. Good work, and keep practicing! 

Sincerely, 

[Your Name]"
267,E1774,"In Expertiza, the metareview feature in Expertiza enables a third party to evaluate the quality of feedback that a reviewer gives to a reviewee. Metareview is an important feature that can help students become a better reviewer for their peers by providing detailed feedback that is actionable and positively formulated. Unfortunately, this feature is broken and the following issues were identified. Your task is to fix these issues so that this feature can be used again. Dynamic assignment of metareviews does not work. When requesting a new metareview to perform, it shows NoMethodError undefined method ‘includes?’ in assignment.rb line 102. Fix: This line has been fixed and now checks if response_map.reviewer == metareviewer rather than response_map.reviewer.includes?(metareviewer), which was invalid. <code>. New Feature: Metareviewer should be able to see author feedback. Currently, the metareviewer can only see the review and doesn't have access to the author feedback. Implementation: This feature is implemented using the ""reviewed_object_id"" from the ""response_maps"" table to fetch the authors feedback for the particular reviewed id. Below are the code changes for implementing this feature. responses.html <code> student_review_controller.rb <code> show_authors_feedback.html <code>. Meta-reviews do not show the review to be reviewed. When I am assigned the meta-review, the original review I'm supposed to critique is not shown, only the link to the wiki article and the review rubric. Fix: Updated response.html.erb: Previously, this view was rendering a partial which was actually not present in the views. So we are not rendering that partial anymore. Now the actual review is displayed by calling an action of response.controller to show the original review which metareviewer is supposed to critique. Old Code <code> New Code <code>. Student selected a new meta review they get their own project to metareview This functionality is working fine as per the requirement. When a user selects a new metareview, a review is assigned to the user to be reviewed, which have the different author other than the User. This can be tested using the test scenario mentioned in the testing section. Metareviews need to be fixed to work with staggered-deadline assignments Fix: The submission is reviewable if the submission is in a stage where reviews can be done. It does not depend on the stage of the topic the reviewer is writing on. The same has been incorporated by the below changes. Code mentioned in defect: <code> Recent code: student_task/view.html.erb <code> student_task_helper.rb <code>. Test Case: If review found, assign new metareview. Edge case: If no review found redirects to same page. Code snippet: <code>. Test case: Meta reviewer should be able to see author feedback. Edge case: If no feedback from author, message ""No feedback done yet."" should be displayed on the screen. Code snippet: <code>. Test case: show original review to be reviewed to meta-reviewer. Edge case: No edge cases for this issue as the meta-reviewer will only have access to ""Begin"" link if review exists (see issue #970). Code snippet: <code>. 1) Login as Admin, create an assignment with all the necessary details like maximum no of users per team, add topics for the assignment, enroll users(students) in the assignment. 2) Select checkbox ""add metareview deadlines"", select dates and add metareview rubric for the same. 3) Go back to manage assignment and add select Assign reviewers. 4) Add meta-reviewer to a particular review submitted by students. 5) Impersonate the meta-reviewer assigned above and go to others work for the same assignment. 6) Select the option ""request a new metareview"" and a new review will be dynamically assigned for meta-review. 1) Login as Admin, create an assignment with all the necessary details like maximum no of users per team, add topics for the assignment, enroll users(students) in the assignment. 2) Select checkbox ""add metareview deadlines"", select dates and add metareview rubric for the same. 3) Go back to manage assignment and add select Assign reviewers. 4) Add meta-reviewer to a particular review submitted by students. 5) Impersonate the meta-reviewer assigned above and go to others work for the same assignment. 6) Select the option ""request a new metareview"" and a new review will be dynamically assigned for meta-review. 7) Option to view the author's feedback will be visible next to Begin button. 1) Login as Admin, create an assignment with all the necessary details like maximum no of users per team, add topics for the assignment, enroll users(students) in the assignment. 2) Select checkbox ""add metareview deadlines"", select dates and add metareview rubric for the same. 3) Go back to manage assignment and add select Assign reviewers. 4) Add meta-reviewer to a particular review submitted by students. 5) Impersonate the meta-reviewer assigned above and go to others work for the same assignment. 6) Select the option ""request a new metareview"" and a new review will be dynamically assigned for meta-review. 7) click begin button and show review option should be visible on the top to view the origin review to be reviewed. 1) Login as Admin, create an assignment with all the necessary details like maximum no of users per team, add topics for the assignment, enroll users(students) in the assignment. 2) Select checkbox ""add metareview deadlines"", select dates and add metareview rubric for the same. 3) Go back to manage assignment and add select Assign reviewers. 4) Add meta-reviewer to a particular review submitted by students. 5) Impersonate the meta-reviewer assigned above and go to others work for the same assignment. 6) Select the option ""request a new metareview"" and a new review will be dynamically assigned for meta-review. 7) Select begin button. 8) The submitted work is different from the work submitted by the metareviewer. 1) Login as Admin, create an assignment with all the necessary details like maximum no of users per team, add topics for the assignment, enroll users(students) in the assignment. 2) Select checkbox ""add metareview deadlines"", select ""Staggered deadline assignment?"" checkbox in general tab and update the deadlines for metareview in ""due dates"" tab. 3) Go back to manage assignment and add select Assign reviewers. 4) Add meta-reviewer to a particular review submitted by students. 5) Impersonate the meta-reviewer assigned above and go to others work for the same assignment. 6) ""Request a new metareview"" option should be visible to the user if the deadline is the future date for that particular assignment. 1. <link> 2. <link> 3. <link> 4. <link>.",Write up is straighforward and well structured.  A few grammatical errors but no other weaknesses at all. Could be enhanced with some screenshots so that the reader could understand the problem and fixes just by scanning it real quick.  ,"You have done a commendable job detailing the issues with the metareview feature of Expertiza, providing potential fixes, and describing new feature implementations to enhance the module. The structure of your work is well organized into problem identification, potential fix, and test case approaches. 

However, there are a few areas that could be improved:

1. Throughout the assignment, when mentioning code, you use the phrases like ""code snippet: <code>"", or ""Old Code <code> New Code <code>"". It would be helpful to actually detail this code or at the very least, write a pseudocode representation of the changes made.

2. You have listed several test case scenarios but some of them are repetitive. For each issue fix or future enhancement, one solid test scenario would suffice. You could devote the extra space to link the issues with the test scenarios in a clearer manner.

3. Repetitions were noticeable in the last five points. A more concise summary of steps is recommended to maintain clarity and simplicity.

4. It's good practice to add a summary or conclusion in the end. This could include an overview of all the reported issues, solutions provided, and enhancements suggested. This will give a complete overview of your work.

Overall, the content of your assignment is constructive and informative. By focusing on the organization and managing repetitions, your future works will be even more effective. Keep the great work going!"
269,E1651,"For users intending to view the deployed Expertiza associated with this assignment, the credentials are below: 1. Instructor login: username -> instructor6, password -> password 2. Student login: username -> student4340, password -> password 3. Student login: username -> student4405, password -> password. Expertiza is an educational web application created and maintained by the joint efforts of the students and the faculty at NCSU. It’s an open source project developed on Ruby on Rails platform and it’s code is available on Github. It allows students to review each other’s work and improve their work upon this feedback. The current project deals with the functionality of managing teams in Expertiza. There are 2 types of teams, Course Teams and Assignment Teams. Course teams stay same for the whole course, while assignment teams can be different for different assignments within a course. An instructor has the functionality to copy an assignment team to make it a course team and vice versa. Few issues with current functionality are - 1. No test cases to check copy team functionality 2. UI is not intuitive as User has to go through ""Create teams""->""Create team""->""Inherit teams from course"" to copy teams 3. Duplicated code in ""create_team_and_node"" method for assignment and course teams The objective of the project is to - 1. Write test to check if the current functions work properly. 2. Debug the code for copying teams. 3. Improve the UI. 4. Refactoring the code to leverage polymorphism. 1. Models 1.1. team.rb 1.2. course_team.rb 1.3. assignment_team.rb 1.4. assignment_node.rb 1.5. sign_up_sheet.rb 1. Controllers 1.1. review_mapping_controller.rb 1. Views 1.1. teams/list.html.erb 1.2. teams/new.html.erb 1.3. tree_display/actions/_teams_actions.html.erb 1. Specs 1.1. models/assignment_team_spec.rb. 1. Team Model In the team model, we refactored the method create_team_and_node to remove an unnecessary argument teamtype, and inferred the teamtype from the Class. We also created a new method parent_model_for_id to fetch the related Assignment or Course object. 2. Sign up sheet, Team, Review Mapping Controller, Assignment Team, Course Team All of these files called the create_team_and_node method. Since we changed the signature, we changed the respective method calls in these classes. 3. teams/list.html.erb, teams/new.html.erb Moved the inherit teams functionality from new.html.erb, an internal page, to list.html.erb. List page, thereby removing 1 user click. 1. Course and Assignment Team Model We created the parent_model_for_id method to return the related Course/Assignment object and also fixed the copy method, which earlier had an undefined local variable. 2. Assignment Node Model In the Assignment node model, we created a new method to check if the related assignment object has a course associated with it. This is then used in a view. 3. tree_display/actions/_teams_actions.html.erb This is the partial to show actions related to teams. The option to copy teams from assignments to course should not be visible if there is no course associated with the assignment. Added a condition to the if statement to check for the same. 1. Assignment Spec Wrote test cases to check if an assignment belongs to a course. 2. Assignment and Course Team Spec Wrote test cases to check the method to copy assignment teams to course teams and vice versa. 3. Team Spec Wrote test cases to verify create team and node functionality for course team and assignment team.","They explain what was done, and show the UI that they updated.  But they didn't explain the code they wrote or changed to do this.","Thank you for your submission. Overall, the work done on the Expertiza project is impressive. You have provided a clear and detailed explanation of the project's objectives and your approach to achieving them.

Some notable points include:

1. The refactoring of methods in the model to optimize the process of creating teams and nodes and removing redundancy.
2. The logical and systematic rearranging of the inheritance teams' functionality to enhance user-friendliness, and thus contributing to the objective of improving the UI.
3. The creation of new methods to supplement the existing functionality by succinctly identifying whether a course or assignment is related to a team. 
4. The attention to the edge case of an assignment without an associated course deserves recognition as this helps increase the robustness of your solution.
5. It's also commendable that you have written adequate test cases to verify your code and ensure it works as anticipated. This speaks to your commitment to deliver robust, error-free code.

Going forward, you may want to consider the following recommendations that could help improve your work even more:

1. Include a brief overview at the beginning of your report, summarizing what your assignment primarily covers.
2. It could be helpful to provide more explanation regarding the determining condition for whether a team is visible or not, which would let a reader understand your design choice better.
3. A concluding paragraph summarizing the benefits of your changes over the initial version can provide a clear perception of the value added by your work.

Overall, an excellent job on this project. Keep up the great work!"
270,E1604,"Our contribution to this project is a suite of functional tests for the assignment calibration function. These tests are designed to provide integration, regression, and acceptance testing by using automation technologies. Expertiza has a feature called Calibration that can be turned on for an assignment. When this feature is enabled an expert, typically the instructor, can provide an expert review for the assignment artifacts. After students finish their own reviews they may compare their responses to the expert review. The instructor may also view calibration results to view the scores for the entire class. While this is a preexisting feature within Expertiza, there currently exist no tests for it. The goal of this project is to fully test the entire flow of the calibration feature using the RSpec and Capybara frameworks. The moment a line of code is written it becomes legacy code in need of support. Test cases are used not only to ensure that code is operating properly, but also to ensure that it continues to do so after having been modified. An important aspect of this is acceptance testing to verify that the project meets customer requirements. Rather than performing these tests by hand, it is easier to combine an automated testing system like RSpec with a driver like Capybara which allows testing of an application's functionality from the outside by running in a browser. A more detailed description of the calibration may be found <link> Before analyzing code, one must familiarize themselves with the steps involved in calibration on Expertiza. The steps involved are: 1. Login with valid instructor username and password 2. Click on ""Assignment"" 3. Click on ""New public assignment"" 4. Input all the information needed, check the “Calibrated peer-review for training?” box, click on Create 5. Select the review rubric in “Rubrics” tab 6. Go to “Due dates” tab, make sure that this assignment is currently in Review phase, also, make the submission allowed in review phase. 7. Add a submitter to the assignment. This submitter will add documents to be reviewed. 8. Go to the list of assignments, click “edit” icon of the assignment 9. Go to the “Calibration” tab, click on the ""Begin"" link next to the student artifact for the expert review, and click “Submit Review” 10. Go to “Review strategy” tab, select Instructor-Selected as review strategy, then select the radio button “Set number of reviews done by each student” and input the number of reviews 11. Login with valid student username and password who is a reviewer for the assignment 12. Click on the assignment 13. Click on “Other’s work” 14. After clicking “Begin”, Expertiza will display peer-review page 15. Click “Submit Review” 16. Click “Show calibration results” to see expert review 17. Login with valid instructor username and password 18. Click on ""Assignment"" 19. Click on the “view review report” to see the calibration report. 1. rspec-rails 2. capybara 3. selenium-webdriver 4. factory_girl_rails. Rspec-rails is a testing framework for Rails 3.x and 4.x. It supports testing of models, controllers, requests, features, views and routes. It does this by accepting test scenarios called specs.<ref> <link> </ref>. Capybara helps you test web applications by simulating how a real user would interact with your application. It comes with built in Rack::Test and Selenium support. WebKit is supported through an external gem.<ref> <link> </ref> To control the environments in which the scenarios are run, it provides before and after hooks.<ref> <link> </ref> 1. before(:each) blocks are run before each scenario in the group 2. before(:all) blocks are run once before all of the scenarios in the group 3. after(:each) blocks are run after each scenario in the group 4. after(:all) blocks are run once after all of the scenarios in the group. Selenium is a portable software testing framework for web applications. Selenium provides a record/playback tool for authoring tests without learning a test scripting language (Selenium IDE). It is the default javascript webdriver for Capybara. Factory Girl <ref> <link> </ref> is a factory gem meant for use in testing. It allows for easy and highly configurable on-the-fly model creation that allows tests to request a new instance of a model template and optionally override any of the defaults. The following scenarios were considered when writing tests for the calibration use case: An instructor creates a calibrated assignment An instructor authenticates to expertiza They select to add a new assignment While creating the assignment, the instructor selects to turn calibration on After creating the assignment the instructor sees a calibration tab on the assignment page An instructor edits the calibration configuration An instructor authenticates to expertiza They select to edit an existing assignment The instructor clicks on the calibration tab and sees it is populated with submitted artifacts An expert submits a review for calibration An expert has been added to an assignment to provide the expert review The expert authenticates to Expertiza and begins the expert review The expert finishes and submits the review Student Calibration A student has submitted a response for the assignment and it is currently in the review phase The student authenticates to Expertiza and chooses to view calibration for the assignment The student sees their own answers compared to the expert review. Answers that match are marked green, and answers that differ are marked red. Instructor Calibration It is currently the review phase for an assignment An instructor authenticates to Expertiza and chooses to view calibration The instructor can see the student and instructor responses for the assignment. Code for the tests exists in two locations 1. <link> 2. <link>. We attempted to follow good OO practices by implementing the CRUD<ref> <link> </ref> design pattern using Factory Girl and Capybara. Our specs follow the standard RSpec describe/it syntax. For example: describe 'Some Feature' do before :each do end it 'should do x' do expect(true).to be(true) end it 'should not do y' do expect(true).to be(false) end end. The following are steps required to run the test 1. Clone the repository in a new directory <code> Create and then prepare the test database <code> 1. Type the command to run tests for assignment submission <code>. The following screenshot shows the result of the rspec command. <image>. 1. All test cases are green, which means there are no currently failing tests. 2. Test cases are run through the Selenium driver on Firefox for javascript support. Because they are full acceptance tests they are slower than regular unit tests, but still beat evaluating the feature by hand. 3. Tests are independent and repeatable. Database changes are made within a transaction that is rolled back after tests complete. 1. <link>. <references></references>. 1. <link>.","""You used a nonstandard page name.
Too much of the page consists of lists.  Using lists is fine, but there should have been narrative describing them.""","Great work on this assignment. Your contribution to the project through implementing the functional tests for the calibration function on Expertiza is commendable. Your detail orientation in mapping out and explaining the different stages that the calibration goes through shows good understanding of the system. Your intent to ensure that the code continues to operate correctly even after modifications by using test cases is impressive. 

It is particularly good to note how you broke down the explanation of RSpec and Capybara and your reasons for using these testing frameworks. Your description of Selenium driver and its role in this process also provides valuable insights. Also, using Factory Girl for easy and configurable on-the-fly model creation in testing is a clever strategy.

The scenarios you provided are detailed and paint a clear picture of various use cases that you analyses while writing the tests. The idea of marking matching answers as green and differing ones as red in student calibration is a simple yet effective tool that enhances understanding.

I appreciate your effort to adhere to both good OO practices and the CRUD design pattern in your code for the test. Your use of the standard RSpec describe/it syntax makes the code easy to follow and shows a good understanding of coding standards.

The steps to run the test are clear and well detailed. However, the content describing how to run the test cases seems to be presented in code format which might make it a bit unclear for some readers. You may want to consider reformatting it to improve readability. 

It's good to see your test cases are green and you emphasize the importance of acceptance tests even if they are slower than unit tests. Your approach to making tests independent and repeatable provides a solid foundation for further testing and adjustments. 

Overall, your assignment shows in-depth understanding and excellent effort. Dedicated work like this greatly contributes to continually improving and enhancing the functionality of projects like Expertiza. Well done!"
271,E1773,"<link> is a open-source ruby-on-rails project on <link> . It constructs a peer-review system by enabling interactions among users and instructors. Students can sign up for a class, view assignments, submit assignments and give peer reviews using expertiza. Instructors can publish assignments, surveys, and reviews, view statistical results and make announcements. The website is created and currently maintained mainly by the students and faculties from NCSU. <link> is a online debugging tool for rails projects that is currently incorporated in Expertiza. Thus, Expertiza production errors at run time are tracked and reported statistically to Airbrake for reviewing and debugging. Our goal for this OSS project is to fix <link> ranked by occurrences reported to Airbrake. You can check the 10 most ranked exceptions by click on the previous hyperlink. By investigating into the top 10 errors from airbrake, we can divide them into different categories by the root of their causes. 1. NoMethodError: undefined method for nil:NilClass (4 out of 10) 2. AbstractController::ActionNotFound (4 out of 10) 3. ActionController::InvalidAuthenticityToken (1 out of 10) 4. ActiveRecord::RecordNotFound: Couldn't find Participant without an ID (1 out of 10) As we have discovered, the same or similar fix can be used to fix all exceptions in the same different category, which is how we categorized these exceptions initially. /config/routes.rb. From the Airbrake issue page, we could find out that the problem is actually caused by a gem called passenger. Although we couldn't find any sign of passenger gem in the recent master branch, but there is a clear sign we found during our review of other errors that some developers had used passenger. The gem might be under the production path `/home/rails/.rvm/gems/ruby-2.1.5/gems/passenger-5.0.16/' So the solution might be just to remove the gem passenger from production environment. For more information, please check <link> NoMethodError: undefined method 'role' for nil:NilClass is one similar error that occurs during run-time <image> <link> pic1 <image>. <code> NoMethodError: undefined method 'uniq' for nil:NilClass is one similar error that occurs during run-time <code>. In most of the cases, the error is caused by an abusive use of RESTful routing provided in rails. In the middle of somewhere of the app, an index or show action is considered ""called"" when the redirect url matches such an action which is undefined in the controller. By thoroughly investigating the controller in trouble and its routes, we came up with a solution that to either reroute the url to an effective url or abort the RESTful route. For one example, in app/controllers/auth_controller , we found no show/index action defined or needed, but in /config/routes.rb , we have the following: <code>. By using resources:auth, rails actually creates index and show actions by default. Somewhere in the app, a redirect is made available to the user to an index or show view page which does not exist. Thus, in order to save the trouble finding the redirect, we simply redirect anything points to those invalid pages to a valid page, which is the root.The modified code is below: <code> Following the same principle, we have modified /config/routes.rb for routes that have caused the most exceptions due to exposure of invalid url redirection to the user. <code> There are 10 similar errors in Top 40 errors involved 5 controllers, which are ResponseController, AuthController, AdminController, ImpersonateController and PublishingController. If a controller mentioned above never uses a method declared by resources, we delete the relevant resources and add the routes of method separately, otherwise we use except expression to exclude methods we don't use. <code> The error was raised in config/initializers/request_forgery_protection_mod.rb And the error actually happened in response#create The background of this problem is that The authenticity token is a random value generated in your view to prove a request is submitted from a form on your site, not somewhere else. This protects against CSRF attacks. The expertiza problem could be the user session expired and the solution can be delete the code in the config/initializers/request_forgery_protection_mod.rb , and redirect or just refresh the page, which would not raise an error. This error is not necessarily a bug in the code, but rather a protection masochism. As said before, it is a matter of choice to get rid of this error or not. Raising an exception is the simplest way to stop the app when some behavior is not wanted. The error was raised in app/models/review_assignment.rb:171 And the error actually happened in review_mapping#assign_reviewer_dynamically The intuition is that the review to a topic should be assigned dynamically and ""too many reviews"" problem should be handled by action revew_mapping#assign_reviewer_dynamically . So we could add the below condition in the above controller action to handle this problem. Instead of raising an error, we could simply handle this problem, which can make ""flash danger message"" unnecessary. Also, the solution is a matter of choice. The simplest way to stop users to submit or post any new data into the data base is to raise an exception which will stop the app. So we are merely making a suggestion here. First, follow the instructions given on <link> . It's your choice to use virtual machine or set up your own environment. Clone the repository which is also the submitted <link> . In this project, we will mainly use airbrake to do testing. Expertiza has already implemented the airbrake gem. You need an airbrake account to begin test. In /config/initializers/airbrake.rb , change the following line <code> You will get your project id after you registered an airbrake account and created a new project on it. It is in your account profile. where project key will be at the same location with your project id. Once you have the right key and id pair, you can start testing the run-time exceptions. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link>.",Excellent job of explaining the errors and what is responsible for them.  One of the most readable writeups.,"Dear Student, 

Good job on detailing the methodologies for investigating and correcting errors in the Expertiza project. You successfully demonstrated your understanding and proficiency in the Ruby on Rails environment and the OSS project. 

However, your assignment could be improved with clearer organization and focus on readability. While the technical explanations are comprehensive, they may be difficult for someone unfamiliar with the project to follow. Consider using subheaders to divide your content into sections or smaller chunks. This would improve the cohesiveness of your paper and make it easier for readers to understand. 

It is commendable that you have thoroughly investigated the root causes of the issues, categorizing them, and providing solutions for each. Your in-depth analysis of the problems and your proposed solutions demonstrate your strong problem-solving skills. 

One point for improvement is your language clarity. Some sentences are long and complicated, which may confuse readers. For example, you could break down this sentence: ""The expertiza problem could be the user session expired and the solution can be delete the code in the config/initializers/request_forgery_protection_mod.rb , and redirect or just refresh the page, which would not raise an error."" into simpler, shorter sentences.

Also, please do not forget to ensure you are correctly and consistently formatting code snippets - some of them are marked as ""code"" instead of actually showing formatted code.

Overall, you have shown a good understanding of the project and presented plausible solutions. Maintain your diligence in exploring and rectifying coding challenges in future assignments. 

Good work!

Best,
[Your Name]"
272,E1726,"Expertiza is an open source web-based peer review system developed using Ruby on Rails. It is a dashboard containing all assignments for a particular course which is managed by the Professors and Teaching Assistants. It eases the process of selecting assignment topics and choosing team-mates for the projects and greatly reduces the burden on the Professors and Teaching Assistants of assigning and managing teams for each assignment. The main motive of this project is to make learning more effective through peer review. It allows students to review each other’s work and improve their work upon this feedback. It not only helps one improve their work but also provides a new way to learn. Students upload or provide URLs of their work on expertiza which would be reviewed by the instructors and peers. Students later get to improve their work based on the reviews provided their peers. The project requires us to remove the cache column from the roles table in database. Expertiza's 'roles' table has a 'cache' column, used by the superfish-rails gem to display different menus for different roles (super-administrator, administrator, instructor, teaching assistant, student, and unregistered user). There is a Role model which makes use of the long text string data stored in the roles table under the cache column to load the menus (e.g., Users \n Questionnaires \n Courses …) for a particular role at the top of the page after login. Storing such long strings in databases is a bad idea because if we want to change that large text we are required to write a migration file which would be inconvenient and also there is a restriction on the number of characters allowed for long string datatype in MySQL. The Design plan followed here is as follows: 1. Move the cache column value to YAML files for each role. 2. Load the YAML value on environment/server startup. 3. Use the corresponding YAML values for the corresponding role for the user logging in. The reason for using this design is to have a pre-defined menu list for each roles. This gives more DRY principle for the application code, instead of going with the new object declaration every time the role model is needed. 1. Create YAML files containing the cache column data for each role from roles table in database. 1.1. Create YAML files under 'config' folder named 'role_admin.yml' and put the 'cache' column value in it split across rails environment 1.2. Create ruby script under 'config/initializers' folder named 'load_roles.rb' - to load the corresponding YAML values once the environment is set up 2. Change the role.rb model to facilitate the use of above defined YAML files 3. Remove the cache column from the roles table by migration 4. Write rspec unit test for 'role.rb'. 1. 6 new files (role_admin.yml, role_instructor.yml, role_student.yml, role_super_admin.yml, role_ta.yml, role_unreg_user.yml) each corresponding to specific role are created 2. Content of cache column from roles table are added for development, production and test environments <image>. This code loads content of ""/config/role_admin.yml"" file and assigns to CACHED_ADMIN_MENU. Similarly, fields corresponding to different roles are populated from corresponding ""/config/role_[ROLE]_.yml"" file <image>. Rebuid_credentials and rebuild_menu method are modified to load content from yml file. Here ApplicationHelper exposes get_cache_roles method to retrieve cache content corresponding to role id. <image> <image> In rebuild_cache method, role.save line is removed as cache field is not saved in database now. Since cache field is removed from roles table, this field is added to role model using attr_accessible. It’s getter and setter are also created <image>. Before removing cache column in roles table <image> Roles table after removing cache column <image> Migration file to drop cache column <image>. The test plan followed here is done across 3 roles namely, student, administrator and instructor. The scenarios covered here are as follows: 1. Check for the cache field and see if we get the expected value. 2. Check if the role is valid role. 3. Check for the cache field mismatch, that is, invalid cache field match. The sections below points out the implementation steps taken to cover the test plan described above. 1. Login into Expertiza as one of the roles - super-admin or admin or student or instructor 2. Check the menu tabs on the top and you can find the respective drop-downs according to the role logged in 3. On clicking the option from the drop down you will be able to navigate to the respective pages 4. This ensures that the code change done by us didn't break the code and it delivered it's expected functionality. Unit tests have been written to check whether the modules work as it did earlier before. We have written rspec unit test for ‘role.rb’ which can be found here: ‘spec/models/role_spec.rb’ which tests 10 cases 1. Evaluate the cache value with YAML values for student 2. Evaluate the cache value with YAML values for instructor 3. Evaluate the cache value with YAML values for admin 4. Validation of name for student 5. Validation of name for instructor 6. Validation of name for admin 7. Check the mismatch for cache values for the student in factories.rb 8. Check the mismatch for cache values for the instructor in factories.rb 9. Check the mismatch for cache values for the admin in factories.rb 10. An invalid check for role object <image> <image>. The steps required to execute the unit tests as an automated run: 1) cd into the expertiza directory 2) Run the command: rspec spec/models/role_spec.rb. There is a lot of scope for improvement for the current code. For instance, in the present situation, the YAML files have the database data corresponding to menu_items hard coded. We could define YAML file for menu_items table and load the menu_item YAML into the corresponding role YAML during environment setup. This would eradicate the use of menu_item table from the database.","The page title needs to be changed (i.e., the page needs to be copied over to a new page with the requisite title).  It should be named after the project,, E1726, not the author.  But other than that, it is a very informative writeup.","Dear Student,

Thank you for your thorough assignment submission. Your understanding of the issue at hand is well-articulated. I appreciate your clear explanations of your design plan and thought process, from creating YAML files to migrating the cache column. The step-by-step approach enhances comprehension and I must commend you for the illustrations provided.

Your written code, as far as I can tell is well-written and easy to understand. However, I couldn't fully evaluate it since the code excerpts you included are represented as ""<image>"" placeholders. For future assignments, consider including the actual code or posting screen captures if visuals are necessary.

Likewise, I appreciate your thoughtful inclusion of a comprehensive testing strategy. This clearly shows your understanding of the need for robust testing in real-world development scenarios. However, considering your discussion of testing cases, some scenarios seem to be a repetition of others. I would encourage you to explore a broader range of independent scenarios in future assignments to increase the efficacy of your testing strategy.

Lastly, your take on possible improvements for the current code is quite insightful. It's evident that you're thinking steps ahead, contemplating the benefits of structural changes for better functionality and efficiency.

In addition to your well-structured work, make sure to proofread and spell-check your submissions. There were a few spelling and grammar errors which can detract from the overall impact of your work.

Overall, you've shown a significant grasp of the project's objectives, methodology and coding concepts. Keep up the good work! 

Best,
[Your Name]"
273,E2068,"This project contributes to <link> , an open-source project using <link> . Expertiza is a platform for student learning that encourages active and cooperative learning while discouraging plagiarism. quiz_questionnaires_controller.rb is used in Expertiza to handle all functionality related to quizzes. A quiz is a type of questionnaire that allows reviewees to interact with their reviewers and making sure they read the submissions before reviewing. The student creating a quiz is supposed to ask questions related to their work, which, ideally, a reviewer should be able to answer. (If a reviewer cannot answer the questions about the reviewed work, then we might doubt the quality of that reviewer’s review.) This controller needs some changes as detailed below. 1. Change the way min_question_score and max_question_score are set for @questionnaire on lines 39-40, as well as on lines 53-54. 1.1. These statements set the min and max scores to 0 and 1, respectively, regardless of what the user enters, which is not intended. 1.2. Change it so that the values are set according to what the user enters from the UI. 2. Change the error message on line 78: 3. Consider lines 259-265, different methods are called with the same parameters (question, choice_key, q_choices) to create different types of questions, depending on q_type. 4. Make appropriate changes to tests so that they pass after the above changes. Quizzes are created with a default minimum_ and maximum_question_score, which is the minimum or maximum score that can be obtained. The values are automatically set by the controller as 0 and 1, respectively. The final score of a quiz is calculated by multiplying the weight of the question by the score and summing the value of each question. Currently, minimum and maximum values cannot be set in a custom way per quiz. Fields for minimum_question_score and maximum_question_score have been added to the form for creating each new quiz, and subsequently passed to the controller. The value is set per quiz, not per question. The values are not restricted. The original error message stated ""Your quiz has been taken by some other students, you cannot edit it anymore."". This error message is vague and can be easily misunderstood. The error message now states ""Your quiz has been taken by one or more students; you cannot edit it anymore."". When creating a quiz, there are currently three different methods for each of the three different question types: true-false, radio, and multiple choice. Radio and multiple choice implement very similar, almost duplicated, functionality in both methods. Radio and multiple choice questions have been combined into a single method so as to remove the duplicated functionality. True-false questions will remain separate, because the functionality is significantly different. Future adjustments would require too many changes in the code and tests. <link> <link> <link> <link> <link> <link>. The image below shows the addition of the min_/max_question_score fields to the quiz questionnaire form. <image> The image below shows the values from the form used in the controller. <image> The image below shows the creation of a single function to handle both types of multiple choice questions. It also shows that the new function is called in the save_choices function instead of calling both the original functions. <image> The image below shows changes necessary for assigning the correct answer for radio button multiple choice questions after making the changes from the previous image (the changes to the functions in the controller). <image>. Testing for the quiz_questionnaires_controller already existed, this project added and altered test cases that were affected by our project's implementation. 1. min_question_score and max_question_score score being negative 2. max_question_score score being less than min_question_score. 1. Create test for raising an error if min_question_score is less than zero 2. Create test for raising an error if max_question_score is less than one 1.1. Testing based on less than one since: 1.1.1. min_question_score should be less than max_question_score 1.1.2. min_question_score must be greater than zero 1.1.3. therefore, max_question_score must be greater one 3. Create test for raising an error if max_question_score is less than min_question_score. <code> 1. This test verifies that the save_choices method in quiz_questionnaires_controller.rb functions correctly 1.1. save_choices contains calls to create_truefalse and create_multchoice 2. This corresponds to our changes with merging create_checkbox and create_radio methods into create_multchoice method. <code> 1. This test verifies that a quiz with valid parameters can be created and saved correctly 1.1. This test case verifies that min_question_score and max_question_score error <code> 1. This test verifies that quiz_questionnaires_controller.rb flashes an error when max_question_score is less than min_question_score 1.1. This handles an edge case scenario <code> 1. This test verifies that quiz_questionnaires_controller.rb flashes an error when max_question_score and min_question_score are less than 0 1.1. This handles an edge case scenario <code> 1. This test verifies that the questionnaires.rb model raises an error when max_question_score is less than min_question_score 1.1. This handles an edge case scenario. 1. Coverage increased (+0.03%) to 42.982% 2. Coverage for related files 1.1. quiz_questionnaires_controller.rb 96.2% 1.2. questionnaire.rb 81.25%. rspec spec/controllers/quiz_questionnaires_controller.rb. <link> The instructions below can also be found <link> with screenshots to follow along. 1. On the main menu, click on “Manage.” Note: If you click on ""Assignments"" from the drop down menu here, you will incur an error that is outside of the scope of our project. 2. The following page will have a sub-menu for Courses, Assignments, and Questionnaires. Click on ""Assignment."" 3. Click on the plus sign on the right side of the page to create a new assignment. 4. Under the “General” tab, fill out the “Assignment Name,” select a course from the drop down menu, and check “has quiz.” 5. Once you have filled out the form, click on the “Create” button at the bottom of the page to create the assignment. 6. Once the assignment is created, a new field called “Number of Quiz questions” will be created on the right side of the page. Its default value will be 0. Change it to your desired number of questions. (Note: There are three different kinds of questions: Multiple Choice (four answer choices), Radio (four answer choices), and True-False. In order to test all answer possibilities, you can set this value to 17.) 7. Click on the Due Dates tab. 8. Set the dates for submission and review to any date after the current date. 9. Click ""Save."" 10. Under editing the assignment, click on the Other Stuff tab. 11. Click on “Add Participant.” 12. Add instructor6 as a participant. 1. On the main menu, go to the ""Assignments"" tab. 2. This page will look similar to the Expertiza home page for the class. Find the assignment you just created under the “Tasks you have not yet started” list and click on it. 3. On the assignment page, click on ""Create New Quiz"" under “Quiz.” 4. Fill out the form. Once you select the type for each question, the view will update to allow you to enter your answer options. Remember these settings to check the correctness later. (Note: If you only provide one potential answer for the “Multiple Choice - Checkbox” option, the quiz will not be created and the entire form will clear.) 5. Once you have filled out the entire form, click ""Save"" at the bottom of the page. 6. You will be returned to the “Submit work for Assignment” page. There will be new options under “Quiz.” Click on “View Quiz.” 7. This page should show all of the settings of your quiz, including correct answers, weight, and minimum and maximum question score.","The wiki page is very well structured and explains the changes that have been made.  However, I think the descriptions of the code modifications are too terse, e.g., ""shows the values from the form used in the controller"" doesn't explain why two different groups of two lines were changed.  Test descriptions are adequate.","Dear Student,

I appreciate this well thought out and comprehensive contribution to the open-source project Expertiza. You have demonstrated a good understanding of the task and identified important issues in the existing codebase.

Your commitment to detail is apparent. You have effectively addressed major issues such as clarifying the error message and removing code duplication by merging radio and checkbox functionalities into a single method. The provision for the user to set maximum and minimum question scores is a useful addition to the functionality of the quiz controller. 

Your comprehensive documentation, illustrated by screenshots and code snippets, is commendable. This makes it easier for others contributing to the project to understand the changes you have made. Your amended and additional tests showcase your understanding of the role testing plays in development and add to the robustness of the project.

However, I would suggest going more in-depth about your implementation process in regard to changes made in the controller. Also, it would be beneficial to elaborate on the parameters used in the quiz controller, explaining the purpose of each parameter in detail.

Your test coverages are high and laudable but can you please interpret the uncovered lines? What impact do these uncovered lines have on the overall function of the controller and what suggestions would you make to bring these to cover?

On the whole, this was a well-executed project. I look forward to seeing your continued contributions to the project.

Best regards,

[Your Name]"
274,E1508,"Expertiza is a web application where students can submit and peer-review learning objects (articles, code, web sites, etc). The Expertiza project is supported by the National Science Foundation.<ref> <link> </ref><ref> <link> </ref>. Classes involved: <code> What they do: Allows the user to create and edit responses to questionnaires … such as performing a review, rating a teammate, or giving feedback to a reviewer. What's wrong with it: 1. It doesn’t do authorization properly. 2. It contains duplicated methods. 3. Functionality that should be in models is incorporated into the controller. What needs to be done: 1. latestresponseversion seems misnamed. It fetches all previous versions of a response (which is to say, all previous review versions by the current reviewer of the current author for the current assignment). 2. get_scores gets all the scores assigned in a particular response. A “response” is created when someone submits a review, a partner evaluation, a survey, etc. 3. The rereview method is 98 lines long. Several parts of it should be turned into methods. Sorting review versions is really not a controller responsibility; it would be better to do this in a model class (which class?) Ditto for determining whether a review is current (i.e., was done during the current assignment phase). This is a query that is made about a review (actually, about a response, which may be a review, author feedback, etc.). It should be placed in the appropriate model class. 4. rereview contains special code to check whether an assignment is “Jen’s assignment”; this was the first assignment we ever created with a multipart rubric. It was hard-coded into the system, rather than working on a rubric that was created in the normal way. It is probably impossible to remove this code without breaking that assignment, but it should be done in a separate method, and commented appropriately as a kludge. 5. Again in rereview , creating a new version of a review is a model responsibility, and should be moved out of the controller. 6. There are two (consecutive) copies of the edit method. The second appears to be the newer one, and, according to the rules for method definition, is the one that is currently in use. The first should be removed. Ditto for new_feedback and view --the 2nd version of each appears to be newer & should be kept. 7. Authorization to perform actions is not checked correctly. It is supposed to be done through the action_allowed? method at the beginning of the class definition. Different authorization should be required for different operations. For example, someone should be allowed to view a response if they wrote the response, or they are the person or on the team whose work the response applied to, or if they are an instructor or TA for the class. The person who wrote a response should be allowed to edit it, but not the person/team who was being reviewed, nor the instructor or TA for the class. Currently, authorization is denied by the redirect_when_disallowed method, which was an earlier, more error-prone way of controlling access. It should go away, now that the class has an action_allowed? method. <table>. <table>. The latestResponseVersion method is misnamed. It fetches all the previous versions of a response and its current name does not reflect its actual functionality. The method was renamed as previous_responses since it better suited the actual functionality. <table>. The ResponseController allows the user to create and edit responses to questionnaires, and the functionality changed over time, causing two new_feedback and view methods to be created; the oldest of which doesn't get called anymore. <table>. The ResponseController allows the user to create and edit responses to questionnaires, in doing so, there needs to be some sort of authentication, and the proper place for that is in the action_allowed? method, however the un-refactored code did in the redirect_when_disallowed method. Moreover, once this code was moved to the action_allowed? method, all of the references to redirect_when_disallowed were removed (action_allowed? gets called automatically). <table>. The get_scores method was being implemented in the controller. Its function fits better in the model. As such, the method was moved and changed to retain the functionality of code that uses it. Since the variables it requires were no longer in scope, they're passed in as arguments. Also due to scope, the result has to be explicitly returned. <table>. The code to sort response versions has been moved from rereview method to a separate method. This was done because the rereview method was becoming very long and confusing. <table>. The rereview method had some special code to check if the current user is jace_smith and uses a custom hard-coded rubric instead of a rubric from the system. This was a code segment that was written when multipart rubrics were first tested. Removing this code will break the assignment and so the code was moved to a separate method and commented as a kludge. <table>. Action allowed is called before every method call to confirm whether or not the currently logged in user has the required privileges to complete the requested action. To test the functionality of this method one has to attempt to complete an action that they have privileges to complete, and confirm that they're allowed to complete it. One also has to attempt to complete an action that they don't have the privileges to complete, and confirm that they're not allowed to complete it. Log into the application with the user having a student's role ( User Id: user5072, Password: password) 1. Click on Assignments, and you should see the following: <image>. Log into the application with the user having an instructor's role ( User Id: user6, Password: password) 1. Click on Assignments, and you should see the following: <image>. Get scores is called anytime the scores for reviews are shown. Given that, the way to test its correct functionality is to navigate to a completed review and make sure the scores are shown and are correct. Log into the application with the user having a student's role ( User Id: user5072, Password: password) 1. Click on Assignments 2. Click on Writing assignment 1b, Spring 2013 3. Click on Others' Work 4. Click on Review done at --2013-03-01 23:57:55 UTC Successful loading of this page confirms the get_scores method. Rereview manages the versioning of multiple reviews for the same assignment. To test the correct functionality of review, one should attempt to update a review (i.e. 'rereview'). Log into the application with the user having a student's role ( User Id: user5072, Password: password) 1. Click on Assignments 2. Click on Writing assignment 1b, Spring 2013 3. Click on Others' Work 4. Click on Update (beside Metaprogramming in dynamically typed languages) Successful loading of this page confirms the rereview method. <references></references>.","Very well organized, explains changes well.
","Your work on analyzing the Expertiza web application is comprehensive and well-reasoned. Here's some feedback on your assignment:

1. Good job identifying the problems and possible solutions in the Expertiza code. You made an excellent observation about misnamed methods and issues with the authorization system, as well as the inappropriate distribution of responsibilities between methods and classes. Your suggestions for refactoring look quite sensible.

2. Your detailed report on the actions taken is great. You moved methods to appropriate locations, renamed methods for clarity, and improved the authorization system, which shows a solid understanding of programming principles.

3. Your proposed method for testing the edits you mention is thoughtful and thorough. By outlining step-by-step tests for different user roles, you make it easier to ensure that the implemented changes work as intended.

A few points to improve:

1. Your explanation could benefit from more detailed, technical descriptions of the exact changes made and why they were necessary in the context of the programming principles. This will further demonstrate your understanding and ability to apply these principles.

2. Try to maintain a more concise and coherent style in your writing. Long paragraphs can be challenging to read, and key points may get missed. Make use of bullet points and subheadings to improve readability.

3. Though not explicitly required, incorporating diagrams or other types of visual aids could help portray the structure of the system and the changes you suggest more effectively.

4. Lastly, while you've done a competent job in identifying and correcting these issues, try also to consider the possible side effects those changes might have on other parts of the code. It's important to provide as much context as possible and consider all potential impacts.

Overall, your work is impressive and show both strong analytical skills and an understanding of software development principles. Keep pushing to improve your descriptions and consider wider implications of your work, and you'll continue to progress as a programmer and analyst."
275,E1956,"Contents 1.1. <link> 1.1.1. <link> 1.2. <link> 1.1.1. <link> 1.1.2. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.3. <link> 1.3. <link> 1.4. <link> 1.1.1. <link> 1.5. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.6. <link> 1.7. <link> 1.8. <link>. <link> is an open-source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. E1956. There is no shortcut to get free review points: Review Assignment Bug. Each assignment contains an review strategy. We can generally submit 'n' reviews according to the review strategy. For an assignment with topics, a student has an option to choose a submission to review or can say “I don’t care” and the system chooses any available topic for review. 1. The number of reviews done by any student is not checked in the back-end with the maximum number of submissions allowed as per the review strategy. 1. There is no check to see if the submission is already assigned to the student. 1. There is no check on the number of outstanding reviews a user can have. This project, in particular intends that the students collaborate and work on making enhancements to the code base by applying the concepts of Rails,RSpec, DRY code,Test driven development etc. This provides an opportunity for students to contribute to an open-source project and learn further about software deployment etc. Currently, there is no check in the backend that limits the number of reviews a student can be assigned. Students can get more peer reviews than review strategy. Also, there is no check to see if the user has submitted enough reviews for that assignment before getting a new review. Problem 1: No limitation on the maximum number of peer reviews. 1. There is no check in the backend that limits the number of reviews assigned to a student. There is a check in the UI, but one could evade the limit by typing in a URL to make the same post request. One can also evade it by clicking multiple times on ""Request a review for submission"" button in UI. Problem 2: No check on duplicate submissions 1. There is no check to see if the submission is already assigned to a student (on consulting the TA, it was made known that the feature was working correctly without editing any of the code and thus no refactoring was performed for this task). 2. If the same request is re-sent, the system adds the same submission for review a second time. Problem 3: There is no check on the number of outstanding reviews 1. A user can request for submissions even if the current outstanding ones are pending. <image> <image>. review_mapping_controller.rb 1. The is_reviews_allowed method checks the number of reviews assigned to a student and then compares it with the maximum number of reviews allowed as per review strategy. If the student is asking for more reviews than the review strategy then it returns False. <code> 1. The check_outstanding_reviews checks the number of outstanding assignment reviews a user can have at a time. The check_outstanding_reviews keeps a count of the number of reviews in progress as well as the number of reviews currently completed by the user and returns a Boolean value depending upon whether the former is less than the maximum outstanding reviews allowed as per the review strategy or not. The user can only request for a submission if the check_outstanding_reviews returns True. <code> review_mapping_controller_spec.rb 1. Change has been done in the implementation of review_mapping_controller.rb where a new check was added. This check fetches the number of reviews done by a student currently from ReviewResponseMap table. To adapt to those changes, two new mocks were added to the review_mapping_controller_spec.rb. 2. ReviewResponseMap is mocked to return 0. This is the number of reviews that a student has done so far. 3. Assignment is mocked to return 1 as number of reviews allowed for the assignment. 4. To test number of reviews, we added new tests. The code works on size of object returned by querying reviewer_id and reviewed_object_id. To avoid database call, ReviewResponseMap is mocked to return empty list and a list of values. Empty list indicates that student has not done any review and therefore must be allowed. List of values is returned to check if the size of list is greater than allowed number of reviews according to review strategy. 5. To test outstanding number of reviews, we added new tests. The code works on number of reviews completed. If the number of reviews completed are less than assignment's max outstanding reviews, then student must not be allowed new review. To test the functionality we mocked ReviewResponseMap to return an object. 6. For one of the test cases we mocked the assignment's max outstanding reviews to be 0, which means without doing even a single review he can request as many reviews as he wants. For the other test case we mocked assignment's max outstanding reviews to be 2 and hence without doing two reviews he can't ask for more. We mocked ReviewResposneMap to have one object. For users intending to view the deployed Expertiza associated with this assignment, the credentials are below: Instructor Login: username -> instructor6, password -> password. Use the given link: <link> Follow the instructions below to test the implemented changes: 1. Login as instructor. 2. Go to Manage->Assignments and navigate to assignment name 'test1'. 3. Click on add participants. This will give a list of all participants. 4. Now click on any student username in order to impersonate. 5. Go to test1->other's_work and click on request submission button continuously and wait for the response. 6. It would be noted that the request would never exceed the number of submissions mentioned in the review strategy. To test outstanding number of reviews: Follow the steps above, you will get 2 reviews at first. 1. Fill up one of the review, You will get the button to request again. 2. Click on button continuously. 3. It should be noted that despite continuous request, user will not get any more reviews than difference of max outstanding review and completed reviews. All the test cases have been automated in the review_mapping_controller_spec File 1. Student has done reviews less than review strategy: <code> 1. Assign Review Dynamically. 2. Redirect to Student review page. 2. Student has done reviews more than the review strategy: <code> 1. Redirect to Student review page. 2. Show Flash Error. [flash[:error] = ""You cannot do more than "" + assignment.num_reviews_allowed.to_s + "" reviews based on review strategy""]. All the test cases have been automated in the review_mapping_controller_spec File 1. Student has pending reviews less than review strategy [default 2 pending reviews at most]: <code> 1. Assign Review Dynamically 2. Redirect to Student review page 2. Student has done reviews more than the review strategy [default 2 pending reviews at most]: <code> 1. Redirect to Student review page. 2. Show Flash Error. [flash[:error] = ""You cannot do more reviews when you have ""+ assignment.max_outstanding_reviews + ""reviews to do""]. 24.317%. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link>.","Explanation of the problem statement where the student is allowed to do more reviews than the specified number in the assignment poilicy could have been better
.  However after that, the explanations of the changes are very complete and understandable.  There is also a good description of the changes that were made to each file.

It would have been clearer to cut and paste test from the Github diff view than to use the textboxes in the wiki, which are monochrome with fixed-width characters.","Thank you for this detailed submission. You've clearly put a great deal of effort into it. There are, however, a few areas you could improve upon:

1. Organization of content: While the assignment is filled with great content, it's somewhat difficult to navigate due to the use of excessively detailed subheadings and lack of a clear structure. It would significantly improve readability if you organized your content more intuitively and highlighted key areas of your analysis. 

2. Clarity: At several points in your assignment, it's a bit unclear what you're explaining or discussing. Try to use simpler, more straightforward language to clearly explain your code, the existing problems, and the solutions you've implemented. Providing a brief overview at the start of each section would also be beneficial.

3. Redundancy: There seems to be a level of repetition in your content. Please review your work and eliminate unnecessary repetition of facts or lines of reasoning. This would help to make your assignment more concise and easier to follow.

4. Real life application: You have done a good job identifying and addressing problems within the system. It might be useful to further extend this by discussing the real-world implications of these issues and how your solutions could resolve these.

5. Proofreading: There are a few typos and grammatical errors throughout your submission. Proofreading your work can help improve its professionalism and readability.

Overall, you've done an excellent job with the technical aspects of this assignment. The next step would be working on clarity, conciseness, and presentation of your content. Keep up the good work, and I look forward to your future submissions!"
276,E1903,"1. The questionnaires_controller.rb has multiple methods to handle quizzes. Some of these methods cater only to quizzes. The controller has to be refactored into 2 controllers by moving the functions related to quizzes and the dependencies into a new controller called quiz_questionnaire_controller.rb. 2. Some methods in the questionnaires_controller.rb are long or have hardcoded parameters. These methods have to be refactored into shorter functions rid of hardcoded parameters. 1. Creation of new controller A new controller called quiz_questionnaire_controller.rb was created using scaffold. The methods in the questionnaire control pertaining to quizzes were moved to the new controller. Certain methods such as create_questionnaire which are to be needed in both classes were refactored as explained in later sections. The routes.rb file was edited to reflect the new routes to the new controller's actions as shown in image below. <image> The views for the controller were not created or moved from questionnaires controller. Instead, every action in the quiz_questionnaire controller renders a view from the old controller itself. However, the links and redirect was edited multiple controllers and views (as stated in affected files), so that the action in the right controller was called. to be filled 3. Refactoring current controller Problem : Due to multiple refactoring over the years, there are few redundant methods in questionnaire_controller.rb. Additionally, a few of the methods like update_quiz, create contain the redundant piece of code and multiple switch statements. Refactoring of create_questionnaire method : The create_questionnaire method from questionnaire_controller.rb is used to create a questionnaire based on the type of questionnaire. The implementation corresponding to the quiz is irrelevant in the context of questionnaire_controller.rb. Newly created quiz_questionnaire_controller.rb undertakes the task of creating a questionnaire of type Quiz and the original method handles the creation of all other types of questionnaires. The control was delegated based on the type of questionnaire and the corresponding method is called. Refactored create_questionnaire method <image> Refactored create_quiz_questionnaire method <image> Refactoring of create method : The create method is used to create a questionnaire in the questionnaire_controller.rb. Based on the type of questionnaire, the name in the view is changed. Assignment of display type is done using a switch case that takes up 11 lines of code and each case adds ""%"" to the camel cased value. Solution: The implementation was changed to check if the display type matches with the available type and when matched, uses Regex, split and join methods to evaluate the same in a single line. <image> Refactoring of update_quiz method : The update_quiz method is used to update the quiz when the user edits the existing quiz. Iterating over the set of questions, the attributes are updated based on the type of question (viz. Multiple Choice, Radio, True/False). The implementation for two of these types can be changed and can be used as private methods. <image> Refactoring of save_choices method : The save_choices method contains a lot of redundant hard coded data that is not accessed/used in the application. These hardcoded variables were removed and the relevant code is refactored to work seamlessly. 4. Creation of new route for quiz_questionnaire_controller and updated the affected links in views Created a new route quiz_questionnaire for quiz_questionnaire_controller in ""routes.rb"" and moved the custom created ""get/post"" routes for quizzes from questionnaires route to it. <code> Then changed the controller name and route in all the following views which are accessing quiz_questionnaire_controller while keeping the application flow intact - /app/views/questionnaire/view.html.erb <code> /app/views/questionnaire/new_quiz.erb <code> /app/views/questionnaire/edit.html.erb <code> /app/views/submitted_content/_main.html.erb <code>. The following files were created or refactored 1. /app/controllers/questionnaires_controller.rb 2. /app/controllers/quiz_questionnaire_controller.rb 3. /app/views/questionnaire/view.html.erb 4. /app/views/questionnaire/new_quiz.erb 5. /app/views/questionnaire/edit.html.erb 6. /app/views/submitted_content/_main.html.erb 7. /config/routes.rb 8. /spec/controllers/questionnaires_controller_spec.rb 9. /spec/controllers/quiz_questionnaire_controller_spec.rb. The refactoring of code was done in a manner as to not affect the functionality or the code flow. Therefore, the test plan has not been modified from the original spec file apart from moving quiz_questionnaire relevant tests from questionnaire spec file to quiz_questionnaire spec file. The code is not hosted as there are no new functionalities created. As with other refactor projects, a video of using the UI is attached in the submission. 1. <link> 2. <link> 3. <link>.","Starts out very well, with good explanations and code snippets.  Further down, the code snippets are pasted in with raw text and the commentary is less complete.","Dear Student,

Thank you for your submission on the refactoring task of `questionnaires_controller.rb`. Your overall approach, implementation, and presentation are thorough and clear. Here are some comments and suggestions:

1. It's apparent that you put a good deal of thought into how to split `questionnaires_controller.rb` into two, more focused controllers. This is a key aspect of the ""Single Responsibility Principle"" and is essential in enhancing the maintainability and readability of the code. Well done on that!

2. Your effort in explaining how you refactored the `create_questionnaire` and `create` methods is commendable. Your solution to simplify and streamline the code is neat and logical.

3. Your refactoring of the method `update_quiz` is well justified. Making certain functions private also follows good practice of encapsulation and modular design.

4. You did well in acknowledging the need to clean up and refactor the `save_choices` method, removing redundant and unused hard-coded variables. This is a crucial step to improve maintainability.

5. The creation of new routes for `quiz_questionnaire_controller` and the updating of affected links is well documented. This shows your great attention to maintaining the application’s flow even after the refactoring.

6. While it's good to see that you've ensured the functionality of the code remains intact post-refactoring by not modifying the test plan, it could have been useful to write additional tests for the new controller you created, `quiz_questionnaire_controller.rb` to validate its functionality.

7. Lastly, I'd recommend you to include a brief explanation for all the attached images <image> and the links <link> to provide context and to reinforce your points.

Overall, your refactoring efforts have resulted in cleaner, more manageable code, and your clear explanations and demonstrations of the changes made have greatly aided in the review process. Good job!

Keep up the excellent work!
"
277,E1951,"The Expertiza project is software to create reusable learning objects through peer review. It also supports team projects, and the submission of almost any document type, including URLs and wiki pages. Expertiza has Assignment objects, which represent an assignment that is done by some number of users. For some assignments, students need to select a topic before submitting work. Topics associated with an assignment be reached as follows: 1. Log in as an instructor or a TA. 2. Select Manage->Assignments, which will bring up a list of assignments. 3. Click on “edit logo” under the “Action” column of an assignment. 4. Click on “Topics” tab in edit assignment page. If an instructor or a TA wants to delete topics, he has to delete one topic at a time and has to wait for the page to refresh and then (s)he can proceed to delete the next topic, topics can only be deleted one by one. 1.There should be a checkbox column, along with other columns in “Topics” tab, where a user can select the topics (s)he wants to delete. 2.There should be a delete button/link at the end of the topic table with the name “delete selected topics” to delete the selected topics after a confirmation, prompted post clicking the button/link. 3.There should be a button/link alongside “delete selected topics” by the name “Select all” so that a user can select all and delete them in one go after clicking on “delete selected topics”. 1. Beside ""Home"", click ""Manage..."", then click ""Assignments"". 2. Choose an Assignment ( Final project (and design doc) is recommended).Then click ""Edit"" below Actions. 3. Click ""Topic"" tab. 4. Create some topics by click ""New topic"" on the bottom line. 5. Select them and click ""Delete selected topics"". Then click ""Yes"". (It may take a while!) 6. Then you shall see they are deleted. (For some reason we don't know, it failed when editing a staggered deadline assignment.). File: app/views/sign_up_sheet/_add_topics.html.erb Add bottoms of 'Delete select topics' and 'Select all' <code> File: app/views/sign_up_sheet/_table_header.html.erb Add 'Select' header <code> File: app/views/sign_up_sheet/_table_line.html.erb Add selected checkbox <code>. File: app/assets/javascripts/signup.js Select All function checks all checkbox of topics. <code>. File: app/controllers/sign_up_sheet_controller.rb Define delete all and get selected topics methods. <code> File: app/views/sign_up_sheet/_add_signup_topics.html.erb <code> File: app/views/sign_up_sheet/_add_topics.html.erb Delete function destroys all selected topics. <code> File: app/views/sign_up_sheet/_table_line.html.erb <code> File: config/routes.rb Add url. <code>. Before clicking 'Select all' bottom, there are checkboxes that could select each topic. <image> After clicking 'Select all' bottom, all checkboxes are selected. <image> After pushing 'Deleted selected topics', there's a confirmation alert. After clicking yes could delete all topics. <image>. File: spec/controllers/sign_up_sheet_controller_spec.rb Select assignment with id '834' and topic with id ['E1732'] as params. Post params to delete_all_selected_topics. Expect success flash with 'All selected topics have been deleted successfully.' and redirect to '/assignments/834/edit#tabs-2'. <code>.","The wiki page does not provide background to what topics it is talking about, and does not explain where in the UI the change would be made.  I have added the description by copying it from the project specification, so future readers will understand what it is about.
The solution should be described before manual testing.
Seems like the ""Select all"" link should precede the ""Delete selected topics"" link.
The png files have really large text, and code text is tiny.  This makes the page hard to read.
But, the changes have been described quite well.","Dear student,

Thank you for your detailed work on this assignment. Your proposed solution for deleting multiple topics at once in Expertiza is thoughtful and well-documented. I appreciate your use of sequential instructions, which clearly outline each necessary step in the process, as well as your HTML, Ruby and JavaScript snippets, which demonstrate your understanding of these languages.

However, some necessary information is difficult to understand. For example, the purpose of certain functions or lines of code is not always clear. When presenting your code, it would be beneficial to include more detailed explanations to fully express your thought process. Your ""<code>"" placeholders could be replaced with small code snippets and explanations so the readers know what is being changed or affected.

I would also recommend adjusting the structure of your work to more explicitly differentiate between your proposed solution and the current functionality. Paragraphs and clearly defined sections will make your assignment easier to navigate, especially for readers who are not familiar with the tools and resources you used.

Your images are not displayed and it seems like there might be some missing portions of text or code, indicated by these ""<image>"" placeholders and ""<code>"". Make sure to include those in your report and ensure they are displayed correctly. 

Lastly, remember to take careful note of your grammer and spelling; for instance, the word is ""button"" not ""bottom"". These small errors can detract from the overall professionalism of your report.

Feel free to revise your work based on these feedbacks and resubmit. Keep up the great work!

Sincerely,
[Your name]"
278,E1873,"One of the fantastic features that Expertiza provides is for each assignment, it allows students providing reviews for others' jobs. This is done by offering a pre-defined questionnaire for the whole assignment, which is called the rubric for this assignment. Each rubric has several questions, each question provides a criterion to evaluate the performance from a specific angle. Then students can evaluate the entire job by rating and answering these questions. The team did that job can also get a detailed feedback for different aspects of the project. One of the problems for the review system is that for each assignment, different topics are included. Students can choose the one topic they like, and those topics fall into different categories. That is, an assignment always include different kind of projects. In Expertiza, the topic can be refactoring projects, testing projects, Mozilla projects, etc. Apparently, for different kinds of projects, we have different criteria to evaluate their performance. However, due to the current design of the system, all projects belong to the same assignment can only have the same rubric, which may lead to unnecessary criteria for some projects and inadequate criteria for other projects. To make sure all kinds of projects can be evaluated properly. We plan to refactor the system to allow assigning different rubies for different projects in a specified appointment. To realize such purpose, we have the following tasks need to be done: For current design, the rubric used for a specified assignment is set at the following page. To make sure users can choose to set different rubrics for different projects, we need first add a checkbox at this page. Therefore, users can use this box to indicate if they want to use the same rubric for all the projects or set some different rubrics for some projects. <image>. To make sure users can choose rubrics for each project, we should add a new dropdown list beside each project in the following page. The number of dropdown list should decide by review round number. Therefore, each time users choose to identify different rubrics for different projects, the list will appear and users can choose proper rubrics. The default rubric set at last page will be overwritten in this case. <image>. Make changes to the controller so that these functions can work. Most of our logic control codes will be written in helpers/sign_up_sheet_helper.rb . logic flowchart: <image>. Add questionnaire_id in sign_up_topics table to make sure the projects can always relate to correct rubrics <image>. Test what we changed to make sure it works as intended and not influence the original system. 1. edit the file views/assignments/edit/_rubrics.html.erb 2. add a checkbox at the top of the page which says ""Vary rubric by topic"" 3. set the default state for this checkbox as unchecked. 1. edit the file views/assignment/edit/_general.html.erb 2. add a variable to indicate if the checkbox said in Task 1 is checked 3. create a new file under views/sign_up_sheet called ""_rubrics_list.html.erb"" to store the code for the dropdown list 4. edit the file views/sign_up_sheet/_table_line.html.erb 5. add the code to render the dropdown list 6. making a judgment before rendering the dropdown list, only if the checkbox in Task 1ist checked to render the page. Change the update method in sign_up_sheet_controller.rb to make sure when new rubric is chosen for a specific topic, it can be stored in the database properly. 1. create a new migration to add questionnaire_id in sign_up_topics 2. the questionnaire_id is a foreign key which references to questionnaires 3. change the file models/sign_up_topic.rb, and add the relations with the questionnaire, the relation between them is one-to-one. 1. make a test plan for the features that need to be tested 2. follow the test plan to write automatic test codes 3. evaluate the results and refactor codes. We mainly use cucumber and capybara to test UI, and the following are detailed plans. 1. go to the rubrics page under the assignment 2. we can see the checkbox says ""Vary rubric by topic"" shows on this page 3. the initial state of the checkbox is unchecked. 1. the checkbox ""Vary rubric by topic"" is unchecked 2. go to the topics page under assignment 3.there are no dropdown lists beside topics. 1. the checkbox ""Vary rubric by topic"" is checked 2. go to the topics page under assignment 3. the table to show the topics have a row called ""rubrics"" 4. under this title, each topic has a dropdown list. <image> <image>. Instead of testing UI, we did some unit tests using Rspec. For testing update_topic_questionnaires. 1. when attributes are nil <code> 1. when attributes are not nil and at least one topic_questionnaire's id is nil or blank <code> 1. when both save and update_attributes method do not work <code> 1. when both save and update_attributes method work well <code> For testing review_by_rounds, check the number of rounds which decides the rounds of the questionnaire that each assignment needs. 1. when used in round is nil <code>.","The document gives a good overview of how the code is implemented, but it would be good if it included links to the code, e.g., in Github.  The screeshot of the implemented signup page is not very clear.  On the tests, instead of just saying ""when"" they are used, it would be good to see what conditions cause them to pass or fail.","Hi Student,

Thank you for your comprehensive work. Your assignment shows a high degree of understanding of the Expertiza review system and its development requirements.

In your initial discussion, you provided a thorough analysis of the current challenges faced within the system. Specifically, you identified the need for different evaluation criteria for different kinds of projects. This is a key insight and your subsequent proposal to solve this issue reflects a careful consideration of the system's functional requirements.

Your proposed solution, including the need for a checkbox and dropdown list, is well-structured and makes interesting use of the existing framework. The tasks you have outlined for the refactoring process are detailed and provide a clear roadmap of what needs to be done. The delineation of this plan into several actionable tasks reflects strong project management skills.

Your plan to test changes and ensure they do not impact the existing system is an important part of the development process. It is commendable that you have considered this and included unit testing as part of your strategy.

On the downside, your assignment can be improved in the following ways:

1. Explain your technical jargon: Recap the terms for those who might not be familiar with them.
2. Include pseudocode or sample code in the sections where you mention <image> and <code>.
3. Provide clearer instructions on how you plan to implement the changes. Adding more details will make this easier for anyone who wants to implement your suggestions.

Overall, this is a strong effort and your work shows a deep understanding of the system. Keep up the good work.
"
279,E1826,"The navigation for an instructor follows the below structure. 1. Home 2. Manage... 1.1. Users 1.2. Questionnaires 1.3. Courses 1.4. Assignments 1.5. Impersonate User 1.6. Anonymized View 3. Survey Deployments 4. Assignments 5. Course Evaluation 6. Profile 7. Contact Us And that for a student follows the below structure. 1. Home 2. Assignments 3. Pending Surveys 4. Profile 5. Contact Us For an instructor, the menu item 'Assignments' is present in 2 places - in the main menu as 'Assignments' and in the sub-menu as 'Manage.../Assignments' ( italicized above). This could potentially be confusing. 'Manage.../Assignments' sub-menu item allows the instructor to create/edit assignments. The menu item 'Assignments' allows an instructor to participate in assignments. This is typically something that the instructor wants to do in a student role and hence there needs to be a student view for instructors to act as students without impersonating them and thus reducing confusion. The same needs to be implemented for admin and super admin as well. Create a student view for instructors so that they can perform student operations without impersonating them. When an instructor logs in, he/she is in the default view with corresponding menu items (with the exception of the 'Assignments' menu item). There should be an option to switch to and revert back from the student view. When in student view, an instructor is presented with the student menu as listed above. This file is shared between all views and is responsible for rendering all the elements on the navigation bar including the menu items. In order to switch between default view of the user and student view, the following code was added. When in default view, the instructor is presented with a link, Open Student View , to switch to student view and when in student view, the Close Student View link can be used to switch back to the default view. <code>. A new role_switch_controller.rb file has been added. This controller contains the actions to open/close student view. <code>. New post methods are added in config/routes.rb . The routes are directed to the role switch controller's open_student_view and close_student_view actions. <code>. A new menu node with the below format is added under 'Manage...' node in the yml configuration files for admin, superadmin , teaching assistants and instructor. <code>. 1. Login as an instructor. Enter 'instructor6' as username and 'password' as password. 2. Click on Open Student View below username to switch to student view. <image> 3. Click on Close Student View below username to come back to default view. <image>. The following lines are added to spec/features/student_view_spec.rb file. 1. Check whether Assignments is absent in the menu in default view and there is an option to Open Student View This test case is to check if the menu item Assignments is absent and 'Open Student View' link is present when an instructor is in default view. Also on clicking the 'Manage...' button the 'Student View' sub-menu item should be listed. <code> 2. Check whether Assignments is present in the menu in default view and there is an option to Close Student View This test case is to check if the menu item Assignments and link Close Student View are present when the instructor switches to student view. The following lines are to be added: <code>. 1. Link to forked repository [ <link> ]. Expertiza 1. <link> Expertiza Github 1. <link> Expertiza Documentation 1. <link> RSpec Documentation 1. <link>.","Duplicated code is not explained on the wiki page.  In general, the documentation shows code snippets with a two-line description before them.  Except for one snippet, the code does not contain comments.  The overall strategy does not seem to be explained.","Dear student,

Thank you for your submission. Your explanation of the navigation structure and how the issue of instructor and student views may cause confusion is clear and comprehensive. I also appreciate that you provided a solution to this issue and explained it meticulously, bringing up the need to create a student view for the instructor. 

From a design standpoint, your proposal significant reduces redundancy and improves user experience. Your detailed explanation of the steps to be taken is quite commendable. Your clear and concise flowcharts allow anyone to easily understand the navigation structure, whether it be an instructor or a student.

I appreciated the addition of test cases to check the implementation of your proposal. Constructing them demonstrates a good understanding of quality assurance in code development.

However, please make sure you format your code properly next time. The '<code>' opening and closing tags have been used, but the actual code has not been included. Given that the assignment includes altering an existing code, it is really important to showcase these changes. Also, make sure that the links you provided for the forked repository and documentation are working, the placeholder '<link>' isn't replaced with the original hyperlinks. 

In future assignments, remember to validate your links and include the actual code you have worked on for better comprehension and to provide a more in-depth response to the requirement of the assignments. 

Overall, you've done a great job! Keep up the good work. 

Best regards,
[Your Name]

"
280,E17A4.1,"1. Purpose Expertiza is an open source website based on Ruby on Rails. Calibration is one of the main feature Expertiza provides, which allows students to compare their reviews with experts' reviews and learn from the comparisons. 2. Problem Definition Currently, the instructor is able to calibrate the students’ peer review abilities on Expertiza. However, the instructor needs to create a separate assignment just for calibration purpose of a project . Then the instructor and students can start doing peer reviews for the project with the newly created assignment . However, calibration should become one part of the normal assignment. The instructor could turn on this feature if necessary. Adding a separate assignment every time a project needs a calibration process is not efficient. This project proposes a solution to include the process of calibration in a regular assignment. “Calibration for training?” feature of an assignment in Expertiza provides a solution for the Instructor of a course to effectively add a calibration to a newly created or existing assignment. The instructor should be able to turn on this feature by checking the check box ""Calibration for training?"" under the General tab of an assignment. The instructor will also be able to provide or change the corresponding deadline for calibration. Then students will be pre-assigned several sample assignments. After students finish one peer review , there will be a link named “Show calibration results” to show the calibration report. <image> Picture above is ""Calibration for training?"" box in editing/creating assignment page. 1. The instructor shall be able to add calibration process to an newly created or existing assignment. 2. In student_task/list page, current stage column shall display calibration when assignment is in calibration period. 3. The added calibration of an assignment shall have it owns type of due date. 4. The added calibration of an assignment shall have the same behavior as the current working calibration process. <image> 1. Edit/Create Assignment Use Case Id: 1 Use Case Description: Instructor can click to edit an existing assignment or create a new assignment. Actors: Instructor Pre Conditions: The user is logged in as an instructor. Post Conditions: Instructor can edit the assignment. 2. Enable Calibration Use Case Id: 2 Use Case Description: Instructor can select the option - ""Calibration for training?"" and save the assignment. Actors: Instructor Pre Conditions: Instructor is in the editing or creating assignment page. Post Conditions: The assignment becomes a calibration assignment and the deadline for calibration now appears in the due dates tab. 3. Add calibration due date Use Case Id: 3 Use Case Description: Instructor can set due date for calibration under due dates tab. Actors: Instructor Pre Conditions: Calibration for training? is enabled. Post Conditions: The deadline for calibration is now updated. Constraints: Calibration deadline should be before the first round submission deadline. 4. Expert Review Use Case Id: 5 Use Case Description: Instructor can do expert reviews for works. Actors: Instructor Pre Conditions: The assignment is a calibration assignment and the work is submitted. Post Conditions: The work has the expert review. 5. Calibration review Use Case Id: 6 Use Case Description: Students can do calibration review. Actors: Student Pre Conditions: The assignment is a calibration assignment and the current stage is in calibration review. Post Conditions: Students have done the calibration review. 6. View calibration result Use Case Id: 7 Use Case Description: Student can see the comparison between their reviews and the experts' reviews. Actors: Student Pre Conditions: Instructors finished the expert reviews and this student submitted his reviews. Post Conditions: NA 7. Submit work Use Case Id: 4 Use Case Description: Students can submit their works when the current stage is ""submit"". Actors: Student Pre Conditions: Current stage is ""submit"". Post Conditions: The database has the new works. A software development process begins by writing an (initially failing) automated test case that defines a desired improvement or a new function, and generate the minimum amount of code to pass that test. It helps the developer to focus on a smaller portions of functionality at a time. By following the process of TDD we can ensure to maintain the minimum amount of code while writing that specific function, and the developer can gain an overview of the function. 1. We created a file ""calibration_spec.rb"" in ""spec/ features"" and write feature tests for the calibration function. 2. We created a migration file ""_add_new_deadline_type.rb"" to add a new record to deadline_types model 3. We added a calibration due date in due date tab if it's a calibration assignment 4. We added calibration_review in deadline_right file (Modified file: app/models/deadline_right.rb) 5. We changed the function of finding next due date from find_by to where().order('due_at').first 6. We changed ""app/controllers/student_review_controller.rb"" file to exclude calibration reviews when counting the review number. We filtered the reviews with timestamp earlier than submission due date, which means reviews are done in calibration period. 7. We changed the view for student review list in ""app/views/student_review/list.html.erb"" file. You can refer to a youtube video to see how's calibration function working after our implementation: <link> Below are the screenshots for the important parts: 1. After enable calibration for training function, the instructor can see a calibration due date in ""due date"" tab and can assign a due date for this calibration training: <image> 2. When the current stage is in ""Calibration Review"" we can only do the calibration reviews and show calibration results after submitting. <image> 3. When the current stage is in ""Review"", we can see the calibration reviews and do the regular reviews. <image>. 1. When it is in assignments#edit page: 1. To check it has a checkbox with title ""Calibration for training?"" in assignments#edit page 2. This feature test check for when Calibration for training? is selected, the value of assignment is calibrated is set to be true so the calibration tab will show up on the top of the page to fill in the due dates for the calibration period. <code> 2. When current assignment is calibration stage: 1. To check it shows current stage of the assignment to be ""Calibration"" on student_task#view page when current assignment is in calibration stage 2. To check it shows ""Calibration review 1,2,3..."" instead of ""Review 1,2,3..."" on student_review#list page 3. To check it allows students to do calibration review and the date can be saved successfully 4. To check the student is able to compare the results of expert review by clicking ""show calibration results"" link 5. Since the test contained duplicate code, we load the code in load_work method and set the stage of the current assignment as ""calibration"" state so the review contains Calibration Review 1, 2, 3 and student can view their calibration result when clicking on View link. <code> 3. When current assignment if in review_stage: 1. To check it excludes calibration reviews from outstanding review restriction and total review restriction 2. To check it shows ""Review 1,2,3..."" instead of ""Calibration review 1,2,3..."" on student_review#list page 3. When the project is in review stage, the number of review allowance will not affect by the number of calibration review numbers, so we check the number of review allow is still the same after changing the stage to review stage and the page should contains Calibration Review 1 and Review 1. <code>. 1. app/controllers/student_review_controller.rb 2. app/models/deadline_right.rb 3. app/models/due_date.rb 4. app/views/assignments/edit/_due_dates.html.erb 5. app/views/student_review/_responses.html.erb 6. app/views/student_review/list.html.erb 7. New created file: spec/features/calibration_spec.rb 8. New created file: 20171206202730_add_calibration_review_to_deadline_types.rb.","Most of the document is quite readable.  There is still room for improvement.With so many use cases, I think there should've been a prose paragraph preceding them explaining how they all fit together.  In the TDD section, you don't need to explain what TDD is, but you should give an overview of the tests.  ""Write feature tests for the calibration function"" is much too general.  The test plan is reasonable, but would be better if (1) it had an easily rememberable name for each test, and (2) covered edge cases.","Dear Student,

You have done a good job presenting a thorough analysis of the problem at hand and its proposed solution. The literature is well-structured and flows smoothly from one topic to another. Your visuals also make understanding the whole process easier. You have illustrated a high degree of understanding on the Expertiza system and the calibration problem.

Your use cases are well-detailed, and they provide a comprehensive explanation of the actors, conditions, and outcomes. This portrays a clear understanding of the requirements of the problem to be solved. The steps you've outlined to implement the feature are thorough and justified. The screenshots you've provided are a good touch as they allow for good visualization of your implementation.

The test-driven methodology you have used in development is commendable. Your approach to writing feature tests before implementing functionalities ensures that you write only the code that passes the tests, thus maintaining minimalism in your codebase. 

One recommendation I would make is to perhaps try and be more concise in describing your process. While the detail is appreciated, the content can at times be convoluted and a bit hard to follow. Simple, clear, and concise writing can assist in making your work more digestible. 

Finally, the next step would be to validate this functionality with end users to ensure it indeed solves the problem you have set out to solve. 

Well done!

Best,
[Your name]"
281,E1667,"<link> is an open source application developed on the <link> framework. It allows instructors to create assignments, set deadlines and give grades to the assignments. In this application, students can submit their assignments by providing links to their sites or repositories or upload files and folders. The students can also review assignments submitted by their peers. Goal: The aim of the project was to write a feature test that mocks the Heat Map that a student views for an assignment of his. The following tasks were performed to accomplish the goal: 1. Understanding the flow of the creation of Assignment by instructor. 2. Understanding the flow of the submission of an assignment by a student and then the flow of submitting reviews to an assignment uploaded by a student. 3. Understanding the flow of viewing the Heat Map related to an assignment by a student. 4. Mock the above steps using capybara. 1. <link> 2. <link>. <code> Repository URL can be found by visiting this <link> . Go to your cloned expertiza directory in terminal and run the following command: <code>. 1. Run the Expertiza database migrations. This should populate your database with the current tables of the schema. <code>. 1. Go to your cloned expertiza directory and run the following command for the tests: <code> Note : Travis CI build fails because we are directly using the development database for our tests, thus Travis CI is not able to locate the login information. This was done because it was not possible to create factories or fixtures for our tests. So, please don’t consider the build failure in the pull request to be a valid error. The heat_map_spce.rb contains the feature tests written to test the creation of the heat map viewed by the user. The rails_helper is copied to spec/ when you run 'rails generate rspec:install'. All the rspec-expectations config goes into the spec_helper_file. The testing has been done using Capybara and RSpec. Capybara helps in testing web applications by simulating how a real user would interact with the application. We selected Capybara to write our tests because it has an intuitive API which can mimic the language that an actual user uses while using the application and also we the tests can be run from a fast headless mode to an actual browser without changing our tests. <image>. <code>. We faced the following issues and hence were not able to complete the project: 1. We could not find any documentation about how to use the factory related to our task and couldn’t figure out its implementation in other tests. 2. We tried to solve the problem by using previously implemented test but were unsuccessful. 3. So we (Mahesh Masale) contacted you and you provided us with a new approach for the problem. What we were asked to do was to write a test that would simulate everything from scratch. There were multiple points where we struggled in this approach but the major ones were: 1.1. While adding questions to rubric the question field’s id is auto generated so there is no way to assume an id for that field in test. We overcame this problem by searching a specific text to find the all text fields but this will be a problem if that test is present at a location other than the test field. 1.2. While trying to select a rubric which is a dropdown there was no id provided to the select tag. So we googled but to no success and then we found a piece of code in the assignment_creatiion_spec.rb but that code also failed in our solution. 1.3. We also tried to add a participant to an existing assignment through test and struggled with it because the id to the button was dynamically generated and the url could not be accessed through “visit” command. 4. So we switched back to the old method due to lack of progress after investing a lot of time. We used the factory and were able to create assignments and reviews but our user was not able to view those reviews in heat map. We even tried previously implemented code but that also did not show reviews for our test. 5. We communicated with other teams for help but they also could not solve our issues.","The writeup is not sufficiently detailed.  There is a huge flow diagram, and then the code is pasted in.  Nothing describes the testing that is carried out (you have to read the code).  Also, it is not explained why the test that you have written is a sufficient test for the heat-map functionality.","Dear Student,

Thank you for your detailed analysis and effort in trying to execute the objectives of your project. Despite not fully completing the project, it is evident that you have undertaken significant research in order to solve the problems you encountered.

Coming to the issues you faced, factory related problems are indeed common especially for testing purposes. Without proper documentation or examples, they can prove to be challenging. It's great to see you reached out for assistance and attempted different approaches to find a solution. This is a crucial part of learning.

It is also noteworthy that you understood the value of testing from scratch to emulate a real user's experience. Web testing can be tricky especially when dealing with elements that are generated dynamically, like the id's you mentioned. It's commendable that you attempted different strategies to hurdle the obstacles.

Moving forward, consider collaborating with peers or reaching out to the community forums about the testing mechanism in <link> framework. This might guide you to different or alternate scenarios that can come in handy.

Another learning point here is the need for effective test data management. You mention that Travis CI build fails because you're using the development database for your tests. Usually, testing is separated from the production or development environment to avoid unexpected situations. Consider looking into ways to mock your database as part of your journey.

Remember, not being able to fully implement a project is not a failure, but an opportunity to learn. You’ve spent your time troubleshooting and deepening your problem-solving skills, which will benefit you in the long term. 

Keep up the determination and continue to embrace the challenges!

Best regards,
[Your Name]"
282,E1698,"Scenario: An instructor using Expertiza wants to do an experiment comparing anonymous review with identified (non-anonymous) review. And in general, there is quite a bit of research interest in the implications of anonymity in student interactions. In this experiment, Approx ½ the class will conduct two rounds of formative reviews in small groups (4-5 students/group). The groups will stay the same for both rounds. The students in the groups should be able to see who they are reviewing and who is reviewing them. For the non-anonymous groups, I'd like the students to be able to request group members, so I would want to be able to have some control, perhaps with an option to use random assignment to groups if they had no preference for group members. Approx ½ the class will conduct two rounds of formative reviews anonymously (using the normal method we used this fall) What needs to be done : The Review Strategy tab of assignment creation needs have a new checkbox for anonymous reviews, which would be checked by default. If it is checked, student views would be the same as at present. If it is not checked, students would see their reviewers and grades in the same way as the instructor now sees them; thus, instead of seeing “Reviewer 1”, “Reviewer 2”, the student might see, “Anthony Adams”, “Bessie Brown”, etc. The code for displaying names obviously already exists, because it is used in the instructor views. Implement the changes in an elegant way; for example, instead of checking multiple times in the view to determine whether the reviewer’s (or author’s) real name is to be displayed, try to send a message to a model class that will “do the right thing.” This may involve creating separate model classes for anonymous and identified review, so that messages could be sent polymorphically. It’s hard for me to know, without studying the code, whether this would simplify the code or clutter it, but please give some thought to what is the clearest and most robust way to code both anonymous & identified reviews, from the student’s and the instructor’s perspective. The other piece of the project is to enable review within groups, which means that every student in a group will review every other student in the group (but no students outside the group). This can be configured on the Review Strategy tab when the review strategy is set to “Instructor-Selected”. Under the “Set number of reviews done by each student” box, there could be another one, “Review done in groups of [ ] students”, where “[ ]” is a small text box. There should also be an information button describing how group-based review works. The project provides instructor a functionality to make assignment reviews to be anonymous or non-anonymous. In addition, instructors have authority to create and assign review groups (students assigned same review group will review each others work) randomly.This scenario will be valid for individual assignments only. Also, anonymity is taken care from the perspective of reviewer as well as the reviewee. In case of non-anonymous groups, students may have the option to invite other students to join their group provided group size is not exceeding the maximum limit. <link> is a peer review system which provides incremental learning from the class. This project has been developed together by faculty and students using <link> framework. Expertiza allows the instructor to create, edit and delete assignments, create new assignment topics, assign them to a particular class or selected students, have students work on teams and then review each other's assignments at the end. For the students, they can signup for topics, form teams, and submit their projects and assignments. Students then review the work done by other students and give suggestions to improve. Teams after reviews are allotted scores and they can refer to the peer comments to further improve their work. It also supports submission of different file types as well as URLs for assignments. Assignment Creation: Providing a checkbox in ""review strategy tab"" to mark an assignment to have anonymous or non-anonymous reviews. By default, every assignment will be having anonymous reviews but an instructor can change it by unchecking the checkbox (Anonymous would be boolean field present in the group model). Group Formation: The instructor has the authority to create and assign groups randomly. In this case, students can not drop the group they have been assigned and only an instructor can change their group if needed. In case, a group has not been assigned by an instructor, students will have the functionality to invite other students to join their group. This functionality is analogous to the invite members to join their team. Students in the same group can review work of their group members only. For this, we will be creating a separate model for groups and will store all the group information into the corresponding database table. In order to follow the DRY principle, we will try to integrate the group code with the code written for teams. <image> Non Anonymous Reviews In the case of non-anonymous reviews, students will be able to see the names of all the group members who have graded their individual work. In addition, students can also see whose work they are going to grade so that the non-anonymity is maintained from both sides. 1. This is the view of the review strategy tab where the checkbox for anonymity has to be added <image> 1. This is the view where names would be visible to ensure non anonymity of reviews <image>. This project is part of an experiment to test whether anonymity makes a difference in reviews of students, thus to implement it one assignment would be made as anonymous and another as anonymous and the quality and the review scores would be tested to say if there is a change in quality and values of control and test. The project can be tested by doing the following: <code> On the student side <code> when you check your scores for each review when you log in as a student you should see the name of the reviewer appended to review 1. 1. controller/reveiw_mapping_controller.rb 1. controller/teams_controller.rb 1. model/team.rb 1. views/assignments/edit/_review_strategy.html.erb 1. views/grades/_reviews.html.erb. 1. Bhavesh Kasliwal 2. Bhavya Bansal 3. Chinmoy Baruah 4. Rishabh Sinha.","The titles are not too long and got repeated from section 2 to 7. The design pattern discusses about the planning on making changes, but not really related to design pattern.","Dear Student,

I have gone through your assignment, and I find it to be very thorough, which is great. You seem to have understood the complexities of the problem at hand. The assignment outlines not only the surface changes needed in the platform, but also delves deeper into the code implications, deciding the best possible approach.

However, here are a few suggestions to better your output:

1. Structure: While the depth and coverage of your assignment is commendable, the flow seems slightly disjointed at times. The explanation could be somewhat clearer. Consider including a clear, concise summary at the beginning explaining the objective of the project, the approaches used, and the expected results in brief. 

2. Design and UX/UI: You have suggested changes in the UX/UI, such as adding checkboxes to enable anonymous reviews. However, a more vivid depiction of these changes could have enhanced the understanding of your design. Consider visualizing these changes using wireframes or UI mockups, which illustrate the new elements in their intended positions. Also, explain how these changes would affect the user's interactions with the system.

3. Coding: You segued into code snippets and the possible changes required in the existing codebase. While this is good, it would have been helpful to see code samples or pseudocode. It provides a better understanding and could lead to better assessments of the potential issues and considerations required in the process.

4. Testing: Your conclusion on testing seemed slightly abrupt and lacking in specifics. Consider detailing how each new function could be tested or a possible testing strategy.

5. Team and Acknowledgment section: The presentation of this section could be cleaner. It would be advisable to mention this section in the beginning or at the end of the assignment.

Let's remember, the smoother the flow of your explanation, the easier it will be to understand your thought process. There is strength in your ideas, you just need to think about organizing them in a way that aligns with your reader's comprehension. This is excellent work! Just a bit of refining would make it even better.

Best wishes,
[Your Name]"
283,E1632,"<link> is an <link> developed on <link> framework. It is primarily developed as a platform for instructors to create, assign and grade assignments and quizzes and for the students to view, submit assignments and take quizzes. Other activities involved in a course can also be done via Expertiza, like creating teams, reviewing assignments among others. Collusion detection is a feature that Expertiza needs. Collusion detection is supposed to detect when peer reviewers “return favors” to each other by giving each other higher scores than they deserve. There are 2 types of collusion that instructors may worry about: small-circle collusion and pervasive collusion. Small-circle collusion refers to the practice that a few teams/authors reach an agreement that they give each other high scores if they get chances to review each other’s work. The number of the teams/authors could be any number. Pervasive collusion refers to the practice that giving each other high scores becomes a trend in some assignments. This practice has been observed by Dr. Luca de Alfaro in his paper: ... Once a nucleus of students starts to assign top grades to all the submissions they review, other initially honest students see what is happening, and join the colluders, both to save work in reviewing, and to avoid being penalized in the review precision as the only honest students who disagree with their colluding peers. 1. The code in collusion_cycle.rb is not called anywhere. Even it were called, the code would not work (due to some nasty refactoring done previously). The algorithm was badly designed - creating separate methods for detecting x-node cycles. The following tasks need to be accomplished at the end of this project: 1. Remove all the methods in this model. Redesign and recode the whole model from scratch. 2. In the new model we will create a new collusion cycle detection method which will take x as an input. Given the parameter x, the algorithm then can detect any collusion cycles consisting of x nodes. 3. We will use spread and the ratio spread/(# of peer reviews done) to measure the pervasive collusion in one assignment. Here spread is the peer-review score difference a reviewer (max peer review score given - min peer review score given) A higher spread is better, because it indicates that the reviewer is discriminating between good and bad work. [Dr. Gehringer’s survey, 2014] Spread/(# of peer-review done) should work better than spread alone if the # of review done varies between reviewers. 1. We will consider each student in an assignment a node and each peer-review record (namely, user A reviews user B, which is recorded in review_mappings table) as a directed edge. So finding small-circle collusion becomes a task of finding cycles within x nodes in a directed graph. 2. This algorithm can use depth-first search. 3. The idea of having a threshold : If A gives B a low peer-review score (less than min_collusion_peer_review_score), we prune this A->B edge. 1. We will create a report page (small collusion cycles report) under “view review report” icon for instructors. The instructor can input x and run this algorithm to detect small collusion cycles. The instructor can also set the min_collusion_peer_review_score on this report page. The default of min_collusion_peer_review_score can be 95%. 2. We might also need a similar report page (pervasive collusion report) for pervasive collusion. The Use Case diagram for such design is: <image>. We are planning to implement the modified DFS for finding a cycle of size ""n"". The basic algorithm for this looks like: <code> This algorithm has to be implemented in ""collusion_cycle.rb"", and the implementation will roughly look like: <code>. The test case will be written as ""rspec"" 1. We will need a test case, which returns the cycles detected in the graph, and confirms that the size of the cycles is no less or no more than the user specified size ""n"". 2. We will need to check the performance of this algorithm. In some cases when the graph becomes too large the algorithm should still perform in acceptable time frame. This is a soft commit for the project. We are planning to have a visually asthetic way of representing the collusion detected. For this purpose we have identified a few ways: 1. Visulization tool called <link> 2. <link> 3. <link>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. <link> 8. <link> 9. <link>.","The cycle detection may miss come cycles.
There should be UI which allow instructor to input the k.
There should be some visulization, or at least table of cycles in the report page.","Dear Student,

Thank you for the great effort you’ve put in your assignment. It is clear that you have a solid understanding of the task requirement and I am pleased to see the thought process behind your strategy. Your plan to redesign and recode the collusion detection model, the incorporation of a modified DFS, and the visualization techniques are good indications of your thorough understanding of the task.

However, this feedback only focuses on the analytical concept of your approaches, as the lack of complete URLs and identity of the links in your assignment makes it hard for me to make a complete comprehensive review.

I am also unable, because of the lack of a concluding explanation, to assess the connections between the points. This leads to some confusion in terms of the overall structure of your assignment. It would be beneficial to include a summary or closing paragraph for each point to ensure clarity and to establish logical connections between your thoughts.

Lastly, you did not make it clear why and how these technological tools were chosen. The analytical context, for instance, could demonstrate what makes those tools an ideal choice for this project. 

Please consider these points and make necessary modifications. I look forward to seeing your updated work. 

Keep up the good work!

Best,
[Instructor]"
284,E1745,"Expertiza is an open source webapp built on Ruby on Rails stack. It provides a platform to students with various features like peer-reviewing projects, submitting work, form teams, viewing grades etc. The project is being built and maintained by students and faculty at NCSU. The file response_controller.rb handles the operations on responses based on user permissions and redirects the user to the appropriate place after the action is complete. The responses here constitute of peer reviews/questionnaires/survey. The controller takes care of tasks such as creating, saving, editing, updating and deleting these responses. 1. Refactoring response_controller.rb Included: 1. Breaking down large methods into smaller chunks of readable reusable code. 2. Changing code to adhere to latest Ruby conventions 3. Creating functions to reuse chunks of code that were previously written multiple times 2. Testing response_controller.rb Included: 1. Writing stubs and mocks 2. Writing integration test cases to ensure that response_controller redirects to the right places with a given parameter set. The pull request for this task can be viewed at <link>. Without wasting much time, lets jump into the refactoring by describing code which existed previously followed by the changed code. Previous Code :- <code> The view case is extracted into a separate method and some common variables have been extracted out of the cases <code> This has extracted an independent functionality and enhanced readability apart from sticking to guidelines of short methods. <code> Moving on with latest Rails conventions, function is being modified as <code> This will avoid any unexpected behaviour when further upgrading the Rails framework. <code> has been replaced with <code> This is the way to sort based on an object attribute. <code> This method involved a lot of code which violates guideline of short methods. Moreover, the lines of code can be reduced along with readability enhanced as similar functionalities in multiple lines can be combined. 53 lines of code have been reduced to 32. The refactored method is given below:- <code>. 23 integration tests were written to ensure the functionality works and also to make sure the refactoring does not break any of the existing functionality. These tests check for the basic functionality of the controller response_controller.rb and whether these function calls redirect to the right place with the correct status code. Consider the following example. <code> The above given test checks that if the instructor wants to view a review, he is given permission to go ahead and view it. This is checked by setting params = {action: ""view"", id: review_response.id}. To do so, we set these params and expect the function action_allowed to return true. The current user is set in the before(:each) part of the test file because that is used commonly by a number of test cases. We tested the existing functionality of the controller like view, edit, action_allowed, redirection, etc since we are changing only the implementation of the code. And a general rule of writing test cases is that changing the implementation should not have any effect on tests. Test case scenarios were provided by our mentor and our job was to write the integration tests for those scenarios. the test cases were pretty exhaustive. We didn't have to write extra cases for the parts we refactored as the refactored portions are an extraction of an existing function in smaller ones, in which case the existing function is already calling the new written code. So in a way writing the test cases for existing parts automatically tests the new refactored code. We wrote a number of stubs for the test cases. We separated out stubs into two parts, the ones that are being commonly used by multiple tests and wrote them in the before(:each) part. The other uncommon ones are written in the respective test cases to avoid extra computation. Stubs allowed us to replicate the behaviour of the database without actually calling, thus avoiding cost of accessing the database and avoiding the pitfall of having a test case fail because of an incorrect database layer logic rather than the controller logic. First let us understand how a mock object is created. Have a look at the following piece of code: <code> This will build a response object (whose specifications are provided in the factories.rb file) with an id 1 and make it available through out the test process. We are therefore using this object as the object returned from a database without actually interacting with the database, thus ""mocking"" an object. To understand how stubs work, consider the following piece of code in before(:each) block of the testing controller: <code> What this stub does is that when Response.find is called, instead of going into the database and finding an object and returning it, Rails will blindly return review_response mock. So this line tells Rails that if find is called on Response, return the pre created about review_response. This reduces the dependency on the database. We wrote stubs and mocks required to successfully test all the pieces of the controller. All of it can be viewed in response_controller_spec.rb. 1. Expertiza Main Repo <link> 2. Expertiza Documentation <link> 3. Pull Request <link> 4. Screencast for E1745 <link>.","As one of the reviewers noted, ""The author has just mentioned what they have done but not mentioned as to why it was done in any instance except one ""Replaced find_by_map_id with find_by"". There is not mention of the design pattern used although it is understood by the Title of the assigned task.""  The Test Plan section is better on that score.","Dear Student,

Thank you for submitting your Ruby on Rails project. Your explanation shows your professional approach to the task, your comprehension of the material, and a deep understanding of the modules. 

I appreciate your effort in refactoring the response_controller.rb file, breaking down complex methods into smaller ones definitely increases the readability and maintainability of the code. Following the latest Ruby conventions shows that you properly updated your knowledge and kept up with the ongoing improvements.

Your work on testing is impressive; I like your integration of stubs and mocks, the test case scenarios covered a wide range of functionalities, and this helped in ensuring the reliability of the controller's functions. The system of breaking down the stubs into those that are commonly used and those that are used sparingly is very pragmatic. 

Your explanation of objects and how a mock is created was clear and helpful, and will definitely give other readers a clear understanding of the concepts, as is your clarification of how stubs work. 

However, for future projects, it would be better if you provide the real code in your report rather than simply referencing it as ""<code>"" - this would make it easier to understand on a practical level exactly what you have done in your refactoring and testing work. 

Overall, I commend your effort and dedication to this assignment. You have completed an exceptional work on the response_controller.rb file. Your work contributed to increasing the performance and usability of the Expertiza project by enhancing code readability and maintainability. Well done and keep up the good work!

Here is the grade for your assignment: A

Best,
[Your name]"
286,E1660,"In Expertiza, there are two ways of assigning reviews to reviewers: either the instructor decides who reviews whom (“instructor-selected”), or “auto-selected,” in which case reviews are not assigned until a student seeks to choose something to review. To allow reviewers a larger set of topics to choose from, the instructor can set the threshold (on the Review Strategy tab of assignment creation/editing) to some integer k > 0. Then any submission that has within k reviews of the fewest number can be chosen by a new reviewer. Let’s say that all submissions have at least 1 review. If k = 3, then the reviewer can choose any topic where there is a submission that has 4 or fewer reviews so far. Suppose that the minimum number of reviews for any submission is 2, but that I have reviewed all the submissions that have only 2 reviews. Then I’m not allowed to review at all (unless k > 0). That’s wrong; I should always be allowed to review the work with the least reviews that I have not already reviewed. And that should generalize to situations in which k > 0. Another issue is that there is no way for Expertiza to tell a reviewer how many reviews are required. In the case of instructor-selected reviewing, that’s not a problem, but for auto-selected reviewing, there is no way to specify how many reviews are required (or even how many are allowed, in case students are allowed to do extra reviews). The purpose of this task is to solve the above mentioned issues collaboratively. The assignments table now contains the Max reviews required and allowed field which can be set from Review strategy tab. This allows the admin to set the threshold value for required number of reviews for the assignment. Another feature implemented is, now students can check how many reviews he/she needs to write which helps students determine how many reviews to write and also how many reviews he/she has already written. Another issue resolved was the reviewer who finished reviewing all submissions with least number of reviews, should be able to review the next set of submissions with greater number of reviews. That is, the threshold rule was more relaxed. Implemented the necessary test cases for the new features implemented. 1. app/views/assignments/edit/_review_strategy.html.erb 2. db/schema.rb 3. Added two new unit tests in RSpec file in spec/models/assignment_form_spec.rb 4. Added two new columns in Assignment table as shown below 5. app/models/review_assignment.rb 6. app/controllers/review_mapping_controller.rb 7. added new file review_assignment_spec.rb in spec for testing the above functionality. <code> 1. add new RSpec tests in assignment_spec.rb <code>. The new RSpec test added to the assignment_spec.rb is used to verify that the reviewer who submits their assignment should not be allowed to review their own work. The test mainly simulates mouse click on the webpage and tries to find certain content. One student account is created to submit the assignment which is stored by the system. Since this submission is the only one for the existed topic, the system is supposed to not to assign reviewer anything, which is equivalent to have the correct output for code, expect(page).to have_no_link ""view"". The test file shows desired result and the issue resolved. <link>.","Hardly anything was done, except to rewrite the project specs, tell about the new fields, and paste in the testing code.  The app code changed was not included or described.","Dear student,

First off, great job! You've shown a good understanding of Expertiza's review assignment mechanism, and have thoughtfully highlighted some existing issues. Your proposed solution addresses these problems and you've taken time to explain the changes that you have made, which is very commendable.

For the assigned task, you've presented a clear implementation strategy, giving detailed explanations of not only what you have done, but why it was necessary and how it fits into the existing infrastructure of Expertiza. The way you have introduced the notion of maximum allowable reviews as a threshold for reviewer duties, whilst considering existing limits in providing review opportunities, is especially noteworthy and contributes well to overcoming the addressed issue. 

The mere fact of submitting the assignment demonstrates your diligence with adding relevant test cases, and it's great that you make sure that your changes are solidly covered by the tests. Just remember to always make sure that your tests not only cover ""happy path"" scenarios, but also edge and failure cases. 

Your mention of editing the 'app/views/assignments/edit/_review_strategy.html.erb' and 'db/schema.rb' files, among others, is very detailed and shows the depth of your understanding of the necessary changes. This level of detail is truly appreciated.

Just to clarify, it's not entirely clear in your explanation about how you've handled the reviewer who has finished reviewing all submissions with the least number of reviews. It might be beneficial to provide some additional details of how you have relaxed the threshold rule in these scenarios, to provide a thorough understanding.

On a final note, remember to properly close your HTML tags. For example, the open <code> tag doesn’t have a closing tag.</code>. Paying attention to these minor details is crucial as you continue to evolve as a developer. Nonetheless, you've performed exceptionally well on this task, keep up the good work!
"
287,E1635,"This page provides a description of the Expertiza based OSS project. <link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. The following tasks were accomplished in this project: 1. Renamed the ""invitation_controller.rb"" to ""invitation_controller.rb"" 2. For simple if nested in else, we changed it to elsif and thus decreased number of layers in the if nest. 3. For added comments to explains what each method does and explaining important variables 4. refactored the create and update methods 5. changed the wordings of the flash messages to make them more meaningful. 1. Rename to invitations_controller.rb, in accordance with current naming convention. 2. Convert if nested inside else to elsif. 3. Add comments explaining what each method does, and comments on how important variables are used. 4. Refactor create and accept methods. Shorten and clarify them by adding private methods (e.g. extract a ready_to_join? method and call it from accept method) 5. Change awkward flash messages. 1. Convert if nested inside else to elsif, and add comments explaining what each method does, and comments on how important variables are used. <image> The if else can extract from multiple nest to one. There have two different functions in one nest, one is flash and another is invitation check. Divided two different purpose to two if else nest. <image> 2. Refactoring the accept method <image> <image> <image>.","The writeup is created by taking screenshots, which means that the code is not searchable.  Low-level changes are enumerated, but the high-level changes are not explained (they are stated, at the beginning of the document, but the changes are not pointed out in the code).  Also, there is no explanation of how to test.","Dear Student,

Firstly, thank you for a well-detailed description of your work in the Expertiza based OSS project. You've given a good account of what the software does and your actions to improve its functionality.

However, there are a few areas in your assignment that require refinement. 

1. Duplication: You've repeated your tasks performed several times in different words, which borders on redundancy. Instead, provide a single, clear list of the modifications you made.

2. Clear mapping: While you have mentioned several improvements, it is not clear where these changes occurred. Mapping your changes to images/screenshots would be beneficial. Also, ensure your text accurately corresponds with any images you have embedded within the assignment.

3. Explanation of changes: You've mentioned many changes such as renaming controllers and refactoring methods. However, you haven't provided insight into why these changes were necessary or how they improved the project. This would provide a good understanding of your decision-making process.

4. Grammar: There are a few grammatical errors, such as: ""For added comments to explains what each method does"". This sentence sounds a bit disjointed and could be made clear.

5. Structure: Make sure your assignment has a clear structure. Begin with an introduction to the project, then the tasks performed, followed by details of each task. Using bullet points or numbering can make it appear more organize and easy to follow.

These edits should greatly improve the clarity and organization of your submission. 

Overall, I see clear evidence of your understanding of the project and your contributions to it, so well done on that front. Once you make the changes I've suggested, your work will be even more impactful!

Best Regards,
[Your Name]"
288,E2059,"The purpose of this project is to improve and test the email handling systems in Experteiza. The project's primary goals are to solve the following issues; unreliable student email receipts, and unreliable instructor email notices. Expertiza is intended to send students email notices when they receive a project submission for review, when their own work is reviewed, or when their reviews are reviewed. However, this functionality has proven to be unreliable and inconsistent. Additionally, instructors are intended to receive email copies of all emails being sent from the system. This functionality is also inconsistent and unreliable. This issue aims to address these errors and the remainder of this page describes how this is accomplished. The following are identified tasks to be accomplished for the project: Email Queue Appropriate tests for the following: 1. Check queues to ensure that emails are being sent out. 2. Check to see that the recipient of this message is the correct recipient 3. Check to see that the body of the message has the correct content. Instructor Email Notifier 1. Appropriate tests instructor should be able to get copies of emails: 1.1. Rails message that queues the email to the instructor 1.2. Check to see that emails sent by the system are also sent to the professor. Merge in PR1604 to address Issues This pull request was the last attempt to address the changes made that are required to be tested above. <code>. All tests are written using rspec. A list of all files changed are found at the bottom of the report and the following section explains each test. This method is used to send a generic email to user by passing the email, subject and the contents of the message. The RSpec test for this method first creates an generic_message object and verifies if the correct parameters were passed. Then the next test was to test if the ActionMailer successfully sent the email using generic_email. This was done by using the ActionMailer::Base.deliveries to check the outbox of the ActionMailer and ensured the contents of the outbox mached that of the mailer. Setup <code> Test <code>. This method is used to request_user_message to a user by passing the super_user details, user name and the email subject. The RSpec for this creates a User object to be passed into generic message. Once done, the first test was to ensure that request_user_message received the correct parameters that were passed, the next test was to ensure that the ActionMailer successfully sent the email by checking the outbox in Setup <code> Test <code>. The send_mail_to_all_super_users method is a method that uses the request_user_message method to send emails. For this we wrote a proxy test to ensure that it and request_user_message were correctly sending emails by creating user object and passing the necessary fields to the send_mail_to_all_super_users and ensuring the ActionMailer::Base outbox had the correct outputs. Setup <code> Test <code>. This method is used to notify_reviewer_for_new_submission to a user by passing the user object, partial name and the message to be sent. The RSpec for this creates a User object to be passed into notify_reviewer_for_new_submission message. Once done, the first test was to ensure that notify_reviewer_for_new_submission received the correct parameters that were passed, the next test was to ensure that the ActionMailer successfully sent the email by checking the outbox to see if the contents of email matched that of the outbox. Setup <code> Test <code>. The submission_mail_to_reviewer method is a method that uses the notify_reviewer_for_new_submission method to send emails. For this we wrote a proxy test to ensure that it and notify_reviewer_for_new_submission were correctly sending emails by creating user object and passing the necessary fields to the submission_mail_to_reviewer and ensuring the ActionMailer::Base outbox had the correct outputs. Setup <code> Test <code>. Tests in this portion ensures emails are being sent upon a submission via the sync_message protocol. Feedback Response Setup Feedback review response submission is being tested to ensure emails are sent upon a feedback submission. <code> Feedback Test <code> Metareview Response Setup This test ensures that an email is sent upon a review of a review being submitted. <code> Metareview Test <code> Response Survey Setup This set of tests ensure that an email is sent upon an assignment or course survey submission. <code> Response Survey Tests <code> Teammate Review Response Setup This test ensures an email is sent upon submission of a teammate peer review. <code> Teammate Review Response Test <code>. Suggested Topic Approved Test This test ensures an email is sent upon approval of a suggested topic. <code>. Notify Grade Conflict Notification Setup This test ensures an email is sent when a score is outside the acceptable value. <code> Notify Grade Conflict Notification Test <code> Notify Instructor On Difference Setup This is a proxy method that calls the Mailer method to send e-mail to the instructor when a score is outside the acceptable value. This test verifies that the Mailer method is called with the expected arguments. <code> Notify Instructor On Difference Test <code>. 77 examples, 0 failures.","The documentation should cover more than the tests. The documentation is little more than a listing of the code for the tests, with an occasional one-paragraph description of what it does.  There really needs to be more narration.  For example, when you list appropriate tests, explain how the tests are performed.  The document should give a rationale for what you have written, and an overall description of how it works.","Dear Student,

I have reviewed your assignment and it appears you have completed an extensive assessment on the email handling systems of the Experteiza project. 

It's great to see that you have critically identified the mail related problems plaguing students and instructors and have addressed these issues systematically. The clear breakdown of the tasks to be accomplished for the project is noteworthy and shows forward-thinking.

In terms of testing the different methods, you have followed a logical pattern of creating an object, administering the tests, and checking the results which is commendable. Your usage of proxy test to ensure e-mails are being sent correctly is innovative and adds depth to your testing methodology.

However, while reading your report, I noticed you have somewhat repeatedly used the same testing formula. It might be worth investigating alternative methods for robustness and efficiency, perhaps approaches that leverage data-driven testing or behavior-driven testing.

Furthermore, the write-up lacks specifications of preprocessing and postprocessing steps (if any). Involving these steps would add thoroughness to your methodology.

On a different note, the document could benefit from better structuring and formatting for legibility. Your extensive and detailed work might be difficult for a reader to follow without proper formatting. This includes your use of the ""code"" tag, which appears to be empty in several instances.

Lastly, concluding the report with a summary of your findings and a possible direction for future work may help give more completeness. The ""77 examples, 0 failures."" is an excellent result but elaborating on what these tests specifically imply about the system would be ideal.

Despite these areas of improvement, I'd like to emphasize that your work shows a clear grasp of the project requirements and a strong practical application of software testing practices.

Keep up the good work!

Best regards,
[Instructor's Name]"
289,E1866,"config/locales/ 1. en.yml 1. hi_IN.yml config/ 1. routes.rb 2. application.rb app/controllers/ 1. applcation_controller.rb Student View Files: 1. app/views/ 1.1. shared/ 1.1.1. _navigation.html.erb 1.2. sign_up_sheet/ 1.1.1. _suggested_topic.html.erb 1.1.2. _table_header.html.erb 1.1.3. list.html.erb 1.3. student_task/ 1.1.1. list.html.erb 1.1.2. view.html.erb 1.1.3. _publishing_rights.html.erb 1.4. student_teams/ 1.1.1. edit.html.erb 1.1.2. view.html.erb 1.5. submitted_content/ 1.1.1. _hyperlink.html.erb 1.1.2. _main.html.erb 1.1.3. _self_review.html.erb 1.1.4. _submitted_files.html.erb 1.1.5. _title.html.erb 1.1.6. edit.html.erb 1.6. grades/ 1.1.1. view_my_scores.html.erb 1.1.2. view_team.html.erb 1.7. student_review/ 1.1.1. list.html.erb 1.1.2. _responses.html.erb 1.1.3. _set_dynamic_review.html.erb 1.8. participants/ 1.1.1. change_handle.html.erb. Currently Expertiza only supports the English language. Many students are from other countries. So, we aimed to allow them to view their pages in another language. This is done by internationalizing static strings in Expertiza for Student Assignment related pages to another language (ex: Hindi or Chinese). Students had the ability to change the language through a dropdown located in navigation bar at the top of the page. We did not affect any strings that are dynamically shown. We focused on adding the Hindi language as a lot of students are Indian. 1. We added a dropdown in the navigation bar for a student to use 2. They are able to choose from English or Hindi 3. <image> 4. When the language is clicked on it changed all the static strings in the Student Views related to Assignments to the newly selected language. 5. Students could also manually change the language in the URL themselves by. The language is put before the page name. Example: www.example.com/en/book -> www.example.com/hi_IN/book. 1. For this project, we added support for one language, Hindi. 2. We used Google Translate to convert the strings to Hindi. 3. We used the <link> to help us add multi language support. 4. There are two yml files in the config/locales directory representing the different languages that can be used in Expertiza. 1.1. One for English, which will be the default language used, and another for Hindi. 1.1.1. en.yml 1.1.2. hi_IN.yml 1.2. These yaml files contained the translated strings for their respective language. 5. We editied the routes.rb, application.rb, application_controller.rb files and all the view files related to Student Assignments (which you can see at the top of the wiki) so that it can read from the yml files to show other languages. <image>. <image>. username: student1016 or student[4000-8000] password: password. 1. When going between pages, use the Back button link located on the bottom of pages, not on the browser 2. When going to the main Assignment page, use the Back button link to get there to test out the scenarios below, not the link in the navigation bar. 1. Log in to Expertiza as a student. 2. Go to language dropdown in the navigation bar and choose Hindi. 3. Check if language is changed in the URL from en to hi_IN 4. Check to see if the English strings on the page are translated to Hindi 5. While still logged in as a Student, check if the other Assignment related pages are also translated. 1. Log in to Expertiza as a student. 2. Go to language dropdown in the navigation bar and choose Hindi. 3. Check if language is changed in the URL from en to hi_IN 4. Check to see if the English strings on the page are translated to Hindi 5. While still logged in as a Student, check if the other Assignment related pages are also translated. 6. Go back to the main Assignment page and choose English from the dropdown. 7. See if the language was changed in the URL to en. 8. See if the strings are translated back to English for all Assignment related pages. 1. Log in to Expertiza as a student. 2. Go to URL and change the language from en to hi_IN. 3. Check to see if the English strings on the page are translated to Hindi. 4. While still logged in as a Student, check if the other Assignment related pages are also translated. 1. Log in to Expertiza as a student. 2. Go to URL and change the language from en to hi_IN. 3. Check to see if the English strings on the page are translated to Hindi. 4. While still logged in as a Student, check if the other Assignment related pages are also translated. 5. Now change the language back from hi_IN to en in the URL. 6. See if the Hindi strings are translated back to English for all Assignment related pages. Due to time, there were some things we weren't able to fix or work on. 1. Problems: 1.1. When a student goes back to the main Assignment page, views/student_task/list, by clicking the link in the navigation bar, the language locale doesn't appear in the URL. This means that if you did change the language from the dropdown or manually, it will go back to the default locale language. See the URL below: 1.1.1. <image> 1.2. If you try to use the language dropdown in a page other than the main Assignment page, it will give an error like the one shown below: 1.1.1. <image> 1.3. But if you manually change the language in the URL, it works fine and persists as you navigate through the pages. 2. Feature: 1.1. We also have translated keys for many course pages, but did not implement the actual translation code in the view files for them. You should be able to look at the keys to find out which view files they are. 1.2. Adding translation for Chinese. 3. Additional Considerations(After our discussion during presentation): 1.1. A future team needs to add support for dynamic text. Our project was only concerned with Expertiza's static text. The dynamic text needs to change too for a completely seamless end user experience. 1.2. When generating translations, one must consider the differences in sentence structure between languages. In many cases throughout Expertiza we see the following pattern: <static_text><dynamic_text><static_text>. This is a difficult case to handle. What looks like a natural break in sentence structure in one language may not look natural in another. Dr. Gehringer mentioned the possibility of having that location of the dynamic text also be able to change between locales. This needs to be investigated by a future team. That may require a different API, or generating an entirely separate view for each locale(not ideal). 1.3. When dealing with dynamic text two approaches need to be investigated(in addition to researching API suppport): 1.1.1. Query the model in its default locale and attempt to match the string with a translation after retrieval(ideal). This would be the preferred approach. We don't want to have to alter our model to alter our translations. Barring API support, this might present complicated view code, but would be preferable to created dependency between the model and the translation. 1.1.2. Store separate text fields in the model for each locale(not ideal). This is something we want to avoid. We should not be altering the model to add functionality to our views. 1.4. The student16 login used to test Expertiza needs more work. Some student views are inaccessible due to a lack of inbuilt data. This makes testing more difficult to accomplish. 1. Pull Request: <link> 2. Github: <link> 3. Video: <link>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 1. <link> 2. <link>.","The design document does a good job of describing how the changes were implemented.  Perhaps in response to peer reviews, the team has added a good deal of graphical information describing internationalization.  There is a helpful section on future work. ","Dear Student, 

Thank you for your effort on this assignment. It's evident you've put in a good deal of work in attempting to internationalize the system. Your contribution towards introducing a new language option into the system is a significant achievement and has the potential to improve accessibility for many students who are more comfortable using Hindi.

Your documentation seems well-structured and thorough. You have outlined a detailed process and described the challenges clearly, which is certainly commendable. However, there are some areas that could use some improvement:

1. Please proofread your document for errors and editing mistakes. A few instances where file paths and instructions are repeated which might be confusing.

2. While you've clearly mentioned the issues and obstacles encountered during the process, the identification of the specific solutions to these problems could have been expanded upon or outlined more clearly. 

3. Planning for future developments, including dealing with dynamic text and more languages is good, but try to focus more on solidifying and perfecting what has already been implemented before expanding further.

4. The limitations of the project were clearly identified, which makes it necessary for future work to focus primarily on these issues. The navigation bar link issue, in particular, is something that requires urgent attention, as it affects the user experience significantly.

5. Finally, the usage of images and links throughout the document is good practice and it enhances the readability and understanding of the concepts. However, ensure these links are valid and direct to the proper resources. Due to the unspecified nature of the placeholders for Links and Images, it was a bit difficult to check their validity and relevance. 

All in all, the work carried out in this assignment is substantial, and it has great potential if the highlighted issues are resolved appropriately. Keep up the good work and remember to take these pointers into account when moving forward. 

Regards,
[Your Name]"
290,E1833,"Expertiza is an educational web application created and maintained by the joint efforts of the students and the faculty at NCSU. It’s an open source project developed on Ruby on Rails platform and it’s code is available on Github. It provides a dashboard for all the Assignments corresponding to a course and provides absolute control to the Instructors and Teaching Assistant. In addition to Assignments, it encompasses peer reviews where in participants are allowed to provide feedback anonymously about each other's work thereby providing scope for better outcome. In Expertiza, instructors (also admin, super admin and TAs) can create rubrics (they are called questionnaires in DB, there are different types like review rubric, teammate review rubric, etc. Each rubric may have one or many criteria (called questions in DB). For each criterion, it may have 0 to many suggestions/advices. Issue Description: Instructors and TA’s under the same instructor can make changes to each other’s rubric. Only the owner (an instructor) and his/her TA(s) should be able to edit the corresponding rubric. The first step towards solving this issue was to retrieve id of current user and check its authorization with regards to questionnaire.To achieve this, we are checking if current user is a 'Teaching Assistant' and his/her 'instructor' has access to current questionnaire. If the instructor has access of questionnaire, his/her Teaching Assistant should also have access to the respective questionnaire. This is implemented by checking the instructor id of the TA against the question's instructor id. To get the instructor id of a TA, the assign_instructor_id was reused. 1. app/controllers/export_file_controller.rb 2. app/controllers/questionnaires_controller.rb 3. app/models/question.rb. <code>. <code>. <code>. <image>. <image>. When logged in as super admin. At the bottom of the rubric, we will find links to import it and export it. The Export Details does not work and is not relevant to the context. Export page does not display the names of the rubric. When a rubric is exported, the headers on each column were incorrect and not related to the rubric. It seems to be headers from an export of information on users. Export page needs to give the name of the rubric When a rubric is exported, the column names should be proper. Exporting ""details"" for rubrics should mean exporting the advice associated with the rubrics. And then could rename ""export details"" to ""export advice"". Also change name of columns as per advice information extracted. In order to implement export functionality for questionnaire, two functions were added to question_advice model namely export_field and export. Export_fields returns an array of model fields and Export returns the advice data for current questionnaire. A new route has also been defined to handle the question advice export request. Views were also changed to display “Export Advices” instead of “Export Details” in the case of the Question model. You can find similar export functionalities in other modules as well including question model. 1. app/controllers/export_file_controller.rb 2. app/views/export_file/start.html.erb 3. app/config/routes.rb 4. app/models/question_advice.rb. <code>. <code>. <code>. <code>. <image>. Issue 696 There were no existing test cases for the Questionnaires_controller. We have made changes in questionnaires_controller_spec.rb which covers testing scenarios to check access over questionnaire module as per the role defined in the system i.e. for roles Instructor, TA and admin. The specs were run on the previous and current files and they return the same results implying that the changed code does not break anything. Below are the test Scenarios covered: 1. when the role name of current user is super admin or admin. 2. when current user is the instructor of current questionnaires. 3. when current user is the ta of the course which current questionnaires belongs to. 4. when current user is a ta but not the ta of the course which current questionnaires belongs to. 5. when current user is the instructor of the course which current questionnaires belongs to. 6. when current user is an instructor but not the instructor of current course or current questionnaires. Issue 577 There was no implementation in place to export question advice associated with questionnaires. We have created a new file question_advice_spec.rb to test question_advice.rb model. Test case is created to test both the methods i.e export_field and export. Below are the steps to perform manual testing for the issues resolved. Issue 696: 'Teaching_assistant520' has access to review 'review/517 F09 wiki' 1. Step 1: Login as teaching_assistant520/password 2. Step 2: Navigate to path manage->Questionnaires-> Review rubric 3. Step 3: Select questionnaire named Review from the list, which Teaching Assistant has access to. 4. Step 4: Choose question 517 F09 wiki and click on edit question button(pencil symbol). 5. Step 5: Teaching Assistant should be able to edit the questionnaire.(If Instructor/Teaching assistant does not have access to current questionnaire, system will show an error message). Issue 577: 'Teaching_assistant520' and 'Instructor' has access to review 'review/517 F09 wiki' 1. Step 1: Login as instructor/password or teaching_assistant520/password 2. Step 2: Navigate to path manage->Questionnaires-> Review rubric 3. Step 3: Select questionnaire named Review from the list, which Instructor/Teaching Assistant has access to. 4. Step 4: Choose question 517 F09 wiki and click on edit question button(pencil symbol). 5. Step 5: Click on the link 'Export questionnaire' at the bottom of the page. 6. Step 6: Top of the page shows Export Questions. When clicked of export, you will be able to export questionnaire for current rubric. 7. Step 7: Bottom of the navigated page will show 'Export Advices'. When clicked on Export, you will be able to export advices for current rubric. Issue 696: <code>. Issue 577: <code>. 1. Link to forked repository [ <link> ]. Expertiza 1. <link> Expertiza Github 1. <link> Expertiza Documentation 1. <link>.","Very good write-up. it covers almost all the aspect of the work done by them and most reviewers gave them the highest score. One issue is that the ""Problem statement"" should actually be included in ""background"" since it barely explains what the problem is, and more explanations are needed for the description of the first issue. Also I'm not sure why they included the modifications of questionnaires_controller.rb and questionnaires_controller.rb in the section ""Modified Files"" of the first issue since they are supposed to be included in that section of the second issue. A minor mistake: section ""2.1.3.1.1"" shoule be in the same level with section ""2.1.3.1"" in ""Contents"" And I'd suggest they include the links to the videos in Wiki.","Dear student,

Your assignment submission is comprehensive and clearly demonstrates an understanding of the subject in-depth. You have eloquently shown how the Expertiza web application works, outlining issues and offering thoughtful solutions. 

One area where the assignment thrives is explaining the practical steps taken to resolve identified issues. You have not just identified the problems but expanded on the solutions by giving bits of the code that you worked with. 

It was good to see the definitions of the different roles within Expertiza early on in the submission as it provided context about the system and its hierarchy. Also, I appreciated the terms and the way you crafted the explanations. However, it would be beneficial to use bullet points to elaborate on differentiations more visibly.

Your work in the issue sections is excellent. You bring up pertinent issues and give clear, understandable solutions. Also, your testing steps, especially with issue 696 and 577, are thorough and logically composed.

In future assignments, please consider breaking your work down into smaller paragraphs. This will aid in readability and improve the flow of your content. Owing to the complexity of the topic, ensure to use headings and subheadings to break down information into manageable bits.

Overall, you have shown a high level of technical knowledge in Ruby on Rails and provided depth and substance in your assignment. Your work is logical, well-structured, and academically sound.

Keep up the good work!"
291,E1944,"<link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. The focus of the project is on a controller named ReviewMappingController and the primary goal is to make changes to the internal structure of the controller to make it easier to read and cheaper to maintain without changing its observable behavior. This can be achieved through refactoring some of the more complex methods, modifying some of the language to make it more Ruby friendly, removing redundant code, etc. The number of routes directed to review_mapping_controller is illustrated here and since it is intertwined with a lot of other parts in the code base, it is quite imperative that this code needs to be refactored. Link to the Pull Request Submitted: <link> Link to the Repository <link> <image>. <image> We were tasked to refactor the review_mapping_controller.rb and solve any cascading issues or bugs we could find. We followed the above work plan to complete this task. There were many times when all the Rspec and Cucumber tests passed locally but ran into an issue when we uploaded the changes on GitHub. Prompt feedback from the TRAVIS CI helped us recognize the issue. Then we went on local machine and followed the whole process of refactoring again. In this way, we covered every refactoring we did and ensured that the TRAVIS CI get passed with minimum issues on the code-climate. 1. review_mapping_controller.rb 2. review_mapping_controller_spec.rb 3. assign_quiz_controller.rb 4. assign_quiz_controller_spec.rb 5. review_response_map_controller.rb 6. review_response_map_controller_spec.rb 7. routes.rb 8. Other views & partials associated affected by these changes. This controller will map the submissions made by the teams to the students for facilitating peer-reviewing. A couple of long and complex methods such as peer_review_strategy and automatic_review_mapping were refactored from this controller along with the removal of some non-related methods such as add_calibration and assign_quiz_dynamically . Variable names have been changed and code has been modularized and helper methods were separated from the important methods into a module and were included in the class. Test Cases were created for the newly created controllers such as assign_quiz_controller etc. After refactoring the Review_Mapping_Controller.rb , there were some tests still present in the spec file of this controller. So, we removed such tests from the review_mapping_controller_spec.rb to the appropriate spec file. assign_quiz_dynamically (Quizzes are also stored in the Assignment table) is not a seemingly/semantically related task to review mapping. Hence this was moved into a separate controller. Tests related to assign_quiz_controller were moved into this file. Add_Calibration is a nuanced method and has seemingly different functionality than Review Mapping Controller. Methods having a different purpose than review_mapping or helping review_mapping should not be present in this controller. So we moved this method into a separate controller . Tests related to review_response_map were moved into this file. New routes were added to newly created controllers. <code>. Routes were changed in the views and partials. app/views/student_quizzes/_set_dynamic_quiz.html.erb app/views/assignments/edit/_calibration.html.erb. 1. Changed 'instructor = build(:instructor)' to ‘@instructor = build(:instructor, id: 1)’. *Removed code redundancy from review_mapping_controller_spec.rb. Two variables were being initialized containing the same value. One was in the before(:each) loop and other was being called in first three test cases. *Replaced the one in the before(:each) loop by @instructor = build(:instructor, id: 1) and used @instructor class variable, wherever required. 2. Changed :i_dont_care to :no_particular_topic *:i_dont_care was used in the /app/views/student_review/_set_dynamic_review.html.erb as a flag to store if student is interested in any particular topic or doesn't care which topic to review. *It was also used in review_mapping_controller.rb to check if student has selected any particular topic. *Since, name :i_dont_care was very difficult to understand, we replaced it with something logical such as :no_particular_topic. It gives hint about what the symbol stores. 3. Removed cascading effects of above change from features spec *Above changes caused ./spec/features/review_assignment_spec.rb this feature test to fail. *This spec has used the above symbol to check if the list of available topics collapse or not after selecting the I don't care option. before: <image> after: <image> 4. Created a variable named ‘allowed_actions’ in method choose_case(action_in_params) *Switch case in above method from review_mapping_controller.rb contained all the actions having the same output for around 70% of cases. *Hence, replaced the switch statements and initialized a list with those switch cases. *Even the space complexity increased, the tradeoff got balanced because if someone has to change some actions, he will have to just add or remove the action name from the allowed_actions list. before: <image> after: <image> 5. Refactored Peer_review_strategy by using a helper method gen_random_participant_id *A random participant_id is generated from the possible pool of candidates but the code block for that is kind of a query, i.e. it does not change or set anything. *And it is equally complex enough to confuse the reader. So this has been put into a helper method with an expressive name to increase readability. <code> 6. Refactored automatic_review_mapping by using a helper method check_num_reviews_args *Parameters such as num_reviews_per_student, num_calibrated_artifacts etc passed are first verified to check if they are in acceptable range or pattern *To increase readability, the not-so good looking sets of if-else statements have been moved into check_num_reviews_args method. <code> 7. Modularized helper methods into a module and was mixed in the ReviewMappingController Class. *Only some of the methods written in the class have external usage i.e called by another controllers, views etc. *The other methods are just helpers and as such moved into a Helper method module and mixed in the class Before Modularization <code> After Modularization <code> 8. Abided to the principles of Magic Tricks of testing and did not test any internally used methods, The other tests are written were already following this principle. *Internally used methods were not tested *Tests for newly created controllers have been moved into a separate spec files. 9. Isolated AssignQuizDynamically method into a separate controller as the functionality was not related to ReviewMappingController. *This method assigns a quiz(Stored as an assignment object) to the participant. *This method is not related to ReviewMapping functionality, so it was made into a new controller. 10. Associated Specs/routes/views/partials have been modified to adapt the change in controllers. *The controller paths present in the views/partials have to be changed to not to break the functionality *The controller paths in views/partials/routes have been changed for the newly created controller of AssignQuizDynamically View File Affected by the creation of AssinQuizController <image> 11. student_review_num sounds like a number or an id associated with a student review, while it actually stores the number of reviews that a student can perform. So it is renamed num_reviews_per_student. 12. submission_review_num sounds like a number or an id associated with a submission review, while it actually stores the total number of reviews that can be performed on a single submission. So it is renamed num_reviews_per_submission. 13. calibrated_artifacts_num sounds like a number or an id associated with the calibrated artifacts, while it actually stores the number of calibrated artifacts. So it is renamed num_calibrated_artifacts. Similarly, uncalibrated_artifacts_num is renamed num_uncalibrated_artifacts. 14. participants_hash is not an appropriate name for a hash whose keys are participant ids and values are number of reviews performed by corresponding participants. So it is renamed num_reviews_by_participant_hash. 15. Extracted a method make_review_strategy (from automatic_review_mapping_strategy) that returns a review_strategy based on the values of num_reviews_per_submission and num_reviews_per_submission. 16. add_calibration is a method that changes the attribute of a ReviewResponseMap and has little to do with Review Mapping. So it is now put in a separate controller named ReviewResponseMapController. 17. The name add_reviewer may lead the reader to think that the method adds a reviewer to a collection of reviewers (e.g. a list of reviewers). Changing the name to assign_reviewer_manually informs the reader that the method assigns a reviewer (to a submission) and hence improves the readability of the code. Since this is a Refactoring Project, We made sure that the changes made did not break any functionality. <image> Note: Tests have been run for three controllers (one existing and two new). As the controller routes have been modified in the routes.rb and the other view files, there are potential chances of failures in Integration tests. However, no such failure has been reported by Travis build. <image> <image>. Code Coverage for Controllers section climbed up. <link> # Link for the COVERALLS stats of our pull request. <image>. Assign Reviewer Manually Demo <link> Regression and Unit Testing of Controllers Demo <link> Automatic Assignment of Reviewer Demo <link>.","1. The ""Files created/modified"" list should be described in conjunction with the changes made.  As it is, one has to flip back and forth to see what changes were made.
2. The changes that were made are described apart from the code that makes them.  This would requre more looking back and forth to understand what was done.
3. Mentor had asked the team to remove code snippets that have been extensively used all over the document.  If the snippets were shorter, with descriptions of each step, they wouldn've been easier to understand.
4. A list of 17 changes is much too long to be comprehended.  More organization is needed.  The changes should be associated with particular issues, or divided into a few types.
5. The team has given test results and code coverage screenshots and have provided a video to test the feature in expertiza deployment and regression testing.","Dear student,

Impressive work on the refactoring of the ReviewMappingController! From your submission, it's clear that you've made significant improvements to the code. You've improved its readability, reduced its complexity and adaptability, and adhered strictly to the principles of refactoring which is commendable. 

The renaming of variables to better explain their function in the code demonstrates your understanding of the importance of readability in code. Furthermore, your decision to separate out unrelated tasks to new controllers is a good instinct, showing your understanding of the Single Responsibility Principle. You've kept the maintainability and efficiency of the code in mind at all phases of this project, which shows maturity and practicality in your software development approach.

The approach you used to ensure that refactorization doesn’t break any code, including the use of TRAVIS CI and systematic testing of each part of the code, is commendable and shows your practical understanding of continuous integration and its importance in maintaining code quality.

Suggestions for improvement would be to provide a brief summary of the function and scope of your changes at the beginning of your report, to make it easier for the reader to understand the main points of your work. Also, for each change, provide a brief explanation about why the change is necessary. This can help readers to understand the importance and urgency of each change, and how it can improve the overall quality of the project.

Lastly, it would have been helpful if you had added the result of the code inspection tools (e.g. Rubocop, Reek) after making the changes to the code. These could provide an evaluation of the changes in terms of standards' compliance and code smells reduction.

Overall, great job on the project, keep up the good work!

Best,
[Instructor's Name]"
293,E1861,"The Expertiza application running on Ruby on Rails is used for a variety of purposes by students and faculty members. There are many pages that display information about students, assignments, rubrics and reviews. The information is displayed with attributes like name, ID, due date etc. This project works on improving the search facility by adding search criteria in existing search bars, making it look elegant and adding search bars if not present. 1. An instructor or administrator can search for a user by name, user-ID, or other characteristics. 2. An instructor should be able to search for assignments by name, due date, or other characteristics. 3. An instructor should be able to search for rubrics (or other questionnaires) by name, or by the courses or assignments they have been used in. 1.1. For the instructor, there also needs to be a way to quickly find rubrics (and other questionnaires) that have been used in a single course. It should be possible to search or click somewhere to bring up a list of questionnaires used in the course, expanding only the applicable questionnaires in the list of questionnaires. 1.2. One should also be able to search for questionnaires by words used in questions that belong to the questionnaires. 4. There should be a way to search all reviews of a particular team’s work for particular scores or text strings. Reviews should be able to be filtered by score, text comment length, reviewer and reviewee. 5. An instructor or administrator should be able to search for all the assignments that a particular user has participated in. 6. If more than one criteria needs to be specified, there should be an 'Advanced Search' button. In the current system workflow the user is able to search for a particular user by entering a partial or a complete text that matches with the user name. In the proposed workflow searching by name, searching by User ID will also be supported. The user will be able to apply multiple filters at a time and the output of the query will match all filter applied. If no results are found an empty list will be returned. Steps to reproduce the proposed workflow: 1.1. Log in to expertiza to view the home page 1.2. Go to Manage > Users 1.3. Type the name of the user in the search box available below the ‘Users’ tab 1.4. In the dropdown list that opens up, click on the ‘Advanced Search’ button if you wish to apply more filters. 1.5. All the entries that match the given criteria will be returned. In the current system implementation, searching via the name of the assignment is supported. In the proposed system, the user will be able to search for an assignment using additional filters such as date created, date updated. The user will be able to apply multiple filters at a time and the output of the query will match all filter applied. If no results are found an empty list will be returned. To search for an assignment by creation date, the user can enter a time duration within which the assignment was created. All assignments that were created within this date range and which match other filters will be returned. The procedure is same for searching by date of update. Steps to reproduce the proposed workflow: 1.1. Log in to expertiza to view the home page 1.2. Go to Manage > Assignments 1.3. Type the name of the assignment in the search box available below the ‘Assignments’ tab 1.4. In the dropdown list that opens up, click on the ‘Advanced Search’ button if you wish to apply more filters ( date of creation, date updated). 1.5. All the entries that match the given criteria will be returned. The existing system does not have a search functionality under Questionnaires. The proposed system will implement a search functionality for searching via the name of the questionnaire, the text in the question within a questionnaire, date of creation, date updated. The user will be able to apply multiple filters at a time and the output of the query will match all filter applied. If no results are found an empty list will be returned. To search for a course by creation date, the user can enter a time duration within which the course was created. All courses that were created within this date range and which match other filters will be returned. The procedure is same for searching by date of update. The questionnaires will be grouped on the basis of their courses and will be expanded when clicked. All the above will be available under Manage > Questionnaires. The existing system does not have a search functionality under Reviews. The proposed system will implement a search functionality for searching using the attributes like team name, score, reviewer, comment etc. <image>. We though about 2 ways of adding the search functionality in the system 1.1. Adding a search controller to the system 1.2. Adding search functionality to individual models. If we followed this approach the search query would be like 1. localhost:port/search/user?name=<> 2. localhost:port/search/assignment?name=<> This would mean that we are thinking of search as a resource on the system which to us looked as a wrong approach. If we followed this approach the search query would be like 1.1. localhost:port/user/search?name=<> 1.2. localhost:port/assignment/search?name=<> On discussions we concluded that that the latter was a more RESTFul design For most of the cases we have tried to minimize the changes required in the respective model by reuse We propose to add search methods in each model for corresponding changes. Therefore in order to perform search every entity required changes in all the three layers 1. View : Changes in view are changes added to UI, and it is used to pass search parameters to controller 2. Controller : Parses the changes from UI, essentially takes params[] hash. 3. Model : Bulk of search logic is implemented here, once the model gets the parameters for the search ( hash ), the query is incrementally built using all the params and then executed to get the list of objects. User changes have been handled differently than for Questionnaire, Assignments and Review because Users follows the traditional RoR scheme, where as others user React for UI. React based View changes are in app/assets/javascripts/tree_display.jsx. 1. Search fields 1.1. username 1.2. name 1.3. email 1. Modified files: 1.1. app/views/users/list.html.erb 1.2. app/controllers/users_controller.rb 1.3. app/models/user.rb 1. Modified functions 1.1. UsersController#list : Parses the username, name and email from the params hash. 1.2. User#get_user_list : Model returns list of users to the view, changes in this function uses regex to filter out the entries that do not match search params. 1. Search fields 1.1. name 1.2. assignee_username 1.3. assignee_name 1.4. due_date_before 1.5. due_date_after 1.6. created_before 1.7. created_after 1. Modified files 1.1. app/assets/javascripts/tree_display.jsx 1.2. app/controllers/tree_display_controller.rb 1.3. app/models/assignment_node.rb 1. Modified functions 1.1. TreeDisplayController#initialize_fnode_update_children 1.2. TreeDisplayController#update_fnode_children 1.3. AssignmentNode.get. 1. Search fields 1.1. name 1.2. text 1.3. course 1.4. assignment 1. Modified files 1.1. app/assets/javascripts/tree_display.jsx 1.2. app/controllers/tree_display_controller.rb 1.3. app/models/questionnaire_node.rb 1. Modified functions 1.1. TreeDisplayController#get_tmp_res 1.2. QuestionnaireNode.get. 1. Search fields 1.1. team 1.2. text 1.3. min_score 1.4. max_score 1. Modified files 1.1. app/views/review_mapping/_searchbox.html.erb 1.2. app/controllers/review_mapping_controller.rb 1.3. app/helpers/summary_helper.rb 1. Modified functions 1.1. ReviewMappingController#response_report 1.2. SummaryHelper#summarize_reviews_by_reviewees. The simplified version of ER Diagram depicts relationships between the entity sets that are used in the system. Many-to-many relationships are identified by named-diamonds - teams_users, assignment_questionnaires, which are implemented as tables. <image>. <image> <image>. We plan to two types of testing. Setup: create a user with name=""student"" and userId=""5000"" Action: Instructor clicks on manage - > users -> in textbox enters name=""student"" Response: Relevant details of student, name=""student"" is displayed Action: Instructor clicks on manage - > users -> advanced search->clicks on checkbox student id and enters ""5000"" and click ""ok"" Response: Relevant details of student, name=""student"" is displayed. Setup create an assignment with name=""assignment"" and set a due date Action : Instructor clicks on Manage -> Assignments, in textbox enter ""assignment"" in relevant tab Response : Relevant assignment should be displayed Action : Instructor clicks on Manage -> Assignments-> drop down and apply filters for due date and enter date and click ""ok"" Response : Relevant assignments should be displayed. Setup : Create a Questionnaire, add questions to it Action : Log in as instructor, Manage -> Questionnaires, in text box enter text Response : Questionnaires matching text are shown Action : Log in as instructor, Manage -> Questionnaires, click advanced search and check creation date and enter value Response : Questionnaires matching text are shown. Setup : Setup review for an assignment, login as student and then add review Action : Log in as instructor, Manage -> Assignments, Click on Review Report icon on corresponding assignment Result : Review should be seen Action : Click Advanced search, check review by text and enter text Result : Matching review should be visible. Automated tests in RSpec will be added as we implement the search functionality for each Model Most tests added will be unit tests that cover the test cases for each flow and changes in the model. Test Details 1. User Model ( spec/models/user_spec.rb ) 1. Search by user name 2. Search by user name that does not exist 3. Search by user email 4. Search by user email that does not exist 5. Search by user email containing a substring 6. Search by user full name 7. Search by user full name is empty 8. Search by user name and email.","This document describes the project in several relevant ways: discussion of the design approach, usecase diagram, classes and methods changed, changes to database schema, and test plan.  Each one of those is described in reasonable detail.  There are no major weaknesses.","You've done an impressive job in elaborating the project's needs regarding improving the search facility. Your comprehensive description of the current system features and your proposed updates is very clear and well-organized. 

1. You have correctly identified issues with the existing Expertiza application, providing viable improvements for these weaknesses. The addition of new search criteria as well as implementing filters will be extremely beneficial for users.

2. The steps detailing your proposed workflow provide an excellent understanding of how the improved features would function in the application. In addition, you've explained how these changes will be integrated into the overall structure of the application, specifying the changes that need to be made for each component (view, controller, and model).

3. The addition of search criteria and fallbacks in cases of no results found, are very well-thought and would certainly improve user experience.

4. Your outline for testing both manually and using automated tests are comprehensive and well-planned.

However, some areas to improve and consider:

1. There are sections where the numbers seem to restart midway. This could either be a formatting error or a miscommunication in the structuring of your explanation. It would be beneficial to ensure all items are numbered consistently.

2. Some of the technical terms or explanations may not be well understood by non-technical users or stakeholders. Consider explaining these in more accessible language.

3. Including some of the potential challenges or limitations that might be encountered with implementing these changes could provide a more well-rounded assessment of the project.

Overall, excellent work. You're showing an in-depth understanding of the system and the improvements necessary. Keep going in this direction!"
295,E1943,This page gives a description of the refactoring done in the sign_up_sheet_controller.rb as part of the OSS project. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link> 1.2. <link> 1.3. <link> 1.4. <link>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. Clean Code: A handbook of agile software craftsmanship. Author: Robert C Martin.,"There are not enough comments describing changes to the code.  Simply providing before and after snippets is not enough.  For example, ""Fixed the if-else ladder in signup_as_instructor_action action"" does not describe what was wrong, and how the fix was structured.  The document would thus not be very helpful in understanding the code.
There is a youtube video provided for testing that shows that the code has not been regressed
Appreciate the results/conclusion section in the doc which describes how their code change impact and what they bring to the table
It would be much clearer to cut and paste code snippets from Github rather than to use the formatting available in the wiki.","Dear Student,
Thank you for your submission. This assignment appears to involve the refactoring of a specific controller in an open source software project. However, it is unclear exactly what has been accomplished as the majority of your submission consists of unspecified links. 

For a more comprehensive review, it is vital to provide more context about each refactoring undertaken, detailing what the initial issues were, what changes were made, and why these changes constitute an improvement. It is also beneficial to discuss what impact the changes have had and how they contribute to the overall functionality and performance of the controller or the project as a whole.

While it's good to see Robert's C. Martin's book, ""Clean Code: A handbook of agile software craftsmanship,"" cited as a reference, it would be productive to mention how the principles from the book were applied in your refactoring process.

To facilitate a more thorough evaluation, please revise your assignment accordingly and provide further detail. It would also be helpful if you explain what each link refers to, instead of leaving them unspecified.

Looking forward to your revision, and keep up the hard work!

Best Regards,
[Your Name]"
296,E1916,"<link> is a web application developed using Ruby on Rails Framework whose creation and maintenance by students and the faculty of NCSU. The code is available on Github <link> . In Expertiza, instructor can create new assignments and customize new or existing assignments. The instructor also can create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. All the team member will show under the team member list. A Student can comment on his teammate's performance of the project. Students can also peer review other students' submissions and give tag comment by other's peer review. Students can submit their work by URLs or multitype file submission. Project E1916. Fix Code Climate issues in controllers with names beginning with A through N. There is some code smells of expertiza app/controllers detected by the code climate. These violate many of the ruby/rails best practices and needs to be rectified. Our team is to fix all code smells except： 1. Assignment Branch Condition size for [method name] is too high 2. Perceived complexity for [method name] is too high. 3. Cyclomatic complexity for [method name] is too high. 4. Method [method name] has a Cognitive Complexity of XX (exceeds 5 allowed). Consider refactoring. 5. File [file name] has XXX lines of code (exceeds 250 allowed). Consider refactoring. 6. Class [class name] has XX methods (exceeds 20 allowed). Consider refactoring. 7. Method [method name] has XX lines of code (exceeds 25 allowed). Consider refactoring. 8. Mass assignment is not restricted using attr_accessible. 9. Potentially dangerous attribute available for mass assignment. In all files in app/controllers/ with names beginning with A through N, except assignment_controller.rb. 1. [MAINTAINABILITY C] app/controllers/assessment360_controller.rb 2. [MAINTAINABILITY B] app/controllers/automated_metareviews_controller.rb 3. [MAINTAINABILITY B] app/controllers/grades_controller.rb 4. [MAINTAINABILITY C] app/controllers/impersonate_controller.rb 5. [MAINTAINABILITY F] app/controllers/import_file_controller.rb 6. [MAINTAINABILITY C] app/controllers/lottery_controller.rb. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. Our task is to fix code smell issues for some of the controller files. In order to prove that our modification did not break the application, we ran all the controller tests to make sure they all pass. We firstly set up the environment through VCL. Then we cloned our repository and simply ran: <code> Then we get the following results which represents that we passes all the controller tests. <image>. 1. Our Team GitHub Repository: <link> 2. Our Team Code Climate: <link> 3. The Class GitHub Repository: <link> 4. The Class Code Climate: <link> 5. The testing video: <link>.","On the micro level, you have described your changes well,  But rather than look at them one by one (which I could do through Github's diff), I'd like to see a summary of what were the issues that cropped up frequently, so we can advise future students to avoid them.  ","Dear Student,

Firstly, I commend the diligent work and enthusiasm with which you approached the assignment. Your determination in working to resolve the code smell issues in different controller files is clearly impressive.

However, there are a few issues with the assignment that need to be addressed. Throughout the text of your assignment, you've labeled multiple instances as ""Example <code>"" and ""Solution <code>"", but no actual examples or solutions follow these notes. In future assignments, please make sure that your examples or solutions are correctly formatted and clearly visible. 

Also, you have mentioned that you ran controller tests to verify the changes you made did not break the application but have not provided any details or the results of these tests. Can you please make sure to include these details along with screenshots or any relevant data to support the results? 

Lastly, it seems there are several links missing in your submission where I suspect we should find the links to the GitHub repository, Code Climate, and the testing video. 

In terms of improving your assignment for the future, make sure that any tests you carry out are clearly defined and have detailed results included. And don't forget to double-check your assignment for missing elements before submitting it.

Keep up the impressive work and don't hesitate to reach out if you have any questions. Let's make sure that the next assignment is not only completely done, but also properly documented!

Best,
[Your Name]"
297,E1757,"In Expertiza, instructors can act as students, but they do so by using different pull-down menus. This is potentially confusing, especially for Assignments, which appear both in the admin and student menus. An instructor sees the following menus across the top (if his/her window is wide enough; otherwise, the menus show up when the menu icon is clicked on): Home Manage Survey Deployments Assignments Course Evaluation Profile Contact Us A student sees these menus: Home Assignments Course Evaluations Profile Contact Us On the instructor’s Manage menu, one of the options is “Assignments”. Having Assignments appear in two places in the menu is potentially confusing. Manage > Assignments allows the instructor to edit and create assignments. The Assignments menu that both students and instructors see allows them to participate in assignments. Hence, to avoid confusion, a new view is introduced. To create a Student View that would make the instructor view the system the way (s)he would view it if they were a student. Once the instructor is in student view, the menu items are same as a student would view, so to come back as the instructor, a button should be visible to the instructor that would exit the Student View and take the instructor back to his/her home page. A new controller is created app/controllers/student_view_controller.rb to handle the new student view functionality, which sets and instructor to student view and reverts the view back to instructor. <code>. A new view is created for the instructor in config/role_instructor.yml which will show the view under the Manage menu item. The view id is 25. <code>. A new session variable (:student_view) will be used to check if an instructor is in student view or not and will be used to exit the Student view, code changes in app/views/shared/_navigation.html.erb <code> <code>. The different menu items are shown for particular roles, we check the new session variable to show or hide the various menu items accordingly for the instructor in app/views/menu_items/_suckerfish.html.erb <code>. The new controller methods are added in config/routes.rb <code>. The user needs to log-in as instructor to view the developed functionality, this won't be visible for other user roles- 1. Go to Manage > Student View 2. Instructor views Expertiza as a student. 3. A revert button appears at the top right corner, to exit the Student view. 4. Clicking the button takes you back to the instructor view. 1. link for forked repository [ <link> ].","Writeup is quite short, but also fairly easy to read.","Dear Student,

Thank you for your work. Your analysis on how instructors can view the system as students in Expertiza is quite thorough, and the steps you have proposed for creating a 'Student View' are insightful. 

Your in-depth analysis of the existing menu items and the confusion they could potentially cause is commendable. You have recognized a significant flaw in the user interface and are presenting a smart solution. 

The creation of a new controller is a significant development. However, it would be useful to provide more detailed information, like the methods and functionalities added to this controller. For instance, how did you manage the switch between the views? What actions occur when the 'revert' button is clicked?

When it comes to the view id, it would be interesting further detail regarding how it works, as well as where it is defined.

The implementation of the session variable is well-considered and seems highly efficient for managing the role switch. However, please explain further how you implemented this session variable, its functions, and how it can be accessed and manipulated.

Also, it seems you might have forgotten to close the <code> snippets and this is causing some confusion in reading the assignment. 

For your next step, it would also be valuable to include testing of your proposed solution, issues encountered during development, resolutions, and lessons learned. 

Overall, your work is excellent. There is a clear understanding of the system and the issues at hand. It would be interesting to see how the actual implementation of your solution would look and work.

Keep it up!

Best,
[Your Name]"
298,E1702,"The purpose of the project is to acknowledge the accomplishments of best performers in the class on various pre-decided areas. It will also motivate other students to perform better academically. It is deduced from a research at the University of Chicago which shows that Test performance can improve dramatically if students are offered rewards just before they are given standardized tests and if they receive the incentive afterward. The aim of this project is to implement a badging system for expertiza where certain students are awarded with badges based on their exceptional academic performance in assignments, project submissions etc. We have used Credly to make Badges. We are asked to make four badges now. And we can always add, remove or modify the existing badges in the future. The four badges selected by the instructor Zhewei Hu and our Team are: 1 Top Score 2 Dream Team 3 Good Reviewer 4 Consistency. LIGHTWEIGHT BADGING SYSTEM in Expertiza will act as a rewarding module of Expertiza to the students where they will be awarded badges, which can be understood as medals , in addition to the scores earned. We have decided on four badges which will be awarded to students who fulfil certain conditions explained in detail below. <image>. For every assignment in Expertiza, we have students perform differently on a scale of 100 based on the reviews their projects receive from their peers. The topper badges will be used to honor the team(s) which scores the maximum for a assignment. For example: <image> If we take the same example, the following Team will win the Top Score reward for OSS assignment <image>. The motive behind choosing this badge is to honor the hard work of team(s) who scored the maximum in class. This way, we can motivate other students to score better in the next assignment and score the best. We wish to achieve better quality submissions by introducing this badge. <image>. In Expertiza students are required to give reviews to the work of other teams. This is evaluated on a scale of 100% by the teaching staff. The Good Reviewer badge will be awarded to the student(s) who receive at least 95% score in the peer reviews awarded by the teaching staff for a project. For example: <image> If we take the same example, the following students will win the Good Reviewer badge as each of them got at least 95% in peer review score for OSS assignment <image>. Good reviewer badge will motivate students to give good reviews to fellow students on their work. This will serve dual purpose. First, It will help the students to improve their work taking advice from healthy feedback. Second, it will motivate the student to give good reviews and go through the work of other students which will give him/her the opportunity to learn. <image>. The performance of students across assignments vary. The Consistency badge will be awarded to the student(s) who receive at least 90% score in all the assignments. This badge will help the instructor also to know the consistent performers of the class. For example: <image> If we take the same example, the following students will win the Consistency badge as each of them got at least 90% in Assignment score for all the assignments. <image>. The motive behind choosing this badge is to motivate students to perform consistently throughout the semester. This will help keep students on their toes throughout the semester and result in better quality submissions. It will also improve the overall grade of the class. This is how the student page will look like. <image>. This is how the instructor page will look like. <image>. <image> The above diagram shows the implementation of badges for students. 1. The badge.rb is the Model class. It will contain the business logic for various badges. 2. The student_task_controller.rb is the controller class which will use the methods of badge.rb to determine which badges a particular individual/team has earned. 3. The list.html.erb in in student_task folder is the view class which will use the data to display the badges to the user. <image> The above diagram shows the implementation of badges for instructors. The data flow is same as that of students. The badge.rb is the model class, participants_controller.rb is the controller class and list.html.erb under participants folder is the view class. Their purpose is same as their corresponding colleagues in previous implementation. 1. As per requirement, the badges need to be displayed in the list view for both instructors and students. And thus, the list.html.erb has been chosen as the views to be modified. 2. The controllers student_task_controller.rb and participants_controller.rb are invoking the views mentioned in the above point. Thus, this list method in both the controllers need to be refactored to figure out what badges the team/ individual deserves. 3. All business logic regarding badge assignment criteria will be put in badge.rb, a model class created for the specific purpose. 4. Both the view and the controller mentioned above will have minor refactoring. 5. Since all business logic will be in the model class this class can be easily expanded to include more badges in the future. This provides both modularity and scalability which are the most important consideration behind the design. There were no existing test script for student_task controller and participants controller. We created two test scripts (spec/controllers/student_task_controller_spec.rb and (spec/controllers/participants_controller_spec.rb) to automatically test the list method in both of the controllers. The scenarios we tested are explained below: 1: If you try to access the student_task/list or participants/list when you are not logged in, you will be redirected to welcome page (""\""). 2: You can visit student_task/list by logging in as either a student or an instructor by invoking the list method in student_task controller. 3: You can visit participants/list by logging in as an instructor by invoking the list method in participants controller. 4: If you try to access the participants/list when you are logged in as a student, you will be redirected to welcome page (""\""). We used the two scripts initially to make sure that the list method in both the controllers are working as expected before we started adding any code. Later, when we were adding code for the required functionality , we used these scripts for regression testing. We have thoroughly tested the all the functionalities we have implemented by manually testing expertiza. 1. We have logged in as instructor6 and identified the top scorer of a particular assignment. Next, we impersonated all the students of the top score team to make sure all of them have received the top score badge for that particular assignment. 2. A Team in which each member has got more than or equal to 95% from all team mates review should receive the dream team badge. This has been verified by logging in as the members of the team. 3. We have logged in as instructor and given 100 points and 90 points to 2 students respectively as review scores for a particular assignment. Then we impersonated the 2 students to check that one of them has received a good reviewer badge and the other hasn't received the badge for that assignment. 4. Logging in as instructor, we have identified a student who has scored more than or equal to 90% in all the assignment for that course. Next we logged in as that student to make sure (s)he has received the consistency badge. We have further checked that instructors can see the badges the student has received for a particular assignment by visiting the participant_list/list view page. The page shows all the assignment specific badges (Top score, Dream team and Good reviewer badge). The link for the demo video is : <link> You can also replicate the testing according to our video. You can find the pull request in here : <link>. Currently, the average score of all the reviews for each assignment is computed dynamically and not stored anywhere in the database. This incurs huge latency in loading the pages which queries the score. This is the reason why ""Review Score"" page from instructor view takes long time to load. For the topper badge, we need to query the average score of all the teams for all the assignments in a particular course and decide whether the current user is the member of the team having the highest score in any of these assignments. This involves large number of computation and increases the home page load time of student view by an unacceptably large margin. Currently, a project is underway to fix this problem by storing the scores of teams in database. Once this task is completed, we can refactor our Top Score method to take advantage of this change. This will significantly reduce the latency of the Top Score badge for both student and Instructor view.","Very good job, including all the major elements: prose descriptions, screenshots, code snippets showing what was changed, and testing.","This proposed project on implementing a badging system in Expertiza is remarkably evaluated and explained lucidly. The vision to recognize top performers as a means to drive motivation and better performance is commendable. In the description, you've fit in the technical details as well as the conceptual groundwork, which is very noteworthy.

In the context of testing and implementation, your deliberation of test scenarios demonstrates your understanding of the complexities that could occur and your anticipation for them. 

Your project design's scalability and modularity are substantial and well thought out, which should prove advantageous when expanding or adjusting the system in the future. The use of specific models, controllers, and views in your implementation is also praisely mentioned and this illustrates your subject mastery. 

Nevertheless, there's always room for improvement. It could have been much easier to understand some points if the text was broken down into smaller, digestible paragraphs. Also, you should consider explaining the implications of your proposed changes more deeply, particularly providing concrete examples where possible. 

Regarding your concern about latency due to computational requirements around the Top Score badge, I appreciate your proactive approach in terms of identifying potential bottlenecks and suggesting future improvements - this greatly demonstrates your commitment to ensuring that your implementation is robust and efficient. 

Overall, you have done an excellent job on this assignment. Your clear articulation of the problem statement, solution, and methodology reflects your comprehension of the project requirements. Great work. Keep it up!"
299,E1675,"This page provides a description of the Expertiza based OSS project. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.1.4. <link> 1.1.1.5. <link> 1.1.6. <link> 1.1.7. <link> 1.1.8. <link>. <link> is an open source project based on <link> framework. Expertiza is a software to create reusable learning objects through peer review. It also supports team projects, and the submission of almost any document type, including URLs and wiki pages. In Expertiza we accept hyperlinks as well as files submitted by students, which makes it harder to track the updates for student's submission. In this project we were required to keep track of timestamp records for student's submissions and updates of artifacts (submitted files or hyperlinks). Authors can delete or re-submit files and hyperlinks, those activities were also recorded. What needs to be done: 1. Record the timestamps for file/hyperlink submissions. 2. Add code to keep all those time stamps tracked and updated. 3. Change the view of 0.0.0.0:3000/assignments/list_submissions view (by clicking the “View submissions icon”) to display the submition histories of each team. 4. Make the available submissions clickable (some submitted items maight be deleted, so they are displayed but not clickable). 5. After this project, the ResubmissionTime model (and related code) will not be used anymore. Please remove related code and db table. 6. Create tests to make sure the test coverage increase. We created a set of new controller, model and views to implement the functionality of timestamps. We added a model named SubmissionRecord that contains the following attributes. 1. Hyperlink - hyperlink that could be uploaded - String. 2. Upload File - file that could be uploaded - File. 3. Team id - id that links the model to the team that created it. - Integer. 4. Created at - timestamp for time of creation. 5. Operation - Description of operation performed. - create, update and delete. 6. User - User who change the status of current table Get this from current user id. 7. Content - String, the file name or the hyperlink. 1. In present code, the application has the control to decide which kind of user could have access to the specific page. In order to let the instructor see the submission_record, we need to add action_allowed method in submission_record_controller. Below is reference code : <code>. 1. After we created the table, there isn't a specific page for us to fill in the submission_record database table. So we implemented this feature using the previous functionality already existent in the submitted_content controller/model. This page had information about the hyperlinks and files which were previously submitted by the student. We add functionality to fill in submission_record table once a hyperlink or file is submitted. Below is a code snippet for reference : <code> <code>. 1. When students want to delete their hyperlinks or files which they had submitted before, the data in submission_record table should not disappear. We wanted to save all the operations made by the team. As a result, we added specific functionality in the existing delete function to reserve the data in submission_record table. <code> <code>. 1. In order to make the student submitted hyperlinks clickable, we check if the operation performed is 'Submit Hyperlink' in database. <code>. We utilize the params hash from the previous view called List_submissions. We then use a WHERE SQL query that matches the team_id from the submissions record table. <code>. The testing for this project has been done using several advanced ruby features. Below are a few of the features which were used : 1. <link> 2. <link> 3. <link> Using these techniques, the project was thoroughly tested. Models were tested for their validation. We had to verify each of the parameters which we received in our model. This was done by developing a Ruby Factory which had sample data. This sample data was fed into the models. Using RSpec, we then checked for validity for each of the parameters received in the models. This validity check is important since this information is prerequisite for having a perfectly working controller and view. Below is a code snippet which describes the testing methodology. <code> Controllers were tested to make sure the rendering, redirection and views are proper. Steps for testing the project using the User Interface. 1. As an instructor, go to manage assignments. 2. Click on submissions view of an assignment. 3. You will see all the items submissions. 4. Click on ""Show Submission Records"". 5. You will see a history of the submission along with the timestamps for each submission. 6. You can also see when the submission was added, updated and removed. 7. Visit below video link to see an interactive demo. 1. <link>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. Clean Code: A Handbook of Agile Software Craftsmanship. Author: Robert C Martin.","Good job of enumerating the changes made.  Good prose description the code snippets that you have included.  However, the code snippets themselves should contain comments.","Dear Student,

Thank you for this detailed submission. Here is my review on your assignment:

Your assignment shows a clear understanding of the Expertiza based OSS project and the tasks assigned. The steps you provided enabled me to clearly understand the requirements and the changes that you were required to implement. Your effort to methodically describe your approach is very commendable.

However, some issues need to be addressed:

1. There were missing information in your submission. Please replace the <link> and <code> placeholders with the actual links and codes for better understanding and reviewing.
2. Please remember to include a brief reason why each step was taken in your coding processes. This will help your peers understand the logic behind certain implementations and choices.
3. The formatting of the content was less clear in places. Breaking down information into smaller, more digestible sections or lists could significantly improve readability.
4. The section on testing could be expanded a little more. Although you have provided an overview of your testing methodology, it would be helpful to have more specific examples and results from your testing process.
5. Please also provide screenshots of the implemented changes to provide visual understanding of your work.

Overall, your conceptual grasp of the topic is impressive. Your thoroughness and focus on detail is to be praised. With a few adjustments and additions, this assignment will provide a robust guide to comprehensive understanding of the OSS project. 

Please revise accordingly. Keep up the good work!"
301,E1750,"Expertiza is an open source project base on Ruby on Rails framework. It allows students interact with each other through different assignment. It provide service as bidding on project topics, reviewing your teammate for different categories, and submitting assignments online. Expertiza also allows instructors to create assignment with different rubric and creating different topics for assignments that student can bid on. A software development process begin by writes an (initially failing) automated test case that defines a desired improvement or a new function, and generate the minimum amount of code to pass that test. It help the developer to focus on a smaller portions of functionality at a time. Also the refactoring process is safe since it happens after the test is written. Test can also serve as a documentation to a developer. review_mapping_controller.rb handles peer review response, and author-feedback response which is a complex file. It contains long methods that would be hard to understand. This project focused on breaking down some of the method in a form that would be easier to read/understand. Before starting the refracting task, failing test cases needs to be completed for the corresponding method in the review mapping controller. After completing the refactoring certain method if the review mapping controller then failing test should have a new status of pass. 1. Complete pending tests in review_mapping_controller_spec.rb, and write integration tests for newly-created methods. 2. Refactor automatic_review_mapping method 1. Refactor response_report method 1. Use find_by instead of dynamic method (L135) 1. Use sort_by(&:name) instead of sort { |a, b| a.name <=> b.name } (L275). 1. review mapping controller 1. Refactor methods 2.review mapping_controller spec.rb 1. Finished corresponding test for exiting method as well as created new test for newly added method. Here are two of the examples of the test cases. Tests on assign_metareviewer_dynamically method which assigns a assignment to the corresponding student. The describe section of the test introduce the controller method this test focus on. Followed by an description of the result on would be expecting from this test for developers to follow. The different expect conditions expressed as each test should make only one assertion which helps us finding different errors in the code. <code> Here is another example tests on add_reviewer and get_reviewer method which assigns reviewer to student's work. The test is divided into two different sections, and each section specifies one (and only one) behavior. This way will delivery a test that test all different possibilities and give the exact location of the error when it happens. This test followed the same step as the above test. <code>. In this example, we divided automatic_review_mapping method into 4 different simpler method so the code will be easier to follow. As before, the whole method is filled with nested if else statements when testing for certain conditions. We started by dividing the code from the if else statement, so an nested if else statement occurs we would divided the code into 2 method each performs a different set of function. We further divided the code by categorized their functions so that each method can perform the same kind of function or function belongs to the same controller. By doing this, our code is successfully divided into 4 simpler method with a name that describe their functionalities. 1. Original Code <code> 1. Refactored Code <code>. Response Report method had different switch statement testing different conditions. We split it into simpler method in different model to achieve a better cohesive in our code. We place different portions of code in models that related to their function. By just calling the corresponding method decreased the length of the review mapping controller. Updated the test after the code is completed. <code> 1. Original Code <code> for example this portion of the code summarizes the reviews of each reviewee by each rubric criterion. Which is placed in the summary class with a method name def self.response_report_by_review_and_criteria. <code>. 1. 39 examples, 0 failures, 39 passed 2. Finished in 12.099842971 seconds 3. Randomized with seed 22837 4. Coverage report generated for RSpec to /home/expertiza_developer/RubymineProjects/expertiza/coverage. 1400 / 4988 LOC (28.07%) covered.","In refactoring, we were interested in what principles they enforced, or which design patterns they used.  The comments are pretty general and do not give a good sense of what is done.  There should be more whitespace and more comments in the code.  Just showing original & refactored code doesn't indicate clearly how it was changed.","Dear student,

Thank you for the submission, it clearly shows your understanding of the project and Ruby on Rails framework. Your description of the Expertiza system and how it functions expresses your hard work on the assignment and comprehension of the topic. However, the assignment can be improved in several ways:

1. It contains spelling and grammar errors that hamper clear communication of information. Please revise the text for spelling (i.e., ‘refracting’ should be ‘refactoring’ and 'exiting' should be 'existing') and grammar errors (e.g., 'writes an' would be better written as 'writing an'). Proper use of prepositions, auxiliary verbs, articles and tenses are essential for clarity - don't neglect these.

2. Provide a better structure to make your points clearer. At various points in your assignment, it is hard to distinguish between the system's description, its potential use, and the tasks you are describing. Clear indications of these segments will help the reader to understand your work better. 

3. The naming convention of the methods lacks consistency, be sure to maintain a consistent naming convention for readability and simplicity.

4. When discussing bits of code or code changes, it would be helpful if you included the actual code as examples, which is missing in the assignment. This makes it easier for others to understand your explanations.

5. Elaborate on the description of your test cases and their results. Detail their function and what they test for in the program.

6. When you talk about splitting complex methods into simpler ones, it would be beneficial to explain in more detail how this improved the functionality and readability of the code.

7. Lastly, your reflection on the assignment and an overall summary of the work undertaken would aid in emphasizing the value of the work you have done.

Please revise your assignment considering the above points. Your effort is evident in the work and I'm confident your revised assignment would clearly illustrate your understanding of Expertiza system, the Ruby on Rails framework and your practical work."
302,E1705,"Expertiza provides the functionality of peer reviews. The best advantage of peer review for the students is that it allows students to learn from each others' work. 1. It provides a dual benefit for both the reviewer and the writer as they are introduced to a different set of eyes on the code 2. It might expose edge cases not previously thought of 3. It helps instructors review a project faster 4. It emphasizes the importance of writing in such a way that it's easy for a third person to read and understand In order to understand the correlation between the time spent in reviewing and the knowledge gained through reviewing submissions, we need to track the time that each student spends on peer reviewing the work. The knowledge gained can be measured by assignment score and reviewing score of the reviewer. This data can be further be utilized for research studies related to learning through peer reviews. 1. Design and implement a solution that handles the use case, where students’ submissions are hosted on an external website e.g. GitHub and Youtube use cases 2. Design a database schema for logging the time a reviewer spends on each submission link 3. Modify Review report (views/review_mapping/_review_report.html.erb) to display the response time summary report for each reviewer. Generally, the submission links can be one of the following: 1. GitHub project/repository link , GitHub Pull requests link or Deployment link 2. Youtube videos 3. Wikipages 4. Text document/doc/pdf/ppt 5. Images - png/jpg 6. Downloadable contents. The task is to know how much time a reviewer spent reviewing other teams. 1. We earlier thought of having response_id as one of the fields which could help us identify for which response we are recording reviewing time. But, entry in the responses table is created only once the response is either saved or submitted. Since we want our response_times entry to be created before that, we did not have any response_id corresponding to the response. 2. We primarily needed reviewer and reviewee specific data. So, another parameter to help us identify this primary information was response_map_id in the response_maps table. Once the review is started , we have the response_map_id from which we can later derive both reviewer_id and reviewee_id .There can be separate links uploaded per round, hence round is also an important parameter to be recorded. We need to record start and end time per link . The following table response_times was created to implement a solution for this project: <image>. Start and end time of each link viewed in one session needs to be recorded. The following are the steps that will be followed to keep track of the time: 1. Log the start time when a user clicks on a submitted link (a new entry in the response_times table gets created) during new review or while editing his saved review. An AJAX call is made from the view to ResponseTime controller action record_start_time to save start time details to database. 2. End time of all open links (where end time has not been recorded yet) for that session get recorded in the cases mentioned below. In this, an AJAX call is made from the view to ResponseTime controller action record_end_time to save end time details to database. All these cases are handled with the help of javascript onbeforeunload property 1.1. User logged out 1.2. User closed the window 1.3. User clicked on 'save' or 'submit' button 1.4. User switched to some other view other than the page where he is currently writing the review in the same tab. Note - the user is free to switch between tabs. The end time will not get affected in this case 3. Next time the reviewer opens the links again to review: 1.1. New entry gets created in the response_times table and start time gets recorded for this new session 1.2. The above procedure for end time remains the same 4. In case there is no user activity on the expertiza reviewing page for more than 5 minutes, there will be a pop up asking the user if he is still reviewing the submission. 5. As soon as the pop up is shown, the end times of all open links get updated to this time. The user has two options to cancel or to okay. If the user clicks on 'okay', then the above links for which we just updated the end time, need to be added as new entries again in this new session with start time as the current time. 6. This way we have individual entries for each link corresponding to each session with both start and end times recorded in the database. <image> Behaviour Diagram : <image>. Instructor can now view the total times taken by reviewers in the Review report summary. This report is rendered by partial review_mapping/_review_report.html.erb . We shall modify this view to record the times spent by the reviewer per review round for each team reviewed for this particular assignment. For example - 15.32, 12.67 indicates that reviewer spent 15.32 minutes on round 1 review and 12.67 minutes on round 2 review as shown below. Modified View : <image> Now, we can see that this report is simply an overview. If the instructor wishes to view fine-grained details, he can click on the reviewer link in the report. A popup is then rendered by popup/reviewer_details_popup.html.erb . This view shows reviewer details and details of time spent per link per round by that particular reviewer. Note - total time represents total time spent by the reviewer over all rounds over all links. If the user clicks on ""alternate view"" for a particular round, a pie-chart representation of the same data for that round appears above the details table. The user can toggle this view off by clicking ""hide details"" and ""show details"". <image>. 1. What happens when the user clicks on the same link twice in the same session: 1.1. It may so happen that once the user clicked on a link, by mistake he/she closed it or lost the link and wishes to view it again. If the link is again clicked, a second entry gets created with the current time as start time. 1.2. We account for the previous entry by updating its end time as current time. 2. What happens when the user downloads the submission: 1.1. If the user downloads any submission, the start time will be recorded on click link and end time will get recorded as above or when he submits the review. 1. response_controller.rb 2. response/response.html.erb 3. submitted_content/_main.html.erb 4. submitted_content/_hyperlink.html.erb 5. response/view.html.erb 6. review_mapping/_review_report.html.erb 7. popup/reviewer_details_popup.html.erb 8. helpers/review_mapping_helper.rb 9. config/routes.rb 10. application.js. 1. response_time_controller.rb 2. response_time.rb 3. review_mapping/_review_submissions_time_spent.html.erb. To test if the time spent by the reviewer on the submitted links shows up in the response_report in Instructor View. 1. Login as a reviewer, for example (student5930). Click on the submitted links to start reviewing. Once review is done, the time spent is recorded in the background and saved in our database 2. Login as an instructor. Click on assignments tab. Click on 'View Review Report' under actions for the particular assignment. In the view rendered we expect the total time spent by the reviewers for each to be visible 3. Click on the reviewer in order to see detailed information of time spent by each reviewer 4. Click on alternate view for each entry in order to see link wise time spent in form of a pie chart. To test the two new controller methods, we wrote and ran RSpec tests for it. We have two methods in the new controller - record_start_time and record_end_time. 1. In the following code, we are checking that there is a successful POST request to both the methods. To record the starting and ending time of a person looking at the submission, we call 'record_start_time' and 'record_end_time' respectively. We create a stub student user and a record in response_times database to imitate the real data entry. <code> 1. The image below shows the RSpec test running successfully <image>.","Includes all the major elements, in a very readable format.  The one weakness is that it does not go into detail about how the project will be implemented.  It discusses changes to the db but not to the code.","Overall, it is clear that you've put a lot of thought into the design and implementation of this project. Your review provides a comprehensive analysis of the matter in hand, and it's apparent that you understand the process of peer-reviewing and the data it carries quite well. 

However, there are a few things you might want to improve in your submission:

1. Clarity - At times, it is a bit difficult to follow your thought process due to the dense information provided. Consider breaking down complex paragraphs into smaller, more digestible chunks of text. This would make it easier for both - the reviewer and yourself - to ensure that all points have been covered, and nothing important is getting lost in the detailed explanations.
  
2. Simplify - The assignment appears to be rather technical, which isn't a bad thing in and of itself, but there's always a balance to be struck. Make sure the language you're using is appropriate for your audience - overly technical jargon can alienate some readers. Consider using more layman's terms or, when technical terms are necessary, providing brief definitions or explanations.
  
3. Tables and Charts - You occasionally reference tables or charts in your assignment (with phrases like ""<image>.""). Make sure to actually include these elements in your report and ensure that they effectively explain whatever you're trying to communicate with those charts.
  
4. Coding Snippets - Throughout the assignment, you occasionally mention different parts of a codebase, which would make the report more interactive and supportive if code snippets were included.
  
5. Conclusions - Towards the end of your report, provide clear takeaways from your study. 

Applying these revisions will make your assignment substantially more robust and user friendly. Keep up with the good work!"
303,E17A9,"The <link> page contains lists of courses, assignments, and questionnaires. This lists can be very long and takes time to load especially when the instructor also loads public assignments since all of them are loaded and rendered in the list. A more common way to accelerate this is to load the first few records that show up in the screen, and load more records as the user scroll down which is called lazy loading. We would like you to optimize this page by implementing such lazy loading using Jscroll or other plugins since the original tree_list code is written in ReactJS. Moreover, the tree_display lists have some bugs that you should fix: 1. It always goes to assignment page first, so when a user is editing a course then click browser’s back button. It goes back to the assignment instead of the course tab. The same applies when a user is editing a questionnaire, then click back, it goes back to the assignment, instead of questionnaire. We want you to enable “back” to the correct tab. 2. Secondly, when “Include others' items” checkbox has been checked, then the user is editing an assignment or courses, then goes back. The checkbox is unchecked again. It should remember the last state and load the assignment or courses accordingly. The following picture is what the page looks like now. We can see from firefox developer tools that getting all data from the database once costs 4303ms which is very slow. Therefore, we need to use infinite scroll to load a certain number of the record at one time e.g., record #1-#10 <image> The instructor page load extremely slow due to too much backend Database query ran before loading the front end. We could analyze both frontend and backend of this page to figure out a best solution to improve the performance of this page. The backend part could try to translate more than a thousand SQLs to just a few by Query modification. The frontend can use infinite scroll to reduce the render consumption. At first, we tried to solved the problem using jscroll. However, it did not make any difference and there were only a few examples and documentation online. Those resources did not help us find the bug. Therefore, because the instructor said we do not have to use jscroll to implement infinite scroll, we decided to use a react plugin called ""react-infinite"" instead. After we decided to move to another project, Prof. Gehringer mentioned two minor bugs in tree_display/list page. <image> In ""Questionnaires"" table, after the user click one row to expand the table, he cannot click again to close it. It would raise an error ""TypeError: React.addons is undefined"". ""Others' Public Assignments"" list is very long and unorganized. We need to organize it first by ""Instructor"" and then by ""Creation Date"". The majority of the logic behind the tree display page was written using ReactJS in expertiza/assets/javascript/tree_display.jsx. So we need to take the following steps: 1. 1. Install the dependencies we need to add infinite scroll functionality to ReactJS. 2. 2. Since there is no easy way to implement infinite scroll in a table tag of html, we should figure out a way to refactor the whole structure of tree_list. 3. 3. Add react-infinite to the tree_list. 4. 4. Modify the corresponding functions in assignment, course, questionnaire controllers to support lazy loading. For example, we may need to add ""LIMIT"" to the statement which query data from the database. <code> <code>. react-infinite <link> react-infinite is A browser-ready efficient scrolling container based on UITableView. Here's a demo <link>. 1. When a user first navigate to the page, there are 10 records and he can scroll down to see more records. 2. When a user edits a course, he will go back to course tab after clicking browser's back button . 3. When a user edits a assignment, he will go back to assignment tab after clicking browser's back button . 4. When a user edits a questionnaire, he will go back to questionnaire tab after clicking browser's back button. 5. When ""Include others' items"" checkbox has been checked, then the user is editing an assignment or courses, then goes back, the checkbox remains checked. 6. When ""Include others' items"" checkbox has not been checked, then the user is editing an assignment or courses, then goes back, the checkbox remains unchecked. While we are working on this project, we have tried multiple approaches, but nothing had worked out. The first one is jscroll, we had load jscroll into vendor directory using bower, and able to required in the project, but it turns out that jscroll doesn’t work in ReactJS. Thus, we tried to find third party React Plugins to achieve the function of infinite scroll. The first React Plugin is react-infinite, We were also able to load react-infinite into vendor directory using bower, and has no error occurred while adding to the react component. add dependency ""react-infinite"" to bower.json <code> run setup.sh to load ""react-infinite"" into /vendor/ modify ""app/assets/javascript/application.js"" to require the plugin <code> add ""react-infinite"" tags to ""app/assets/javascript/tree_display.jsx"" <code> However, it also didn’t work out because of the main content is html table. After that, we have asked this problem on the stackoverflow. People recommended another plugin called react-infinite-scroller, this plugin couldn’t find by bower package manager, so we have to load this package by another package manager like webpacker, but webpacker needs Rails 5 to load React, however Expertiza is based on Rails 4.2.6. We’ve also tried sprockets but we were unable to import. Our last try is <link> <link> <code> But we still stuck at this bug. <code> This project turns out to be really complicated to implement. So we asked to switch the project to implement Rspec integration test for the users_controller.rb. Because React.addons cannot be used here, I changed it to the function of JS. <code>. I sorted the list before the data is returned to the frontend in the tree_display_controller.rb. The list is sorted first in ascending order of 'instructor' and then in the descending order of 'creation_date' which requires 'creation_date' to be converted to timestamp. <code>. Our new project is to write Rspec Test for the users_controller.rb. Here is our code. <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code>. The test result is as below: <image>. 1. <link> 2. <link>.","The team had a hard time completing the project, and tried to update the design doc to reflect their new direction.  This makes it a bit disjointed, but that is to be expected.  There are a few issues mentioned by reviewers, like the tests should have been better documented.  Just showing the code is not very useful.","Dear student,

Firstly, thank you for the detailed observations and the effort put into solving the task given. It is evident from your submission that you have a clear understanding of the issue at hand and have tried a multitude of approaches to resolve it.

Your choice to switch from jscroll to react-infinite indicates your problem-solving approach and adaptability. However, the challenges you've faced in adapting react-infinite or react-infinite-scroller to the specific project requirements show there is still room for exploration and testing.

You've identified a bug when the page includes table content, which is a good finding. Your attempt to overcome the challenges faced by seeking help from external resources like Stackoverflow is an excellent practice for developers. Don't get discouraged if hurdles and roadblocks spring up.

The error you encountered might have to do more with compatibility issues among the different packages used in the framework, specifically since you mentioned that there is a discrepancy in the versions of Rails and consequently the existing webpacker and react versions.

The test cases you've written for user_controller.rb are appreciated and I'm glad to see your adaptability when the original project was proving tough to crack.

But remember, the original issue still exists and it's a crucial functionality. I would suggest you keep exploring more about this issue and seek advice from seniors or peers who may have experienced similar challenges.

Make sure to document your trials and errors in detail as this could help you in debugging and future development activities.

Good work and keep it up! Regardless of the progress made, the methods and tactics you've employed here are part of the learning process and essential skills in the developer's toolkit."
304,E1672,"This project mainly focuses on removing duplicated codes in feature tests and using Code Climate Chrome Extension and Travis CI to evaluate the modified code. Expertiza is an educational web application created and maintained by the joint efforts of the students and the faculty at NCSU. It’s an open source project developed on Ruby on Rails platform and the code is available on Github. It's a web portal used by students for assignment submission and team selection among other activities as listed below 1. It allows students to submit their work- either a wiki page or a deployed link. 2. Review other’s work and grade them. 3. Make changes according to user reviews 4. Allows the instructor to create new assignments and customize new or existing assignments. 5. Allows the instructor to create a list of topics the students can sign up for. 6. Students can bid for topics of their interest by assigning priorities to the topics 7. Students can form teams in Expertiza to work on various projects and assignments. The following is an Expertiza based OSS project which deals with the files in spec/features folder, to be specific: assignment_creation_spec.rb, instructor_interface_spec.rb, questionnaire_spec.rb, quiz_spec.rb, delayed_mailer_spec.rb and scheduled_task_spec.rb. It focuses on removing the duplicate codes, following DRY concepts, change DateTime class object invocation, etc. The goal of this project is to attempt to make this part of the application easier to read, maintain and improve the quality of the code. The existing redundant codes, use of long methods, incorrect method invocation and other errors are pointed out by the Code climate extension which are modified in this project. The code climate extension also provides a rating for all files as well as an overall score for the entire application, to help us make proper modifications. The following tasks were accomplished in this project: Install the Code Climate Chrome Extension, and when you go to Expertiza repo, you will see the extension will highlight the duplication code. Improved the clarity of code by improving the variable and parameter names. Remove the duplicated code by extracting a new method, moving code to before(:each) block, etc. Long character strings were taken and given appropriate names. Improve the Code Climate rating of classes whose original rating is F. Do not delete existing test cases and keep them pass TravisCI after refactoring. Files modified in current project Six files in spec/features that are to be modified are : 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link>. Code Climate is a open and extensible platform for static analysis and works on the principle: healthy code ships faster. Code climate platform leads to healthier code by clear and actionable static analysis regardless of the technology used. The static analysis engines and all the static analysis code used are published under Open Source licenses. This paves way for the users to dig in and understand how the code is being evaluated. The rating and GPA provided by Code Climate extension is an estimate of the quality of the code. The ratings vary from A to F and the GPA varies from 1 to 5. Code with a higher GPA is expected to have higher quality. Getting started with Code Climate To get started with Code Climate the following 4 steps are to be followed 1. <link> 2. <link> 3. <link> 4. <link>. 1. <link> and allow the extension to be used with your browser 2. Sign into your Github account and add the repository to be checked by clicking the extension from your browser. <code> 1. Manually add the repository from the dashboard. <image>. Similar code found in 1 other location (mass = 50) Duplicated code can lead to software that is hard to understand and difficult to change. Refactorings -Extract Method,Extract Class,Form Template Method,Introduce Null Object,Pull Up Method,Pull Up Field,Substitute Algorithm Use find_by instead of dynamic find_by_name. Do not use DateTime.now without zone. The files in the project include duplicated code which violates DRY concept and is to be removed. The various changes that can be made to the files are explained. When there is duplicated code within the file or between files of the same project, the code can be created as a function with variables that are assigned based on the different cases. This function can be called wherever the functionality is required to be fulfilled and also by passing the required parameters. This makes the code more readable and in fact, much easier to understand. By writing similar lines of code again and again, we only increase the number of lines and decrease the efficiency of the code.For example, the following error was pointed out by Code Climate Extension in <link> Similar code was found <image> <link> code similarity New functions were added to remove duplicates <image> <link> code similarity. In the different spec files, find_by_name function is used to identify variables according to their name. find_by can be used to match the argument with the variable directly, instead of making sure if the function parameters are matching with the given file. For example in file <link> , find_by_name was detected: <image> This was corrected to find_by <image> The grade of the code improved when find_by_name was changed to find_by. Refactoring is the process of improving a source code without altering the external behaviour. It improves Extensibility and Maintainability. We can implement refactoring using one of the methods mentioned above. A common code that is present across files can be added to rails_helper.rb and called across files when needed. One example of this is the cod in integration_test_instructor_interface function which was typed out without being encapsulated as a function in both <link> and <link> . <image> <code> <image>. Same variables may be assigned values through the program which may not be used later. These assignments are said to be useless as the new value never gets used anywhere. These lines can be removed from the program as they do not implement anything and are of no use. <image> And another example: <image> <link> Useless assignment These assignments were removed. To use the current time in the program, we need use Time.zone.now instead of DateTime.now. The latter uses the system's date and time as it is part of the Ruby standard library. It is better to use Time.zone.now because it returns the time that is corrected according to our corresponding Time zone as it has been extended by ActiveSupport. Example is as given : <image> <image>. Programs need to be indented properly. 2 White spaces are used to write statements within any block. Accordingly, the end of the block statements also follow the corresponding white spaces. Indentation improves code readability and makes it easy for the user/programmer to understand what happens within the program. The grades of the 6 files changed after the duplicates were removed Before modification : <image> After modification: <image>.","Please title your page after the topic, so that it can easily be located by a search.  I would also have liked to see you enumerate more of the changes you made, rather than just give examples of them.  (I wouldn't expect you to describe every change, though.)  But the idea of describing different kinds of changes was good.  The huge screenshots are annoying; did you try to find a way to shrink them?","Dear Student,

This is a comprehensive submission and it is clear that you have put significant effort into understanding and resolving issues in the Expertiza code base. Your project focused on removing duplicated codes in feature tests, which in itself is a big step towards improving software maintainability. The detailed explanation of the project and Code Climate's system could be helpful for others who aim to work on similar projects.

It's evident that you have a good grasp of how the Code Climate Chrome Extension and Travis CI can evaluate the quality of code and how the DRY (Don't Repeat Yourself) principle can be applied to improve the quality and maintainability of code.

One suggestion for improvement could be to include examples of actual code that you refactored, with before and after versions. It's helpful that you explained the process in text, but including concrete examples would make it even clearer.

Moreover, I note that your project dealt primarily with reducing repeated code, but there was no mention of any new features added. It would be great if you also focused on feature addition or improvement in future projects. 

I also noticed that while you did a good job describing Code Climate, it would be beneficial for you to dig deeper into how the TravisCI integration works with it to enhance code quality.

All in all, your project submission shows a high degree of effort and understanding. Remember to continue building upon what you have learned, and not shy away from exploring new areas and expanding your coding skills. 

Good job, and keep up the good work!

Best Regards,
[Your Name]"
306,E1843,"Expertiza is an open source project based on Ruby on Rails framework and the code is available on Github. Expertiza allows the instructor to create new assignments as well as edit new or existing assignments. Instructors can also create a list of topics the students can sign up for and specify deadlines for completion of various tasks. Students can form teams in Expertiza to work on various projects and assignments as well as peer review other students' submissions. Expertiza supports submission across various document types, including the URLs Wiki pages. 1.There is no deadline that specifies when a team can drop their topics. Due to this, few problems occur: The team might drop a topic later on which is close to the submission date and this results in topic not being assigned to any other team on time such that they can submit their assignment. Also, if one team was wait listed for the same topic which the other team dropped closer to the submission deadline, then the first wait-listed team will be assigned to the dropped topic which is not desirable as they might be working on their assigned topic for long time. 2.There are different topics on which students can work during different times. This type of assignment is known as Staggered- deadline assignment in which different topics have different submission and review deadlines. For these assignments too, there is a need for ""Drop Topics Deadline"". In the current implementation, the drop topic deadline is same for all the topics in a Staggered Deadline assignment which is not desirable. 1. The instructor can specify a Drop Topic deadline date now. After a drop topic deadline passes, the ""X""(signup option) in the Sign-Up sheet disables so that the student cannot drop the topic and the wait-list for that topic is cleared, which will resolve the issue of the topic being assigned to a wait-listed team very close to the submission deadline. 2. Staggered deadline assignments now have different drop deadlines for different topics in that assignment.The above resolution also works for Staggered Deadlines Assignment. 1. app/controllers/assignments_controller.rb 2. app/controllers/sign_up_sheet_controller.rb 3. app/models/student_task.rb 4. app/views/assignments/edit.html.erb 5. app/views/sign_up_sheet/_add_signup_topics_staggered.html.erb 6. app/views/sign_up_sheet/_due_dates.html.erb. 1. Clearing the waitlist after Drop Deadline passes is implemented in sign_up_sheet_controller.rb where it is checked if the current time is greater than the time mentioned in Drop deadline. If the deadline has been passed, the 'update_is_waitlisted' method of SignedUpTeam model is called to delete all the waitlisted teams for that topic. 2. Changes are made in Assignments View to add an additional column for Drop-Topic Deadline for Staggered Deadlines Assignment. The code snippets for corresponding changes in controllers and models are as below: (i) app/controllers/sign_up_sheet_controller.rb <code> (ii) The 'update_is_waitlisted' method is implemented in app/models/signed_up_team.rb as follows: <code> (iii) app/helpers/sign_up_sheet_helper.rb <code> (iv) app/models/student_task.rb <code> (v) app/views/assignments/edit.html.erb <code> (vi) app/views/sign_up_sheet/_add_signup_topics_staggered.html.erb <code> <code> (vii) app/views/sign_up_sheet/_due_dates.html.erb <code>. It was discussed that project does not require any Unit Test cases to be implemented as the changes are mostly visible in views. 1. Expertiza on GITHUB: <link> 2. GitHub Project Repository Fork: <link> 3. The live Expertiza website : <link> 4. Demo link: <link> 5. Expertiza project documentation wiki: <link>.","Good description of the work to be done, but I think that the code snippets need to be accompanied by an explanation of what they are doing..  In this document they are just pasted in, with no comments.","You have put together a well-structured assignment which demonstrates that you understand the nature of the problem and have thought through an excellent solution. You present your reasoning and proposed solution clearly and thoughtfully. I appreciate your attention to detail, especially your explanation of how your solution resolves the problem with specifying a 'Drop Topic' deadline. 

However, there are a few areas in your assignment that need improvement. Your assignment could benefit from different code snippets to support the understanding of your explanation. Also, it's crucial to explain in detail about the changes in the controllers and models, which you have mentioned in your assignment. 

In addition, it's recommended to follow best practices even if Unit Test cases aren't required. Writing them would strengthen the integrity of the project by ensuring every component works as expected. 

Lastly, your referencing is incomplete. While you have included links to repositories and documentation, it's important to explain in text what those resources contain and why they are relevant to your work. 

In your next assignment, I encourage you to provide more detailed code examples and clarify your references. Also, consider the benefits of implementing Unit Test cases. Great job overall, keep up the good work!"
307,E1934,"After an instructor gave a grade to an assignment, there is no way to track who gave the grade. A grading audit trail must be created and the following information needs to be stored: 1. When a grade is assigned by an instructor, there needs to be an indication of who did it and when it was done. 2. Comments previously provided by other instructors must also be preserved. This information needs to be stored every time an instructor edits a grade/comment and clicks the save button. Currently, there are two places need to add grading audit trail: 1. Review grade : Log in as instructor -> Manage -> Assignments -> View Review Report 2. Submission grade : Log in as instructor -> Manage -> Assignments -> View submissions. We created a database called grading_history in the system which stores elements of instructor id, assignment id, grade type, student id, grade, comment, and timestamp. We used MVC design to create a model, a controller, and a view for both of Review Grade and Submission Grade . Model: grading_history.rb. Has a list of attributes contains instructor id, assignment id, grade type, student id, grade, comment, and timestamp. Controller: grading_history_controller.rb. Saves a new entry into the database every time a review grade or submission grade is saved View: index_html.erb. Displays current submission or review's grading history. An existing example of this is a submission record in the system. We modified grades controller, so that every time, a grade is submitted or edited, grading_history_controller.rb will call a method to create an entry saves into the database. <image>. <image>. <image>. Functional testing: 1. Test if SubmissionGradeHistory.create is being called when a submission grade is changed. <code> 2. Test if ReviewGradeHistory.create is being called when a submission grade is changed. <code> 3. Test if GradeHistory.where is being called when grading history button is clicked. <code> Feature Testing: 1. Test if the grading history is visible and shown in chronological order <code>. 1. app/controllers/grades_controller.rb <code> 1. app/controllers/review_mapping_controller.rb <code> 1. app/views/assignments/list_submissions.html.erb <code> 1. app/views/reports/_review_report.html.erb <code>. 1. app/controllers/grading_histories_controller.rb <code> 1. app/models/grading_history.rb <code> 1. app/models/review_grading_history.rb <code> 1. app/models/submission_grading_history.rb <code> 1. app/views/grading_history/index_html.erb <code> 1. spec/features/grade_histories_spec.rb <code> 1. spec/features/helpers/grade_histories_helper.rb <code>. <link> <link> <link> <link> <link> <link>.","The design document is supposed to give a rationale for the design, but this design doc is mainly screenshots and a list of files that were changed.  The screenshots could be described (e.g., why did you add a column to View Submissions) and you could have shown, or linked to, code snippets and described what the snippets were doing.","Your assignment is considerably comprehensive and well-detailed. Your clarity in the problem statement, current system description and system modifications made are noteworthy.

In your overview of the problem, you've convincingly expressed the importance of a grading audit trail. By highlighting the need to record who assigned the grade and when, you've successfully argued the importance of transparency in grading.

Your solution description demonstrates proficient knowledge of MVC design. Adding the list of attributes to your model, modifying the controller to log each new entry into the database, and adjusting the view to display the corresponding history reflects your understanding of this design pattern.

You've also presented clear points on how you integrated this functionality into two different sections of the system, which shows a high level of code manipulation and modification.

Moreover, it's impressive that you included functional and feature tests. These additions show a firm understanding of agile development practices and solidify the integrity of your solution.

However, keep in mind that including real images and code snippets would have made your document more appealing and easier to follow. Also, maintaining the numbering system in your assignment outline would have made it more organized.

In terms of improvements, while you've detailed the solution, it would be beneficial to delve deeper into any challenges you dealt with during the implementation. Detailed explanations of the problems faced and what approaches you used to overcome these challenges are great ways to illustrate the full extent of your thought process and technical expertise.

Keep up the great work! You've displayed a commendable level of understanding and expertise in this assignment."
308,E1961,"1. E1961 Project aims to fix the problems of making the email notification function more reliable. 1. The forked git repository for this project can be found <link> 1. Deployed on VCL: <link>. The following tasks were accomplished in this project: 1. Issue1: Fix the problem that the author(reviewee) cannot receive the email notification about the review from someone else. The Expertiza is supposed to email authors each time a review of their work is submitted. 1. Issue2: Fix the bugs to make Expertiza emails reviewers each time an author that they have reviewed submits new work. 1. Issue3: The instructor could get a Blind carbon copy every time. 1. Issue4: The users can turn off those email notifications by unchecking boxes on their profile page. 1. Add a method in both ""update"" and ""create"" functions to call the email function to make the Experiza send the email to reviewee when reviewers submit the reviews Changed files: app/controllers/response_controller.rb: 1. previous version <code> 1. current version <code> 1. refactor the email method, which is called by send_email_to_reviewee. Changed files: app/models/review_response_map.rb: <code>. 1. Add new function to email all reviewers a new submission is ready to review: 1.1. In the first round, there is no reviewer before they take a request 1.2. Except the first round, reviewers get an email every time when there is a new submission Changed files: app/controllers/submitted_content_controller.rb: <code> <code> Changed files: app/helpers/mailer_helper.rb: <code> 1. Changing the email content, which is the message content send toward the receiver. Changed files: app/views/mailer/new_review_message.html.erb: <code> Changed files: app/views/mailer/partials/update.html.html.erb: <code>. 1. The instructor is able to get copies of emails that are sent to students by the system. Also the instructor could cancel the function by editing the checkbox on the profile page. Changed files: app/controllers/submitted_content_controller.rb: <code> Changed files: app/models/review_response_map.rb: <code> 1. Add a new attribute: bcc_mail_address Changed files: app/helpers/mailer_helper.rb: <code> <code>. 1. Fix the problem that the users cannot choose to uncheck the email options. Changed files: app/views/users/_prefs.html.erb: <image> 1. previous version: <code> 1. correct version: <code> 1. fix issue disable email_on_review is not working on profile Changed files: app/models/review_response_map.rb: 1. previous version: <image> 1. correct version: <image>. We manually tested our functions including the mentioned issues. Please check our video test. 1. <link> 1. instructor6 create a new assignment 2. student10, student11 submit a hyperlink as the first submission 3. nstructor6 modify the due date of first submission(For the test, the student only can do the review after the due date of the first submission) 4. student 11 does the review for student 10 ---->the student 10 and the instructor6(Blind carbon copy) should receive the email to notify that there's a new review 5. student 10 resubmit another hyperlink as the second submission --->the student 11 and the instructor6(Blind carbon copy) should receive the email to notify that he needs to update the review Database: 1. we modified the email address of instructor6, student10 and 11 to do the test in the video <image>. 1. test function: if the user unchecked the box of email_on_review(When someone else reviews my work) option, he should not receive the email. 1.1. We create a new student2 with email_on_review options is false (default is true) Changed files: app/spec/models/review_response_map_spec.rb: <code> <code>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link>.","The documentation was not submitted, though it could be found by searching the wiki.  The description essentially just consists of before and after versions of the code, with almost no explanation of the changes.  There is a video, but it does not contain audio, so it is very difficult to follow.  It apparently shows email being sent and received.","Dear Student,

First of all, congratulations on the work done - you have achieved a comprehensive coverage of the project, and I noticed that you solved a number of issues that arose during the process. The clear structure of the write-up and your attention to each component is commendable. Each point has been explained nicely, showcasing the diligent efforts placed in solving bugs, adding functions and implementing improvements.

However, I noted that some of your listed tasks were numbered as ""Issue 1"". From your bullet points, it seems you were trying to create sub-points, but the format seemed to become muddled due to this. Please review your formatting - it would make your assignment look more polished and easier to follow.

The details on changes in code, added methods, and the reasoning behind them are well-articulated. It's excellent that you've included the correct and previous versions; that helps in understanding the changes you've made. However, it could have been better if actual links or working examples of code were provided, instead of simply writing <code>.

I would like to recommend a slight improvement for future projects: please make sure to add detailed comments in your code to help others (and yourself, in the future) understand what each code block is meant for. This can be a great tool for collaborative work.

You've done a considerable amount of testing, which is great. However, it would add more value if you also included exact results of these tests, instead of just video links. Perhaps a brief description of the test outcomes would make it clear if goals were achieved.

In conclusion, this was an impressive project. Your dedication towards fixing issues and enhancing functionalities is admirable and you've communicated your solutions effectively. Make sure to follow the recommendations provided. Keep up the good work!

Best regards, 
[Your Name]"
309,E1844,"In Expertiza, teams are created for every homework. Somewhere in the bidding code, or the code that assigns topics based on bids, team names are generated. In this case, team names are not appended to the name of the assignment, like they are when teams are created elsewhere in the code. The team names should be of the form ""Team_random_number"". Also currently, the usernames can have spaces in them but then you cannot impersonate that user. The expertiza should prohibit spaces in usernames. Issues as described by the problem statement: Team names created by bidding are incorrect Somewhere in the bidding code, or the code that assigns topics based on bids, team names are generated. In this case, team names are not appended to the name of the assignment, like they are when teams are created elsewhere in the code. Team names generated everywhere must be standardized. Usernames can have spaces in them. And currently, if you create a user with a space in the username, you can't impersonate that user. Expertiza should prohibit spaces in usernames. Implementation should probably just include a format check in the user model, and tests to validate a username. 1) app/controllers/lottery_controller.rb 2) app/controllers/suggestion_controller.rb 3) app/models/team.rb 4) spec/models/team_spec.rb. 1) app/models/user.rb 2) spec/models/user_spec.rb. Teams are generated within Expertiza in various scenarios. Teams are generated for every assignment, course and team names are generated in various formats at several places in the bidding code. Also, automatic generation of teams for assignment follows a different team name format. A single team name format was fixed, i.e. 'Team_random_no' (e.g. Team_51) and all the automatically generated teams were assigned a team name with the standardized format. Standardizing team names is a good way to avoid discrepancy in team names irrespective of the source of team generation. This approach has been chosen because changing the parameter value (string of the team name) is the simplest way to standardize names of the auto-generated team names. We preserved the existing functionality of the functions and removed the use of unnecessary variables keeping the code DRY. Pseudocode standardizing auto-generated team names throughout expertiza <code>. Expertiza allows spaces in username. But, if a user has username with spaces then that user cannot be impersonated by an instructor. Thus, the task is to prohibit users from having spaces in usernames. By doing so, it increases the user-friendly quotient of Expertiza. Even if the username is created by using spaces, the white spaces are removed from the string by the following pseudocode. Thus, the username can now be impersonated in the same way as any username having no white spaces at all. Pseudocode representing the logic we have used to modify app_models_user.rb <code>. 1.) Login as instructor, <code> 2.) Login as student, <code> <code>. Following are the identified team creation methods and corresponding code changes: <image>. <image>. The validation check has been added to the model of the user class so that no white spaces are present in the username : <image>. 1)Login as Instructor, create an OSS assignment for bidding with all the necessary details like maximum no of users per team, add topics for the assignment, add participants(students) in the assignment. 2)Login as a Student(say Student7348), whom you have enrolled in the assignment. You should be able to see the assignment now in the Assignment section. 3)Click on the assignment and then click on 'Your team'. 4)Invite a student(say Student7349) whom you have also added as a participant in your assignment, to be your teammate. 5)Login as student7349 and accept student7348's request to join his/her team. 6)Now, the team name would appear on the top section of the webpage. The team name would be of format : Team_RandomNumber ( say Team_21 ). 1. On clicking Manage and then on assignments, following page appears. <image> 2. Click on copy assignment icon and edit the information as per requirement. A new assignment would be created. <image> 3. Now login as student7609 and click on 'Test Assignment'(assignment that you have created as an instructor) under Assignment tab. <image> 4. Click on 'your team' and send teammate invitation to another student7508. <image> 5. Now login as Student7508 and accept the teammate request of student7609. You can view the team name 'Team_7' at the top of the page which is the required standardized format. <image>. The existing Rspec test is modified so that the expected value of the team name is modified to the new format. The existing Rspec file user_spec.rb is modified in order to add another test case to validate the use of white spaces in the username. <image>. <link> <link> <link> <link> <link>.",Most reviewers think the writeup is great. It has been structured very well and clearly explains what was done. The only issue I can see is that they have used images to display code instead of code snippets.One reviewer comments that the screenshot could have been of a 'standard' size.,"Dear student,

Thanks for your work on this assignment. It is clear from your detailed process and explanation that you understand how to identify and solve the problems related to team names and usernames in the Expertiza system.

Your logic and the thought process you've followed for both the team name standardization and the restriction of whitespace in usernames is coherent and will likely result in a more usable system. It is also commendable that you detailed your implementation strategy and approached it by adhering to the DRY principle. 

However, there are areas of the assignment where you have just referenced '<code>' without actually providing the code samples or pseudocode. In future assignments, always make sure to provide these as they are crucial to understanding the steps you’ve taken towards your solution. 

Additionally, the use of '<image>' and '<link>' placeholders throughout your assignment suggests you meant to include visual aids or links to additional information, but these were not included in the final document.

Finally, for your user testing, it would be helpful to elaborate what the specific expectations are and what would be considered a successful outcome.

Overall, your work is insightful and thoughtful. However, don't forget to fill in those placeholders before submitting next time. Keep up the great work. 

Best,
[Your Name]"
310,E1933,"An error occurred while attempting to extract the child content. The objective of this project is to: 1. Add a feature for students to toggle the visibility of their reviews. When reviews are marked 'public', instructors will have the option of adding them as a 'sample review' to any assignment. When reviews are marked 'private' they will not be shown to other students as a sample. 2. Add a feature for Instructor to select a subset of 'public' reviews and make those reviews visible as sample reviews of any of their assignments in the course. 3. Add a feature for instructors to select a subset of 'sample' reviews and set those reviews as sample reviews for a particular assignment. 4. Create a view where the student can see a list of sample reviews of the assignment and have a detailed view of each. The goal of this project is to enable instructors to select certain reviews to show as examples to the entire class. Thus the students will be able to see good reviews that one student has submitted for another student's work. The students will be able to get understand what a good review looks like and what exactly is expected from them when they review any other team's work. 1) Creating a checkbox : When a student submits a review, they should be able to choose if they want to make their review public or private. Thus we added a checkbox to the review page. Checking this checkbox will make the review public. Unchecking it will make the review private. When this status changes, a message is displayed next to the checkbox saying if the status was changed successfully. 2) Allow students to make a review private : Students should be able to change the visibility of their review even after they have submitted it. A checkbox similar to the one described above was implemented where students can see the reviews they have given. If a review has been made private after an instructor has selected it as a sample review, it is still not displayed to students as an example review. 3) Allow instructors to select (remove) sample reviews : If a review has been made public by the reviewer, the instructor is able to select that review to be made a sample review. If the review is already a sample review, the instructor is able to remove from the set of example reviews. If the review was private, the instructor is shown a notice that 'This review is private.' and they are not allowed to select it as a sample review. This selection can be done when the instructor is viewing the review. 4) Set some of selected reviews as sample for an assignment : Sample reviews can be identified by the assignment, reviewer (a participant) and the reviewee (a team). When editing an assignment, the instructor is able to select past assignments, select a reviewer and select the reviewee. The way in which the instructor selects the assignment is to select the from a dropdown. the assignment dropdown is populated with all the assignments that the instructor has created and all the assignments that belong to the course. When the assignment is selected, the reviewer dropdown will then be populated with the names of the reviewers whose reviews have been made public and have been selected by the instructor. Once the reviewer is selected, the reviewee dropdown will get populated with names of teams to whom the review has been given. This will identify the selected review. The instructor will be able to set it as sample review for the current assignment. This means that the instructor can even set a review from any of their earlier assignments as a sample. 5) Allow students to see sample reviews : When a student wants to review other team's work, they will be shown a list of sample reviews that the instructor has selected for them. In the list each review is a link to the full review. 1. Create migration to create a column called status which can take on the values 'selected' = 2, 'public' = 1 and 'private' = 0. Changes will reflect in db/schema.rb Status can have 3 values as listed below: <table> 1. Created a checkbox in a view: views/response/response.html.erb . To allow students to mark their reviews as public. 1. Added code to check the status field from response.html.erb and update the db, in controller: app/controllers/response_controller.rb (in method ""create""). This will reflect the choice of the student in the database. 1. The instructors will select sample reviews from a set of public reviews. The code change will be in the file team_users_popup.html.haml which is under the views/popup directory. 1. Students will be able to view sample reviews. The code change will be in the file list.html.erb which is under the views/student_review directory. 1. In order to paginate and display a list of reviews to chose from for the instructors, we will have to create partial view files. 1. Use Case - <image> Power Users: Instructors, TAs, Admins and Super Admins. A team in the Fall 18 semester had partially done this project. As per their findings, there was no association maintained between assignments. Thus it is impossible to recognize if sample reviews from a previous session of the same course can be shown students of the current session of the course. The earlier team decided to create a model to store such an association between assignments. This model contains two columns both having different assignment IDs. This means that all the selected reviews in an assignment will be shown as sample in the other assignment. 1) We did not want the all selected reviews in an assignment to be shown. Instead we added a facility for instructors to select individual reviews and set them as sample. Hence we created a migration where we create a model. The model has an assignment id and a response_map_id. The assignment_id is the id of the assignment for which the sample is to be shown. The response_map_id is the id of the sample review. 2) We also added a column called visibility to the responses model which will show if the review has been marked 'private', 'public' or 'selected'. In our project, the implementation of a new functionality would be through a Delegation pattern which is an object-oriented design pattern that allows object composition to achieve the same code reuse as an inheritance. This shows the overall flow of what the users of the system should be able to do. We will write tests such that the entire flow will be completely tested. As a Power User (TA/Instructor/Admin/Super Admin) (Scenario 1) 1. Log in 2. Click on Manage->Assignments 3. Displays a list of Assignments 4. Click View Report/Review for a particular assignment. 5. Displays a list of reviews submitted by students. 6. Click on any review in ""team reviewed"" column for a particular student. 7. Displays the summary of reviews submitted by that student, with a ""Make as sample"" button on the right of every review. 8. Click on ""Make as sample"" for the intended reviews, which opens a popup that displays a list of all assignments that are a part of the instructor's courses. 9. From this list select all assignments for which the review has to be shown as a sample. 10. Click on 'Submit' after selection (this closes the popup). 11. Navigate to view reviews of that particular assignment and click on ""Sample Reviews"". 12. A new page is opened that lists out all the sample reviews of the assignment. As a Power User (TA/Instructor/Admin/Super Admin) (Scenario 2) 1. Log in 2. Click on Manage->Assignments 3. Displays a list of Assignments 4. Click Edit for a particular assignment. 5. Click on the review tab. 6. Select an assignment from the dropdown 7. Select a reviewer from the second dropdown. 8. Select a reviewee from the third dropdown. 9. Click 'Add' button to add the selected review to be shown as a sample for this assignment. 10. Add as many sample reviews as you want in the same way. As a Student (Scenario 1) 1. Log in. 2. Click on Assignments 3. List of assignments is displayed. 4. Click on any assignment for which the review has to be submitted. 5. Assignment task page is displayed. 6. Click on ""Other's work"" to open the reviews summary page (at /student_review). 7. Below the heading ""Reviews for ..."", click on the ""Show sample reviews"" link. 8. This opens a page where the student can view all sample reviews for that assignment. As a Student (Scenario 2) 1. Log in. 2. Click on Assignments 3. List of assignments is displayed. 4. Click on any assignment for which the review has to be submitted. 5. Assignment task page is displayed. 6. Click on ""Other's work"" to open the reviews summary page (at /student_review). 7. Chose to review any of the teams' assignments that are displayed. 8. Select a team for review and fill in the review. 9. Before submitting the review, select the checkbox that says ""I agree to share this review anonymously as an example to the entire class"". 10. After clicking on the submit button, the review submitted has been made public. Students are able to toggle between private and public visibility of their review. <image> <image> The screenshot below shows a button next to every review which gives an option Mark as Sample . This access will be given to instructors. <image> Once the review is marked as sample, the instructor will be given an option to Remove as Sample . <image> The instructor is able to select a review to be shown as sample by selecting from assignment, reviewer, reviewee dropdowns. <image> Students are able to see the sample review for an assignment. <image>. <link> <link>. <link> <link> <link>.","For design doc: This is a very good description of the changes to be made, and the rationale for making them.  But it has not been updated to reflect how the code was actually written, and that is one of the most important needs for programmers who follow on later.This is a very good description of the changes to be made, and the rationale for making them.  But it has not been updated to reflect how the code was actually written, and that is one of the most important needs for programmers who follow on later.","I appreciate the thoroughness of your assignment and the effort you put into describing your project design and implementation process. Your clear description of the problem analysis and your approach to solve it shows a good understanding of the subject matter.  

You demonstrated excellent organization skill and detailed planning, outlining the functionality, execution steps, and possible user scenarios. Your segmentation of the review process, like allowing students to choose their review status and offering the ability for TAs/Instructors to select which reviews can be displayed as samples, adds a flexible element that should enhance user experience with the system.

However, there are multiple portions of this assignment that include placeholders for images or links (“<image>” or “<link>”), which makes it difficult to visualise what you are trying to describe in these sections. In future assignments, please ensure that you replace these placeholders with the intended images or links to provide a more complete view of your work.

Similarly, the use of enumeration seems to be a bit off in some places; for example, references to ""1)"" are overused and make it difficult to follow your thought progression. Adjusting this can make your explanation smoother for the reader. 

I understand that you decided to use the Delegation pattern in this project and would appreciate it if you could provide a deeper explanation of why it was chosen over competing patterns and how specifically it was applied in this assignment. 

Overall, you have submitted an in-depth, solid submission that could be improved with the completion of your placeholders and some adjustments in your numbering for clarity. You’ve demonstrated a good understanding of the topic, keep up the hard work!"
311,E1966,"Expertiza is a open source project currently for CSC517 instructor and students forming groups, submit work, review, and view grades. The project is based on Ruby on Rails framework and the code is on Github: <link> . Expertiza serves wiki page, collecting information of all internal information and updates of all versions. 1) On student end, Expertiza uses grades/_reviews.html.erb partial file to display reviewers, scores and review details; on instructor end, it uses Response model methods to construct html file for review pages. We need to use the same kinds of partials in instructor-end and student-end. How to get the view of reviewers, scores and review details on student end? Click ""Alternate View"" button, and click ""show reviews"" link. The reviewers and scores pop up on the top and review details are below them. How to get the view of reviewers, scores and review details on instructor end? Click ""Scores"" for a certain assignment and choose a team. Click ""Statistics"" tab and then reviewers and scores table show up. Click ""Reviews"" tab and then click one of students' name link in the table head. And a new page pops up with review details. 2) Give Feedback link at view_my_score at student-end should not appear at folded view. Where to find Give Feedback link? On student end, click ""Alternate View"" button and click ""show reviews"" link. At the bottom of a certain review, a give feedback link shows up. 1) We need to use the same kinds of partials in instructor-end and student-end. So we decide to use grades/_team_statistics.html.erb to display reviewers and scores and to use grades/_tabbed_reviews.html.erb to display review details for both student-end and instructor-end. 2) Give Feedback link at view_my_score should appear at the bottom of expanded view. For student end, split reviews.html.erb into two partial files. One is grades/team_review_statistics.html.erb for reviewers and scores. The other one is grades/tabbed_reviews.html.erb for review details. For instructor end, it used to use response model methods to construct html files for review details, now we use grades/tabbed_reviews.html.erb to display review details. So student end and instructor end both use grades/team_review_statistics and grades/tabbed_reviews to display reviewers, scores and review details. <link>. 1. In student end, render grades/team_review_statistics and grades/tabbed_reviews two partial files instead of grades/reviews partial file. app/views/grades/_participant.html.erb <code> 1. Add statistics view to student end by using the team_review_statistics.html.erb file. app/views/grades/_participant.html.erb <code> app/views/grades/_team_review_statistics.html.erb <code> <image> <image> 1. Add feed back link in student end view. app/views/grades/_tabbed_reviews.html.erb <code> <image> 1. Add javascript to tabbed review so it can be hidden or shown by clicking the show/hide reviews. app/views/grades/_tabbed_reviews.html.erb <code>. 1. Create new method view_instructor for response_controller app/controllers/response_controller.rb <code> 1. change the url jumping to after clicking to a certain reviewer. app/views/grades/_view_heatgrid.html.erb <code> 1. render grades/tabbed_reviews for review details at instructor end app/views/response/view.html.erb <code> 1. show right round according to which round user click at instructor-end app/views/grades/_tabbed_reviews.html.erb <code> 1. Create construct_instructor_htm_helper in respond model in order to not show review number app/views/grades/_tabbed_reviews.html.erb <code> app/models/response.rb <code> 1. Show just one review in instructor-end app/views/grades/_tabbed_reviews.html.erb <code> <image>. 1. The rspec test plan is written such that each requirement(for student-end and instructor-end) will have at least 1 different test. 2. The test plan is also used as a check of bug fix implementation. It ensures that each required function is implemented and each bug is well fixed. 3. The test file can be manually executed the by running ""rspec ./spec/features/tabbed_reviews_spec.rb"" on rails terminal. 4. Use Unit test to test all the codes mentioned above with respect to views, models and controllers. 1. tabbed_review_spec.rb created and added 3 test cases for alternate view of reviews spec/features/tabbed_review_spec.rb <code>. 1. <link> 2. <link> 3. <link> 4. <link>.","In the ""What to do"" section, it is not clear whether the two partials you name are new partials.
It is also not clear whether more or less code is being duplicated than in the current system.
It is not clear how the two different partials are used.  How do they interact?
I also find the ""Student end"" section confusing. For example, what is in the ""statistics view""?
When you give a code snippet and say that it does something, you should point out the changes made to accomplish them.  Github diff view would be good for this.  In the current document, I'm left with just the code, and I need to try to figure out what it does and how you changed it.
To summarize, too much code is shown with too little explanation.
","Dear Student,

You've provided an extensive analysis of the Expertiza open source project and detailed the steps to manipulate the student and instructor ends. I appreciate the depth of your review, your understanding of the assignment's complexities and the practical implications of your suggestions.

However, there are a few areas that need improvement:

1) Clarity: The assignment is extensive and requires a lot of understanding to follow along. You should strive to make your explanations clearer and easier to follow for those not well versed in this topic.

2) Organization: At times, it was challenging to determine whether you were discussing an existing feature or proposing a new one. More explicit topic sentences at the beginning of each idea would be helpful.

3) Referencing: While you've included some code snippets and links to other resources, any actual code needs to be properly annotated for ease of understanding.

4) Proofreading: There are some grammar errors and punctuation issues throughout the document. A careful reading could make your assignment more refined and professional.

In your future assignments, I encourage you to provide more context about your thought process and also organize your work more effectively. This will help your readers understand and appreciate your contributions better. 

Keep up the good work!"
312,E2069,"The suggestions_controller.rb of Expertiza is involved in creating/editing suggestions topic suggestions for a project and involved approvals. Students can submit suggestions and work on them if approved. We intend to improve the readability and code quality of the suggestions_controller.rb. Since this controller has methods that must actually be done by other classes (owing to Single Responsibility feature of the SOLID principles), we have realized the need to move these methods to their respective classes. 1. Move the method create_new_team (on line 94) to a more appropriate class. (Ex: Team.rb or AssignmentTeam.rb ) 2. Move the method approve to SignupTopic.rb , since it is modifying fields belonging to SignupTopic directly. 3. There are two methods named similarly: approve and approve_suggestion . Their functionality is not clear at first glance. Rename them so that they more accurately reflect their purpose. Add appropriate comments. 4. Move the send_email method to the Mailer class in app/mailers/mailer.rb . 5. In views/suggestion/show.html.erb and views/suggestion/student_view.html.erb , there seems to be a DRY violation which needs to be fixed. Merge both files into a single view file in order to fix the DRY problem. 1. app/controllers/teams_controllers.rb 2. app/models/sign_up_topic.rb 3. app/mailers/mailer.rb 4. views/suggestion/show.html.erb. Issue : Move the method create_new_team to a more appropriate class. This method was moved to assignment_team.rb since it is appropriate. <image> We pass the required variables inside the scope of this function as method parameters. Then we call the new method as a method of the AssignmentTeam class. <image> Issue : Move portion of the method approve to SignupTopic.rb , since it is modifying fields belonging to SignupTopic directly. <image> First, we moved everything in the approve method from suggestion_controller having to do with a sign up topic to its own new method in sign_up_topic.rb now called new_topic_from_suggestion . In doing so, we also delete the entire approve method from suggestion_controller , since refactoring for that method happens concurrently as a result of another issue in this project. Issue :There are two methods named similarly: approve and approve_suggestion . Their functionality is not clear at first glance. Rename them so that they more accurately reflect their purpose. Add appropriate comments. <image> Here, we changed the name of approve_suggestion to approve_suggestion_and_notify , since it really seems like this method is both to handle approving a suggestion as well as calling the notification method from elsewhere in the controller class. We also add in the first part of the original ""approve"" method here, so that we can set the instance variables that suggestion_controller might need ( @user_id, @team_id, and @topic_id ) as well as calling our newly created new_topic_from_suggestion method in SignUpTopic with the proper suggestion passed as a parameter. Issue : Move the send_email method to the Mailer class. This method was moved to the Mailer.rb file which seems to have many built-in functionalities for mail services. <image> Next, the required variables for this method were passed as parameters from suggestion_controller and is called as a method of Mailer class <image> Issue : Merge app/views/suggestion/show.html.erb and app/views/suggestion/student_view.html.erb into one view. Modify student_view method in suggestion controller to provide @current_role_name and render show template. <image> Migrate code from student_view.html.erb to show.html.erb and wrap in an if statement that will display view only if user role is a student. <image> Move the rest of the remaining code from the original show template to the else block. <image> Delete the student_view.html.erb file since all of it's contents are contained within the show.html.erb file. <image>. Since only the code style/process was changed, the expected functionality before and after, will be the same. Student should be able to create a suggestion for an assignment, just like before. 1. Log in as an instructor. 1. Login with username instructor6 and password password . <image> 2. Create a new assignment. 1. Click the Assignments link. <image> 1. Click the + icon. <image> 3. Fill in the following fields in the ' General' tab. 1. Provide Assignment name . 2. Check the Has Teams checkbox and set maximum number of members to greater than or equal to 1. 3. Click the Create button. <image> 1. Page will reload and have an additional checkbox, Has topics? . Check it off and click the Save button. <image> 4. Make the following selections in the Topics tab. <image> 5. Assign this assignment to a student belonging to this instructor 1. Select Add participant link within the Other stuff tab. This will bring you to a new page. <image> 1. Find student of interest (we recommend using student1876 ). Select Add button. <image> 1. You should receive confirmation of successfully adding the student to the assignment. <image> 6. Impersonate the assigned student. 1. Select from the Manage dropdown menu Impersonate User . <image> 1. Fill in field with student username and select Impersonate button. <image> 7. Let the student view this assignment (may need to register too) 1. Select the created assignment from the table seen at the bottom of the page. <image> 1. Select Suggest a topic link. <image> 1. Create new suggestion, provide a title, description, and click the Submit button. <image> 1. Select View link for the suggestion created. <image> 1. This will bring the following page (information previously provided by student_view.html.erb). <image> 1. The corresponding page for an instructor would appear as such. <image> Please refer to our short videos to get more context on what was done. 1. Here is our first <link> demonstrating the same functionality is maintained after refactoring. This video demonstrates a suggestion being approved. 1. Here is our other <link> demonstrating the ability to reject a suggestion. NOTE TO TA: Our Travis CI build failed because of an error in Travis's config settings (bundle exec danger --verbose). Hence, we have included this video as a proof of our working logic and testing. The demonstration shown in the above section is how we tested the functionality and behavior of our changes. The spec tests below will test that the moved methods work independently. This test ensures the working of the mailer method for approved suggestions <image> This test ensures the working of the team creation method <image>. 1. <link> 2. <link>.","Very good description of changes, and appropriate code snippets are shown.  Manual testing is shown with annotated screenshots, which are very useful.  In an Rspec test, sending email to an actual person's address is not a good practice.","Dear Student,

Thank you for your detailed work on improving the code quality in suggestions_controller.rb for the Expertiza project. Your effort in addressing each of the identified issues is commendable.

1. I appreciate that you have successfully identified and moved the appropriate methods to the correct classes, honoring the Single Responsibility Principle of SOLID.

2. Renaming the ambiguous methods 'approve' and 'approve_suggestion' to more descriptive names enhances code readability, which aligns nicely with the essence of your assignment. Good job on that!

3. Your efforts to modify and consolidate the 'show' and 'student_view' into one view to avoid DRY violations speaks to your understanding of the principles of clean and effective code. However, make sure that the functionality and readability, especially for the users, are not compromised.

4. It seems you have encountered a problem with your Travis CI build. While this is unfortunate, I appreciate your transparency and the additional effort you put into creating videos to demonstrate the functionality of your work.

5. Your tests seem robust, and it is good to see you taking the time to ensure that the moved methods work independently following the refactor.

A few areas of improvement:

1. While moving methods to different classes, were you able to confirm if any change led to a decrease in test coverage? 

2. Also, it might be beneficial to explore why your Travis CI build failed and how to address it, even when there's an issue not directly related to your code changes. This would be a good practice for real-world software engineering.

3. Always ensure that the images and links mentioned in your assignment are correctly placed and functional. They seem to be missing in your text.

Overall, you've done a great job applying good coding practices to a real-world project, and I'm sure these changes will greatly improve the clarity and maintainability of the code. Keep up the high-quality work!

Best regards,
[Your Name]"
313,E1727,"This project was completed as part of a greater open source project called Expertiza. Expertiza is a web application platform, similar to wikipedia, which offers teachers and students a way to organize for group assignments and porjects. By using Expertiza, students have the ability to submit and coordinate peer-review learning objects (articles, code, web sites, etc). The Expertiza project is supported by the National Science Foundation. Expertiza offers several features which are useful to a classroom-style learning environment. Among those several features, this project represents a contribution to the organization of the code used for assignment signup sheets. The work for this project was completed by a group of three students from NC State. However, the project was completed according to guidelines provided by a coordinator who works with Expertiza. Following the guidelines provided, the group worked to clean up a portion of the Expertiza project code through refactorization and reorganization. More specifically, logical code needed to be separated from portions of the project which were not responsible for containing code for the functionality of the application. The motivation for this project was to make the project code easier for programmers to read by compartmentalizing portions of the code to separate locations in the project according to the functionality of the code. The scope of this project was limited to functionalities associated with the signup sheet. This meant that logical code that was embedded in ""view"" (a folder containing html formatting and design code) should be moved to a more appropriate location, the ""helpers"" folder (this folder contains compartmentalized auxiliary functions that ""help"" with other parts of the project). <code> 1. Move javascript code to assets (folder): There was some javascript at the bottom of the file _add_signup_topics.html.erb. This was moved to a new file app/assets/javascripts/signup.js. The functions were modified to pass in the number of teams that needed to be toggled (since it is now in a separate file without access to that information). The javascript from the file _due_dates.html.erb was also moved to the new signup.js file. This functionality can be tested by logging in as an instructor, making sure you are managing assignments, then click the ""Edit"" button of an assignment (the little pencil icon on the right), then choose the ""Topic"" tab. If you click ""Hide all teams"" link, all team names and team member unity ids will be hidden. Click the link again and the content will be shown. If you click individual top names, it should hide/show only one team's info. <code> 1. Move logical code to helper file and assign self-explanatory method names. <code> 1. Move logical code to helper file and assign self-explanatory method names. Testing: 1. Create a test file named sign_up_sheet_helper_spec.rb in spec/helpers 2. Write test cases for all methods in sign_up_sheet_helper.rb using factories. 1. sign_up_sheet_helper.rb 2. sign_up_sheet_helper_spec.rb. <code>. <code>. <code>. <code>. <code>. <code>. Implemented positive and negative test cases for all the methods in sign_up_sheet_helper.rb. We have hosted our forked repo so you can review our changes here: <link> Suggested login for Instructor privileges is 'instructor6' with password 'password'. To login as a student, you can use 'student5000' with password 'password'. This functionality can be tested by logging in as an instructor, make sure you are managing assignments, then click the ""Edit"" button of an assignment (the little pencil icon on the right), then choose the ""Topic"" tab. If you click ""Hide all teams"" link, all team names and team member unity ids will be hidden. Click the link again and the content will be shown. If you click individual top names, it should hide/show only one team's info. There is no change in the expected behaviour. 1. get_suggested_topics : Retrieve list of topics suggested by signed in user for an assignment. 2. get_intelligent_topic_row : Render Intelligent Row in bidding based topic selection. 3. get_topic_bg_color : Render background color for row based on signed in user and status of the topic. 4. render_participant_info : Render Participant Info based on topic, assignment and participants. Unit tests were required per the project assignment for helper methods which previously had no associated unit tests. These tests verified that each discrete method returned the proper values. The tests were written using RSpec/FactoryGirl and are listed above. A summary of the test cases is shown below. <table>. 1. Navigate to the expertiza home folder 2. Run `rspec spec/helpers/sign_up_sheet_helper_spec.rb`.",The introduction does not give a good picture of what the project is about.  It should describe a signup sheet and state why it is important to get complicated logic out of the main view file.  It would be very useful to show the changes (e.g. using a Github diff).  Good test plan.  ,"Dear Student,

Thank you for your submission. The report provided contains sufficient details regarding the project, the steps taken, the changes applied to the initial source code and the results achieved. Also, the explanation on how the new functionality can be tested was thorough and clear.

However, there are some areas where you can improve:

1. You've mentioned ""logical code needed to be separated from portions of the project"" but didn't elaborate explicitly what code was restructured. Please give some examples of the code that was moved or restructured.

2. There are numerous occurrences of the `<code>` tag towards the end of your submission, but they do not seem to enclose any specific code. Please revise and ensure that if you're using these tags, they are applied correctly. 

3. Provide a more detailed analysis of the test cases and their outcomes. Instead of simply stating ""a summary of the test cases is shown below"", actually provide a summary of those test cases and their results.

4. The login credentials for accessing the hosted repo should be provided more securely. Never provide passwords in plaintext, especially in a public setting. Please be aware of data security and privacy issues.

5. While you've made a good case for the necessity of this refactorization project and you've explained the modifications done, providing some evidence of the impact of your changes on code readability or usability would strengthen your presentation further.

Overall, notwithstanding these few points that need attention, your work on this project shows dedication and a good understanding of the topic. Good job and keep it up!

Best Regards,
[Instructor's Name]"
314,E1772,"<link> is a peer review based system which provides incremental learning from the class. This project has been developed together by faculty and students using <link> framework. Expertiza allows the instructor to create, edit and delete assignments, create new assignment topics, assign them to a particular class or selected students, have students work on teams and then review each other's assignments at the end. For the students, they can signup for topics, form teams, and submit their projects and assignments. Students then review the work done by other students and give suggestions to improve. Teams after reviews are allotted scores and they can refer to the peer comments to further improve their work. It also supports submission of different file types for assignments, including the URLs and wiki pages. Online peer-review systems are now in common use in higher education. They free the instructor and course staff from having to provide personally all the feedback that students receive on their work. However, if we want to assure that all students receive competent feedback, or even use peer assigned grades, we need a way to judge which peer reviewers are most credible. The solution is the reputation system. Reputation systems have been deployed as web services, peer-review researchers will be able to use them to calculate scores on assignments, both past and present (past data can be used to tune the algorithms). For this project, our team's job is to refactor the file: reputation_web_service_controller.rb. This file is the controller to calculate the reputation scores. A “reputation” measures how close a reviewer’s scores are to other reviewers scores. This controller is the sub-class of Application_Controller, in this controller, it implements the calculation and query of reputation scores. Reputation_web_service_controller.rb is a fairly complex file. It contains a lot of methods that are long and hard to understand. These methods need to be broken down into simpler and more specific methods that are easier to read/understand. Also, the few instances of code duplication that exist should be removed. 1. Replace class variable with a class instance var, and change all other places using these variables. 2. Refactor method db_query 3. Use zero? method instead of == 0 4. Use find_by instead of dynamic method 5. Delete lines which is wrong or useless. 6. Comment lines. reputation_web_service_controller.rb. reputation_web_service_controller_spec.rb. <link> <link> <link>. In ruby, class variables are started with '@@'and this class variable are shared in the whole inherit chain, and class variables are shared by all objects of a class. For instance variables, in Ruby, instance variables are started with '@' and instance variables belong to one object, can not be used by sub-classes. In the project, we are asked to replace the class variable with a class instance variables. So, as the figure 1 shown, in variables declaration part, we changed all class variables to instance variables. <image> Next, we need to change all other places using these variables. In action send_post_request <image> <image> <image> <image> <image>. In the Reputation_web_service controller, the action db_query is important, because it implements the query of peer review grade.To refactor the db_query method, we need to firstly focus on the input variables of this method, there are 4 variables need inputs. The db_query method is shown as follow: <code> There is a problem: Optional arguments should appear at the end of the argument list, in this method, another_assignment_id is a optional arguments, but in the original version, the optional arguments -- another_assignment_id just appear right behind the argument-- assignment_id , so we need to refactor it. <image> And the same problems occurs when we assigns value to variable @results . We also need to change it. <image> There is another problem in the db_query method, we can see there is a input variable named hasTopic , but actually that's not follow the ""good Ruby and Rails coding practices"" , so we need to refactor it which shown as follow: <image> Finally, The project asked us 'Move Line 26-50 before this method' , it's important for code refactor, because it's very inelegant if you put the comments inside the method. If others want to read your codes, it will cost their much more time so that it needs to be changed. Simply, we can just move the whole comments before the method, and that will make the codes easily for reading. <image>. In the original version of project, every time there is a zero judgement occurs, it use ' ==0' or ' !=0' , of course it can achieve the judgement of zero, but according to the security consideration in ruby on rails development, we need to avoid the use of ' ==0' or ' !=0' . So the best way to solve it is using the zero? instead of ' ==0' or ' !=0' , which shown as follow: <image> <image>. This issue is replacing the find_by_id to find_by(id: id). The only difference of this change is syntax and their function worked in the same way. But if the customer want to change the way to find assignment, find_by(id: id) would be easier to change because programmer only need to change the parameter, while find_by_id need to change the whole method and its parameter. Therefore, in this project, using find_by_id is more efficient. <image> <image>. In Line 111, the variable inner_msg has never been used, so it can be deleted <image> From line 164 to 201 and line 204 to 241, cases for reputation value and do not need to handle the case for assign id. req body would change only in the case for 'Add expert grades'. If these two part failed to be deleted, the body would append three times and output wrong result. <image> <image>. The function for controller is not for output but just control and update the change of view. So puts should not appear in controller <image> <image>. Our test plan is to test if db_query(assignment_id, round_num, has_topic, another_assignment_id = 0)(in line 51), db_query_with_quiz_score(assignment_id, another_assignment_id = 0)(int line 82), json_generator(assignment_id, another_assignment_id = 0, round_num = 2, type = 'peer review grades')(in line 101) work in the right way. These are in controller/reputation_web_service_controller.rb <code> The above codes is to test if get query can parse id and some other variables and return the correct review grade. Our test make sure the review grade are array and array contains data which is not null. <code> The above code is to test if we can query quiz score by given assignment id and another assignment id and return correct quiz score array. Our test make sure that the the result is array and not a null array But when we try to test json_generator(assignment_id, another_assignment_id = 0, round_num = 2, type = 'peer review grades'). There is a wrong report which is no method. the line 106 that is no method is: @results = db_query(assignment.id, round_num, has_topic, another_assignment_id) And the report is that: <image> Because this method can't be called for some reason and this is not the part that we need to refactor, we can't test this part.","Very good job of describing chages that were made.  Reasonable job of describing test plan, though more detail would have been useful.  I didn't understand, "" it's important for code refactor, because it's very inelegant if you put the comments inside the method. If others want to read your codes, it will cost their much more time so that it needs to be changed.""","First of all, good work on detailing your process of refactoring the file and providing snapshots and examples at each step. Your explanation on why certain changes were made is insightful and shows a good understanding of code refactoring principles, as well as Ruby and Rails coding practices. Your attention to detail when explaining each task is commendable. 

I particularly appreciate the careful thought given to readability and the elimination of redundant codes. Your focus on clarifying variable and method names, repositioning code comments, and using native ruby methods like zero? and find_by is aligned with good coding practices. 

However, there are a few areas that need further attention. There seem to be some inconsistencies in your description. For instance, you have mentioned that using find_by_id is more efficient than find_by(id: id) but the changes suggested in your images indicate the opposite. Also, your explanation about replacing class variables with instance variables lacks depth. A clearer reasoning behind the choice would help readers understand this decision better.

For the testing section, your approach is sound, but keep in mind that the tests should cover all aspects of the functionality. The error you encountered while testing json_generator indicates that there might be a problem in either the method implementation or the test itself. Even if it is not part of the refactoring, it could potentially affect the functionality of the program.

Finally, your write-up lacks a conclusion or summary of the work accomplished, challenges faced, knowledge gained, or any future improvements. This would provide a comprehensive view of your project.

Overall, there are some minor areas for improvement but your attention to best practices and code enhancement is impressive and I encourage you to keep up the good work."
315,E1650,"The purpose of given topic is to sort the Instructor views on the basis of Reviewer's Last Name (by default) without refreshing the existing page. Current Model: 1. Currently Instructor can view the Reports in non-decreasing order, sorted on the value of an 'Average Overall Volume' for the Reviewer. However, instructor does not have any option to sort the list manually. 2. Hence, we are adding a functionality to instructor's view of reviewers' list that can sort the list as per his/her choice. 1. Functional Requirement: Instructor should be able to sort the Reports according to the Reviewer's Last Name in either descending or ascending order. 1. Solution approach: We are using a JavaScript library <link> for sorting the elements in the instructor view's table. TableSorter provides support for both kinds of ordering - ascending or descending. Implementation of sorting algorithm for Instructor views using <link> . TableSorter is a <link> plugin for turning a standard <link> table with table-head and table-body tags into a sortable table without reloading the existing page. TableSorter can parse and sort many data types linked with the table column. To integrate the table sorter into any view two things are needed: i) Include a gem in Gemfile <code> ii) Including jQuery-tablesorter in app/assets/javascripts/application.js <code> The above code loads only the core-widgets. TableSorter is applied to the table which needs to be sorted. For example, in the below code table sorter is applied to the ""myTable"" id. 1. Added in _review_report.html.erb <code>. 1. Added in _review_report.html.erb Custom parser script is created to sort the table according to 'Average overall volume'. It accepts an input that contains a string with a numeric value (percentage) and the table should be sorted on the basis of that. It firsts splits and tokenize the data according to space and return required value which is passed to tablesorter function. <code>. Kindly follow the steps below: 1. Go to <link> to access expertiza 2. Login credentials- Username: instructor6 Password: password 3. Go to 'Assignments' tab > From any assignment, select 'view review report' option (it is next to 'star' option) 4. Now, you must be viewing some list with students name (currently, all the users have name as 'some_number,student') 5. In the column heading 'Reviewer', there is sorting arrow, click on it to sort the list. 6. Similar sorting is implemented on 'Metrics' header 7. If you want to try the functionality on the students with alphabetical name, add student from 'Assignments' > 'Add Participants', and then test it We have added styles on column-headers (as arrows) to show the sorted order: ascending, descending or unsorted. 1. Added in _review_report.html.erb <code>. Below is the screenshot for the above given style: <image>. 1. <link>.","Wiki is well written. It's clear and to the point. I would expect there'd be a comparisson of several libraries on the solution approach, their pro and cons e.g., easiness to program, performance etc. ","Thank you for providing a comprehensive review of your assignment. You've evidently made an effort to add new functionality to the instructor's view of the reviewers' list. Your descriptions are effectively detailed, particularly your solution approach and the steps for implementing it.

However, for future assignments, here are a number of suggestions that could make your work even better:

1. Be mindful of your numbering, particularly in the sections ""Functional Requirement,"" ""Solution approach,"" and ""Added in _review_report.html.erb."" The numbering all start at 1 which can confuse the reader.

2. It would help to define what 'Average Overall Volume' refers to. A brief explanation of this term would allow your reader to fully understand the sorting principle.

3. You can add brief descriptions to your <code> tags to help the reader understand the purpose of the code. This makes your solution more understandable for those without a deep understanding of the code.

4. Lastly, as you've mentioned using screenshots for a clearer explanation, please ensure that the image or link provided is functioning. This way, the reader can significantly benefit from the visual aid. This suggestion also applies to the broken <link> tags in your submission.

Overall, this is a well-done assignment containing thoughtful implementation and an evident understanding of javascript functionalities. Good job! Keep it up and consider these suggestions for your next assignment."
316,E1720,"For testing the changes made, the following credentials are recommended: 1. Instructor Login: username: instructor6 password: password The above user is suggested for testing because is is unlike to run into issues that are unrelated to our work. This project does compile. Reviewers will need to perform ""rake db:migrate"" as we've added a database table to support notifications. The testing plan is at the end of this document. There were also specs added; however, they are in the Git repository. Design principles were not needed since we mostly modified existing work. However, issue #702 is using the Factory Method design pattern, and our work added content to the existing pattern. Expertiza is a web portal which can be used to manage assignments related to a course. It provides a platform to view assignments, manage teams, select topics and work improvement through anonymous peer reviews. For the instructor it provides complete control to create assignments, view reviews submitted and provide feedback. The instructors also have an option to publish the students work based on the rights provided by the student. The following were the tasks identified to be accomplish through this project. 1. Issue #702: Add another institution_id to course table and The Create Course page needs to be fixed to tell the creator to specify the institution (course/_course.html.erb). 2. Issue #316: Remove ""Actions"" column on signup sheet in a completed assignment (sign_up_sheet/list.html.erb). 3. Issue #295: Add a confirmation on deleting an assignment on the admin screen (tree_display/actions/_shared_actions.html.rb). 4. Issue #256: Add a one-time notification at the top of the page which links to an article on the details of the change (it might make sense to put a javascript module in the site_controllers/index.html.rb and let other pages call this). The following files were modified for this project. 1. app/assets/javascripts/tree_display.jsx 2. app/controllers/auth_controller.rb 3. app/controllers/course_controller.rb 4. app/controllers/tree_display_controller.rb 5. app/models/assignment_node.rb 6. app/models/course.rb 7. app/models/course_node.rb 8. app/models/institution.rb 9. app/views/course/_course.html.erb 10. app/views/layouts/application.html.erb 11. app/views/notifications/index.html.erb 12. app/views/shared/_flash_notifications.html.erb 13. app/view/sign_up_sheet/_table_line.html.erb 14. app/views/tree_display/list.html.erb 15. app/views/tree_display/confirm.html.erb 16. app/views/tree_display/new.html.erb 17. app/views/tree_display/edit.html.erb 1. database table ""notification"". This task was pretty involved and called for integrating an institution_id into the course table and updating the Course pages to specify the institution. We modified several parts of the program in order to accomplish this task. On the controller app/controllers/course_controller we edited the update definition and the create definition to store the institution_id into the course table. <code> On the model app/models/course.rb we created a relationship where course belongs to institution. This is to allow the linkage of the two tables and allow the drop down to work in the view. <code> On the model app/models/institution.rb we also created the relationship where institution has many courses. This is also to allow linkage of the two tables for the drop down to work in the view. <code> On the view app/views/course/_course.html.erb we added the collection box to display the linked name from the institution table to the institution_id in the course table. This completed the ability to select and store the institution_id into the database. <code> In order to properly display the institution_id associated with the courses on the view app/views/tree_display/list.html.erb it was necessary to understand the Factory Method design pattern. A subclass of app/models/node.rb is app/models/course_node.rb and app/models/assigment_node.rb . Both need similar functions to be used by app/assets/javascripts/tree_display.jsx for displaying rows of courses and assignments. This was added to both, but only used by app/models/course_node.rb : <code> app/controllers/tree_display_controller.rb was modified to include a local variable for used by the view in displaying the institution_id. <code> app/assets/javascript/tree_display.jsx was also modified to show different rows between courses and assignments, since only courses were required to show the institution_id. This was added in order to show the institution_id which is displayed on app/views/tree_display/list.html.erb : <code>. This task called for removing the 'Actions' column on the signup sheet for assignments that have been completed (sign_up_sheet/list.html.erb). (sign_up_sheet/list.html.erb) renders app/view/sign_up_sheet/_table_line.html.erb and an if statement is used to not show finished assignements. <code>. This task called for adding a confirmation when deleting an assignment on the admin screen. While the instructions indicated (app/views/tree_display/actions/_shared_actions.html.rb), this file is no longer in use in the project. In fact, all assignments and courses on (app/views/tree_display/list.html.erb) are displayed by (app/assets/javascripts/tree_display.jsx) and handled in JavaScript. Moreover, the normal confirmation actions are overridden by (app/assets/javascript/userDeleteConfirmBox.js). The overridden confirmation actions were not compatible with the JavaScript deletion link. We overcame this issue by creating a new view (app/views/tree_display/confirm.html.erb), and redirecting the deletion link to the view for confirmation. We passed the nodeType (assignment or course) and id of the node to be deleted in the URL to be stored by the controller as local variables for use on the confirmation view. The selected assignment (or course) is deleted only after confirmed as per the requirement. The part of the code that redirected deletions for assignments or courses to the confirmation page is in ' app/assets/javascripts/tree_display.jsx' . (Item in bold was modified) <code> Original code (Delete link without confirmation.) <code> Definition added to ' app/controllers/tree_display_controller.rb' for business logic. <code> Here we see that the code inside of the new view ' app/views/tree_display/confirm.html.erb' . <code>. This task called for adding a one-time notification at the top of the page to show changes/notifications. It necessitated adding a table to the database called notifications. Therefore, when conducting peer reviews, a migration must be performed to add the new table. Then we used scaffolding to add notifications (controller, model, and views). Next we added a link on the view (app/view/tree_display/index.html.erb) to go to the view (app/view/notification/index.html.erb) in order to manage notifications. A migration to create a notifications table was added. <code> Using scaffolding, a new index was added app/view/notifications/index.html.erb . <code> Added link on page for managers to manage notifications app/view/tree_display/list.html.erb . <code> Notifications are added and modified in similar views app/view/tree_display/new.html.erb or app/view/tree_display/edit.html.erb . <code> When any type of user successfully logs in, flash notifications called from the controller app/controllers/auth_controller.rb . <code> Flash notifications are displayed once at login due to a line in the view app/view/layouts/application.html.erb which is used by all other views. <code> Each individual flash notification that is active and is not expired is displayed through the use of the view app/view/shared/_flash_notifications.html.erb . <code> The notifications are displayed on whatever page the login screen goes to first depending of the type of user logging into the system. They are only display once and are gone whenever the page is refreshed or changed. <image>. The majority of the changes can be tested via the UI. Follow the instructions below to check the tasks: 1. Issue #702: Add another institution_id to course table and The Create Course page needs to be fixed to tell the creator to specify the institution (course/_course.html.erb). 1. Login as an instructor. It will automatically go to the manage courses page. 2. Click the ""New Public Course"" or ""New Private Course"" button. 3. You will notice a drop down for institutions is available. 4. Create a new course, and the UI will automatically return to the list which displays the courses. You will see the institution listed. 5. Click on the edit button and you will be able to modify the institution for the course. 1. Issue #316: Remove ""Actions"" column on signup sheet in a completed assignment (sign_up_sheet/list.html.erb). 1. Log in as any user or instructor. 2. Go to the assignments list. Note: this is not the manage assignments for instructors. 3. Click into a finished assignment. You will notice the actions column is gone. 4. Click into a current assignment. You will notice the actions column appears. 1. Issue #295: Add a confirmation on deleting an assignment on the admin screen (tree_display/actions/_shared_actions.html.rb). 1. Login as an instructor. It will automatically go to the manage courses page. 2. Click the Assignments link to switch the view from courses to assignments. 3. Add a new assignment. 4. Click the delete button for an assignment. Note: please add an assignment first. Most of the current assignments have dependencies that prevent them from being deleted... this is not an error. 5. The UI will be directed to a page to confirm the deletion. Select ""Yes"" if you wish to delete the assignment. 1. Issue #256: Add a one-time notification at the top of the page which links to an article on the details of the change (it might make sense to put a javascript module in the site_controllers/index.html.rb and let other pages call this). 1. Login as an instructor. It will automatically go to the manage courses page. 2. Click on the ""Manage Notifications"" link above the ""Courses"" and ""Assignments"" links. Note: The link was placed here because the system has numerous issues when adding menu items. It would require us to do more work that the entirety of this project to correct the menu additions in the superuser menu. 3. You will be directed to a creation page for notifications. Note: in order for a notification to display the expiration date must be the current date or later, and the active checkbox must be selected. 4. Log out once the notification is created. 5. Log in using any account. The notification will display on the first page the user is shown. It will disappear when they change or reload the page. Note: instructors on the management page will retain the notification if they switch between Assignments, Courses, and Questionnaires. This is because the JavaScript does not actually reload the page.","It contains info how it's implemented, what was the problem, and how they approached the solution. however, lots of it is copied pasted from the code, instead of trying to explain using UML or other diagrams. They only defined manual UI test, no rspec tests defined. It's a shame, the group should have consulted the notification design with users before it's implemented, but in the end they delivered the expected design.  ","Dear Student,

Congratulations! This is a very comprehensive project submission. It's evident that you have a deep understanding of this assignment and have done a lot of remarkable work. Let me break down some feedback for you:

1. Your description of your modifications to the codebase is detailed and precise - this really demonstrates your understanding of the task at hand. Your application of the Factory Method design pattern adds value to the project and contributes to good architectural principles.

2. I also appreciate that your project submission not only includes the tasks you completed but also the instructions for how these modifications can be tested. This greatly enhances the practicality of your project and eases the review process.

3. The interaction between various components of the application is well explained, which sets a great stage for understanding what you've achieved in the course of the project.

To help you improve going forward, here are some points to keep in mind:

1. Try to focus on a more reader-friendly composition next time. While the information is correct & thorough, the document could do with some spaces for easier absorption and a better flow.

2. Stick to one standard for styling code snippets. Sometimes you used <code>, other times you didn't. Uniformity is key in technical documents.

3. You might want to consider attaching screenshots for a few crucial steps in the testing section of your report, since visuals can support readers in understanding what they should be seeing throughout various stages of testing.

Overall, excellent work and keep it up! You've shown a high level of technical competency, and your work reflects the effort you've put into this assignment. Would love to see you maintain this thoroughness in the upcoming projects.

Best,
[Your Name]"
317,E1793.2,"For team-based assignments, it always takes time to find suitable team members. We already have bidding, which could help you to join in a team with other team members hold similar bidding preferences. However, you may not be satisfied with automated team formation and want to switch to another team. In this project, we will build a new feature to help students find teams to join. Currently, there are 2 ways to find other students to join your team: 1.If your team is not full, you could invite people by inputting his/her UnityID. It will send an invitation to certain user. If s/he accept your invitation,s/he will leave original team and join your team. 2.You could create an advisement by clicking “Your team” link and then clicking “Create” link under “Advertisement for teammates” section. Then your advertisement will appear the last column of the signup sheet page with a horn icon. In this way, all classmates could see your advisement. Someone could send a request to join your team. If you accept their request, s/he will leave original team and join in your team. It would be better for students who do not have team yet or whose team is not full yet to be able to see a list of students who don’t already have teams. So too for instructors. Fix the second way to find other students to join your team. Currently, after you create an advertisement, the horn icon does not appear in the the last column of the signup sheet. For student end: Display a list of students who do not have a team with invitation links in student_teams#view page You could invite students to your team by clicking invitation links. If s/he accept your invitation,s/he will leave original team and join in your team. It will be more straightforward than typing UnityID. For instructor end: Display a list of students who do not have team in teams#list page Write feature tests to verify your modifications: Create team_invitation_spec.rb file in spec/features folder. 1)app/views/student_teams/view.html.erb 2)app/views/join_team_requests/_list_received.erb 3)app/controllers/join_team_requests_controller.rb 4)app/models/join_team_request.rb 5)app/models/sign_up_sheet.rb 6)app/views/sign_up_sheet/_table_line.html.erb 7)app/views/sign_up_sheet/_all_actions.html.erb 8)app/views/teams/list.html.erb 9)spec/features/team_invitation_spec.rb. When someone creates an ad ,the horny icon does not appear in the the last column of the signup sheet.the code that show horny icon is below: <code> After debugging ,I found even if you create an ad before ,the if block of code will not be executed. Therefore something must be wrong with has_teammate_ads? method.Then I rewrite that method.Signupteam has an attribute:advertise_for_partner ,it will be set true after team members create an ad for their team.i return this attribute to the has_teammate_ads? method and the horny icon appears.This method code is below: <code>. I found currently when you sent join team request in the ad,the team received that request would see invite and decline button on their student teams#view page.if they are willing to add the student who send request as member ,they have to send invitation and wait for reply. This is not reasonable and convenient. what should happen is that when the student send join team request,the team members could see accept and decline button ,After they click accept button ,the student would leave his/her original team and join the new team. What I have done is that I add accept method in join team request controller.The method is below: <code> Here @invited_userid is acquired from the student who sent join team request. inviter_userid is from the team members who received the request. team_id is invited student's team id. We build a new feature to help students find teams to join. Students who do not have teams or whose team is not full are able to see a list of students who do not haven a team.The code for this issue is showed below: <code> In the code above, if @student.assignment.max_team_size > 1 we then execute the below code ,this is because our new feature is only available when assignment team size greater than 1.we use if @student.team==nil|| !@student.team.full? to allow students who have no team or whose team is not full to see this list.Next we found all participants ,we use if statement to sample those who has no team , their role are students and they won't see themselves if they do not have teams.We then put these sampled participants on the list .these achieved by the code below <code> We also need to add invitation links next to students without teams,before adding links , we need to know whether students who want to invite the students on the list have team or not .if they do not have their own teams. we will automatically create a team for them ,this mechanism is called team lazy initialization.the code for this part is below <code> Finally we just use form_tag to create invite button which is related to invitation controller and create method in it . we also display a list of students who do not have team in teams#list page for instructor.This part of code is showed below. <code>. 1)The horny icons appear in the the last column of the signup sheet. <image> <image> 2)Received request from advertisement and the changed team members after clicking accept button. <image> <image> 3)For student end ,the list of students who do not have a team with invitation links <image> 4)For instructor end ,the list of students who do not have a team. <image>. The last part of this project is to test all the modifications. And in order to test the new features we created a new Rspec file, which is spec/features/team_invitation_spec.rb. The codes below are all tests we created. Some edge cases: 1) The owner of a team can accept or decline the request sent by other students, if the team is already full, the team will remain the same even the request is accepted. <code> <code> <code> 2) In the student_team#view page, students should see a list of students who don't have teams and can be invited at present, if the invitation is declined, the team remains the same. And the invitee can only join the team when it is not full. <code> <code> <code> <code> 3) Testing advertisement features. <code>.","A test plan was added, evidently, after the last review deadline.  But the main issue I see is that it is not a very readable description of what is to be done and why.  It's necessary to reread the prose an ponder it to determine what the changes are and the reason for them.  The explanation is more important than seeing the code.","Hello,

Thank you for the detailed submission. You have shown a marked effort in tackling the assignment comprehensively.

Strengths:
- Your understanding and ability to articulate the problem is laudable. You accurately identify areas that need fixing, and suggest feasible solutions.
- The detailed descriptions for each task completed is commendable. It's easy to follow through the changes you've made and the impact on the functionality.
- Your considerations for edge cases is proof of your thoughtful problem-solving approach and care for user experience.
- Your screenshots provide a clarity that enhances understanding of what you accomplished.
- Your code snippets effectively demonstrate the changes you've implemented.

Areas for Improvement:
- It's not clear which is your write up, your code, and debugging process. Using clearly marked headings and bullet points could help to better organize your submission.
- The testing portion of your submission isn't as detailed as the rest. Make sure to include specifics on your test cases, including what each test was for, the expected outcome, and the actual outcome.
- Double-check your work for typos. There are few in your submission that may create confusion (for example, ""horny"" icon instead of horn icon).

Going forward, consider incorporating these improvements into your assignment write-up. Overall, great job on this assignment and keep up your level of dedication and detail!"
318,E1602,"Expertiza is an open source project based on Ruby on Rails framework. Expertiza has a quizzing feature which allow student authors to create quiz questions and test the peer reviewers. The idea behind this is, if a reviewer can answer the quiz questions which were created by the author correctly, we assume that the reviewer has read the artifact carefully enough and thereby we trust the peer-review. 1. Following three different types of questions are supported in quizzing feature of Expertiza 1. Multiple Choice Radio 2. Multiple Choice Checkbox 3. True/False 1. The current implementation of Quizzing feature is not consistent with the current questions and questionnaires. Since Quiz questionnaire is one sub type of questionnaire, so it should follow the design of other type of questionnaires. But, the current implementation is inconsistent with other questionnaires. 2. In order to create a quiz, the existing code is written in the views which has a series of if-then structures to implement the functionality of each different question type. This kind of implementation makes the code slower and violates the principles of MVC architecture. 3. Current HTML code doesn't looks like source code. 4. Code is repeated for different question types. 5. Proper Ruby naming conventions are not followed. 1. All logic moved to model. Four separate methods - edit , view_question_text , complete and view_completed_question in order to generate the same HTML for each of the question types. We used polymorphism by declaring all these methods in QuizQuestion which inherits from Question and has sub-types MultipleChoiceRadio , MultipleChoiceCheckbox , and TrueFalse . 2. When questionnaire author creates a quiz, edit is called. To call this on UI, you can login as a student, click 'create quiz' / 'edit quiz' on 'Your Works' page. The edit method is now called from /view/questionnaires/_quiz_question.html.erb 3. When questions are viewed by the author or the instructor, view_question_text method is called. To call this on UI, you can either login as a student, click 'view quiz' on 'Your works' page or login as an instructor, find an assignment with quizzing feature and click the icon 'view quiz questions'. The 'view_question_text' calls view/questionnaires/view.html.erb 1. When the quiz takers tries to take the quiz, complete is called. To call this on UI, you can login as a quiz taker, request a quiz to take on “Take quizzes” page, then click “begin”. This method is now called on view/student_quizzes/take_quiz . 2. When the quiz taker finished taking a quiz and wants to view the quiz result again, view_completed_question is called. To call this on UI, you can login as a quiz taker, find a finished quiz and click “view”. This method is called on view/student_quizzes/finished_quiz . 3. Using polymorphism and DRY principles, code repetition has been virtually eliminated. The view_question_text method is called when the author of the quiz or the instructor views the quiz. The method is responsible for generating the HTML to display the question along with each of its choices. The correct choice(s) should be bolded. Prior to refactoring, this functionality was located in app/views/student_quizzes/review_questions.html.erb : <code> This logic has been moved to app/models/quiz_question.rb , so now the view simply needs to call the method: <code> Unit tests were added to spec/models/quiz_question_spec.rb covering all three types of questions to ensure that the correct HTML is generated. The edit method is called when the author creates or edits a quiz. It makes every element of the quiz editable. Prior to refactoring, the HTML was in app/views/questionnaires/_quiz_questionnaire.html.erb : <code> After refactoring, the same file looked like: <code>. Logic is written in multiple_choice_checkbox model for multiple choice checkbox question type. Similarly, same process is followed for remaining question types. To begin a quiz, complete is called from the model. <code>. The logic for viewing completed question and their answers is written in app/views/student_quizzes/finished_quiz.html.erb using a redundant if-elsif structure as shown below. <code> The app/views/student_quizzes/finished_quiz.html.erb was refactored by removing the logic from the view and making it clean. We used a single construct which determines question type and answer type by calling view_completed_question method declared in quiz class as shown below. <code> Similarly, logic was written in models for each of the question types. Following code snippet shows view_completed_question for true/false question type. def view_completed_question(count, answer) <code> Remove irrelevant comments from the student_quizzes_controller The student_quizzes_controller has a few comments which are irrelevant and make the method bulky. These could be safely removed from the code. We added unit tests in spec/models/quiz_question_spec.rb which check the generated HTML for each of the refactored methods. by We used context blocks to incorporate tests for each type of question. Here is an example of the tests for view_question_text : <code>. You may want to use the following information to make UI testing easier if you are using the link in the Expertiza submission: Assignment : Quiz Assignment Instructor : super_administrator2 Students : student15, student16, student17, student18, student19, student20 If you are using the link in the Expertiza submission, you do not need a password. We made this change to facilitate testing. The committed code does not make any change for authenticating users. Since this project involved code refactoring, no new functionality was added. But here are tests for each method to verify they are working correctly. 1. Login as a student. 2. Select an assignment that has quizzing enabled (e.g. Quiz Assignment). 3. Select ""Your Work"" 4. If you haven't created a quiz yet, go ahead and create one by clicking the ""Create Quiz"" link. 5. Select ""View quiz"". 6. You should see each question, followed by the choices. The correct choice(s) will be bolded. 1. Login as a student. 2. Select an assignment that has quizzing enabled (e.g. Quiz Assignment). 3. Select ""Your Work"" 4. If you haven't created a quiz yet, go ahead and create one by clicking the ""Create Quiz"" link. 5. Select ""Edit quiz"". 6. You should see each question, followed by the choices, each in an editable text field. The correct choice(s) will be checked. 1. Login as a student. 2. Select an assignment that has quizzing enabled (e.g. Quiz Assignment). 3. Select ""Your Work"" 4. If you haven't created a quiz yet, go ahead and create one by clicking the ""Create Quiz"" link. 5. Select ""Take Quizzes"". 6. Click 'Begin'. 7. You should see each question, followed by the choices. You can record your answers for each questions and then click 'submit'. Your answers will be saved. 1. Login as a student. 2. Select an assignment that has quizzing enabled (e.g. Quiz Assignment). 3. Select ""Your Work"" 4. If you haven't created/taken a quiz yet, go ahead and create one by clicking the ""Create Quiz"" link and take the quiz. 5. Find a finished quiz and click on 'View'. 6. You should see each question, followed by the choices. The correct choice(s) will be bolded and your recorded answer will be shown. N.B. The VCL image sometimes may take a longer time to load. But, it's up and running perfectly.","Some of the explanations are rather dense (which is to say that they could explain it more clearly by going into more detail).
Some of the code sequences are too long (more than a page) without any commentary.  Could explain the code more fully.","Dear student,

Thank you for your well elaborated and detailed report. You have clearly understood the requirement of the assignment and have showcased your efforts in a commendable way. You did a great job outlining the problems within the Expertiza platform and proposed several efficient solutions. The refactoring process you explained in your report clearly shows your understanding of the Ruby on Rails framework and the MVC architecture.

However, there are a few areas in your report that needs improvement:

1. Formatting: Your report needs better formatting, as there is no clear separation of headings, sub-headings and content. This would make it easier to read.

2. Presentation: When presenting technical content, it is always better to have architecture diagrams, flowcharts etc.. This would have greatly complemented your written explanations and made it easier to understand.

3. Interactivity: Some parts of your report could have been more engaging if you included screenshots of the screens/ steps involved during the various tasks. This would help to visualize better.

4. Context: Ideally, you would explain each point with some background and the impact it would have. Some points seemed to be out of context.

5. Validation: Did you validate the refactorings you made? Did they improve the performance as intended? If you have done any validation tests, please provide the results. 

It is impressive to see the level of detail you were able to cover, identifying the potential issues within the platform and suggesting remediation strategies. The technical aspects of the solutions you provided, utilizing polymorphism and keeping dry principles, for example, seems quite sound. 

However, the benefits or improvements yielded by the refactoring should have clearly indicated to precisely understand the value added by your contribution.

Please also remember to reference your sources properly when referencing external sources. 

Great effort and keep it up,

[Instructor Name]"
319,E1657,"<link> is a web based open source peer reviewing tool based on <link> developed and maintained by current and past students of <link> , Raleigh. Students will be able to manage all their project submissions, project teamups, topic selections etc. Few of the notable features include: 1. Instructor can control most of the stuff that is related to each course. 2. Student can control who he/she wants to team up with etc. 3. They can provide feedback to each of the topics. 4. Instructor can make use of the various submission phases available. Our project is to introduce a Student view to the instructors.The goal of this project is to provide instructor with a functionality using which an instructor can switch to student view and see how the student view looks like. The instructor will also be able to go to future date and see how student view looks like in future date. 1. Introduce a ""Student View Button"" on Instructors UI to switch to student view. 2. Introduce a Revert to instructor View"" on Instructor's Student UI 3. Time travel in Student View. On the right top, left to the logout button , anyone having access to view as instructor gets a textbox and a button saying ""Student View"". in-order to view as a student you have to type in the students ID and press Student View button. You can exactly see what the student's page looks like. <image> If you need to revert back to instructor view you just have to leave the text box empty and press the Revert button. This takes you to the instructors view again. Else if you need another students view, just type in the students ID and press Revert . <image> We also have implemented a time travel feature where you can go to a particular date and see what a student see on that day. You can find this feature as soon as you go to a student ID. You have to select a day you need to travel to, type in the student ID and submit. Boom! you got he student view as on the date given. <image>. 1. Introduce a ""Switch to Student View Button"" on Instructors UI A 'Student View' button was added in the top right portion of menu-bar for instructor. This button allows instructor to see the student view. This button is linked to impersonate action of <link> . The button was simply added in menu-bar view. When the button is clicked, it calls impersonate method in impersonate controller which loads new view as student for provided student id. Required changes in 1 files : <link> <code> If student ID is not provided, the system will randomly select an student ID from all the students in the database, and impersonate the selected student view. This is useful when the instructor doesn't remember the specific student ID. Required changes in 1 file : <link> <code> 1. Introduce a Revert to instructor View"" on Instructor's Student UI Once instructor impersonate to a student view, a Revert button appears which when clicked revert back to instructor view from impersonated student view. Once the student view is loaded by instructor, session[:superuser] is set and based on this flag a revert button will be displayed. 1. Time travel in Student View. Required changes in 4 files : <link> <code> First, we introduced a date box where you can select a date from the UI. <link> <code> In this controller, we took the value from UI and store the same in User model. <link> <code> The value from the above controller is stored in Users model object (not instance) as goto_date. Thus you can access this date through out the sessions. <link> <code> When ever the system calculates due dates, the time is taken from goto_date that we have stored above in Users model. 1. Login in as Instructor. 2. Create assignment. I have created one with name Test_Changes with submission deadline Nov 09 and review Deadline Nov 14. Add all the student in course for this assignment. <image> 1. Switch to student view. Once switched to student view you can see the assignment with submission deadline Nov 09. <image> 1. Go to future date and view the assignment list. I went to Nov 10 in future and we can see that the current phase for our assignment is review. <image> <image>. 1. Requirement: Add a “student view” button for instructors. As we were required to add a button , it makes more sense to add a similar button used across the application. Thus we choose class=""btn btn-primary"" for buttons and :class => 'form-control input-sm' for textboxes. 1. Requirement: Introduce a revert button to go back to instructor: After an instructor enters a student ID of a student and enters student view, there should be a way to go back to instructors . Thus we have introduced a revert button. Also if the instructor wants to go to a different student’s view he should be able to do so as well. Making these two tasks possible with single textbox and button was better instead of an extra button to go back to instructors view. Now to go back to instructors view, instructor has to leave the textbox blank and click “revert”, if the instructor wants to go to a different student’s view he just need to enter the new student’s id and click on “revert”. 1. Requirement: View on specific date: We decided to include a date box which on clicked on the date field a data picker pops up. We have added this picker as it makes sense to just click on which date instead of typing the whole date. <link>. Screencast <link> to our demonstration.","The writeup explains the functionality of the project, but doesn't explain enough of the underlying design decisions.  For example, how is changing the current time implemented?  Do functions that ordinarily look at the system time look somewhere else to find the time that the user has switched to?","Overall, you have provided a thorough understanding of the project. Your attention to detailing each step, discussing your thought process and changes very systematically is commendable. Below is the feedback on some parts of the assignment:

1. The goal of the project is well defined. You have explained the purpose and use of each feature effectively. 

2. The step-by-step explanation of the changes made along with corresponding code snippets is well-documented and provides a clear understanding of the changes done.

3. The implementation of features including the ""Student View Button"", ""Revert to instructor View"" & ""Time travel in Student View"" has been described well.

4. You could add more explanation about the necessity for each modification to further improve your work.

5. Your inclusion of the changes in user interface along with the backend operations provides a comprehensive view of the project.

6. Your screencast provides an effective demonstration of the page layout changes and features. 

Overall, great work with the assignment. Your level of detail and clear descriptions make it easy to understand your contributions and the overall functionality of the project.

For future, you could consider addressing potential challenges faced during the assignment and how you overcame them. Always strive to keep improving and learning!"
320,E1926,"This page provides a description of the Expertiza based Semester project. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link> 1.1.8. <link> 1.1.9. <link> 1.1.10. <link> 1.1.11. <link> 1.1.12. <link>. <link> is an open source project based on <link> framework. The Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. The Expertiza provides an option for students to self-review their submissions. In which, each member of the team gets to evaluate their project on the same criteria as the peer review. However, these scores contribute in no way to calculate the overall score for their assignment. So, we focus on improving the self-review system and to extend its functionality. Some of the objectives we try to achieve for this project are as follows – 1. Provide a formula that takes both the peer review score and self-review score into account for calculating the composite score. 2. The composite score should get higher as the self-review score gets closer to the peer review score. 3. Make sure that the peer review scores are not visible before the self-review submission. 4. Display the composite score on the “View Scores” page. 5. Display the self-review scores in the ""View Scores"" and heat map of peer-reviews, showing that they are a different type of review. The need for the self-review section is to know how well the students can judge their work and understand how to evaluate their flaws and rectify them. Also, if they can score themselves close to their peers, then it means that they have good self-assessment skills and they are being honest about what they think of their work. <image>. Previously, Expertiza allowed students to submit an assignment and provides a link for self-review. Once the self-reviewing was done, the submitted score gets stored in the database but was not used in calculating the overall score of the assignment for the student. Because of this, students can score themselves higher than what they should get. This helps students in no way. So, to make productive use of this score and to help students learn self-evaluating, we have made some changes in the review score calculation which is explained in the section below. We derived a new formula that takes into account the self-review score and calculates a composite score, which will be the student's final score. After we made the changes needed, now the students are able to see their peer review score, Final score and the Final derived peer review score displayed on the “View scores” page. <image> These scores will also be reflected in the ""stats"" as shown below <image> In the same way, we will make some changes to the instructor’s page as well because the instructor should be able to see the self-reviewing score from each member of the team, displayed along with the peer review score for that assignment. <image> <image> 1. The above image shows how the instructor will allow users to give a self-review on the work they have done. The instructor has to go to the review strategy tab while assignment creation to enable the self-review option. 1. User then can see the self-review option on the assignment to do tasks to give a self-review. 1. In the view scores page, a new column showing the self-review scores will be displayed. <image> <image> 1. Actors: <code> 1. Actions <code>. We have to implement a way to combine self-review and peer-review scores to derive a composite score. We have to come up with a formula to derive the composite score as below with the help of research paper: <link> . <code>. 1. Now that the set up is done, to test this, you create 6 students and 2 assignments. 2. One assignment has self-review enabled and the other assignment has self-review disabled. 3. Then student should submit the assignments and the self-review should be done for the required assignment. 4. Try giving same peer-review scores for both assignments and you should see the final score differs accordingly with the self-review score for one assignment but stays the same for the other. 5. You should be able to see the final scores for any student matching to the proposed formula. 6. Perform testing using “Cucumber” and “rSpecs”. 1. app/controllers/grades_controller.rb 2. app/models/assignment_participant.rb 3. app/models/author_feedback_questionnaire.rb 4. app/models/review_questionnaire.rb 5. app/models/response_map.rb 6. app/models/vm_question_response.rb 7. app/views/grades/_participant.html.erb 8. app/views/grades/_participant_charts.html.erb 9. app/views/grades/_participant_title.html.erb 10. app/views/grades/view_team.html.erb 11. app/views/reports/_self_review_report.html.erb 12. spec/controllers/grades_controller_spec.rb 13. spec/models/assignment_particpant_spec.rb. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. <link> 8. <link> 9. <link> 10. <link>.","For design doc: It is not clear how the score is derived.  You refer to the SPARK Plus paper that gives the formula for SAPA, but SAPA is just a measure of how much more positive you are about yourself than your teammates are.  There is no obvious way to combine this with a peer-review score.  You list files that are to be modified, but don't say anything about why they will be changed or what changes will be made to them.","You have provided a very comprehensive assignment, showing in-depth understanding of the Expertiza system as well as the proposed upgrades to its functionality. You illustrated your grasp of problem-solving steps, moving from recognizing an issue in the existing self-review system to devising a plan to address it. 

Your intention to include the self-review scores in the final grade calculation was clearly explained and justified. You particularly highlighted an important skill being cultivated: self-assessment. This is a skill which is indeed beneficial for students, not just academically, but in their future careers as well.

The number of images you included were helpful in visualizing your actual and planned changes to the system. However, in future assignments, you should ensure that these images have been inserted correctly, as not all of your images were visible.

You gave a clear list of components or files which would be impacted by the upgrades, which indicates your understanding of the system architecture and possible implementation implications. This was followed by comprehensive testing strategies and guidelines.

However, while the implementation segment was well laid out, it could have been more detailed. More yearning towards the nitty-gritty of the execution and particular consideration taken for possible problems that may occur would have been advantageous.

Lastly, note that you incorrectly repeated number ""1."" in your listing format towards the assignment end. This might confuse readers and using the correct sequential order enhances clarity considerably. 

Great job overall! Keep up the detailed report, but don't forget to be mindful of the aforementioned areas for improvement."
321,E1973,"Currently, reviews of other student’s work can only be performed by individual students in Expertiza, not by groups of students. Since doing reviews together could help students learn more than by doing them alone, it has been requested that reviews must now have the option to be done by teams instead of individual participants. Therefore, there should be an option when creating assignments that allows the creator to select whether the assignment will use team reviewers or individual reviewers. For simplification, we were allowed to assume that the teams that worked on an assignment together would review together. Each participant should be able to make individual changes to the review (while logged in from their account), but these changes should apply to the team’s collective review. This creates an issue where teammates could accidentally overwrite each other’s work if they edit the review at once. Therefore, it has been decided that the review should be locked while one edits it so that only one participant can edit it at once. Locking the review presents its own challenges. 1. Modification to Response Map Classes 1.1. A field should be added to ResponseMap which indicates whether responses are done by teams or by individuals. 2. Modification to Assignment Class 1.1. A field indicating if the assignment is to be done with team or individuals. This is necessary because part of the suggested requirements is to add a drop down on the review strategy section of the assignment. 3. Locking Solution 1.1. Research needs to be done as to whether a rails mechanism already exists to facilitate a lock on page edits 1.2. A solution can be implemented from scratch by storing a flag in the database on the review’s table entry. This would require an additional migration. 1.3. The ability to have a lock on a review requires the implementation of some kind of auto-unlock feature. If a user never unlocks a review, his/her teammates still need to be able to modify the review. 1.1.1. We should be able to use the “updated at” field to check if the lock has been held for too long and needs to be released. The locking solution we added works as a general locking solution. It adds a new table in the database called locks which create a mapping between a user and a resource. This database change does not force a lock on the resource. Just because there exists a lock between some resource and some user, does not mean that other users cannot edit that resource. The actual prevention of edits, be it redirecting or preventing access to controller methods, is the responsibility of you, the programmer. This class just provides an easy interface to facilitate that behavior. Locks created the following changes: 1. locks 1.1. timeout_period 1.2. created_at 1.3. updated_at 1.4. user_id 1.5. lockable_id 1.6. lockable_type. <image>. Whichever model needs to be able to be locked must include this line: <code> See app/models/response.rb To check to see if a resource is locked, use <code> If the resource is nil, it has been locked. If it's not nil, the given user owns the lock over the current resource. See app/controllers/response_controller.rb#edit To unlock a resource after it is done being used, use <code> See app/controllers/lock_controller.rb#release_lock To check to see if a lock exists between a user and a resource, use <code> See app/controllers/response_controller.rb#update Because locks can time out, if user1 makes changes and stalls on a page, user2 could get the lock, make edits, and release it. If that's the case, we may not want to keep user1's changes. The way to check for that scenario is by seeing if the user still has a lock on this object. Lock.get_lock takes a timeout_period. Timeout_period minutes after a user gets a lock, any user who calls get_lock on a resource will acquire a lock. As the code stands, you MUST include a timeout period if you wish to get a lock. The rationale being that permanently preventing access to a resource is a heavy price for forgetting to unlock a resource. If you wish to do away with this feature, you will need to add the code yourself. (Perhaps using -1 for no time limit). Though I would heavily recommend using the timeout feature. 1. review_response_map.rb (migration required) 1.1. Field - reviewer_is_team: boolean <code> 1. assignment.rb (migration required) 1.1. Field - has_team_reviews: boolean 2. assignments/edit/_review_strategy.html.erb - added check box for has_team_reviews <code> 1. assignment_participant.rb 1.1. Method - get_reviewer 1.1.1. Returns the participant's team if the reviews for the assignment are done by teams. 1.1.2. Several lines of code treated reviewers explicitly as participants. In order to avoid changing too much functionality, and to go with Dr. Gehringer's request that the changes be polymorphic, we just inserted this method whenever the code treated a participant as a reviewer. 1.1.3. Example (review_mapping_controller.rb): 1.1.4. Reviewer used to be retrieved by the call to AssignmentParticipant.where. Now, reviewer and participant are treated seperately. <code> 1. Added lock.rb, lock_controller.rb, and lockable.rb 2. app/views/responses/response.html.erb 1.1. Javascript was added to get locks to be released when the page is exited: <code>. <image>. <image>. <image>. <image>. <image>. 1. Tests were added in response_controller_spec.rb to test that the controller methods properly handle locks and redirect when responses are locked: <code> 1. Tests were created for lock.rb to ensure that all database functionality is handled properly, locks time out, and locks correctly handle requests from multiple users: <code> 1. Since many of expertiza's tests use mocks, several lines in other tests needed to be added since previously un-called methods were now being called: 1.1. Example from review_response_map_spec.rb <code>. Our UI tests aim to capture the following core pieces of functionality: Students on the same team can view/edit the same response: Prerequisites: we use our fixture to ensure that an assignment has been created, and that students 9 and 10 are on a team together. 1. Login as student10. 2. Navigate to assignments, and click on an assignment. 3. Request a new submission to review. 4. In the review, leave the comment ""Excellent work done!"" and click save. 5. Logout and login as student 9. Repeat step 2. 6. Click View. Notice that the review already says ""Excellent work done!"". 7. Go back to the review and click Edit. Change the message to ""Decent work here"". 8. Logout and login as student 10. Repeat step 2. 9. Click View. Notice that the review now says ""Decent work here"". This test was implemented in the file 'teams_as_reviewers_spec.rb': <image>. Students cannot edit the response at the same time: Prerequisites: Same as the above test. 1. Repeat steps 1-4 (inclusive) from the above UI test. However, remain on the edit page. 2. Open another browser and navigate to Expertiza. Then, login as student9 in another browser. 3. Navigate to the assignment and click ""Edit"". Verify that you are redirected and unable to edit the review response since student10 is already editing it. We leave a manual testing section here to cover a scenario we previously planned to add to our feature tests, but realized to be unfeasible. We have functionality that checks that 2 users on the same team cannot edit a response at the same time. However, Expertiza only uses one browser while testing currently. Setting up 2 of them to run at once was deemed beyond the scope of this project. GitHub - <link> Pull Request - <link> Demo Video - <link> Contributors: Spencer Yoder - smyoder@ncsu.edu Ben Fisher - bjfisher@ncsu.edu.","Very thorough and readable description of what was done.  The roughest edge is that the Mediawiki code boxes allow text to flow off the right edge, making it very hard to read.  Better to use the Github diff screenshots.","This is indeed a comprehensive and well-detailed assignment. I appreciate the time and effort you've put into describing and implementing the methods for locking the review editing process. Your explanations on the need for this feature effectively emphasized how this could be accomplished in a team-oriented review situation.

That being said, I have a few suggestions that you could consider:

1. On several instances, your explanation could have been more engaging if you talked about the potential problems that might arise from this feature and how you plan to handle them. 

2. It would have been better if images, figures, or diagrams were provided as well. These can help convey your ideas more efficiently.

3. Perhaps more explanation is needed on the timeouts for the locking mechanism. How exactly are the timeouts calculated? What is the default timeout? Is it customizable?

4. In this part ""This database change does not force a lock on the resource"", could you explain more clearly what the implications of this are and why it was chosen to be implemented this way.

5. There are numerous instances mentioned where code should be included but is missing. It's important to remember to include all necessary code so that one can fully grasp and understand your methods and design approach.

6. Do you have a backup plan in case the lock fails to unlock after the user is done editing? Mechanical or human-made errors could potentially render the lock useless, so having a plan to address those situations would be beneficial.

In general, this is a well-thought-out and thorough proposal. Taking these suggestions into account would further enhance the quality of your work.

Keep up the good work!
"
322,E1804,"1. Deployed app: <link> 2. Github repo: <link> 3. Github pull request: <link>. Expertiza is a web-based framework designed in Ruby on Rails to serve as a medium for students and professors to interact, provide feedback, and manage their assignments. It facilitates all of the electronic turn-ins and provides a good place to review your peers' work. To enhance topic management for instructors and students. 1. Issue 971 : Change create topic UI to AJAX 1. Issue 926 : Sort topics by topic number in assignment#edit 1. Issue 718 : Allow instructors to give feedback when accepting or rejecting suggestions,add comments on those suggestions. We planned to improve the functionality such that when instructors have to manage the topics for an assignment, they can do so much quicker and more reliably. 1. app/spec/controllers/sign_up_sheet_controller_spec.rb 2. app/spec/features/topic_suggestion_spec.rb 3. app/assets/javascripts/application.js 4. app/assets/javascripts/signup.js 5. app/assets/stylesheets/application.scss 6. app/assets/stylesheets/signup.scss.erb 7. app/controllers/sign_up_sheet_controller.rb 8. app/controllers/suggestion_controller.rb 9. app/models/sign_up_topic.rb 10. app/views/sign_up_sheet/_add_signup_topics.html.erb 11. app/views/sign_up_sheet/_add_topics.html.erb 12. app/views/sign_up_sheet/_topic.html.erb 13. app/views/signup/signup_topics.html.erb 14. app/views/suggestion/show.html.erb 15. app/views/suggestion/update_comment.html.erb 16. app/views/suggestion/edit_comment.html.erb 17. app/views/suggestion/_form_comment.html.erb 18. config/routes.rb 19. bower.json. The implementation of this functionality was started using < <link> > as a baseline. This issue calls for the replacement of the html table with a javascript table using jsGrid. The use of jsGrid in conjunction with AJAX calls allow for the user to complete actions such as edit and add for topics from a single page. Furthermore, replacing the html table with a dynamic table should not disrupt the html table for topic signup available to the student. Addition of advertisements is pending. Values for formatting the width of the table columns to enable the table to fit the jQuery UI tab is present, but not fully operational. The functionality below is for an instructor user unless mentioned otherwise. 1. Log in to < <link> > using the username ""instructor6"" and password ""password"". 2. Select ""Manage..."" -> ""Assignments"" from the dropdown at the top. <image> 3. Click the <image> for the ""Final Project (and Design Document)"" assignment. 4. Select the ""Topics"" tab for the assignment. <image> 5. Note the available actions(add,edit,delete) and bookmarks available for each unfinished topic. <image>. To add a topic to an assignment, 1. Select the <image> on the Topics tab of the unfinished assignment that was navigated to in the first section. 2. In the subsequent Add Dialog, enter values for the Topic id, Topic name and Number of slots and click Save. <image> 3. The newly added topic will appear in the table sorted by Topic #. <image>. To Delete a topic from the Topics tab, 1. Select the <image> for the topic you wish to delete. 2. Confirm that you would like to delete the selected topic. <image> <image> 3. Note that the topic is no longer in the table. <image>. To edit a topic to an assignment, 1. Select the <image> on the desired topic of the unfinished assignment that was navigated to in the first section. 2. In the subsequent Edit Dialog, make the desired edits and click Save. <image> 3. The newly editted topic will appear with the new value(s). <image>. 1. Log in to < <link> > using the username ""instructor6"" and password ""password"". 2. Select ""Manage..."" -> ""Assignments"" from the dropdown at the top. <image> 3. Click the <image> for the ""OSS project/Writing assignment 2"" assignment. 4. Select the ""Topics"" tab for the assignment. <image> 5. Note the unavailable actions(add,edit,delete) and bookmarks absent for each unfinished topics. <image>. 1. Log in as ""student5918"" with the password ""password"" at < <link> >. 2. Select ""Final Project (and Design Document)"" from the assignments list. <image> 3. Select ""Signup sheet"" from the assignment menu. <image> 4. Select the check icon next to the desired topic. <image>. For testing the new functionality of methods in the sign_up_sheet_controller, we tested that JSON was correctly rendered from the load_add_signup_topics method, which loads the topics into the edit assignment table 1.1. There were four JSON outputs which were tested: 1.1.1. slots_waitlisted is correctly outputted as JSON 1.1.2. slots_filled_value is correctly outputted as JSON 1.1.3. slots_available is correctly outputted as JSON 1.1.4. participants is correctly outputted as JSON app/spec/controllers/sign_up_sheet_controller_spec.rb <code>. In order to test this area of the project, you need to: 1.1. Install the environment using ./setup.sh 1.2. run bundle install 1.3. run 'rspec spec/controllers/sign_up_sheet_controller_spec.rb'. Overall there are a few more outputs from the method that could be tested. These are values that are pivotal to the table and so testing them is important, so if we are able to, we would like to add those to the project as well, but besides that are proud of the tests that do work. We let JSGrid handle the sorting of topics by the headers in the table. We altered the AJAX controller to enable this sorting. While the table is able to be sorted by the header row, whenever you make a new topic the initial list of topics is not resorted right away. This leads to say E1502, a new topic just made, to be at the bottom of the list when it would normally precede say E1700, if it were in the same topic list. There is no testing required in this aspect, since sorting is a feature of the AJAX table itself, and therefore it wouldn't make sense to test the implementation. We implemented the functionality for approving and rejecting any topic suggestions made by the students. Furthermore we have included comments which the instructor can give for a particular topic suggestion. Some tests have been added to verify the above functionality. The functionality of editing comments also has been correctly implemented. 1. Implement approving and rejecting suggestions. 2. Adding comments to the suggestions(can be multiple). 1. Editing comments in the suggestions view. 2. Removing redundant Approve and Reject suggestion button which were present on the suggestion screen. 1. app/view/suggestion/show.html.erb 1.1. To see all the comments and to edit individual comments: <code> 1.1. To add a comment: <code> 2. app/views/suggestion/edit_comment.html.erb 1.1. Link to form for editing <code> 3. app/views/suggestion/_form_comment.html.erb 1.1. Form for editing: <code> 4. app/controllers/suggestion_controller.rb 1.1. For approving and rejecting suggestions: <code> 1.1. For adding a comment: <code> 1.1. For editing comments: <code> 1.1. For updating comments: <code> Images showing the jist for testing. ' The following steps should be followed to test the functionality:' ' 1. Login as a student2065/2064/2066 with password:password' ' 2. Select any assignment,for example Click on view(RHS of the assignment)""wiki Textbook"" and then click on ""suggest a topic"".' <image> <image> ' 3. Add your suggestion.' <image> ' 4. Login as instructor6 and password:password.' ' 5. Go to assignments and search for ""wiki textbook"".' <image> ' 6. Click on the ""view suggestion"" icon on the right side of the screen.' ' 7. Add a comment on that suggestion and submit.' <image> ' 8. Can edit the comment by clicking on the ""Edit Comment"" button.' <image> ' 9. Login as student and you can see the comment when you go to the assignment and associated topic.' Tests have been added to the spec for testing the above functionality.The following changes are made to the related spec files. spec/features/topic_suggestion_spec.rb. An error occurred while attempting to extract the child content. More tests need to be added to test whether an instructor can edit a comment or not.","The authors have taken care to describe all of the functionality they implemented.  

The section headings refer to issues by number, but in order to find what the issue relates to, you have to look at the ""Problem Statement"" section.  The headings should have included the same information as the Problem Statement.  To make it easier to read, I edited in this information.

The screenshots are huge, requiring the window to be maximized.  It would have been much better to scale them down.  That would have made it possible to see more of the steps at a single time, and helped avoid ""tunnel vision.""

The code snippets don't contain enough description of how the code works.  There are just bullet points about what is done, not how it is done.  It would actually be more elucidating to view the code in Github.","Dear [Student's name],

Thank you for submitting your assignment. I can see that you have dedicated a significant amount of effort and time to build and understand the Expertiza framework using Ruby on Rails. You have put forward a comprehensive understanding of the assignment and the various issues and improvements made.

I appreciate the diligent way you've documented the process and functionalities, being thorough in explaining the changes made for each issue, the code implicated, and how to test them. Your descriptions of the functionalities, the use of jsGrid, the various functionalities for managing assignment topics (add, edit, delete), and the assignment process are impressive.

However, you could strive to make your explanations a bit more concise, arranging details more efficiently so as to make your text easier to read and follow. This could involve grouping related issues together or resorting your information to ensure the most relevant details are highlighted first.

The area that needs looking into is your tests. Please intensify your testing efforts and try to cover all the new functionalities added or updated. This will help ensure that your code works as intended in different situations, adding to the robustness of your application.

You've noted some issues and future enhancements to consider, which shows that you're thinking about continuous improvement, a great approach. The identified bugs and difficulties show that you're testing and critically analyzing your codebase.

Overall, you've made commendable progress. Please continue refining your skills. And remember, creating comprehensive and efficient tests is as important as writing the actual code. 

Keep up the good work!

[Your Name]
[Your Position]"
323,E1921,"The PopupController is responsible for preparing data that will be displayed in popup views. To render the data, which mostly concerns assignments, the controller makes many accesses to database tables such as Response, ResponseMap, Question, Questionnaire, Answer, and Participant. Before our project, there were only two tests implemented that together only achieved a statement coverage of 7%. Our changes have brought the statement coverage to 96%. popup_controller.rb popup_controller_spec.rb. What we need to do is to set up the environment and complete the 'popup_controller_spec.rb' to finish the integration tests for popup controller. This rspec test file can be run by calling the following code: <code>. 1.Write RSpec integration tests to make the statement coverage above 90%. 2.Cover as many edge cases as you can. 3.Achieve as high branch coverage as you can. Teaching staff will use the mutant-rspec gem to measure test thoroughness and fault-finding capability of tests. In total, we wrote tests to cover all 10 methods in the popup controller. We mocked many different objects involved in the controller. The code of the controller can be found <link> . The methods are: 1. action_allowed? 2. author_feedback_popup 3. team_users_popup 4. participants_popup 5. tone_analysis_chart_popup 6. view_review_scores_popup 7. build_tone_analysis_report 8. build_tone_analysis_heatmap 9. reviewer_details_popup 10. self_review_popup. Based on the controller, we mocked models to test different conditions. Models have complex and interdependent relationships, but the Expertiza project already includes a factory to build many of the models. This factory can be seen <link> . Additional database information can be accessed <link> . As you can see from our setup below, most of the objects we created relied on the factory with the exception of the final_versions array, which is not used in enough tests to warrant its own factory statement. Other objects are just built with additional/overwritten attributes, such as the student object. <code> We made one change to the factory.rb file to build an instance of Team. We assume that the Team class may be used in other tests globally, so this should be added to the factory file and thus can be built more easily in future tests. Our addition to the factory.rb file is: <code>. Since it's integration test, we need to test basic logic and return value in both methods in the controller and related methods in the controller. However, some of the methods have been tested in other rspec, all we need to do is to test the methods that haven't been tested. For 'action_allowed?', 'author_feedback_popup', 'team_users_popup', 'participants_popup', 'reviewer_details_popup', 'self_review_popup' methods, we test it separately. With 'tone_analysis_chart_popup', 'view_review_scores_popup', 'build_tone_analysis_report', 'build_tone_analysis_heatmap', we test them together since they both need to get each assignment'answer. Also 'tone_analysis_chart_popup' and 'view_review_scores_popup' all get 'build_tone_analysis_report' and 'build_tone_analysis_heatmap' in their method. The following section shows the Rspec outline of the tests we created. The full test code can be found <link> PopupController Check action permission with four different roles. <code> Get feedback when feedback exists. <code> Get response stats when the response map exists, otherwise only find the team and users. <code> Calculate scores depending on the existence of the response. If a review questionnaire is present, calculate scores with a max. <code> All tone analysis tests are run together. Both popup_* methods set instance variables before calling a build_* method. build_* methods are responsible for actually creating tone analysis tests and returning JSON information/graphics. <code> Test showing details about the reviewer. <code> Get reviews done by self. <code>. The total coverage of the test is 96.41%, meeting our coverage requirement. A video of all tests running can be seen <link> . The main repository can be found <link> The forked git repository for this project can be found <link>. The testing framework in the assignment_team_spec.rb used integration tests to test the methods in the controller. The mock instances are created at the beginning and the method logic is tested in each 'describe'. In addition, we used the Byebug gem to debug our test code. The key to building successful tests is to understand the logic in the method and understand the input and output value for the method.","Good description of what needed to be done, and how it was accomplished.  A little more rationale on why you wrote the tests you did (and no other ones) would've been helpful.","Thank you for your thorough and detailed report. You clearly put a lot of thought and effort into understanding the code, improving your test coverage, exploring edge cases, and providing real value with your changes. I appreciate your use of the factory to create your objects and the integration tests you've implemented for your methods.

Your write-up does a good job of detailing what each test has covered and the logic behind your decisions. This kind of thought process is crucial for quality control and code maintenance so keep up the good work.

I would encourage you to provide a little more detail on the edge case scenarios you tested. Sharing your struggles and what made a particular case or scenario challenging may help others and further show off your problem-solving skills. 

Also, remember to always keep your test as simple as possible. Complex tests can be problematic and harder to maintain. Aim to break down your tests so that they test one isolated aspect of the code at a time. 

Lastly, ensure that the code is readable for anyone who might need to use or modify it. This includes good commenting, proper indentation, and meaningful variable names. This habit will make your work more professional and easier to understand.

Good job overall. Keep up the good work!"
324,E1803,"<link> is a web based open source peer reviewing tool developed and maintained by current and past students of <link> , Raleigh. Currently, when an instructor logs into Expertiza, he/she sees the following menu items across the top: Home Manage content Survey Deployments Assignments Course Evaluation Profile Contact Us And, a student can see the following menu items across the top: Home Assignments Pending Surveys Profile Contact Us On the instructor’s “Manage content” menu, one of the options is “Assignments”. Having “Assignments” appear in two places is potentially confusing. “Manage content > Assignments” allows the instructor to edit and create assignments, whereas the “Assignments” menu (that both students and instructors) see allows the instructor to participate in assignments. Therefore, it makes sense to create a student view for instructors, which will enable them to see menu items that are only related to students. This will help resolve the confusion. Create a student view for instructors. When in student view , an instructor must not be able to view ""Manage content"" and ""Survey Deployments"" menu items, and must be able to switch back to the instructor view (the default view that an instructor first sees when he/she logs in). When in instructor view , an instructor must not be able to view the ""Assignment"" and ""Course Evaluation"" menu items. This file is shared between all views and is responsible for rendering all the elements in the top-most part of the web page. (i.e Displaying the menu items, the logout button etc.) In order to switch between instructor view and student view , the following code was added. When the user is in instructor view , there is a link named ""Switch to Student View"" to switch to student view and when the user is in student view , 'here is a link named ""Revert to Instructor View"" to switch back to the instructor view . <code>. This file is responsible for rendering all menu items and their children (if any). A condition was needed to check if the current menu item that is to be rendered is in the list of hidden menu items. The hidden_menu_items session variable holds the IDs of menu items that must not be rendered. This applies only when the type of user currently logged in is an instructor. Hence, the following condition was added. <code>. A new instructor_controller.rb file has been added. This controller currently contains the actions to switch to student view and revert back to instructor view. <code>. This is a helper for deciding what menu items must be hidden. The update_hidden_menu_items_for_student_view method is used to hide the Survey Deployments and Manage Instructor Content menu items. It does this by including the menu item IDs of these two menus in the hidden_menu_items session variable. (The hidden_menu_item variable will be used by _suckerfish.html.erb to decide whether or not to render a given menu item). Similarly, the update_hidden_menu_items_for_instructor_view method is used to hide the Assignments and Course Evaluation menu items. The set_hidden_menu_items method is used to set check if the given user is an instructor. If it is, then the update_hidden_menu_items_for_instructor_view method is called. This method is used to ensure that only those items that must be visible to an instructor view are visible to an instructor when he logs in for the first time. The method has been designed in this way because, in the future, other menu items may need to be hidden based on the user type. <code>. The after_login method in this controller sets up the session object after the user logs in, so it is a good candidate to include the initial set up of the hidden_menu_items session variable. The following lines were added to the after_login method. This call is intended to set the 'hidden_menu_items' variable in the session object when an instructor logs in for the first time. This is done so that the instructor is by default in Instructor View when he logs in. (i.e Assignments and Course Evaluation are hidden). <code> The following lines were added to the clear_session method. These lines clear the student_view and hidden_menu_items session variables. <code>. New post methods are added in config/routes.rb . The routes are directed to the instructor controller's set_student_view and revert_to_instructor_view actions. <code>. The user needs to log-in as an instructor to view this functionality. 1. Log into Expertiza as an instructor. Enter 'instructor6' as username and 'password' as password. 2. Click on Switch to Student View below username to switch to student view. <image> 3. Click on Revert to Instructor View' below username to come back to instructor view. <image>. 1. Check whether Assignments and Course Evaluation are hidden when in instructor view. This test case is to check if the menu items Assignments and Course Evaluation are hidden when an instructor is in instructor view. The following lines can be added to a spec/features file: <code> 2. Check whether Manage content and Survey Deployments are hidden in student view. This test case is to check if the menu items Manage content and Survey Deployments are hidden when the instructor switches to student view. The following lines are to be added: <code>. 1. Link to forked repository [ <link> ] 2. Link to screen cast [ <link> ]. Expertiza 1. <link> Expertiza Github 1. <link> Expertiza Documentation 1. <link> RSpec Documentation 1. <link>.","Generally does what it is supposed to. Good comments explaining the code changes.  The first two screenshots are in the wrong order.  Wiki refers to a test plan, but no automated tests have been written.","Dear Student,

Thank you for your detailed response on improving the interface of the Expertiza tool. Your assignment is well-structured, and it demonstrates a deep understanding of the Expertiza tool, as well as a good adaptation of the Assignment specs.

Firstly, your problem statement is well-articulated and presents a clear need for different views for instructors and students, aimed at reducing confusion and improving user experience - it shows your commendable empathetic design thinking skills. 

On the technical front, your explanation of the implementation for different views for instructors and students is meticulous and precise. Providing actual code examples on how the change will be implemented is highly appreciated. 

Your clear instructions for testing the functionality, along with the steps for manual verification, is a great touch; it shows your understanding of the importance of quality checks. The test cases are detailed and focus on ensuring complete coverage. 

However, to enhance readability, you might want to make use of specific subsections to distinguish between different components of your assignment, like problem identification, solution, implementation, testing, and others. 

Also, you've provided links to various resources without providing context. Ideally, you should label your links or provide a brief description of what each link leads to.

The assignment indicates a rigorous understanding of the Expertiza tool and creates a comprehensive approach to handling the duplicate menu problem. Well done! Overall, this is a high-quality assignment that gives an insightful solution to the identified problem.

Keep up the good work!

Best,
[Your Name]"
325,E1856,"Students currently are able to “bid” for the projects that they want to do as an assignment. On the other hand, for reviewing others’ work, the policy that’s currently in use is called “first-come-first-serve”. In this project, we update the “first-come-first-serve” policy for assigning projects to reviewers, to the “bidding” policy. In the backend, we implement the “top trading cycles” algorithm. And we modify the controller to meet the needs of the algorithm. At the front end, we create an UI design to present to the students their choices to select. The bidding policy for project topics that students want to work on is already implemented. Students can currently bid on project topics for their team assignment. This reduces a lot of possible conflicts in assigning topics to each team. There’s also reviewing work for each assignment. Currently, the policy to assign the project to the reviewer is “first-come-first-serve”. Students that choose to review a project first will get that project. However, this policy creates an issue — while reviewing students’ work, sometimes the same project is requested to be reviewed a lot of times, while some other projects are not requested as much. A similar bidding policy for assigning projects to reviewers can help students who want to review a project the most to be most likely to receive that project. The completion of this project will allow students to also bid on what projects they are interested in reviewing. We need to alter the “first-come-first-serve” to the “bidding” policy. In this policy, students will be matched to review a submission up to the maximum reviewers. The projects includes implementation of the top trading cycles algorithm on Expertiza. A UI design for the bidding front-end will also be developed for the end-users. Regarding to the functionality of review mapping, it's necessary to describe some of the related models and controllers in expertiza and how they are organized to fully implement the functionality. <image> 1. When an assignment is released, an instance of Assignment is created and corresponding topic instances of SignUpTopics are also imported, indicating that different topics are available for students to choose from within this assignment. 2. Students are assigned as instances of AssignmentParticipant to this assignment and form up their teams(Model Team). 3. Each team registers for several topics and becomes a candidate instance of SignUpTeam. After topics bidding, some of the candidate teams become an official signed-up team of a particular topic. 4. After assignment submission, participants choose their preferred topics and response mappings between assignment(reviewed object), assignment team(reviewee) and assignment participant(reviewer) are created. 5. After the mapping, participants can submit their response and the afterwards is out of discussion range of this document. For now, expertiza employs FIFO strategy on review assignment. In the ReviewMappingController, method ""add_reviewer"" is invoked when students are trying to request a peer review. When it is done, a new mapping is created, that is why review assignment is in FIFO style. If reviewers are allowed to bid on what to review, the procedure of topics bidding implemented by LotteryController is a good reference. Here is the basic workflow of topics bidding: First of all, teams have different preference towards the topics. For example, there are three topics within an assignment, namely A, B and C. Therefore 4 teams W, X, Y, Z. Teams would have their own preference towards different topics: W: B, A, C | X: B, C | Y: C, A, B | Z: A, B, C This data structure is passed to backend service <link> by method ""run_intelligent_assignment"" of LotteryController. The peerlogic service runs top_trading_cycles algorithm to have a fair bidding over the topics and teams. A similar bid can take place on peer review assignment. Why is it workable? The following diagram illustrates the similarity of the two bidding model. <image> As for topics bidding, a few available slots of a particular topic are open for teams contending. In the left part of the diagram, there are 4 slots so only 4 teams can successfully contend for it. Slot is described as ""max_choosers"" of a sign_up topic in Expertiza. Consequently, there will be 4 different responses after the submission, and this time it is the participants that contend for the responses. Some discrepancies need additional attention. 1. Slots can be left unoccupied if no team is willing to response. However, every response needs to have at least some reviewers. 2. The size of bidding data is different, since the number of teams are usually 1/2, 1/3 or 1/4 of the participants. 3. The policy of bidding may be slightly different. Participants are not allowed to review a response submitted by themselves. However, the topic bidding doesn't have this constraint. Almost all of the functionality for our project has already been implemented in the review portions of the Expertiza system. Because of this, we will approach this project by first using delegation pattern to add biding capability to the review mapping controller for choosing topics. Then we will duplicate the view for choosing project topics and modify it so that it interacts with the review mapping controller. We understand that this is not DRY code, so we will try to address this problem by seeing if there is any way we can modify the choose project topics page in order to reuse its code, yet still fulfill the functionality of review mapping. The main idea of this design to a find a delegator to complete the review bidding so that no modification is needs for the original system and reuse the capability of it. Therefore, we need a new set of model, controller and view for this delegator. To maintain the original functionality of Expertiza as well as to add review bidding, we decide to add a new model to handle the data of the bidding. Let's call it ReviewBid. ReviewBid contains the information of bidding assignment and its biddable topics as well as the participants' preference. ReviewBid is served as the input of the bidding algorithm. We decided to let participant to bid on assignment teams rather than topics for simplicity. Here is the definition of ReviewBid: <table>. Construct new new Controller ReviewBidController. This controller handles the following functionality: 1. Trigger the bidding by sending request to PeerLogic backend with proper parameters retrieved from ReviewBid records. 2. Process the response from PeerLogic and transform it into records of ReviewResponseMap. Here we try to refer to the pull request #778 to generate the view code for the review bidding. 1. StudentReviewController: provides a topic-team bidding list to participants; and receives bidding requests from participants so that they can modify their preference. 2. View of Assignment: add a new option of review strategy so that the instructor is able to allow participants to bid on what to review; add a new icon on tree list of assignments to allow instructor to start bidding. For each submission that has received bidding, we keep a record of the interested reviewers, with their preference level. When the bidding is finished, we use the bidding algorithm to assign each reviewer with a submission, according to their preference level, which are stored in each record. Each record is sorted according to their preferences. The most interested reviewer is ordered to be the first, the second most interested to be the next, etc. For example, if there are three submissions A, B, C, and three reviewers D, E and F. Each reviewer chooses two submissions for their preferred review subject. After the bidding period is finished, we collect the following record list: A: [D0, F0] B: [E0, D1] C: [E1, F1] For each record that we have kept, we use the following method to match the submission with the reviewer: 1. We generally assign the submission to the most interested reviewer. 2. If there are several reviewers that are equally interested in this submission, we use random shuffling to assign the submission to randomly one of them. Each of the equally interested individual get equal chances to be given the submission for reviewing. 3. If an individual in the record has been assigned a submission from the previous record-matching, we exclude them from the current matching. So in this example, for assignment A, D and F are equally interested in the submission. So both of them get into the pool for random shuffling. If D gets the chance to review A, then in choosing reviewers for record of B, D is excluded. And E, as the only and the most highest ranked reviewer, gets to review B. Similarly, In C, since E has been assigned a submission to review, F is the only one left, thus gets the submission. Similarly, we have designed the topic bidding algorithm, for reviewers to bid for the topics that they are interested in reviewing. This serves as an alternative for the submission bidding, as one topic sometimes have several different submissions from different teams. Allow Instructor to set review strategy to be bidding: <image> After setting the review strategy to be bidding, participants are assigned with a default bidding list, ordered by topic's name. <image> Participants can drag the items up and own to alter the priority. <image> Instructors can start bidding by clicking the following icon. <image> After the bidding is done, participants can login and see what they are assigned with. <image>. 1. When a participant hasn't reordered the bid, a default list is provided. 2. When a participant has reordered the bid, a priority list is provided. 3. When a participant is ask for a comprehensive bidding list include topics, teams, a bidding items list is provided. 1. Top Trading Cycles algorithm: <link> 2. Top Trading Cycles implementation: <link> 3. Peerlogic service: <link> 4. LotteryController: <link> 5. ReviewMappingController: <link>.","This document describes the strategy in a good deal of detail.  Most of it is clear, but there are some exceptions, e.g., ""Slots can be left unoccupied if no team is willing to response. However, every response needs to have at least some reviewers.""  The code changes are not described, though models, views, and conroller are listed.  The Models section precedes Workflows, but really, both sections talk about workflows.  Revised titles would be better.  Testing is not described, as noted by practically all reviewers.","Dear Student,

Impressive work! The sheer depth of your analysis of the current ""first-come-first-serve"" policy and articulating the need for an upgrade to the ""bidding"" policy is commendable. Your decision to employ “top trading cycles” algorithm is also an interesting choice - it's based on fair trading principles and seems like a fair method for assigning reviews. 

The detailed elucidations of the workflow and the existing models are very well articulated. It's good to see that you've maintained a logical flow in explaining the changes to be made. Your code reusability consideration also shows your awareness to maintain clean and maintainable code.

On a minor note, your assignment lacked a clear Project Objective section that could have set the stage for all the impressive details that you present. For future assignments, do consider including such an introduction to offer a clear overview of the project goals. A sketch or diagram could also enhance your submission by illustrating how the different parts of the system will interact with the new additions. In case you did provide an Image, link, or diagram, they got omitted; please ensure that they are attached correctly in your next assignment.

Also, there are few parts where the context gets a bit unclear, like, ""When a participant hasn't reordered the bid, a default list is provided."". In future, try to offer short examples or further build on these points such that readers more minor versed in the subject can also understand well without much struggle.

Lastly, it’s advisable to explain what “DRY code” is before referencing it as not everyone might know the term. It’s a programmer’s jargon, and hence few might not be able to grasp your point without a preliminary explanation.

Keep up with the same spirit for your next project. All the best!
"
326,E1642,"<link> is an open source project based on <link> framework. It is essentially an educational tool that allows an instructor to create and modify assignments, add topics to assignments, grade students,create evaluation rubrics, etc. Students use Expertiza for submission of their assignments, forming teams, reviewing other students, choosing topics etc. Expertiza also has a bidding feature where students can bid for different topics for an assignment and then it assigns topics to students depending on their priorities and also automatically forms teams. Following are the tasks which need to be completed as a part of our project. 1. P1: Code Climate shows import method is complex, because of lots of checks. This method can be fixed by adding private methods for raising import error. However, you need to check if this functionality is called anywhere. 2. P2: Get_assessments_round_for method can be renamed to get_responses_for_team_round. Team_id private variable is not needed. 3. P3: metareview_response_maps rename, refactoring can be done. No need to do second iteration. 4. P4: Assignment Branch Condition size for final_versions_from_reviewer is too high. 5. P5: Assignment Branch Condition size for get_assessments_round_for is too high, try to get rid of the nested if. 6. P6: Use find_by instead of where.first, e.g. line 60, 65, etc. 7. P7: Wrap the over-long lines: 58, 62 and 181. 8. P8: Write missing unit tests for existing methods. 1. review_response_map.rb 2. assignment.rb 3. on_the_fly_calc.rb 4. vm_question_response.rb 5. factories.rb 6. review_response_map_spec.rb (created). We could find a call to the import method from 4 relevant places in the importFile method in the ImportFileController. Of them 2 are for different models and the other 2 are having different number of parameters. Therefore we concluded that the import method in the review_response_map.rb is not called from anywhere and so we dropped the method. 1. Get_assessments_round_for Method is refactored to get_responses_for_team_round as required. We do not need a separate private variable for Team_id as we can directly use Team.id for the same. <image> Get_assessments_round_for refactoring examples. There is no need for the inner iteration as for every review for a particular round, there is only one metareview. The second iteration was redundant hence is removed. <image> Second Iteration Removed. Assignment Branch Condition size for final_versions_from_reviewer is too high: This function returns a map containing the final versions of a reviewer. The function has duplicate code for scenario with varying rubric and non varying rubric. We moved this code into a new function with method name prepare_review_response. As we removed the duplicate code, this will reduce the Assignment Branch Condition size. <image> Assignments section refactoring examples(code in the red is the ""before"" version and green is ""after"" editing version). <link> method can be used instead of where.first. Although here it wasn't used since the lines of code that used where.first were redundant and were removed to solve other problems. But its application can found on this page <link>. Over long lines can be hard to read in a small screen. Hence proper use of refactoring the lines can save the overhead of reading and understanding long lines of code. In this problem we have wrapped the overlong lines. In an IDE such as RubyMine we can use custom methods such as ""Use Soft Wraps in editor"" to ease the process. There were no tests present for review_response_map. New unit tests were added to test the functionalities and the test coverage result shows that the coverage is now 71.43 % New Added Code <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code>. New Test Cases were created and the test coverage results are as shown. <image> Test coverage increased to 71.43% from 0. This functionality is used for viewing assignment scores for different teams and a detailed analysis for the same. In order to test from UI follow the steps: 1. Login as instructor6 2. Click on Manage... tab and then on the Assignments section 3. Go on Wikipedia contribution assignment and then click on the View scores button.(This will call the above method) 4. Then for any one team, click on Alternate View (This is another call to the method via a different route.). This functionality is used to check the final review summary of a assignment In order to test from UI follow the steps: 1. Login as instructor6 2. Click on Manage -> tab ->Assignments section 3. Click on view review report for any assignment 4. Click on reviewer summary for any reviewer.","This is an excellent writeup, clearly explaining the reason for changes, and highlighting them in the side-by-side source-code display.  It is also helpful to include Code Climate metrics, something I haven't seen any other team do yet.","Dear Student,

Thank you for your thorough analysis and application of the Expertiza project. Your comprehension of the project's requirements and identification of issues is impressive, particularly the intricate explanations you've provided for the changes implemented. 

To begin, it's commendable how you identified and addressed the issue with the complexity of the import method. This forms an important part of software engineering, ensuring that our code remains efficient, understandable, and most importantly, maintainable.

The renaming of ""Get_assessments_round_for"" method has been carried out effectively and the logic behind doing so is clear. Your use of images for visual representation of your changes serve as an excellent aid to comprehend the modifications. You've made good use of this feature to emphasize your points.

The removal of redundancy in the metareview_response_maps is noteworthy. Simultaneously, the explanation of how you reduced the Assignment Branch Condition size for final_versions_from_reviewer elucidates your understanding of clean coding techniques.

Your consideration of the reading difficulty tied with lengthy lines of code and your subsequent action in refactoring the lines is readily noticed and appreciated.

The addition of new unit tests to increase the test coverage highlights your recognition of the need for thorough testing in software development. This has evidently improved the code in terms of robustness and reliability.

On a closing note, the step-by-step instruction to test the new functionalities is a nice touch, ensuring that anyone reviewing your code can easily verify your changes.

Keep up with your solid work in code structuring and organization. Emphasize on testing your code and maintaining clean code practices in the future too. Well done!

Best Regards,
[Your Name]"
330,E1645,"Contents 1.1. <link> 1.2. <link> 1.3. <link> 1.4. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link> 1.1.8. <link> 1.5. <link> 1.6. <link> 1.7. <link> 1.8. <link>. <link> is a peer review based system which provides incremental learning from the class. This project has been developed together by faculty and students using <link> framework. Expertiza allows the instructor to create, edit and delete assignments, create new assignment topics, assign them to a particular class or selected students, have students work on teams and then review each other's assignments at the end. For the students, they can signup for topics, form teams, and submit their projects and assignments. Students then review the work done by other students and give suggestions to improve. Teams after reviews are allotted scores and they can refer to the peer comments to further improve their work. It also supports submission of different file types for assignments, including the URLs and wiki pages. For this project, our team refactored the TreeDisplayController class in the <link> OSS project. This class provides access to questionnaires, review rubrics, author feedback, courses, assignments, and course evaluations. The tree display lists all of these categories with the ability for the user to ""drill down"" into the subcategories or just expand/collapse as needed. The main objective of the project was to refactor the controller to follow good Ruby practices and improve the grade given by <link> by fixing issues detected without breaking any of the existing test cases or functionality of Expertiza. As part of the refactoring task, we had to resolve the issues detected by Code Climate for enhancing code readability and maintainability. Some of the issues detected were: 1. Similar code found in other locations. 2. Cyclomatic and Perceived complexity for get_children_node_ng is too high. 3. Useless assignment to variable - `childNodes`. 4. Use snake_case for variable names. 5. Prefer `each` over `for`. 6. The use of `eval` is a serious security risk. 7. Avoid the use of the case equality operator `===`. 8. Line is too long. 9. `end` at 334, 2 is not aligned with `class` at 1, 0. We used the DRY principle while refactoring our code to remove duplicates in get_children_node_ng and get_children_node_2_ng methods. Duplicated code often leads to a software that is hard to understand and even more difficult to change. According to the Don't Repeat Yourself (DRY) principle, ""Every piece of knowledge must have a single, unambiguous, authoritative representation within a system"" . Violating the DRY principle often leads to more bugs and maintenance problems. In order to make the code DRY, similar code was moved to a new method, and that method was called from the remaining part of the code wherever the same set of lines of code were required. <code> Since only the parameter in find_by_name method was different , we have passed this as an argument in goto_controller method which then executes the same set of steps wherever required with different parameters. Changed to ⇒ <code>. Code Climate has a predefined maximum cyclomatic complexity and raises Cyclomatic complexity too high issue whenever a method exceeds this predefined maximum complexity.This cop tries to produce a complexity score that's a measure of the complexity the reader experiences when looking at a method and raises a Perceived complexity too high issue whenever a method exceeds a preset maximum. In contrast to the CyclomaticComplexity cop, this cop considers else nodes as adding complexity. By creating two separate functions child_nodes_from_params and initialize_fnode_update_children,both the cyclomatic and perceived complexity for this function was reduced. The initialize_fnode_update_children function was in-turn sub-functioned into update_fnode_children which updated the children nodes. The new function looks like this: <code>. Following were removed from the two places: <code> <code>. Variable names using camelCase were renamed to use snake_case as according to ruby coding guidelines. Before: <code> After: <code>. The following for loops were replaced by each, as follows: Before: <code> After: <code>. eval() executes a string of characters as code. eval() is used in situations where the string contents are not known beforehand or even when the string is generated dynamically. Basically, when eval() is called , it starts a compiler to translate the string. This is detrimental especially when eval() is called on a string submitted by or modifiable by the user. Imagine if the string contains an OS call like rm -rf. But , it is perfectly safe to use eval() on strings , if they are known to be constrained. This problem is analogous to SQL injection. Before: <code> After: <code>. As per good Ruby practices, the case equality operator is used only internally along with case statement and should not be abused where simpler operators would do the trick , so as to produce highly readable and easily digestible code. Hence `===` has been replaced by `==` in the following manner: <code> has been changed to ⇒ <code>. Very long lines needs to be made short so that it is more readable, which was done in the following manner: <code> Changed to ⇒ <code> <code> Changed to ==> <code>. Follow the following steps to run all the Rspec tests associated with tree_display_controller 1.) git clone <link> 2.) cd expertiza 3.) bundle install 4.) rename database.yml.example to database.yml and update the database credentials 5) rename secrets.yml.example to secret.yml 6) bundle install 7.) rspec spec/controllers/tree_display_controller_spec.rb. 1. Login in as an instructor or admin using credentials (admin with password: admin or instructor6 with password: password) . The link for the deployed instance can be found in the Project Links section. 2. To check the changes made in goto_controller method, hover over the Manage Content tab in the navigation bar on the top and click all the links and check whether they are being redirected to correct pages. For example, if Questionnaires is clicked, you should be redirected directly to the page displaying all the questionnaires with its sub-categories like Reviews, Surveys etc. 3. When you click on either of the parent nodes - Assignments,Questionnaires and Courses , all the Assignments , Questionnaires and Courses concerned to the Instructor are displayed. 4. To test the changes made in get_children_node_ng and get_children_node_2_ng methods, click on the sub categories under each of the parent tree displays (Courses and Questionnaires) and all of them will further expand to show the details (Click on the name of the Course/Questionnaire to expand them), i.e when you click on a particular course , all the assignments that belong to the corresponding course are displayed. 5. To test the changes made in filter method,enter a keyword in the search bar and you can see that only the courses or assignments containing that particular word are being displayed. For example, if you enter 517 in the courses search bar , only the courses with number 517 are displayed. Direct access to sub categories in tree display <image> Checking the direct access tabs from navigation bar <image> Checking the sub categories in each parent Tree <image> Filter courses in tree display <image>. In conclusion, we were able to successfully refactor the tree_display_controller and related Rspec tests. We have improved and expanded the use of RESTful and DRY design choices, and overall improved the quality and efficiency of the Expertiza codebase. Since a lot of duplicated code was removed, the overall test coverage of Expertiza has also been incresed. We have fixed all the issues detected by Code Climate Chrome Extension and refactored the code to make sure it followed good ruby practices and in the end were able to improve the Code Climate score from F to A while not breaking any of the Rspec tests related. From: <image> To: <image>. <link> <link> <link> <link>.","Really good job of describing the changes made.  A few formatting and grammatical errors; otherwise, great.","Feedback:

This assignment is quite comprehensive and demonstrates a clear understanding of the subject matter related to coding practices and principles. You have not only covered the problem and solution aspects, but also provided ample justification and reasoning for your code changes, which displays strong analytical skills.

Your work on refactoring code to adhere to DRY principles shows good awareness of software best practices. Additionally, bringing the Code Climate score from F to A while maintaining the integrity of the tests shows you've approached the refactoring process with due diligence. I’m impressed by your ability to tackle code complexity issues, and how you adapted the controller to good Ruby practices, like using 'each' over 'for', snake_case over camelCase and your attention to code readability/security with 'eval' handling.

I also see that you have provided clear instructions on how to replicate your results and test the controller and the entire project, which is commendable.

However, I noticed that while you have taken care of most of the issues with the controller, the assignment didn't include a discussion on the possible impacts of these changes on the remaining codebase, or how other parts of the program may interact with the refactored controller. Future assignments should definitely consider this factor, as well.

These minor points for improvement aside, your in-depth approach, demonstration of various coding principles, and commitment to enhancing code readability and maintainability are remarkable. Well done and keep up the excellent work!
"
332,E1732,"Currently, Expertiza doesn’t log anything, beyond the events in the console log. But often there is a need to know when a student logged in, reserved a topic, dropped off a team, reviewed etc. In real time, logs are the first thing to start checking the performance and other metrics. But it is also important to describe which data to log and why. Users activity may not be used for testing or debugging purposes, but can help an evaluator or admin to make sure the authenticity of student submissions and check the timelines. It sure can be used in future to read those logs and report back to users about their action timeline if required. For Students 1. Logins, logouts, signups 2. submission of files/links 3. issuing invitations, joining teams, dropping off teams 4. requesting reviews, submitting reviews 5. undoing any of these operations. For Admin/ Instructor/ TA 1. creating/editing courses and assignments 2. giving grades 3. impersonating other users 4. adding TAs, adding participants to courses or assignments 5. assigning reviewers. The project mainly consists of two parts: 1. Logging the various students and instructors logs and process them accordingly. 2. Extend the existing UI or create one separately if needed along with the required fields as described in the project description. The same has been mentioned in terms of a flowchart: <image>. This same project was assigned to another team last semester and a lot of code was written to log the given accounts. A lot of additions were added to many controllers wherever the events are to be tracked. The code was not merged anyways. We came up with an idea that doesn't modify or add any code to controllers. Logging model shouldn't be a burden to the UI at all. Public Activity Gem The gem we used is <code> According to the documentation: Public_activity provides easy activity tracking for your ActiveRecord, Mongoid 3 and MongoMapper models in Rails 3. Simply put: it records what has been changed or created and gives you the ability to present those recorded activities to users - in a similar way to how GitHub does it. This gem perfectly solves our objectives in two ways. 1. It tracks our events because every event type we need to address has some change or access models. 2. No modifying or adding code in controllers. (Except some session logins and logouts need to be added). We need to read the activities based on the search options added and put onto the user interface to make anyone view based on the filter they provide. Filters include user name, from time and to time. The look of the UI part would be a simple view that contains 1. User : {Textbox} 2. Date From: {Date Filler} 3. Date to: {Date Filler} The results after the querying would be populated in grid that makes it easy to observe. We plan to create a new table in the database for storing these activities. A new migration needs to be created to add the new table to the database. A new model will be created to add each log to the activity. The model will contain fields pertaining to a model such as a user id, type of event, event description, timestamp etc. Table: Event logs <table> Add Public Activity to Model How to add to a model? <code> This small piece of code ensures all the activities are noted when there is an entry made or changed or deleted We added to the following models: 1. assignment.rb 2. assignment_due_date.rb 3. assignment_participant.rb 4. assignment_questionnaire.rb 5. course.rb 6. course_participant.rb 7. invitation.rb 8. join_team_request.rb 9. participant.rb 10. response.rb 11. response_map.rb 12. review_grade.rb 13. sign_up_sheet.rb 14. teams_user.rb 15. user.rb Controllers that were modified, since some activities don't have any effect on a model to enable public activity record those events. 1. activities 2. application 3. auth 4. course 5. impersonate. Public Activity records the events with a trackable id, the table on which the action took place but not any details or description. We add to the public activities views the required code to get the details with the trackable id, type, model taken as parameters. All the activity views specific to each event are added under public activity folder specific to each model. We added the specific filters such as search by user name or any specific date to search for the events. By default, all the activities are shown up on the page accessed with the link ""activities/index"" <image> <image>. 1. Model Testing : Since we are adding a new database table, we need to test Rails model with Rspec that checks if the validations are working fine such as it ""is valid with valid attributes"", it ""is not valid without a user"", it ""is not valid without an event"", it ""is not valid without a timestamp"" 2. Controller Testing : Design includes the addition of a controller that takes care of storing the logs and then loading them up to fill the views if queried which requires a lot of testing. The tests include 1.1. For each event, check if the respective method in the respective controller is called 1.2. For each event, an entry is being correctly stored in the database 1.3. A feature test that checks the UI part of the flow that includes Capybara mocking the admin fills the query page and the testing whether the results are viewed correctly. 1. <link> 2. <link> 3. <link> 4. <link>.","I would like more info on what is logged, and what controllers were modified to do it.  It appears that creating courses, editing courses, creating assignments, and editing assigments are covered.  It would be good to make this explicit by giving a list.  Also, I'd want to know if there's a reason that other activities, like creating users or teams, were not logged.  Are these straightforward extensions for future work?","Overall, your project exhibits a commendable understanding of Expertiza’s data logging requirements and how the Public Activity Gem can be utilized to implement solution. Your detailed plan on actions to be logged, design flow, and extension of the UI is well-articulated. Your additions to the models and controllers address the given issues thoroughly.

However, there are several areas where more clarity or detail would enhance your assignment:

1. You suggest creating a new table in the database for storing these activities, but you should also describe the structure of this table in detail. 

2. Mention the language you are using for coding. While it can be inferred to be Ruby on Rails, stating it clearly would provide better clarity. 

3. Testing: You talk about Model Testing and Controller Testing quite broadly. While you have provided a general idea about what needs to be tested, I recommend diving in a bit deeper and providing specific scenarios that you will be testing. 

4. There are several places in your text where you have put placeholders like <image>, <code>, <link>, <table>. I assume these placeholders are for screenshots, code blocks, references, links to other parts of your text, and tables, respectively. Please ensure that these placeholders are replaced with actual content before submitting the final version.

5. For the UI part you are extending or creating, try to provide some wireframes or sketches of how it will look. This will give a better idea of the experience you are planning for your users.

6. Please describe in brief the potential benefits, implications, and challenges of your solution. Discuss if your solution might affect system performance or load time as your testing argue that it ""shouldn't be a burden to the UI"".

Looking forward to seeing your further enhancements!"
333,E1767,"Expertiza is an open source project created using Ruby on Rails. This project is an software primarily to create reusable learning objects through peer review and also supports team projects. Expertiza allows the creation of instructors and student accounts. This allows the instructors to post assignments (student learning objects) which can be viewed and worked upon by students. These can also be peer reviewed by students later. The Expertiza project is supported by the National Science Foundation. It supports many types of documents, including articles, code, web sites, URLs and wiki pages. Being an open source project, Expertiza is constantly improved. In particular, bugs are often found and resolved. Also new features are often added. The aim of this work is to rectify bugs around the import feature. Expertiza being an online software to learn via peer reviews and team projects. Hence it has several types of users: instructors, students. The instructors are ""administrative"" in nature, they have many roles. Typically a course has 2 or 3 instructors and many students. This project is related to the import feature, which enables the instructor to do an adminstrative task for many students at once, like assigning a project. As there are many students in the course database, adding several things (for each user) individually and manually will be cumbersome and time consuming. Hence another method involving importing things from a file has been developed. Several things, like all students from a class, or all teams for a particular project, or even all possible topics for students for a particular assignment/project can be imported from a file. The reason for doing this is that some lists, like the teams students have formed, may not be available online but rather on a sheet of paper the students have filled offline. In addition, a bug on passwords when importing users (like students) will also be looked into. In Expertiza, various kinds of data may be imported from .csv files, including users, participants in an assignment, topics, and teams. In particular, the file must be a text file and have the data separated by commas. 1. If no password is present in the password column in the CSV file for an user (while importing a list of users), Expertiza returns an error “each record in the file you are importing does not have enough records”. (Issue 183) 2. There should be an option of importing teams (for a particular project/assignment) from an CSV file. (Issue 153) 3. While importing teams, if one (existing) team has the same name as a team being imported, there should be an option of renaming the existing team (Issue 329) 4. The User Interface for importing a course participant and an assignment participant should be similar 5. The Interface for exporting the list of course participants and assignment participants should be similar (Issue 1079) 6. If the file being imported does not have the required fields, the system prints ""The import process expects the following columns:"". However the required column names are not given (Issue 719) 7. Currently the system does not have the feature of exporting review mappings (Issue 1081). Working on this project requires us to set up an Expertiza environment. There are several options, such as setting up on Linux, or on a virtual environment or some more. The one which is recommended and we adopted is:- Install an image of Ubuntu having Expertiza set up on Virtual Box ( Ubuntu-Expertiza image (.OVA) ) The steps to do this are as follows: 1. Download the image :This is the link for the image. ( <link> ) 2. Install VirtualBox and import the downloaded image into VirtualBox. 3. Optional: Some machines/operating systems may require you to enable virtualization 4. After this, run the following commands. 1.1. cd expertiza 1.2. bash ./setup.sh 1.3. bundle install 1.4. rake db:migrate 5. For logging in as an instructor:- Username: instructor6 Password: password. After studying the problem statement, we tested the existing Expertiza environment after careful examination it was determined that the following tasks were already implemented: 1. Issue 719 : If topics are imported without correct data fields , the import page gives this message: “The import process expects the following columns:” but it doesn’t say what the columns are (topic number, topic name, category, number of slots, category) 2. Issue dealing with blank final fields in data file, including Issue 183: It should be possible to leave off the final fields in a line of a CSV file. These fields are often not specified anyway. For example, if a password isn’t specified when a new user is created, the system generates a password (see Issue 183). When importing topics, topic categories are rarely specified. But if the final field is blank, the import requires the CSV line to end with “, “ (comma and space). This should be fixed for all imports. <code>. This deals with the addition of a new feature, hence new code needs to be added. In the existing code, we note that in the controller there was no model object to link the sign up sheet, as shown by following code fragement: <code> In the modified code, it is replaced by : <code> Also the model code shown below is added. Currently, we cannot import teams from a file. Teams have to be created individually, (by the instructor or a student). The solution dealt with adding the feature. This involved adding a method in the model which is showed in the following code fragment: <image> The other changes are to add the method to an appropriate place in the views and the controller. When importing assignment participants and course participants, the User Interface indicates that there are multiple fields expected. However, in fact, user can only import file with 1 column which is user names. We can expect that the imported users are already in the system (otherwise, there should be an error message). Fixing the User Interface and also the code of importation accordingly. For the feature Improve Import Functionalities and Some Export Functionalities, we have added a couple of RSpec tests, as follows: <image> Code Fragement showing test for signup sheet <image> Code Fragement showing change for one more test. <code>. Exporting Course Participants and Assignment Participants neither share the same User Interface nor the same code. Assignment Participants used the common User Interface designed for export functionality. Due to this, the export feature of Assignment Participants return blank file. We decided to use a common user interface everywhere. This involves removing the methods self.export and self.export_fields from both files app/models/assignment_participant.rb and app/models/course_participant.rb. New code is added as below so to ensure that the feature is not lost. Course Participants and Assignment Participants have same User Interface for Export feature as shown in the below image. Course Participants and Assignment Participants are derived from base class named Participants, the export feature can be generalized for both of them by moving it to Participants, which removed redundancy from the code base. Export methods added to participants.rb <image> <image>. app/views/export_file/_reviewer_mapping.html.erb, app/views/export_file/start.html.erb. We have the feature to import review mappings, but we simply do not have the feature to export the review mappings. Created a partial render for Review Response Map. Add the feature of exporting review mapping and making sure it exports in the same format as importations. The changes in the 2 view files are as below: <image> Diagram: Changes in the _review_mapping.html.erb file <image> Diagram: Changes in the _start.html.erb file. 1. Login as instructor 2. In the interface which comes up, on the top menu click Manage and then select Courses. 3. Scroll down to the course you want to add a new team 4. In the right hand side of the screen, corresponding to the course, select the button ""Create Teams"" 5. In the screen which comes up note the name of any one team. Note the names of the users of this team. (The team must have users) 6. Create a text file with one line like this <code> Note that team name must be similar to an existing team name. Also user1, user2 and user3 should not be the same as above. 1. On the lower left of the screen, click the option ""Import team"" 2. Keep Delimiter as comma, and select option ""Rename existing team"", and import using the file you made 3. Now note a new team is added. The new team (with the users as in the import file) will have the desired name, but the team (formerly with the name) will have a new name. <image> <image> <image>. 1. In the case a new team is proposed without valid user names (or without any user names): The team should form, but there should be an appropriate warning message (No such user exists). 1. Login as instructor 2. In the interface which comes up, on the top menu click Manage and then select Assignments 3. Scroll to the bottom of the screen, and select the option Import assignment participants. 4. In a text file create one line like: <code> 1. Import the file 2. Even without password, the user is imported. <image> Fragment if a user with incomplete details is tried to be imported <image> Fragement after the issue was solved. 1. Login as instructor 2. In the interface which comes up, on the top menu click Manage and then select Assignments 3. Scroll to the assignment you want to check, then click Add Reviewer 4. Scroll to the bottom of the screen, and click the ""Export Reviewer mappings"". <image> <image>. 1. Login as instructor 2. In the interface which comes up, on the top menu click Manage and then select Assignments 3. Scroll down to the assignment of interest and click ""Add participant"" 4. Scroll down to the end and click Export Assignment Participants 5. Note the export interface 6. In the interface which comes up, on the top menu click Manage and then select Courses 7. Scroll down to the course of interest and click ""Add participant"" 8. Scroll down to the end and click Export Course Participants 9. Note the export interface. <image>. <link> <link> <link> <link> <link> <link> <link> <link> <link> <link>.","When you say, ""The following tasks were already implemented,"" does that mean that the bugs had been fixed?  Please clarify.  Instead of fixing the import functionality, it seems like you just wrote tests for it.  Screenshots should be scaled back so they fit on a screen.","The thoroughness of your research and the depth of understanding of the Expertiza software platform is commendable. You've offered a comprehensive analysis of the problem statement and exhibited excellent problem-solving prowess in identifying bugs and implementing solutions. 

I appreciate the way you have detailed the process, culminating with changes in the code and the subsequent steps for validation and testing. Your explanation of the problem and the code modification process is logical and efficiently outlined. The steps you have outlined for setting up the Expertiza environment were informative and easy to follow.

The detailed conclusion of bug fixes, their impacts, and the fulsome screenshots and code snippets you provided enable the reader to understand your process completely. 

Your well-thought-out solutions and your comprehensive testing of existing functionalities before implementing new updates are indicative of excellent forensic coding proficiency. 

However, I would also recommend condensing and summarizing your points wherever possible since such long explanations could be intimidating to some readers. Try to separate your thoughts into more readable chunks to enhance clarity and readability. 

I recommend addressing the ' issues' mentioned in the document with more specificity. Specify what the bugs are and how they occurred. This would add depth to your analysis. 

Also, please ensure that the actual code is presented when you mention code fragments rather than just using the placeholder '<code>'. This will provide a better context for understanding the changes made.

You did a great job of covering testing for both the user interface and functionality, through the sharing of images and sample tests ran. This is an encouraging practice in software development. 

In your future assignments, enrich your write-up with references, especially for direct quotes or when giving credit to a solution or idea.

Overall, you've done an impressive job in identifying issues, providing viable solutions, and testing their efficacy. I am looking forward to reading more of your future assignments. Good job!"
334,E1917,"Expertiza is an open source project based on Ruby on Rails framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages[1]. Codeclimate is a command line interface for the Code Climate analysis platform [2]. It can detect code smells which violate ruby/rails best practices. The task is to fix certain code climate issues detected by Code Climate analysis platform in controllers with the name beginning with P through Z. These issues includes unsafe use of methods, inappropriate syntax, non-optimal code structure which violates the DRY principle and so on. There are 37 different types of issues fixed in this project. 1. Unprotected mass assignment 2. Use a guard clause instead of wrapping the code inside a conditional expression 3. Do not use Time.now without zone. Use one of Time.zone.now, Time.current, Time.now.in_time_zone, Time.now.utc, Time.now.getlocal, Time.now.iso8601, Time.now.jisx0301, Time.now.rfc3339, Time.now.to_i, Time.now.to_f instead 4. Move redirect_to ""/"" out of the conditional. 5. Block has too many lines 6. Useless assignment to variable - initheader. 7. Replace class var @@assignment_id with a class instance var 8. Avoid comparing a variable with multiple items in a conditional, use Array#include? Instead 9. Identical blocks of code found in 2 locations. Consider refactoring. 10. Favor unless over if for negative conditions. 11. Operator = should be surrounded by a single space. 12. Line is too long 13. Extra empty line detected at method body beginning. 14. Unnecessary spacing detected. 15. Parameters should be whitelisted for mass assignment 16. Avoid using update_attribute because it skips validations. 17. end at 44, 4 is not aligned with def at 39, 2. 18. Unsafe reflection method const_get called with parameter value 19. TODO found 20. Convert if nested inside else to elsif 21. Similar blocks of code found in 3 locations. Consider refactoring 22. User controlled method execution 23. Extra blank line detected 24. Use empty lines between method definitions. 25. Prefer each over for 26. Prefer Date or Time over DateTime. 27. Omit parentheses for ternary conditions 28. Do not place comments on the same line as the end keyword. 29. Useless assignment to variable - controllers. Did you mean controller? 30. end at 135, 2 is not aligned with class at 1, 0 31. Put one space between the method name and the first argument. 32. Space missing after colon. 33. Use the new Ruby 1.9 hash syntax 34. show, edit, update, destroy are not explicitly defined on the controller. 35. Rename is_user_ta? to user_ta? 36. Avoid comma after the last item of an array 37. Move redirect_to view_student_teams_path student_id: student.id out of the conditional. There are many minor issues such as unnecessary spacing, extra blank line detected, extra parentheses used and so on. We're not going to show all these minor fixing in this section. The focus would be on some of the important issues listed above that we fixed. Mass assignment is a feature of Rails which allows an application to create a record from the values of a hash. Protection for mass assignment is on by default. Query parameters must be explicitly whitelisted via permit in order to be used in mass assignment.This issue appears in different controller files. An example of how we fixed it in questions_controller.rb is shown below: <image>. Used a return/unless combination to return in case the condition is false. <image>. Robocop checks for the use of Time methods without zone. <image>. Robocop checks for identical lines at the beginning or end of each branch of a conditional statement. <image>. Robocop checks against comparing a variable with multiple items, where `Array#include?` could be used instead to avoid code repetition. <image>. Robocop checks for uses of if with a negated condition. <image>. <image>. The method update_attribute will skip validation. Should use update_attributes instead. <image>. <image>. Code climate will complain when a line is too long. <image>. Using the same piece of code violates the DRY principle. We have refactored the code to avoid the repetitive usage. <image>. Renamed is_user_ta? to user_ta? to follow naming conventions enforced by Rubocop. <image>. Show, edit, update and destroy have been explicitly defined to avoid confusion among filters between different controllers. <image>. This ruby syntax has been deprecated as of the current ruby version(2.3.7) used in expertiza. <image>. Space has been added between method name and the first argument to make the code easily readable. <image>. Adding comments at the last the line of the code is considered a bad coding practice according to rubocop standards. <image>. The Expertiza project provides 77 rspec tests under expertiza/spec and 8 of them are related to our controllers files. After modifying those 28 files, we want to make sure these tests could still pass. We passed all the Rspec tests except for ""response_controller"", however, we were not requirement to fix the issues for this controller. <image> <image>. 1. <link> 2. <link> 3. The Class GitHub Repository: <link> 4. The Class Code Climate: <link> 5. Robocop <link>.","On the micro level, you have described your changes well, But rather than look at them one by one, I'd like to see a summary of what were the issues that cropped up frequently, so we can advise future students to avoid them.  Also, when you had the long list of changes, it would've been helpful to group them into similar types so that there would've been some structure to the list.","Hello,

Thanks for your submission. I can see that you have presented a detailed account of the task to fix code climate issues in the Expertiza project. I especially appreciate the time you have taken to identify and highlight the major and minor issues in the different controllers.

Your explanation of how you fixed the highlighted issues is quite well-done. I see that you've described the use of Ruby on Rails methods, Rails validations, and best practices methodically.

However, I have noticed a few areas that could be improved:

1. The readability of this assignment could be improved by properly structuring your content. Use subheadings, bullet points, or numbered lists. 

2. Remember to clearly describe the before and after of the implemented fixes, possibly using code snippets instead of referring to '<image>'.

3. Explain more about why certain changes were made, especially in context of the CodeClimate recommendations or the language/framework constraints.

4. It would help us to understand the context if you include more details about how these fixes impacted the overall functionality of each controller.

5. Even if it's understood that changes were made, actual examples should follow immediately the issues you listed.

6. Ensure proper proofreading to avoid mistakes in the text. For example, there seems to be a typing error - 'Robocop' should read 'Rubocop'.

7. Please confirm the links are valid and direct to the correct resources.

I encourage you to make these modifications and resubmit your assignment. Great job so far!"
335,E1942,"<link> is an assignment portal developed by faculties and students at NCSU. It provides a platform for the faculties to create assignments for the students. Faculties can assign assignments with staged deadlines. Expertiza supports creation of teams for the students, tracking the team members and reviewing the work done by the other team members. Students can also review their peer team's assignment submission. Expertiza has been developed on Ruby on Rails and is available on github. Following is an OSS project which deals with refactoring of stage deadlines in the assignment.rb file. An assignment can have incremental deadlines for different topics in a single assignment. This project involves refactoring the functions in the assignment.rb file related to stage deadlines. There existed five functions to check the kind of stage an assignment is in. However, the names of these functions were ambiguous and functionalities implemented in some of them overlapped with each other. By the end of this project we have refactored these deadline functions. 1. <link> 2. <link>. The assignment.rb file has the following functions implemented : 1. current_stage_name(topic_id = nil) 2. find_current_stage(topic_id = nil) 3. get_current_stage(topic_id = nil) 4. link_for_current_stage(topic_id = nil) 5. stage_deadline(topic_id = nil). The following is the list of refractors done in the code. It discusses the issues we found in the code with respect to Ruby conventions and the solutions that we provided for the same. In the existing code, DueDate.get_next_due_date(self.id, topic_id) has been called at numerous places. This does not follow the ruby coding standards. New private method next_due_date(topic_id) has been added. This function returns the next_due_date by calling the get_next_due_date method on DueDate. File: app/models/assignment.rb. <code> Following places have been refactored. <image> <image>. The condition, if @assignment.current_stage_name(@topic_id) != 'Finished', have been used at various places to check finish status of assignment by comparing with “Finished”. This does not follow ruby coding standards, as we should never compare with static things. Otherwise it becomes difficult to refactor the code later. Assignment is said to be finished if the next due is nil. A new private method finished? has been added. It calls the above next_due_date method and returns true if the next_due_date is nil. File: app/models/assignment.rb. <code> The check with “Finished” has been replaces with a call to finished? . The code has been refactored at following places. <image> <image>. When it is staggered deadline and the topic_id is nil, “Unknown” is returned. This does not follow the DRY Principle. Never should we compare with static strings. To make the code more readable and understandable, and to DRY out the code we have added a new private method topic_missing? to check if the topic is missing in case of staggered deadline. File:app/models/assignment.rb. <code> The code has been refactored at following places: <image> <image> Topic_missing.PNG. The method find_current_stage has been used locally in assignment.rb and once in students controller. However internally, this method calls the next_due_date method for the assignment which has already been separated out. The method find_current_stage has been removed. The places where it was called has been replaced by a call to next_due_date method. File: app/models/assignment.rb , app/controllers/student_controller.rb. <code> The code has been refactored in assignments.rb and the students controller at following places: <image> <image>. The method link_for_current_stage was called once in list.html.erb. This method checks if the current assignment has any URL specified with it and would return it if present. However, the database has no such value. As a result, the if condition where the function was called always evaluated to false. The function link_for_current_stage has been removed. The call to this function has also been removed and the code has been refactored accordingly. File: app/models/assignment.rb , app/views/list.html.erb The code in list.html.erb has been refactored as follows: <image> <image>. The current stage of expertiza did not have any tests for get_current_stage. We have added the test for the same as follows: File: spec/models/assignment_spec.rb. <code>. Tests for new finished? function have been added. File: spec/models/assignment_spec.rb. <code> topic_missing method is a private method and hence no tests have been added for the same.","Very clear description of code changes, significant improvement from last spring's version.  However, the description of the tests is wanting,  What they do is not described in prose; the reader has to read the code to find out.","Good effort on summarizing the assignment and providing a detailed description of the project. You have done a commendable job refactoring these functions and making the codebase more efficient and maintainable. You've clearly explained the changes you made to the code and why you made them. The use of images to demonstrate your changes was also a nice touch.

At various places, you pointed to adherence to Ruby conventions and the DRY principle. To make this stronger, it would have been better if you provided some direct quotes from such conventions and principles to let us understand where, exactly, the original code fell short. 

Regarding your tests, it's great to see you adding tests to ensure the code works as expected after the refactoring. I commend your detailed description of the tests. However, adding a short explanation of the test output or results would be beneficial to readers who are less familiar with testing in Ruby or this specific application. 

Moreover, the information is quite dense. Breaking down your text into more paragraphs, including subheadings, or turning some lists into bullet points could help maintain reader engagement. 

Additionally, bear in mind that a lay reader may not understand certain terms like ""OSS project"",  ""incremental deadlines"", or ""staggered deadline"". Either try to explain these terms, or simplify your language to reach a wider audience. 

Overall, this is a well-thought-out and effectively communicated project with just a few areas for potential improvement. Keep up the good work!"
336,E1835,"Expertiza is an open source project based on Ruby on Rails framework. Expertiza allows the instructor to create new assignments, modify existing assignments and set deadlines. The instructor can also create a list of project topics that the students can sign up for. Expertiza allows students to peer review submissions of other students as well as do teammate reviews. Students can form team on Expertiza to work on assignments and projects. The following tasks were accomplished in this project: 1. Used Sidekiq gem for asynchronous processing of email jobs 2. Created a new mailer class- MailWorker that uses Sidekiq's queue to hold and process jobs 3. Defined the perform method to extract the Email IDs of all participants of the corresponding assignment and send an email reminder 4. Replaced the code that uses the existing DelayedMailer queue to incorporate Sidekiq's queue 5. Added RSPEC test cases to test the creation of assignment deadlines and background Sidekiq email job. Sidekiq is a background processing framework for Ruby. It allows to scale our application by performing work in the background. In particular it consists of three parts: Client, Redis and Server. The client runs in Ruby process and allows us to create jobs for processing later. Once a job is created, a Hash representing that job is created and serialized to a Json String. This String is pushed into a queue in Redis. Redis provides data storage for Sidekiq and holds all the job data. Each Sidekiq server process pulls jobs from the queue in Redis and processes them. 1. Uses the 'delayed_job_active_record' gem for asynchronous processing of delayed jobs The current implementation uses Delayed::Job for implementing a Database based asynchronous priority queue system for storing the job queue of email reminders corresponding to various deadline types. 1. Email reminders were sent to users corresponding to each deadline type The DelayedMailer class includes a perform method that finds Email IDs of the target users corresponding to the deadline type. The subject and body of the email message is then constructed and the delayed_message method of Mailer class is used for sending the emails out to the users. 1. Uses DelayedJob to enqueue email jobs The DelayedMailer object is enqueued into the DelayedJob queue using enqueue method. These jobs are meant to be executed as the deadline of the corresponding Email job approaches. Problem 1 : The perform method in the DelayedMailer class contains a big case statement to check each kind of deadline The perform method in DelayedMailer class checks the deadline type individually using multiple if statements and populates the Email IDs of the target users by querying the database. Auxiliary methods like, for example, mail_signed_up_users is invoked which in turn calls the email_reminder method. This makes the implementation very cumbersome and does not follow the principles of DRY code as the same email_reminder method is called multiple times under different conditions. <code> Solution : The implementation has been changed in such a way that all Participants belonging to the assignment under consideration receive emails irrespective of the deadline type. This is found out by querying the Participant table using assignment_id and retrieving the Email ID by linking it to the User table. 1. The Participant table is queried using assignment_id 2. For each participant, the Email ID is retrieved by linking the Participant and User table. 3. The email reminders are sent collectively to all the email addresses from the previous step. Problem 2 : Scalability Issue: Delayed Job uses SQL database for storing the jobs and processes them in a single-threaded process. It's simple to set up but the performance and scalability are not great. It is not suitable for processing 100,000s of jobs a day. Solution : Sidekiq uses redis for storage which implements a distributed in-memory key-value database and processes jobs in a multithreaded process. It is efficient in terms of processing speed. The worker code needs to be thread safe. 1. In the new implementation a new class MailWorker in app/mailers/mail_worker.rb is created that uses the Sidekiq worker for the mailers queue. The three instance variables- assignment id, deadline type and due date are used in this class as well. 1.1. The perform method takes the above three parameters and calls the auxiliary method find_participant_emails. This method queries the Participant table to extract the Email IDs of the users participating in an assignment and returns the email list. 1.2. The email reminder method is unchanged from the previous implementation. <code> 1. The app/models/assignment_form.rb is modified to make use of the Sidekiq's perform method to queue the job and process it when the deadline approaches. 1.1. The add_delayed_job method now uses Sidekiq's perform_in method to store the email job in the job queue and executes the email job after the time (in seconds) as specified in the first argument has elapsed. 1.2. The corresponding job_id is returned back for further processing. 1.3. The get_time_diff_btw_due_date_and_now method calculates the time after which the email has to be sent and is unchanged. <code>. We modified the existing test cases to replace the delayed job queue with Sidekiq, to test all modifications we have done to the code of assignment_form class. We also added RSpec test for Sidekiq mailer. <code> The tests can be executed ""rspec spec"" command as shown below: <code>. 1. To go to versions index page, type in the following url after logging in as instructor: <link> 2. Create a new assignment and add the rubric and other necessary fields and add the late policy. <link> 3. You can see the new jobs populated here <link>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. <link> 8. Clean Code: A handbook of agile software craftsmanship. Author: Robert C Martin.","This is a very good attempt to document the functionality, and is very readable.  However, some of the excerpted code sequences are quite long.  I would suggest making each method (or almost each method) a separate excerpt and juxtapose the description with each excerpt. Or you might add links to Github commits.","Hello,

Overall, your work on this assignment is quite commendable. You have shown a good understanding of the Expertiza system, Ruby on Rails framework, and the use of Sidekiq gem for asynchronous processing of email jobs. The work you have done on modifying the old mailer class to suit the demands of Sidekiq's queue is impressive. 

I appreciate your critical approach to problem identification. Your solution to avoid repeated checks on the deadline type in the DelayedMailer class by ensuring all Participants receive emails irrespective of the deadline type is fairly efficient and promotes the DRY principle in code. Furthermore, your analysis of the scalability issue with Delayed Job and proposing Sidekiq as an efficient alternative was well explained.

However, your assignment still needs a bit of improvement:

1. Coding snippets: You have quite a number of mentions of ""<code>"" where coding examples should presumably be. However, no coding examples were provided. It would be beneficial to include more code snippets to support your discussion, especially when addressing problems.

2. Hyperlinks: There is a similar issue with your ""<link>"" tags. Be sure to effectively hyperlink to support your argument or show certain aspects of Expertiza. 

3. Conclusion: Your assignment lacks a formal conclusion or a summary. Try to conclude your work by summarizing your findings, problems, and solutions. 

4. References: Please provide a proper citation for your reference. Using a consistent citation style, like APA or MLA, will make this section more effective and professional.

Lastly, always proofread your work to ensure proper grammar and sentence structure. Once these areas are fixed, your assignment will be excellent.

Keep up the great work!"
337,E1860,"Staggered Deadline Assignment is an assignment which can have different topics listed under it and each of these topics have their independent submission and review deadline. Topic's deadline can be the same as parent assignment or independent to it . Such assignments are useful when the class material is more sequential and instructor wants students to complete assignment as and when a topic gets covered in the class. For example it wouldn't make sense to write a paper on a topic from Chapter 4, until the class had covered Chapter 4. This issue occurs when a Topic is created with multiple slots. If the topic is not selected for the first round of topics(assignment) or all the slots did not get filled up, It is still available for selection in the subsequent rounds. If a team selects the topic in a later round, they are not able to submit their work as the submission deadline is already over. If the topic had only one slot which remained unselected, instructor can change the deadline for that topic to match the new deadlines, but for topics with multiple slots, if the deadline is extended, the teams who worked on this topic in the previous round can submit/review the topic again. This should not happen. The signup option used by instructors to signup a team for a topic is visible to the students in their signup page beside every topic. This should not be visible to the students, also the above mentioned issue should be applicable to instructor signup as well. When creating a topic an instructor is required to enter review and submission deadlines for all the topics. To reduce the manual we want to allow the instructor to apply one deadline entry to a set of topics and also let the system calculate subsequent dates for subsequent project phases like review and re-submission, based on an initial deadline entry. Instructor should also have the ability to edit each of those deadlines independently incase he wants to change a particular deadline of a topic. There is no way to identify new submissions or reviews are new since grading was last done. The Submissions and Reviews should appear in different color before and after they are graded. The color scheme should be compatible with the one used for review report. ie Red indicates incomplete Reviews, Blue indicates reviews that have not been graded and Brown for reviews that have grade assigned to them. Students can be prevented from signing up for a topic whose submission deadline has passed. Currently this is happening. Additional Changes : Do not show sign other's up check mark to student. This has been implemented in User.rb and is being used _topic_names.html.erb to determine wether or not to show the check mark next to the topic name. user.rb /* The below code hides the instructor signup option from students and also displays it to only the Instructor or TA of the course, Below are the rules checked; Student can't signup Super Admin can signup Admin of the instructor of the course can signup Instructor and TA of the course can signup */ <code> Logic currently Implemented to prevent the students from signing up for topics whos deadlines have passed is explained by the following diagram. <image> MOCK UI <image>. This is being achieved by calculating the offsets between the dates based on the offset in the dates of the first Topic of the Assignment. Once a new Assignment is created, the default dates (the parent assignment's due dates) are not being assigned to the topic. Instead, we show blank space in the UI. Once the user/instructor enters the first submission date, our JS function grabs the offset from the first topic and applies it to the empty fields of this topic. This was done entirely in the frontend using JS to prevent storing any redundant data and increase the ease of usage. All the fields in the _due_date.html.erb under sign_up_sheet has been changed to a datetimepicker which makes it easy for the instructor to select a date. <code> We have written a function which is fired onfocusout HTML event of the field. This function takes the table, extracts the offsets from the first topic and applies the offset to the topic currently being edited (Note: This does not happen for the first topic as we dont have any data yet) <code> <image>. Below color coding will be used to indicate the current stage of the reviews : Blue - Grade Unassigned to the Review Brown - Review Complete/ Grade Assigned This was working as intended and No changes have been made as discussed with the professor. UI MOCK <image>. Issue 1: # Don’t allow students to sign up for topics that has past due dates. Pre-steps 1. Login as an instructor. 2. Edit any assignment under the General tab, mark it as staggered deadline assignment. 3. Provide deadlines for few topics in the past. 4. Impersonate a student. 5. In the Assignments section, Click on Sign-up sheet. 6. verify topics available for sign-up. Data and Database Integrity Testing None Functional Testing Expectations: 1. The modified topics should not be available for signup. 2. The unmodified topics with deadlines in future should be available for signup. User Interface Testing Expectation: 1. A green tick mark should be available under ‘Actions’ tab for topics with deadlines in the future. 2. Actions’ tab should be empty for topics with deadlines in the past. Performance Testing None Issue 2: # Provide default deadline options for assignments with staggered deadlines. Pre-steps 1. Login as an instructor. 2. Go to assignments and either create a new one or edit a pre-existing one. 3. Change assignment type to staggered deadline. 4. Type in a submission deadline for Round 1-Submission. 5. Verify that other due dates are auto populated. Case 1: Instructor wants to assign default deadlines to a staggered assignment: Steps 1. Click save. Data and Database Integrity Testing Expectations: 1. Verify all deadlines are updated in due_at field in due_dates tables for corresponding deadline types after saving the populated values. Functional Testing Expectations: 1. Deadlines auto-populated for other Round N should be in correspondence with default offset days between rounds. 2. The auto populated deadline should reflect in student assignment section. User Interface Testing Expectation: 1. The auto-population triggered on to corresponding fields by JavaScript should be correct. 2. The format of date auto populated should be as per current system. Performance Testing Expectation: 1. The response time to auto populate the dates to other rounds should be within 5 second latency. Case 2: Instructor wants to enter a custom deadline only for a particular round: Steps 1. Choose offset value from initial vale from dropdown option available against each deadline type. Data and Database Integrity Testing Expectations: 1. Verify all deadlines are updated in due_at field in due_dates tables for corresponding deadline types after saving the populated values. Functional Testing Expectations: 1. The auto populated deadline values are changed as per selected offset days from drop-down. 2. Same should reflect in student assignment section. User Interface Testing Expectation: 1. The triggered change on to corresponding fields by JavaScript should be correct.. 2. The format of date auto populated should be as per current system. Performance Testing Expectation: 1. The response time to change the dates to other rounds should be within 5 second latency. Case 3: Entering an incorrect date when manually entering a deadline for a particular round for a staggered deadline. When the user decides to enter a deadline manually rather than choosing the relative deadlines from the dropdown, care must be taken to ensure that the date is in the correct form: Pre-steps 1. Impersonate a student. 2. Go to assignments and click on others work. 3. Request multiple reviews. 4. Submit one review. 5. Do not start another review and have another review incomplete. 6. Impersonate Instructor. 7. Go assignments page and view review report for this assignment for the impersonate student in step1. 8. verify the results. User Interface Testing Expectation: 1. Incomplete reviews are marked Red. 2. Ungraded reviews are marked Blue. 3. Graded reviews are marked Brown. Automated Test Plan Issue 1 : Topics should be available for signing up a team only by the Instructor or TA of the course, admin and super- admin The following lines are added to spec/models/user_spec.rb file. <code> Issue 2 : Check if the due_dates fields are being populated automatically once the due_date for the first submission is entered for a topic <code>.","This document does a very good job of describing the project.  The rationale for all changes is described, and flowcharts as well as screenshots are shown.  One weakness is that large blocks of code are shown in black and white; it would've been so much better to link to the corresponding diffs in Github.  But the code is nonetheless clear, as it is well commented.  It would also have helped to have a few more comments in the automated test plan, describing what mocks were created and why.","Dear Student,

Thank you for your detailed submission. Based on the review of the assignment, I appreciate your comprehensiveness in your written submission and code implementation. Your explanation of staggered deadline assignments and their advantages was clear and well-explained. The issues and solutions you outlined for particularly tricky instances were thoughtfully considered and your diagrammatic explanation lent clarity to your thoughts.

I understood your code structure, your use of JavaScript to add functionality without storing redundant data, and the step-by-step instructions of code logic implementation. Your decision to implement safeguards to maintain data and database integrity, as well as to ensure efficient performance demonstrated your careful thinking about system usability.

For future assignments, I recommend you organize your work into more structured sections, as your submission was quite lengthy and sometimes difficult to follow. It would help if you can properly format your code snippets and add more inline comments.

However, I found your thoughtful color-coding scheme for review stages to be an excellent suggestion and will promote better usability on the platform.

I noted the detailed testing plans you detailed for each case. It shows you understand the importance of robust testing in system development. Also, an appreciable effort in suggesting automated test plans.

Lastly, it would be beneficial if you could illustrate a more detailed UI mock-up. Mock-ups will help to better visualize the proposed changes and how they would affect the user interface.

Keep up the great work!

Best,
[Your Name]"
338,E1910,"<link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. [3]. The assignments_controller has multiple functions with wrong naming convention, they are classic examples of bad function names. Few of the variables names used in the method can also be refactored to make it more relevant and understandable. In addition, functions code can be optimized to ensure that it follows 'Don't Repeat Yourself' (DRY) principle. Also, most of the functions have missing code comments, which should be added to the functions. <link>. <link>. The only controller modified for this project was the: 1. AssignmentsController 2. Assignment_helper The updated method names in AssignmentController: <code> The thought process behind changing the method names was to make the names shorter and reduce redundancy. There were a few rules that we learned from our mentor; words like nil and nonexist are not allowed in method names. So for handle_current_user_timezonepref_nil we first removed the nil . Then after looking at what the method does we determined that timezone_handler would be appropriate and tells the user enough at a moments glance. More information is available about the method in the form of a block comment. Another example is assignment_form_assignment_staggered_deadline? , the assignment_form bit is redundant, since it is the assignments controller the beginning part does not provide any new information and assignment_staggered_deadline? is sufficient. A different kind of naming is update_nil_dd_deadline_name , we removed the nil but the dd doesn't make sense. No one would know what that stands for just by reading it. This is why this method was changed to update_due_date_deadline_name . It is not any shorter but much more useful at a glance. The assignment_helper file was added to. Some of the methods in the controller were misplaced and according to the DRY principle these methods are better suited to be in the helper method. The methods that were moved from the controller to the helper were: <code> We were asked to refactor the action_allowed? method but after discussing some reafactoring methods with our mentor it was decided that refactoring this method would not promote the DRY principle and the methods created as a result would only be for that one purpose and therefore unnecessary. The DRY principle states, ""Every piece of knowledge or logic must have a single, unambiguous representation within a system.""[4] This project was about furthering this principle and keeping this controller concise and maintainable. This is a controller that helps instructors, TA's, administrators, and super-administrators create/update/edit/show/delete current and past assignments. We updated the aforementioned method names so that the naming convention follows the DRY principle. Many of the method names were far too long, repetitive or unhelpful in understanding what the method actually does. In accordance with the principle we updated the method names to be simple while also being useful in letting the programmer know what the method does. Many of these methods did not have any comments to help the programmer understand the logic driving the method. To further help the programmer in understanding what the code does we added block comments at the beginning of each method that we updated. We cleaned up the controller by moving some methods from the controller into the associated helper file ( assignment_helper.rb ). By doing this we made the controller less messy and easier to read while maintaining and furthering the DRY principle. The code is now easily maintainable and all ""helper"" methods are in one place rather than separated across many files. The delegation pattern states, ""In delegation, an object handles a request by delegating to a second object (the delegate). The delegate is a helper object, but with the original context."" [5] As something extra, the create method was refactored so that the branch condition would be lower and there would be no repetition. We decided to use the delegation pattern because it serves the purpose of cleaning up existing methods while maintaining functionality. As per this pattern we took a request from the create method and put it in a helper method called update_assignment_form . This method handles updating the id of the assignment_questionnaire and the due_date and updating the form accordingly. The create method delegates this task to the update_assignment_form . The update_assignment_form delegated a tasks to the helper method, array_traverser . This method does the job of going through the array and updates id fields to be strings instead of an integer. As a result of these changes two code climate issues have been resolved which are stated below in the Code Climate section. Below are images of the way the create method used to look and how it looks now. Old create method: <image> New create method: <image>. Code Climate checks to make sure that the code that has been written follows certain rules so that everything is legible and concise. During our refactoring we have fixed the following code climate issues. - The create method's Cognitive Complexity was too high. That has been resolved by the delegation we have described above. - The create method was too long with 33 lines of code. That has been resolved by the delegation we have described above. - The Branch Condition size for assignment_form_key_nonexist_case_handler , which is now assignment_submission_handler , was too high. This means that there were too many nested if/elsif/else statements. This has been resolved as a result of us refactoring the code. - The Branch Condition size for update_feedback_assignment_form_attributes , which is now update_feedback_attributes , was too high. This means that there were too many nested if/elsif/else statements. This has been resolved as a result of us refactoring the code. We have three current code climate issues but after discussing with our mentor we have been told to ignore those. The code coverage for the controller was 49% when we got the project. The code coverage when we finished was 53.32%. There is a video on Expertiza titled ""Rspec_test.mp4"" which shows the updated tests running successfully. There were already quite a few test cases for the AssignmentsController ( assignments_controller_spec.rb ). The create block tested just about everything. The two methods we added are private and since we branched out some functionality this needed to be a bit more explicitly tested. There is no precedence for testing private methods and it was frowned upon as per the video The Magic Tricks of Testing . We tested the public method, create , that calls the private method, update_assignment_form and array_traverser . We added a test with the context when assignment_form is saved successfully but fails to update . For the other untested public methods, we found no usage directly in the controller, therefore, we did not test them. These methods are performing the tasks of assigning values to the variables and therefore that is being tested in other methods of the controllers. No changes were made to the associated views and model file. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.","You did a good job of explaining the rationale behind the changes made, and showed the code (albeit in pretty small font) that was affected. This will help the reader understand your changes.  It would have been even better if you had described how the ""after"" code worked (instead of just displaying the code).","Dear Student,

You've done an excellent job on this project, demonstrated proficient technical skills and solid knowledge of the DRY principle, and the delegation pattern for refactoring code. You've successfully shown the application of these principles in improving the code maintainability and readability. Also, your ability to determine the necessity of modifying a method, like 'action_allowed?' based on the code's effects on readability and maintainability is commendable.

Thank you for the detailed and thorough explanation on the process behind changes made, it was thoughtful and clearly shows your understanding of the project's workflow. Also, your choices on renaming methods are well justified and it is encouraging to see your focus on the principle of making the code understandable for others. 

You demonstrated good progress in resolving code climate issues. Meanwhile, your assignment did pay attention to keeping documentation along with writing clean code, which is an important software engineering practice.

It's good to see that you have identified the methods that did not require testing and provided reasons for your choice. I appreciate your effort in increasing the code coverage. However, you can still explore other methods of testing to further improve it. 

Lastly, ensure that each link provided in your report actually leads to a corresponding and essential resource in order to provide more clarity to your readers. Continue this excellent work in your future projects, and always try to explore more ways to improve the quality, efficiency, and readability of your code.

Best regards,
[Your Name]"
339,E1945,"Expertiza is an open-source project based on Ruby on Rails framework. It allows the instructor to create new assignments and customize new or existing assignments. The instructor is allowed to create a list of topics for the students to which they can sign up for. For working on different projects and assignments the students can form teams in Expertiza. Peer review is another feature where students can review other students' submissions. This feature is available in Expertiza. Furthermore, Expertiza supports submission across various document types, including URLs and wiki pages. The UserController is a controller used for managing the creation, modification, and destruction of users in the Expertiza system. Instructor users may be added after creating a request for a new account. A key part of our team’s work was moving methods associated with managing a new account request from the UserController to a new controller named AccountRequestController. This removed coupling between account requests and user objects. Furthermore, it allowed an account request to be properly associated with its own controller, model, and view. Additionally, the team refactored and documented some methods in the UserController. The users_controller.rb file included the standard CRUD methods for a User model along with methods for other workflows. Most notably, the users_controller.rb file handled the creation and management of a RequestedUser object. This was problematic, as the Users controller should deal with User functionality, not requested user flows. The file also included a few methods which had a bad name or lack documentation. The functionality for paginating users did not work either, meaning that all users would be displayed on the List Users page. Thus changes were needed to make the code more readable, as well as to update certain views. The following tasks were required to be done for the project by our team according to the assignment: 1. Separate all methods related to the workflow of a RequestedUser object 2. Move below-mentioned methods to a new file named account_request_controller.rb 1. created_approved_user 2. list_pending_requested 3. request_new 4. created_requested_user_record 5. roles_for_request_sign_up 6. Requested_user_params 1. The RequestedUser model should be renamed to AccountRequest and its lifetime must be managed by the new AccountRequestController 2. The form that was currently displayed when the “Request Account” button is clicked from the Expertiza login page. It had to be edited with the following changes 1.1. Only instructor accounts can be requested, so the dropdown had to be removed. (Student accounts are typically created by the instructor, rather than by directly requesting them from the system.) 1.2. All form labels had to be bold-faced 1.3. The “Self Introduction” label should be re-named to “Self-Introduction” 1.4. The textbox for the self-introduction field should include some hint (“Please include a link to your web site”) 3. Comments had to be written for the following methods 1. get_role 2. show_selection 3. foreign 1. The paginate_list method had to be invoked at the correct location (in the list method) so that it paginates the users list correctly. Currently all users are shown on a single page by default upon clicking on Manage > Users. Because there are nearly 9000 users, the page takes a minute or two to render. This is the page that was loading originally when request account button is clicked in the login page: <image>. Only the Instructor account can be created and not TA which is there as an option originally. For this in the request_new.html.erb file, the selection tag has been changed to label tag in which the Instructor is put on the label. For this in the individual forms inside the view are visited and bold tag has been added individually. Inside the _self_introduction.html.erb file the label is edited to the required one. Initially, the text-box was blank and some hints had to be added. This was done by adding a place_holder attribute inside the text area inside the _self_introduction.html.erb file This is the current page that gets loaded after fixing the above issues: <image>. The following methods had comments written or renamed for better understanding of the working of the methods and to reflect their actual behaviour. 1. get_role - The method was renamed to role , a comment was added explaining that it finds the role of a given user object 2. show_selection - The method was renamed to show_if_authorized , as this method should only display the users if the current user is authorized. Also changed it from a GET to a POST request since it more accurately reflects its working. 3. foreign - A comment was added for this method, explaining that it stores all roles possible and that it gets role id of the session’s user. <image>. Invoked the paginate_list method at the correct location(in the list method) so that it paginates the users list correctly. The number of users per-page has currently been set to 100, which was showing all users in a single page by default. Also added a section at the bottom of the list.html.erb page for navigating between the paginated list of users. <image> As it can be seen now that there are page numbers and not all the users are being showed on the same page as was the case beforehand. The refactoring of the user_controller made the view for the account request more clearer and easy to understand for the user i.e. the UI was improved. Also, the code was made more cleaner and easy to read by for people who works on this later as the methods are segregated for performing their corresponding tasks and they comments are given for those which were not clear. Furthermore, the paginate users is now repaired and is working properly which lets the students list to be shown page wise instead of all the students in a single page which was not readable. Video of Account Request Process: <link>. Tests for UserController were updated to account for the fact that some methods now use the AccountRequestController. The tests for the methods that were moved to AccountRequestController were moved to a new spec in the file account_request_spec.rb . The team did this because it made sense to make a new spec for a new controller. Nevertheless, most test functionalities remained the same. The tests were also updated to not select the user role from the “User Role” dropdown. This was done because the dropdown was removed from the UI since only instructor accounts can be created. RSpec: <code> <code> Manual Testing <code> <code> <code> <code>. Github Repo: <link> Pull Request: <link>.","There were minor inaccuracies on the wiki page, which I have corrected (e.g., instructors may (not ""must"") be created by requesting an account, the way to list users is to invoke Manage > Users).
The UI allows only instructor accounts to be requested.  Administrator accounts should also be requestable from this screen.  If there is only one role, then why does the foreign method need to get a list of available roles?
It would be good to explain the other code changes by pasting in snippets of those too.
They have clearly stated their contribution in the doc
They have uploaded a video that shows testing on their deployment","Dear student,

Great work on reworking the UserController and refactoring the related components, like the AccountRequestController as per assignment's requirement. Here are a few points to be noted:

1. It is clearly evident that you have a profound understanding of the Expertiza system and its functions. Also, your familiarity with Ruby on Rails framework is commendable.

2. The detailed explanation of the changes made and tasks accomplished stood out in your report. You've successfully delineated the separation of methods related to the workflow of a RequestedUser object and the migration of those methods to a new controller, AccountRequestController.

3. Your implementation to improve the UI, like bold-facing all the form labels, improving tooltips, and eliminating unrequired options is well-executed and essential for user-friendliness.  Your endeavors to revamp the old setup and render it more user-friendly deserve appreciation. 

4. The description of how you modified the paginate_list method to improve the list view of users enhances the accessibility of the control tool and the way you related this to the user interface is noteworthy.

5. You've done a commendable job documenting and renaming certain methods for better understanding, which will certainly make future code exploration and bug-solving more manageable.

6. The video of the account request process and the detailed test reports are very useful additions to the document. 

7. As a suggestion, add more in-depth description (possibly through diagrams/images) to illustrate the architecture and how these changes have influenced the overall system's functioning. 

8. In future assignments, perhaps incorporating a summary at the end of the report highlighting the major changes and improvements achieved, might make it easier for anyone unfamiliar with the project to grasp the essence of your work quickly.

9. Don't forget to test each change thoroughly and also validate that changes haven't introduced new bugs or security vulnerabilities into the code.

10. Let's work on better structuring of the report in future assignments as some parts felt a bit cluttered.

Overall, you have completed the tasks required and communicated your work impressively. Excellent work on refactoring and improving the code! 

Keep up the good work.

Best,
[Your Name]"
340,E1832,"Expertiza is an open source project based on Ruby on Rails framework. Expertiza allows the students to peer review other students submission. It also allows Participant of a Team to provide feedback for the review. Apart from that, it allows the instructor to view the summary report of reviews received and feedbacks given by each participant of a team. In current system the author feedback is send by individual team members. It would be better if one team send one single rejoinder to the review and all members could see and edit it. Also there are real usability issues with regards to how students can even navigate to the place where feedback can be given to reviewers. The UI needs to be more user friendly. In Summary report for assignment for instructors, the author feedback section lists feedback from all team members. You should change this to list the team’s collective feedback to its reviewers to a particular assignment. 1. Refactor “new_feedback” actions for adding team as reviewer for Rejoinder. 2. Refactor all the actions in response controllers to pass the participant id. 3. Refactor author feedback tab in summary report view for the instructor. 4. Change in the summary report of assignment for the instructor to display teams feedbacks. 5. In the author-feedback tab on the heat grid, fixed reviewers names on top row. 6. Summary reports navigation to the page where feedbacks are given to reviewers. 1.Team rejoinder. 1. controllers/response_controller.rb 2. views/grades/_reviews.html.erb 3. views/response/response.html.erb 4. models/vm_question_response.rb 5. models/assignment_participant.rb 2.Navigation Issue fixes 1. views/response/view.html.erb 3.Author feedback tab of summary report: 1. models/response_map.rb 2. models/team.rb 3. helpers/grades_helper.rb 4. views/grades/_author_feedback_tab.html.erb 4.Heatgrid top raw reviewer name fix: 1. views/grades/_view_heatgrid.html.erb. 1. Changed per participant feedback display author feedback view to per team in app/views/grades/_author_feedback_tab.html.erb : <image> 1. Added ""give feedback"" and edit feedback functionality in the review view(app/views/grades/_reviews.html.erb). <image> 1. Edited grade helper to use a questionnaire to use team ID for reviews in case of a feedback(app/helpers/grades_helper.rb). <image> 1. Refactored new_feedback method to add team ID as the reviewer Id in the response map(app/controllers/response_controller.rb). <image> 1. Fixed a bug where a wrong assessment was being returned for a feedback because the map was searched on participant id instead of reviewee id. So added a new method which will return a feedback assessment(app/models/response_map.rb). <image>. Issue #622 Assuming a team of two students student559 and student567, and that they have gotten a review from student563. 1. Click Manage-Impersonate User, type username “student559”, then click impersonate. 2. Choose assignment Test Test, go to Your score, and click Review 1, like the screenshot shows, there is an option for giving feedback <image> 3. Now, impersonate user “student567”, choose assignment Test Test, go to Your score, and click Review 1, you can see the same feedback commit ""TESTING Feedback"". with an option to Edit Feedback <image> <image> Issue#895 1. Login as an instructor and Click Manage-Assignment, under assignment Test Test, click view scores. 2. Choose Team 1, and click Author Feedback, you can see the feedback is given by the team, not individual student. <image> Issue#1191 In the above screenshot, you can see that the top row of heat grid is fixed to show the name of Student to whom the feedback is given(in this case to student563). And the link will take you to the review. Fixed the existing test cases for the review feedback by a team instead of a team member. 1. Should test that if there is no rejoinder for the review then it redirects to new author feedback page. 1. Tests that the other teammate is able to edit. 1. The page is redirecting back to the View->review. 1. Tests that the rejoinder by a participant of a team is saved properly. Context 'when current response is nil' do <code> describe '#feedback' do <code>.",They missed the problem statement in their wiki doc. But they have done a very good job describing the changes they made to fix the Github issues.  Test plan needs more elaboration.,"Hi, 

Your work seems impressively thorough, however, it could benefit from better structuring and clearer explanations. Here are some specific areas you might want to improve:

1. Clarity: It is advisable to break down complex sentences and explain your points more clearly. One way to achieve this is to avoid using too much jargon without giving adequate explanations about them. Remember that your assignment should be understandable even to someone who is not very familiar with the topic.

2. Structure: Your assignment comes off as one long paragraph without clear headings or thought flow. Using subheadings and bullet points can greatly enhance the readability of your work.

3. Proofreading: It's also important to proofread your work for typos and correct them. They can distract the reader and reduce the impact of your work. 

4. Screenshots and Code Description: It would be helpful to provide a brief description of what each screenshot or code snippet is showing or doing. This helps the reader to understand their context in your discussion.

5. Test Case Descriptions: The test cases you have written are good. But it would be much better if you could elaborate on what these tests are supposed to check, what is the expected output and why it matters.

6. Proposal: It would be beneficial if you also added a proposal before diving into the changes. This will give readers an insight about what lead you to these set of changes and what you aim to achieve with them.

These changes might seem minor, but they make a huge difference to the quality of your work. I hope you find these comments helpful for your revision. Good work, and keep it up!"
343,E17A8,"Expertiza is an online system that is used by students to view/submit assignments and review others' work. Expertiza also provides tools to visualize the scores and gauge the improvements made during the course semester. It also facilitates and monitors team projects. It is targeted at educational and non-profit organizations. The project is funded by the National Software Foundation (NSF), NCSU Learning in a Technology-Rich Environment (LITRE) program, the NCSU Faculty Center for Teaching and Learning, the NCSU STEM Initiative, and the Center for Advanced Computing and Communication. Expertiza is an open-source project with the source code available as a public repository on GitHub. It is developed using Ruby on Rails and is increasingly becoming robust thanks to the innumerable bugs being fixed by the community. The project has a micro-blog on SourceForge where the developer community report bugs and document updates. 1) Identifying the Expertiza pages which take time to load using Rack-mini-profiler and Flamegraphs. 2) Propose fixes which would improve the Expertiza project. 3) Optimizing the view, models and controllers for few of these corresponding fixes to improve the load time of these pages. 1. rack-mini-profiler :- Middleware that displays speed badge for every html page. Designed to work both in production and in development. 2. flamegraphs :- Flame graphs are a visualization of profiled software, allowing the most frequent code-paths to be identified quickly and accurately. 3. stackprof :- A sampling call-stack profiler for ruby 2.1+.Downloaded as a dependency for rack-mini-profiler. 4. fast_stack :- fast_stack is dynamically resizable data structure optimized for fast iteration over the large arrays of similar elements avoiding memory fragmentation. 5. Kaminari :- A Scope & Engine based, clean, powerful, customizable and sophisticated paginator for modern web app frameworks and ORMs. 1) expertiza.ncsu.edu/grades/view?id=<ID of the team> 2) expertiza.ncsu.edu/users/list. For the purpose of this project, experts in the expertiza domain are Instructors. The following two patterns are implemented in the project - 1.MVC Pattern - The project is implemented in Ruby on Rails that uses MVC architecture. It separates an application’s data model, user interface, and control logic into three distinct components (model, view, and controller, respectively). 2.DRY Principle - We are trying to reuse the existing functionalities in Expertiza, thus avoiding code duplication. Whenever possible, code modification based on the existing classes, controllers, or tables will be done instead of creating the new one. 3.Optimization - In order to optimize, we need to understand the factors which are causing the lag. This can be identified by using the flamegraph generation method and rack-mini-profiler statistics. To complete the given task, we identified the factors which are causing the lag. This was done by using flamegraph generation and rack-mini-profiler statistics. The statistics generated by rack miniprofiler helped us to understand the time taken by each component to get loaded. From these statistics, we identified the model/controller/view/database query which is causing this latency. From here, we identified the methods which needed to be implemented in order to optimize the webpage rendering. Optimization approach for the pages: 1. users/list :- The approach to reduce loading time on this page was by implementing pagination. Instead of displaying all users and their data all at once, we display a certain number of users on one page, and rest of the users can be viewed by accessing the later pages. This reduces loading time of the page by reducing the amount of data to be fetched. 2. grades/view : Ajax must be used for the optimization. Currently, all the data for all the teams present is loaded when the webpage is accessed. Instead, data for particular teams can be loaded when the user clicks on the expand button for that particular team. Thus, data for each team should be loaded asynchronously with ajax. The following is the flamegraph for this page:- <image> The X axis of the FlameGraph represents the time taken to load the page. It can give a clear picture of where the expertiza page is getting bogged down. The widest layers take the longest to run. They’re the areas one should look into, because speeding them up could have the biggest impact. As we can see over here, most of the time taken over here is in the controller action. The following is the rack-mini-profiler statistics for the page:- <image> The box which is seen in the leftmost corner is the MiniProfiler statistics. MiniProfiler gives a constant notification of how long each page takes to load. The miniprofiler statistics show the time taken to render the view as well as the corresponding SQL calls. <image> This image shows the time and the number of SQL calls which are required for each rendering. <image> Here as we can see the total number of SQL calls required for children_node_ng is 1123. This is causing the latency in the entire page by 10564.8 ms. These statistics helped us to identify the method which needs to be refactored. <image> The total number of SQL calls required for 2 components here is 2 each. Hence we do not need to refactor this component. 1. users/list The time taken to load the page was high because the server had to access through hundreds of rows in the database .The page was rendering the entire row of database at the same time. Pagination helped to split the database into manageable chunks of data. Code added to app/controllers/users_controller.rb <code> Code added to app/models/user.rb <code> Code added to app/views/users/list.html.erb <code> 1. grades/view The grades/view is the page where the instructor accesses the grades statistics of each student. The reason for the slow down in the page is that the data for all the teams were loaded as soon as the page was loaded.The design of the page has an individual tab for each team, hence loading the entire data as soon as the page is loaded is quite redundant as the instructor needs to access the scores of each individual team at a given time. The solution to this problem is to access the individual team statistics from the database when the instructor clicks the tab specified for the particular individual. The existing code consists of a for loop in views/grades/_teams.html.erb, which renders the partial ""views/grades/_tabbing.html.erb"" which displays the data repeatedly. Instead, this partial could be rendered through AJAX or JQuery, whenever the expand button is clicked. This would save redundant loading of data and thus reduce the loading time of the page. Issues faced during implementation of this solution :- 1. While implementing this fix, we first created a controller method, which would render the required partial ""views/grades/_tabbing.html.erb"" when called.We also created a route for this controller method. 2. We passed the required data through the Rails params hash. However, since one argument that needed to be passed (tscore) is a Hash, when it enters the params hash, it is getting converted to a String. 3. We tried passing the hash as it is, but after doing this all the data in the hash is not retained, i.e. there is a loss of data. 4. We also tried converting the String back into Hash by using the eval method, and to_unsafe_h method. 5. However, these methods require the hash to be present in a normal form i.e. key value pairs. 6. But our hash has values as Objects, thus these methods cannot be applied 7. Thus, we are unable to access the data in the String-hash. 8. If this could be done, then our approach would result in successfully decreasing the loading time of the webpage. The project is based on optimizing the time required to load the pages which has been mentioned above,in order to test that there is an improvement in the time taken to load these pages one will have to compare the initial loading time and the time taken after the code has been modified. 1)Clone the git repository. 2)Go to the commit on 3rd November (name: initial setup), this is the code which is originally provided by the professor and has not been modified. It however consists of the two gems required to check the loading time. 3)To login as instructor :- Username :- instructor6 Password :- password. Check the time taken to load the page localhost:3000/tree_display/list on the left corner and compare the same for the latest pull. You will notice a substantial reduction in the loading time. There can be no automated test for this program since the improvement in the performance is due to the inclusion of the pagination gem. Hence testing if the pagination gem will work is equivalent to checking if rails is working. As testing rails is not recommended no automated test is added for changes made. 1. Project Demo : <link> 2. Project Repository: <link> 3. Pull request: <link> 4. Github issue: <link>.","This is a very different project, so a lot of sections required in other design docs are not required here and vice versa.  In essence the whole document is a test plan, for performance tests.  The document is generally readable and explains what needs to be done.","Overall, your assignment demonstrates a comprehensive understanding of the topics covered. You have done a good job in documenting the issues related to Expertiza system's loading time, as well as identifying possible methods to optimize it. Your analysis of the issues was thorough and your optimization proposals show an understanding of web-design best practices. 

Here are some specific feedback points:

1. The work on identifying lagging pages using Rack-mini-profiler and Flamegraphs is well done. This shows your depth understanding of profiling and recognizing potential performance issues.

2. Your explanation for implementing the MVC architecture and the DRY principle is likewise commendable.

3. Your solution for optimizing the loading time of the users/list page via pagination is sound and shows an understanding of how to deal with large data sets. However, you could have explained how you selected the page limit for pagination or whether this number can be optimized further.

4. You've done an excellent job in explaining the grades/view page optimization, reasoning well through the problem and its solution. However, you could have outlined an alternative solution to this AJAX implementation problem, or the potential ways to solve the mentioned issues.

5. You did a good job of outlining how you would test the enhancements. However, some automated test methods could be introduced or considered, even if it involves testing timings, which may help reinforce the before-and-after results.

6. Make sure to give proper annotation to the images and code snippets entered in your assignment. It will help in better understanding of the problem, solution and the improvements.

7. Always remember to remove server-side specific information (such as username and password) before submission. If necessary, provide such instructions in a secure or encrypted manner.

In conclusion, this was a very thorough and well-developed project. It demonstrated your strong understanding of optimization issues and how they can be addressed."
344,E1673,"Expertiza is an open source software to create reusable learning objects through peer review. It also supports team projects, and the submission of almost any document type, including URLs and wiki pages. It has following features: 1. Enables students working together in a class and a topic 2. Enables studnets to do peer review and improve both him/her and others' learn experience. The purpose of this work is to rewrite part of the codes in the Criterion.rb, Scale.rb, Checkbox.rb, Dropdown.rb, Text_response.rb, Text_area.rb, Text_field.rb. This is because some of codes have bad writing sytle, or not followingg OO language rules, which confuse others to understand these code. The detail of the requirements are list below: 1. Line is too long 2. Some code found in other location and should put them in the parent class 3. Method has too many lines 4. Some of the code will cause security risk 5. Using the old style validations 6. Using a lower efficent way to do the loop All of these requirements are based on a analysis software called <link>. <image> <image>. Although it increase the number of classes, the length of function decrease and it's easy to read than before 1. Short the long line 2. Improve security by using safe_join Previous <code> Changed <code> 3. Short long method Previous <code> Changed <code>. It makes codes more readable. We also choose safe_join instead of html_safe to prevent security risks. However, we must use html_safe to keep the character encoding. 1. Use new style validations Previous <code> Changed <code> 2. Short the long line 3. Improve security by safe_join Preivious <code> Changed <code> 4. Short long method Preivious <code> Changed <code>. 1. Use each loop instead of for loop Previous <code> Changed <code> 2. Short the long line 3. Use safe_join to be more security Previous <code> Changed <code> 4. Delete the code similar with other file and put the duplicate into parent class. 5. Modify some method that is too long Previous <code> Changed <code>. 1. Short the long line 2. Modify some method that is too long Previous <code> Changed <code> 3. Use safe_join to be more security Previous <code> Changed <code>. 1. Improve security by using safe_join Previous <code> Changed <code> 2. Modify some method that is too long 3. Use new style validations Previous <code> Changed <code> 4. Use each loop instead of for loop Previous <code> Changed <code>. 1. Use new style validations Previous <code> Changed <code> 2. Modify some method that is too long 3. Improve security by using safe_join Previous <code> Changed <code>. 1. Replace condition statements in one line Previous <code> Changed <code> 2. Improve security by using safe_join Previous <code> Changed <code>. 1. Login in as an instructor or admin using credentials (admin with password: admin or instructor6 with password: password) 1. Click the Manage in the top bar,then click the Questionnaires which is down left of the the text:Manage content 1. Add the Name and click create 1. Click the any button you want.","When you say you have ""short"" (shortened) a method, you should explain how functionality that used to be performed by the method is performed now.  The code you've given is much shorter, and couldn't output everything the old view did.","The introduction to your assignment was quite thorough and informative; you explained clearly what Expertiza is and what its features are. However, it's clear that parts of your work need some improvement, particularly with regards to clarity and coherence. While you defined the problem in the codes well and gave a detailed list of the requirements, your explanations and sentences sometimes suffered from typographical errors, inconsistent tense usage, and repetition.

More critically, without the code, your descriptions of your solutions and improvements are challenging to follow. For the reader to understand your methodology and performance, specific examples of the code you were working on are necessary. Your improvements concerning long lines, enhanced security, adapted methods, and use of new style validations would be much clearer if systematic and comprehensive code samples were provided. Consequently, I also couldn't decipher whether your code was effective at meeting the project requirements. 

Another area of improvement is the structure of your report. Points such as shortening lines, enhanced security, adapted methods, and use of new style validations were repeated under each file but it would be more efficient to discuss each change once in detail while referring to the relevant file. 

The final steps you described seem to be for a different assignment or an unrelated section. It might be best to revise this to better connect it to the rest of your work. 

Overall, more care should be given to the presentation of your work, as the formatting and organization can also significantly affect the understanding and appreciation of your work. Please address these points as much as possible for a more comprehensive assignment."
345,E1621,"Expertiza<ref> <link> </ref> is a project developed using Ruby on Rails<ref> <link> </ref>. It provides features like peer review, team assignments and submission of projects. This can be achieved by submitting code base, URL of hosted code on remote server and Wiki submissions. It is an <link> application and the code can be cloned from <link> . This application provides an efficient way to manage assignments, grades and reviews. The Expertiza quiz feature is in need of refactoring. Currently, quizzes are checked by questionnaires_controller.valid_quiz . This method is rather long, involved, and does not take advantage of object-oriented practices. It combs through the parameters hash received from a request and manually checks all quiz fields, all question fields, all question choice fields, and verifies that each question has a correct choice. We will refactor the method to construct a quiz questionniare and then call valid? to recursively validate the object tree using ActiveRecord validations. This is an improvement over the current code which checks all questions manually. The purpose of refactoring in this manner is to enhance readability, DRYness, and maintainability of Expertiza code. In addition to this refactoring we will implement integration testing on the quiz feature to verify that the expected behavior is present for all use cases. A full description of the assignment may be found <link> Program flow of this quizzing feature can be found <link>. 1. questionnaires_controller.rb 2. quiz_quesetionnaire.rb 3. quiz_question.rb 4. quiz_question_choice.rb 5. spec/features/quiz_spec.rb. The Quiz Use Case allows for instructors to create and manage assignments where students may write quizzes for reviewers on materials they have submitted. See the following scenarios for a complete description of how the feature is expected to work. An instructor chooses to create an assignment that has a quiz [S1]. While editing the assignment they may choose the number of quiz questions [S2] and set which phases students are allowed to take the quizzes [S3]. 1. [S1] - When creating the assignment there is a checkbox labeled ""has quiz."" Checking this box creates an assignment that includes a quiz. 2. [S2] - When an assignment has a quiz there is an input field that accepts the number of questions that will be on each quiz. Setting this number appropriately changes the number of quiz questions. 3. [S3] - Students may not take quizzes on a phase that does not allow them to do so. When on a stage that does allow for quizzes, they may take quizzes on work that they have reviewed. After an assignment has been created the instructor may choose to view student quizzes from the tree view [S1]. While on the quiz view page they see student quizzes [S2] and student responses [S3]. 1. [S1] - The instructor may navigate to the list of assignments. Assignments with quizzes enabled will provide a link for the instructor to follow and view student quizzes. 2. [S2] - The instructor shall be presented with the quiz title, questions, and answer choices. The correct answer choices will be in bold. 3. [S3] - The score for each student who has taken the quiz shall be listed along with the average quiz score. A student navigates to the assignment work page and chooses to create a new quiz [S1] or edit an existing one [S2]. By doing so they are able to choose a quiz title and quiz questions [S3]. Invalid input results in an error message prompting the student to fix the issue [E1]. 1. [S1] - A student may only create a quiz if they have not yet done so. 2. [S2] - A student may only edit a quiz if they have previously created one. 3. [S3] - The quiz has the number of quiz questions defined by the instructor in the assignment. 1. [E1] - Possible errors include: 1.1. The quiz has no name. 1.2. One or more questions is missing text. 1.3. One or more choices is missing text. 1.4. A question is missing a correct answer choice. A student decides to take a quiz [S1] on another team's assignment that they have previously reviewed. They select an artifact for review [S2] and fill in their answers. After submitting the quiz they can view their score on the take quizzes page [S3] and see question-by-question scores by clicking view [S4]. 1. [S1] - The student may only take a quiz during a stage in which the assignment is configured to allow them to do so. 2. [S2] - Only quizzes from submissions they have reviewed are available. 3. [S3] - The take quizzes page lists the final score for each quiz. 4. [S4] - Choosing to view a quiz will show a student each question along with their answers and the correct answers. Design for the refactoring has been driven by object oriented principles and test-driven-development, and makes use of the existing object hierarchy described in the following UML diagram. <image> See the below sections for a part-by-part breakdown of the planned implementation for this project. Quiz tests will be added to the file spec/features/quiz_spec.rb and will make use of 1. rspec 2. capybara 3. selenium Tests will be made which fully cover the expected behavior of each listed scenario in the Use Case. Each of the following files will be refactored as described. Refactor the valid_quiz method. It will be renamed to validate_quiz to more properly describe the action that occurs as a result of it being called. The behavior will be changed to construct a new quiz questionnaire with submitted questions wich will be validated using quiz.valid? . The following fields will be validated using ActiveRecord validations. 1. Presence of name. The following fields will be validated using ActiveRecord validations 1. Presence of text 2. Presence of type 3. Has a correct answer. The following fields will be validated using ActiveRecord validations 1. Presence of text. In order to verify that refactoring has been done correctly and maintains the same external behavior, we will write test cases to the existing implementation. These test cases will be the ground truth of the validation feature. Refactored code will not be considered complete until all of these test cases once again pass. Testing and refactoring have been completed and a <link> created to merge features back into master. Refactoring went according to plan. The following model files were edited to use ActiveRecord validations on specific fields 1. question.rb 2. questionnaire.rb 3. quiz_quesetion.rb 4. quiz_question_choice.rb In addition, tests were added to spec/controllers/questionnaires_controller_spec.rb to test quiz validation. With passing tests, the validate_quiz method in questionnaires_controller was refactored. It now constructs a quiz from params and returns it if it is valid. If the quiz is invalid an error message is returned. def valid_quiz num_quiz_questions = Assignment.find(params[:aid]).num_quiz_questions valid = ""valid"" (1..num_quiz_questions).each do |i| if params[:new_question][i.to_s] == // One of the questions text is not filled out valid = ""Please make sure all questions have text"" break elsif !params.has_key?(:question_type) || !params[:question_type].has_key?(i.to_s) || params[:question_type][i.to_s][:type] == nil // A type isnt selected for a question valid = ""Please select a type for each question"" break elsif params[:questionnaire][:name]=="""" // questionnaire name is not specified valid = ""Please specify quiz name (please do not use your name or id)."" break else type = params[:question_type][i.to_s][:type] if type == 'MultipleChoiceCheckbox' or type == 'MultipleChoiceRadio' correct_selected = false (1..4).each do |x| if params[:new_choices][i.to_s][type][x.to_s][:txt] == // Text isnt provided for an option valid = ""Please make sure every question has text for all options"" break elsif type == 'MultipleChoiceRadio' and not params[:new_choices][i.to_s][type][x.to_s][:iscorrect] == nil correct_selected = true elsif type == 'MultipleChoiceCheckbox' and not params[:new_choices][i.to_s][type][x.to_s][:iscorrect] == 0.to_s correct_selected = true end end if valid == ""valid"" && !correct_selected // A correct option isnt selected for a check box or radio question valid = ""Please select a correct answer for all questions"" break end elsif type == 'TF' # TF is not disabled. We need to test TF later. if params[:new_choices][i.to_s][""TF""] == nil // A correct option isnt selected for a true/false question valid = ""Please select a correct answer for all questions"" break end end end end return valid end. def validate_quiz num_quiz_questions = Assignment.find(params[:aid]).num_quiz_questions questionnaire = quiz_questionnaire num_quiz_questions if questionnaire.valid? return questionnaire end questionnaire_errors questionnaire end. All tests were implemented as part of spec/features/quiz_spec.rb and thoroughly cover the Use Case, scenarios, and sub flows listed above. A factory file, spec/factories/quiz_factory.rb was added to aid testing. <references/>.","This is a testing project, and the design doc has only 1 1/2 lines on testing! The document did not cover much detail on how this project is tested","Dear Student,

Great job on this assignment – it's clear that you have understood the task and provided a comprehensive analysis. I'm impressed with your detailed breakdown of the Expertiza project, your suggestions for refactoring, and your plan for implementing testing. 

However, there are still some areas for improvement:

1. The readability of your assignment can be greatly improved. It's recommended that you use bullet points or headings to distinguish between different sections. This will not only make it easier for the reader to navigate, but will also help you to structure your content more effectively. 

2. Be careful with the terminology, make sure it's used in the correct context. For example, when you mentioned, ""This is an <link> application and the code can be cloned from <link>"", it's not clear what application is being referred to. Make sure to fill in or describe what the link is supposed to direct to.

3. While you have made it clear that the aim of refactorization is to improve readability, DRYness, and maintainability, it would be helpful for you to give further examples illustrating how this process can help achieve these goals. 

4. Lastly, please remember to thoroughly proofread your assignments before submitting. There are numerous grammar, punctuation, and syntax errors scattered throughout the text that can hinder understanding. 

Remember that clarity and simplicity are key when conveying complex ideas and processes. Keep practicing and keep improving!

Best,
[Your Name]"
346,E1674,"Expertiza is a web application where students can submit and peer-review learning objects (articles, codes, websites, etc). Instructors add and edit assignments to Expertiza. Students can be assigned in teams based on their selection of the topics. The Expertiza project is supported by the National Science Foundation. Currently in this web application the leaderboard page does not work. As the guide of the director, we need to do the refactor and test only in this project, and the next step is to make the page work. The task of the project is to refactor leaderboard.rb and write unit tests for it. As the name of the methods are not in a standard style, we use snake_case for method names. There are also some useless assignments to several variables. 1. Refactor the leaderboard.rb 2. Create a RSpec file in /spec/models/ foler which contains unit test for leaderboard.rb. What we need to do is to deal with problems listed by the code climate. And we also need to write a new test file to test the functionality of leaderboard.rb. However, the leaderboard itself has some problems and IDE will report some problems when we want to run it. So we need to know which method in this file is broken first and just test others instead. As for this project, we use the code climate plugin to test if our code is good enough. This plugin will obviously help us with the refactor part because it can show which part of the original codes have some problems. We also search through the internet and get to know how to write the Rspec files. We also ended up using the 'rspec/collection_matchers' class of rspec which allows us to match the number of items in a collection for an object. We will list each kind of problems we solved below. As we all know the snake_case means we need to name the methods and variables in which elements are separated with one underscore character and no spaces. Each element's initial letter is usually lowercased within the compound and the first letter is either upper or lower case. For example, we changed this method. <code> Both variable names and method names are not in a good manner. We changed it to the version below. <code>. We deleted those variables since we only wanted what was being assigned to them. Before: <code> After: <code>. We know that 'each' function is more in ruby style for loops. So we would like to change all our 'for' to 'each'. <code> We changed this loop to: <code> And the problem would be fixed. <code> This is the third and fourth level of the block nesting. We need to merge them together. <code> Then the 4-levels loop has been changed to 3-levels one. An error occurred while attempting to extract the child content. The Leaderboard Class did not have any unit tests associated with it coming into this project so we have to create unit tests from scratch. Upon analysis of this class, we noticed that Leaderboard did not hold any variables and was only made up of static methods. So the first round of unit tests that were created made sure that each method could be called from the Leaderboard class with the correct number of arguments. <code> Next we needed to go through the methods and create tests for them. But in order to do this we had to make objects that this class depended on since this class takes the values from other classes to output arrays and hashes. Factories were used to create these objects with a few variables being overridden <code> We tested the methods by seeing whether if we got the right amount of elements in our arrays/hashes like the following. <code> We also tested whether the code could handle invalid arguments like such. <code> We did face situations where methods were being called that were not defined anywhere so we had to use stubs to imitate their expected behavior. <code>. To explain our work in a further step, we did a video on Youtube to show the broken leaderboard page, why we did work in this way and our work for the unit tests and the refactor part. There are still some problems we need to figure out. For the code revising part, there are some methods with this problem: Assignment Branch Condition size for get_participants_score is too high. I think we cannot make too many functions in one method so that we need to make some of these be executed outside of this method. Also, some of the code lines are too long so that it is not clear enough. During the rspec testing we noticed that the methods get_participant_entries_in_assignment_list and find_by_qtype were being called but where not created in the program. To cover these tests we had to use stubs for these methods for the expected outputs. There was also no declaration of ScoreCache anywhere in the program which caused other methods to fail. Trying to stub this was a problem since we were not sure of how it was laid out. 1. <link>.",The writeup clearly explains the modifications done.  The level of detail is appropriate.,"Dear student,

Great work on your assignment! The specificity and detail you provided regarding your work with the Expertiza web application are impressive. Your deep understanding and application of refactoring and testing concepts is clear in the assignment. 

You did an excellent job explaining what the methods and variables should look like in snake_case and showcasing how you implemented that standard in your assignment. The fact that you are able to identify areas that need improvement, such as method assignments that are too high and unclear code lines, shows your devotion to enhancing your skills.

However, make sure to give your full attention to every element of the assignment. I would suggest you being aware of the problem related to ""get_participant_entries_in_assignment_list"" and ""find_by_qtype"" methods that are getting called but not created. This needs to be thoroughly investigated and properly addressed.

In reference to your actual coding examples, there seems to be a mistake as the <<code>> tags are empty. This discrepancy makes it difficult to evaluate and understand the changes you intended to demonstrate. Please make sure you include the actual code within these tags for a more complete assignment in the future.

Finally, the usage of YouTube to showcase your work is an innovative approach for explaining your contributions. This also helps in better understanding and visualizing the complexities of the project.

Keep up the good work! Your commitment to learning is inspiring. I look forward to reviewing your future assignments."
347,E1703,"Currently, Expertiza doesn’t log anything, beyond the events in the console log. But often we need to know when a student logged in, reserved a topic, dropped off a team, etc. This will help the admin/instructor verify claims made by the student saying that he had submitted something or did some other activity that but didnt get reflected in expertiza due to a bug, a network issue or something else that went wrong. In a production environment, logs are the best way to debug the application when something goes wrong. In the absence of logs, it is very difficult for a developer/support technician to debug and analyze what went wrong. In a production environment, logs are the best way to debug the application when something goes wrong. In the absence of logs, it is very difficult for a developer/support technician to debug and analyze what went wrong. Logins, logouts, signups, submission of files/links (although there is already a log of when links are submitted), issuing invitations, joining teams, dropping off teams, requesting reviews, submitting reviews (or author feedback, or teammate reviews, or meta-reviews), undoing any of these operations. Creating/editing courses and assignments, giving grades, impersonating other users, adding TAs, adding participants to courses or assignments, assigning reviewers. <image> There are two parts to this project: 1. Logging the events and other information that will help in debugging 2. Creating a GUI to interpret the logs and show events for a particular user in a particular time frame. We are planning to use the logging framework that comes inbuilt with rails. Rails makes use of the ActiveSupport::Logger class to write log information. Each log statement in the program has a level associated with it which indicates their importance. The hierarchy of log messages is as below: 1. UNKNOWN : An unknown message that should always be logged. 2. FATAL : A unhandleable error that results in a program crash 3. ERROR : A handleable error condition 4. WARN : Warnings 5. INFO : Useful info about system operation 6. DEBUG : Low level info for developers to help with debugging. In the config file, we can specify the level of logs to be printed. A log statement in the program will be printed only if its level is equal to or higher than the level set in the config file. Usually in production, we set the level to INFO or WARN and in in a development environment, we set it to debug which will print out all the finer details of the state of the system which helps in debugging. Currently, the expertiza code contains very little logging statement and it does not record student/instructor or TA activity. The current logs are also of little or no help to a developer/ support technician trying to debug the code when something goes wrong. We plan on improving the current log statements by adding more information to it so that it becomes more useful to the person trying to debug the code and will also record all student, TA and instructor activities. We will also be adding more log statements which will make it easier to track all student, TA and instructor activities. For the second part of the project, we will create a view that is accessible only to the admin from his console. This view will list out the events by interpreting the logs and give an option to filter it based on user and date. <image> We are planning to standardize the log statements by giving them a predefined format. This will also help us in the second part of the project which is to interpret the logs and display student activities in a GUI. This is the format we propose: 1. INFO: <code> In the production environment, we will limit the logs to INFO mode, i.e it will print out only the errors and events. In development environment, we will set the logger mode to DEBUG. This will print out all the logs including errors, events and debug statements. This will help the developer in debugging the code when something goes wrong. This is the second part of the project. We will be creating a GUI to interpret and make sense of all the log data. The GUI will display the events for each user. We will also give an option to filter the event listing based on date and events. This is a rough sketch of what the page will look like: <image> It will have a text field to specify the user ID, a drop down menu to select the event and two date picker fields to specify the begin and end dates for the logs. We have also inserted new code in the following controllers: 1. application_controller.rb 2. admin_controller.rb 3. advice_controller.rb 4. assignment_questionnaire_controller.rb 5. assignment_signups_controller.rb 6. assignments_controller.rb 7. auth_controller.rb 8. course_controller.rb 9. impersonate_controller.rb 10. import_file_controller.rb 11. invitation_controller.rb 12. questionnaires_controller.rb 13. response_controller.rb 14. review_mapping_controller.rb 15. submitted_content_controller.rb 16. teams_controller.rb Defined a logger object in the application_controller that points to our new log file: events.log. Since this is defined in the application controller, it will be accessible in all the controllers and there is no need to redefine it again in the other controllers where we use it to log events. We have added a total of 45 logging statements for different events. The new code in the other controllers are simple logging statements to log events, does not affect the functionality of the existing code in any way. 1. logger_controller.rb We created a new controller for reading and filtering the log records. This has two actions, for viewing the logs and for filtering the logs based on input from the user. 1. log_entry.rb This model was created to represent each log statement in the record. It contains fields that pertain to a log entry like the time, userid, event and log description. 1. view_logs.html.erb This is the view we created for viewing the logs records. The used is also given an option to filter the logs based on time, userid, user type and event type. <image> Each log entry has a serial number, timestamp, name of the event, description of the event, type of the user involved in the event and userID of the user. We have provided the option to search the logs by user type, userID, event type and time. You can notice that there is a second search field below just above the table. It does an in page search of the results that are currently loaded. Its faster if you dont want the latest logs. It will search only the records that were present in the log file when the page was loaded. If you want to search the latest logs, i.e logs that have been added after the page was loaded, you need to use the first search button. This search will be comparatively slower as it involves a controller hit and redirection back to the view page. We have written a feature test in RSpec for the logger module. We have created a new class: logger_spec.rb for the test cases. If the user having less privileges than an admin tries to access the log viewer page, then he/she gets a authentication failure message. This project can be easily extended by adding more log statements to additional or new events by simply making a log entry with our logger object in the specified format. If proper format is followed, it will get picked up by the parser and will be visible in the view. We learned a lot doing this project. It was a good experience contributing to open source software. We got a chance to add an entire model, view and controller to the existing codebase. We also had to read through all the existing controller code to insert logging statements at proper locations to log user activity. This was a good learning experience.","The wiki page covers all necessary items, but ""test plan"" part can be more elaborated. And the last screenshot is useless, it will be better to show the db records, instead of table structure as mentioned during demo.","The assignment submitted provides a detailed account of the problem and proposes a practical solution to the issue. The plan to enhance the logging system of Expertiza both in terms of logging more useful data and presenting a user-friendly interface for reviewing those logs is well-constructed.

The detail of each part of the project has been well written. From defining the problem to the actions to be taken, the procedures, the integration into various controller files, and the planned GUI design have been well described. Fanatic use of technical jargon and terminologies show good subject knowledge. Images provided for explaining the expected outcomes would have helped make your write-up more understandable. 

Maintaining the standard for logging statements is a great idea, and your efforts towards creating a new model, view, and controller are commendable. The learning and experience you gained through this project reflects in your detailed approach.

Suggestion for future assignments:
- The write-up has repetitive lines, try to remain consistent without repetition.
- Remember to proofread your work before submission. 
- It would be more helpful if you could include some programming languages or pseudocodes to give vision to your ideas.

Keep up the good work! Your work demonstrates a good understanding of the problem and a thoughtful, well-planned solution."
348,E1756,"Expertiza is a Ruby on Rails based Open Source project. It is a collaboration tool which lets users with different roles (student, instructor, teaching assistant) to collaborate on a course in an institution. A collaboration could be for an assignment where students teams up for an assignment and instructors grades them on the basis of their submission. Students could review other's works and give feedbacks as well. <code>. <code>. response.rb is the default model to interact with the responses table, which stores the answers to every questionnaire. It is basically the alternate view. The content is displayed based on the user role. There are two important views, one for students and the other for instructors. What’s wrong with it? response.rb is a fairly complex file. It contains lots of methods that are long and hard to understand. These methods need to be broken down into simpler and more specific methods that are easier to read/understand. Also, the few instances of code duplication that exist should be removed. The response_spec.rb did not contain any test cases for the response.rb model except the mocks. Refactor display_as_html method Write failing tests first Split into several simpler methods and assign reasonable names Extract duplicated code into separate methods. Refactor self.get_volume_of_review_comments method Write failing tests first Convert duplicated code into loop. Rename method and change all other places it is used Write failing tests first get_total_score → total_score get_average_score → average_score get_maximum_score → maximum_score. Use sort_by(&:seq) instead of sort { |a, b| a.seq <=> b.seq } Write failing tests first. Use find_by instead of where.first Write failing tests first. The display_as_html method has been modified. The existing logic for display_as_html method has been refactored into two different methods called construct_instructor_html and construct_student_html. Both these methods are generating html content to be displayed based on the identifier parameter passed to the function. The logic of displaying review, which was earlier in the display_as_html method has been included in another method called construct_review_response. The get_volume_of_review_comments method has been modified by putting the repeated statements in to a loop which runs on variable i. The variable names are now created based on the number of reviews. The methods get_total_score, get_average_score and get_maximum_score have been changed to total_score,average_score and maximum_score. The changes have been made in all the places wherever these methods are called. The method 'where' in significant_difference? method has been changed to find_by. The sort method which was in display_as_html method has been changed to sort_by. The sort_by method is present in construct_review_response refactored method. app/models/response.rb. app/models/response.rb. app/controllers/assessment360_controller.rb app/controllers/popup_controller.rb app/helpers/review_mapping_helper.rb app/models/collusion_cycle.rb spec/models/response_spec.rb. app/models/response.rb. app/models/response.rb. Problem 1: The method display_as_html is complex. Many functions are embedded in to a single method. The test cases of response.rb file have been implemented. All the contexts of response_spec.rb pass with the overall coverage of 27.16%. The pre conditions and edge cases for test scenarios are not applicable because the project includes refactoring and testing the refactored methods. <table>. 1. Login as an instructor. Create a new course and create a new team/individual assignment for that course. 2. Add participants to the assignment created. 3. Set the submission and review deadlines, number of submissions, rubrics for reviews, number of reviews and all the other fields for the assignment. 4. Login as a student_1, who has been added as a participant in the created assignment. 5. Now the student_1 will be able to see the assignment, form the team and submit the work. 6. After other students also submit their work, student_1 will be able to review others work and see his reviews given by others. 7. The page which displays the reviews is linked to the model which we have refactored(response.rb). In order to verify the refactoring, please perform the above steps before and after executing our code. <code>. <code>.","The section headers should be more informative.  ""Problem 1"", ""Decision 2"", etc. does not help the reader understand what the sections are about.  When you describe refactorings, it would help to include code snippets, or at least links as you have done in the next section.  Also, it is not clear how the ""Issue and Solution"" section relates to the rest of the document.  Does it cover the same problems as above?  It seems that you have done a lot of work, but the writeup leaves too much for the reader to figure out.","Great work on your assignment! You've clearly shown that you understand how the project works and what needs to be improved. Your explanation of the Expertiza tool, the problems present in the codebase, and your proposed solutions for these problems is thorough and well-reasoned. You've clearly identified the areas of the code that need refactoring, suggested sensible code improvements, and demonstrated an understanding of the importance of testing.

Here are a few feedback points and suggestions for you to consider:

1. While working on refactoring, always ensure that no functionality is compromised in the process. Validate this with appropriate testing.

2. While the problem with the `display_as_html` method was well recognized, it would be great for you to explain why it's problematic to have a complex method such as this one. This explanation would add strength to your proposal for the method refactoring.

3. Your testing coverage is at 27.16%. You mentioned that you have written tests for your refactored methods. However, strive to create more tests to improve this number. Remember, high code coverage is not an indicator of good tests, but having low coverage is usually a sign of insufficient testing.

4. While you've done an excellent job providing the test steps for manual testing, try to consider writing unit tests that can automate these steps. Automated testing would help to catch regressions in the future and would be more efficient.

Overall, you have a thorough grasp of the topic, and the assignment was well executed. Keep up the good work!"
350,E1827,"The following credentials are recommended for testing the changes: 1. Instructor Login: username: instructor6 password: password 2. Youtube link: <link>. Expertiza is a web portal which can be used to manage assignments related to a course. It provides a platform to view assignments, manage teams, select topics and work on improvement through anonymous peer reviews. Expertiza allows the instructor to define different topics that students or teams could choose from as their assignment. Each topic can have 0 or more slots that indicate the number of students or teams that can sign up for that topic. We identified several ideas that can improve user experience when managing the topics. Thus, we would like you to introduce new features to implement these ideas. 1. Issue #971 Change create topic UI into AJAX. 1. Issue #926 We need a way to sort topics by topic number in assignment#edit page. 1. Issue #718 We should allow instructors to give feedback when accepting or rejecting topic suggestions. The following files were modified 1. app/views/sign_up_sheet/_add_signup_topics.html.erb 2. app/views/sign_up_sheet/_table_header.html.erb 3. app/views/sign_up_sheet/_table_line.html.erb 4. app/controllers/sign_up_sheet_controller.rb 5. app/views/assignments/edit.html.erb 6. app/controllers/assignments_controller.rb 7. app/views/suggestion/list.html.erb 8. app/controllers/suggestion_controller.rb 9. db/schema.rb. The following files were added 1. db/migrate/20181027001119_add_feedback_to_suggestion.rb. Currently, when instructors manually enter topics, they have to go back and forth between the list of the topic page (views>sign_up_sheet>_add_signup_topics.html.erb) and the create topic page (views>sign_up_sheet>new.html.erb). This should be done via AJAX so that the adding a new topic can be done through an editable grid or a popup form without leaving the list of topic page. Then and the list should be automatically updated when a new topic is entered. In addition, when adding a topic, the default slot should be 1 instead of 0. the current warning message that shows up when the slot is 0, can't be closed properly and should be fixed (if the form is made popup in the future, the warning should be on the same page as the form e.g., highlight the field and print an instruction to change the # of slot). On the file app/views/assignments/edit.html.erb we added an additional editable <tr> table element which is appended to the table when the add button is clicked in the topics table. It submits a ajax request when the 'save topic button is clicked' <code> On the file app/views/assignments/_table_header.html.erb we added an additional editable <th> table element which adds a add topic button which toggles the editable row for creating topics. <code> On the file app/views/assignments/_add_signup_topics.html.erb we initialize the new topic with max_choosers as 1. <code>. <image>. <image>. The task is to sort the Topics according to the topic number. This functionality is added using Tablesorter css, where clicking the topic# will toggle the topics in the ascending/descending order. To use Tablesorter in app/views/sign_up_sheet/_add_signup_topics.html.erb, we added this script:- <code> And made this change to the current table in html:- <code> Then to make Topic to be sortable, we added this in app/views/sign_up_sheet/_table_header.html.erb:- <code> Sorting in ascending order :- <image> Sorting in descending order :- <image>. We should allow instructors to give feedback when accepting or rejecting topic suggestions. As it is, one can give feedback on topics suggested by students only when the instructor wants the topic to be revised, not when (s)he is approving or rejecting it. Feedback should be possible in any of these cases. On the file app/views/suggestion/list.html.erb ,added an additional editable textbox and a submit button. On click of the button the feedback provided in the text box is saved to the database in a table name suggestions, column name feedback. <code> On the file app/controllers/suggestion_controller.rb ,added an additional method to save the changes in the feedback text box to database. <code> On the file db/migrate/20181027001119_add_feedback_to_suggestion.rb ,added migration scripts. Script is adding a column name ""feedback"" in the suggestions table. <code> On the file expertiza/db/schema.rb ,schema changes as effect of adding column in table suggestions. <code>. <image>. <image>. 1. Login as an instructor. 2. Click Assignments tab next to Courses 3. Select the assignment for which a new topic has to be added 4. Click the edit icon for the assignment and go to Topics tab 5. You will be able to see the topics list in a table format. Click on add icon on the right side corner of the table header 6. Fill in the details and click save topic If a user tries to set number of slots as zero, a warning pops up and prohibits the user from doing so. <image>. As we have shown this in video:- 1. Login as an instructor. 2. Click Assignments tab next to Courses 3. Click the edit icon for the specific assignment and go to Topics tab 4. You will be able to see the topics list in a table format sorted in ascending order by 'Topic# '. 5. Click on 'Topic# ' icon to sort the table in descending order based on 'Topic# ', and if you click it again after that it sorts the table in ascending order based on 'Topic# '. 1. Login as an instructor. 2. Click Manage -> Assignments. 3. After clicking on the Assignment tab, a page will show all the assignments. 4. Click the view suggestions icon on the right bottom corner. 5. You will be able to see a list of suggestions given by the students for that particular topic. 6. Add feedback in the feedback text box and click save feedback button to save it. 7. To verify if the feedback was saved to the table, query suggestions table and match the feedback in the feedback column to the feedback given.","The write up is very well written, it includes pieces of code and screenshots of the UI both before and after changes. I think it is sufficiently detailed. They also have a test plan section explaining the cases they have tested manually.","Thanks for your submission. It is very detailed and you've obviously put a lot of thought into it. Here are a few suggestions to further enhance your work:

1. For consistency, fix the numbering issue under the listed issues that need to be resolved on Expertiza. Each new issue should start with a new number rather than repeating ""1"".

2. It would be beneficial to add some code snippets for important changes made to the files. This will provide a clear portrayal of the resolved issues. 

3. Excellent job on the task to sort the topics according to the topic number. However, suitable code snippets would have further improved readability and understanding. 

4. Avoid explaining the additions made to each file in a condensed paragraph. Instead, explain how your code changes address the issues mentioned. This will make it easier to understand how your changes are addressing the problems. 

5. Great job on the addition of a feedback column. However, it would have been helpful to include a snippet of this new feature in action. 

6. Test your changes thoroughly to minimize the chances of bugs slipping through. Ensure that all features work as expected, and proofread your changes to the UI. 

7. Finally, your video walkthrough seems valuable; however, there's no link provided. In future, do include the required links. 

Keep up the good efforts. You've done a great job on improving the system's functionality!"
351,E1872,"The expertiza project takes advantage of peer-review among students to allow them to learn from each other. To track the review time that each student spend on each submitted resources is meaningful for instructors to study and improve the teaching experience. The previous team working on the project has solved part of such problems by tracking the active time of windows opened from the submitted links by till the window is closed or gives a periodic pop up to ask if the user is still reviewing. And thus records the end time. It is done using mature third-party APIs to record link review time. In this project, we require to conglomerate the details of each review given by a student on the existing Review Report page. This will ease the task for the instructor to get the insights of a review on one single page in order to grade the student based on his/her review. To accomplish this goal, here are the general solutions designed and implemented in this project: 1. Designed and implemented toggle view component using Javascript and Ruby to open students’ reviews inside the review report table 1. Used DOM to calculate and display the total time spent on the review per round. 1. Modify Review report (views/review_mapping/_review_report.html.erb) to show the total and detailed time spent on each review submissions. <image> <image>. Objective 1: The details of time spent on every assignment is displayed separately on the reviewer report page. As this is inconvenient we have to display all the statistics on the review report page. Proposed Solution: 1. We have added a link below the student ID in the first column of the review report page for each assignment. 2. This is a toggle-able link and is available to each student details uniquely as shows below: <image> 1. Clicking on the link will toggle between showing/hiding a new column containing the review details to the table. <image> 1. The table contains the details regarding the team reviewed, round number of the review, total time spent on reviewing and time spent reviewing each link in the submission. <image> Files needed to be changed: review_mapping/_review_report.html.erb. Files Changed: review_mapping/_review_report.html.erb - This is the file for the review report. We have added the functionality of a toggle link below each student id in the first column. Clicking on this link will display the details of the reviews done by this student. On clicking again the details will disappear, giving the user the flexibility of viewing these details if need be. The design makes use of the following models: 1. Participant 2. ResponseMap 3. ResponseTime 4. Assignment 5. Team First we fetch all the reviews done by the student by providing the user_id of the student to Participant which gives us the set of reviews done by that user. Then we iterate through these reviews. As reviews are based on the number of review rounds in the Assignment, we fetch the total number of review rounds for the current assignment from the Assignment model by fetching the current Assignment object using assignment id and then accessing the 'round_of_reviews' property of the object. The details of each review like the reviewer_id, reviewee_id , reviewed_object_id is stored in the ResponseMap model. We fetch the ResponseMap set for each such review from the ResponseMap by giving it reviewer_id and reviewed_object_id as the assignment id. Now we iterate through this set of ResponseMaps. The data for the link reviewed and the time taken for each link is in ResponseTime model which is linked to the ResponseMap through map_id. We make use of this and for each ResponseMap we put in a loop to get all possible ResponseTime for every link reviewed by the student. Finally we display this whole thing in the form of a table with the headers: 1. Team Reviewed : This is the team reviewed by the student. We get the team name by passing reviewee_id found in each ResponseMap to the Team model. 2. Total Time(mins) : This is the total time spent by the student in reviewing this team. We have written custom Javascript functions to calculate total time by adding time spent on individual links. 3. Round : This is the review round number for which this review has been performed. 4. Links : This will give you a list of links one after the other which the student has reviewed. These links are found as entries in the ResponseTime model with other information as well. 5. Time spent per link (mins) : This is the time spent in reviewing each link. Again we have written functions in embedded Ruby to calculate time in mins using the start and end times of reviewing this link. Algorithm: <code>. UI and Manual Testing: Steps: Login as Instructor - <code> 1. Create an assignment and make sure it currently has its 'Review' phase going on. 2. Add participants to the assignment and remember their names or ids. 3. Logout Login as Student who is added to the assignment - <code> 1. Go to the newly added assignment in your pending tasks(the pending task should be that of reviewing). 2. Ask for a team to review. 3. Go to each link submitted by this team and review it. If needed, note down the time spent on each link. 4. Logout. Login as Instructor - <code> 1. Navigate to the 'Review Report' page of the assignment. 2. Search for the above student in the table. 3. Click on the link named 'Review time spent on task' below the student name. Expected - A new column should be added to the table with the information regarding the reviewed team and the time spent per link and in total. 1. <link> 2. <link>.","The document does an excellent job of describing the changes to be made.  It could be enhanced by including links to code snippets in Github.  More should be said about the tests, as mentioned by several reviewers.","Dear Student,

Thank you for your detailed assignment submission on enhancing the existing review report page that aims to track the review time for each student. Your work encapsulates numerous layers of complexity, from designing and implementing new components to modifying existing files and showing the total and detailed time each student spent on their reviews. 

The proposed solution you have given to display all the statistics on the review report page is quite innovative. The use of a toggle-able link to display review details is both user-friendly and efficient. 

Your sequential step-by-step process to access, process and display the required data clearly demonstrates your grasp of the design architectures, and your understanding of working with models like Participant, ResponseMap, ResponseTime, Assignment and Team is commendable. The breakdown of the information to be displayed on the table, such as team reviewed, total time spent, review round number, links, time spent etc., is thoughtful and shows a clear understanding of the assignment requirements.

The illustration of the UI and Manual Testing steps also showcases your comprehension of the project lifecycle, and adds more depth to your assignment. Your diligence in providing an algorithm and subsequent code for the task at hand is also highly appreciated.

However, there are few areas of improvement. It is recommended if you could provide potential challenges that you might encounter in this implementation, or any assumptions you have made. Additionally, kindly ensure to correct the numbering in your report, the indentation looks inconsistent. Lastly, providing pseudo code or flowcharts might help enhance the understanding of your solution.

Great effort overall on the assignment. Keep up the good work! 

Best,
[Your Name]"
352,E1905,"The questionnaires controller had several issues; this project aimed to address some of them, including: 1. Remove or move logic that should reside elsewhere, e.g. in a model class. 2. Remove logic and references to logic that is no longer being used. 1. app/controllers/questionnaires_controller.rb 2. app/models/questionnaire.rb 3. app/views/questionnaires/_questionnaire.html.erb 4. app/views/questionnaires/edit_questionnaire.html.erb (deleted) 5. spec/controllers/questionnaires_controller_spec.rb 6. spec/models/questionnaire_spec.rb. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. 1. There were two methods copy and copy_questionnaire_details present in app/controllers/questionnaire_controller.rb which implemented just one functionality of making a copy of a particular questionnaire. 2. There was no need of two methods in the controller itself. Also, some parts of what was happening needed to be in the model. 1. Nothing special was happening in the copy_questionnaire_details method. Also, it needed to be placed into the model because of the nature of things happening inside it. 2. So, now we have one method copy in the controller, which calls the copy_questionnaire_details method, which is present in the Questionnaire model. The instructor_id as well as the params are passed as arguments to the copy_questionnaire_details method. 3. The other methods that the older copy_questionnaire_details methods used to call, like assign_instructor_id were removed in the changes above and they are now included in the method in the model itself. 4. The Exception (if it occurs while saving the Questionnaire object) is being handled in the copy method of the controller so that the user can be redirected easily. 1. There were parts of the code, specifically when QuizQuestionChoice was created, which was copied throughout the questionnaires_controller.rb. 1. To make the code DRYer, the repeating code sequences were added into a function called create_quiz_question_choice . 2. Calls were made to this method wherever QuizQuestionChoice was made. There is no means of testing the removal of dead code, except to run the existing suite of test cases: <code> Removal of the assign_instructor_id method can be tested by running test cases for the questionnaires controller, since existing test cases rely on the instructor ID being retrieved correctly: <code> Testing the method create_quiz_question_choice can likewise be done with this command. The logic associated with getting the instructor ID from a user is tested using <code> The additions to the questionnaires model can be tested using <code> Note: If you are having difficulties running the rspec command, try using <code> instead. This will use the gems specified in Gemfile that were installed via bundle install . Also, tests were included for the code movement from the questionnaires controller to the questionnaire model. Checks were being made for database calls in the controller rspec method, the same format was followed while writing tests for the moved methods.","Good description of what was done to address the first few issues, but making code DRYer needed snippets of the code you changed (paste in relevant lines, etc.).","Dear student,

Thanks for submitting your assignment. Your project shows a commendable effort in addressing the issues in the questionnaires controller. Your move to eliminate redundancy by combining the ‘copy’ and ‘copy_questionnaire_details’ methods into one is efficient and it's good practice to shift methods appropriately into the model as you did. Good job!

Additionally, the creation of the ‘create_quiz_question_choice’ function is a good use of the DRY principle in coding, eliminating duplicate code effectively.

However, in your explanation, there is some repetition and it could be more succinct. For instance, you've repeated an error message ""An error occurred while attempting to extract the child content"". If it's related to the assignment, can you provide more explanation about what it means and how you addressed it?

In testing, it is important to make assertions to check if the method has performed as expected. It would be great if you can specify what assertions are being made in your test cases. You also mentioned that tests were created for the code shifted from the controller to the model, but you didn’t disclose any specifics about the tests. 

Finally, keep in mind that good documentation is like a good conversation. It would be beneficial if you could add more comments to your code. Overall, you made commendable progress in your assignment and it's evident that you've put in a lot of work. Keep it up!

Best,
[Your Name]"
353,E1820,"Expertiza is an open source project that can be used by instructors to create assignments and assign them to students. Students can manage teams for the assignment and submit work for each of the assignments. After the students have submitted their work they can review other student's work to facilitate grading. The project is based on the <link> framework. You can find our <link> . Tone analysis is a tool that is used to measure the sentiment or tone of a sentence. This will be used in expertiza to help determine the tone of the review comments to determine if the feedback is useful. Since implementing a working tone analysis tool would be a project on its own we will use one that is already implemented through an NC State University project called <link> . Peer logic is going to be used to implement tone analysis throughout this project. The peer logic web service is able to provide colored HTML text based on the tone by sending a POST request of a JSON {“review”: “review comments….”} to an API endpoint <link> . The JSON data that is returned will be used to determine coloration of the cells that are displayed in the popup views as well as in the table. For reference, Peer logic assigns green to a positive tone, yellow to a moderate tone, and red to a negative tone. The basis of this project was to clean up the table in view_review_scores_popup_.html.rb . Currently, the table is very simple and unorganized, reducing its readability. There are incomplete table borders, misaligned cells, and HTML tags littered throughout the text. The other task is to create a pop up under the metrics column for the ""_answer_tagging_report.html.erb"" to show a condensed table of the tone analysis report for all the comments from one reviewer. The purpose of these changes is to help facilitate the grading of review feedback by instructors. The color coding of the tone analysis report will help see which reviews contain things like positive feedback, criticism, etc. These changes should make the grading easier for the instructors. view/popup/view_review_scores_popup.html.erb view/review_mapping/_answer_tagging_report.html.erb. The UML diagram regarding the scope of our project is included below. Overall, an existing view will be modified, and a new one will be created. Both of these views are associated with the popup_controller , which, as a result, will also be modified accordingly. We will put the code for the PeerLogic request in the controller using <link> , a jQuery API used to make HTTP requests. This request will form the majority of the backend requests we have to make in addition to the formatting that will need to be done to the data. This formatting is shown in the wireframes. <image>. These wireframes show the flow of the user to each of the updated views. You can see the implementation of the colored grid showing the tone analysis report. You can also see that clicking on one of the grid squares shows the full text of the comment. To organize each of the review rounds we felt that it would easiest to use tabs to separate them. We chose tabs over a drop-down box because of the ease of organization and also there is already a rails library that will make this easy to implement. You can also see that clicking on the summary link under the 'reviews done' column will take you to a summary of the Review Scores page which shows the highlighted text based on the tone analysis report. This is the table that will be cleaned up to make it more user-friendly. This includes removing HTML tags, adding the color coding from the tone analysis report, and general formatting issues. We have tried to illustrate all of these changes in the wireframe. <image>. We currently have one acceptance test for each of the added methods. However we believe that it should be tested more extensively. We have added some suggested tests below. <code> <code> <code> <code> <code> <code>.","The design doc unfortunately does not explain how the code works.  It just lists files modified, and does not explain how this project's code calls the web service, and how it uses the objects that it gets back.  It would be very helpful if the design doc contained actual screenshots instead of mockups.  It would also be good if the test plan had enough carriage returns to keep text from spilling over the right edge of the boxes","You've done a commendable job on this assignment, providing a thorough overview of how the expertiza platform works, as well as your plans for improving it. You have done a great job integrating tone analysis via the Peer Logic tool, and the way you explained this integration into the assignment demonstrates a sound understanding of how Peer Logic could benefit educators. This project has vast potential for automating the review process, and your initiative to use color-coding is particularly noteworthy. 

You've correctly identified the current issues with the table in view_review_scores_popup_.html.rb, and I'm delighted to see that your proposed changes are focused on enhancing user experience, specifically readability. 

Your discussion about creating a popup under the metrics column to show a condensed table of the tone analysis report was interesting. It'd be even better if you could clarify and provide more detail on how this was achieved.

The UML diagram and the flow images for the wireframes provided a clear vision of your project and its execution. It would have been helpful if you had attached the actual UML diagram and wireframe images for me to review, as they are vital for understanding your project's layout at both code and UI level. 

The testing section of your assignment is sustainable, but it's quite theoretical. I'd highly recommend allocating more time to describe the actual tests and share the code you've written. Remember, concrete examples are helpful in demonstrating your understanding. 

Overall, it's clear that you have a strong foundation and that you've thought this project through. Just remember to provide visuals where relevant and more context around your implementation details to help illustrate your strategies better. Keep up the good work!"
354,E1875,"In the first round of Expertiza reviews, we ask reviewers to give authors some guidance on how to improve their work. Then in the second round, reviewers rate how well authors have followed their suggestions. We could carry the interaction one step further if we asked authors to make up a revision plan based on the first-round reviews. That is, authors would say what they were planning to do to improve their work. Then second-round reviewers would assess how well they did it. In essence, this means that authors would be adding criteria to the second-round rubric that applied only to their submission. We are interested in having this implemented and used in a class so that we can study its effect. 1. Develop UI for authors to create new questions to add to the second round-rubric. This should be a form that includes the following: 1.1. A description of the revision plan. Eg: We will add feature X to address issues a,b and c. We will modify feature Y and expect it to resolve errors d, c and e. 1.2. One or more questions for every proposed improvement. Example: 1.1.1. How effectively did feature X address / solve issues a, b and c? 1.1.2. Did modification of feature Y resolve error d? 2. The new questionnaire must be linked to the second-round questionnaire. 3. The new questionnaire must be part of the team's submission records. In the 2nd round of reviews, the Author should be able to add a statement to direct towards Author selected improvements from Round 1 to Round 2. The OSS and Final projects are different for every team. From a reviewers perspective, not all questions make sense for all projects. The motivation behind this project is: 1. Questions unique to each project gives the reviewers a perspective on the author’s objectives. 2. Allow the Author to get feedback on whether or not they accomplished their self-directed goal. This project has been extended and reworked under Independent Study in Spring 2019. 1. Direct user to Revision Planning Questionnaire. 2. Create a form for the Assignment Team to add Questions to a Questionnaire that are specific to that Submission in the second round of submission. 3. Append Revision Planning Questionnaire to 2nd Round Review Questionnaire. The first image shows a mockup of what the Author will see on the submission page to submit new additional questions for review. <image> Second is a view of what the reviewer will see. It should blend in with the review questions submitted by the instructor for all similar projects. <image>. 1. <link> 2. <link> 3. <link>. 1. <link> 2. <link> 3. <link>. 1. <link> 2. <link>. 1. <link>. 1. <link>. 1. <link>. 1. Login as 'super_administrator2' with password 'password'. 2. Make an assignment with the name 'Assignment1'. 3. Make the following selections: 1.1. Review Strategy: Allow authors to add to rubric. 1.2. Rubric: Rubric varies by round. 1.3. Add participants: Add existing students - student1, student2 1.4. Due Dates: Add deadlines for rounds. 1.5. Add topics to the assignment 4. Set 2 rounds of submissions and reviews. 5. Impersonate student1. 6. Signup for topic and form team. 7. Make submissions in round 1 submission. 8. Move to round 1 review stage. 9. Impersonate student2. 10. Make submissions in round 1 and review it. 11. Move to round 2 submission stage 12. Impersonate student1. 13. Submit a revision plan in the 'Your Work' handle. 14. Repeat above two steps for student2. 15. Move to round 2 review. 16. Impersonate student2. 17. Verify that revision plan questions are added to the review by student1'team and submit the review. 18. impersonate student1. 19. Repeat the above two steps for student1. 20. Verify that review has been received on the revision plan questions after assignment is finished. 1. <link>.","This document is fairly short.  It does not describe how the code has been changed, but rather just links to files in Github.  That is good, in the sense that the Github display is much easier to read than snippets pasted into the design doc.  But just reading one file after another doesn't help the reader understand how the code fits together.  Some narration is needed.  Reviewers were fairly pleased with the test plan.  It should have been mentioned whether the test plan referred to automated or (more likely) manual tests.  What the automated tests tested should have been defined.","Dear Student,

Thank you for your detailed response. It is clear that you invested a significant amount of time and energy into the task. You have demonstrated a firm grasp on the assignment. The way you outlined the UI you wish to develop is to be commended.

Let’s go over a few points you should consider in order to improve your assignment:

1. Please provide more clarity on what the graphics in your assignment represent. You have mentioned a few images and links in the assignment, but these were not included in your submission. Please update your submission with the relevant information if applicable.

2. The section about the motivation behind this project could use more elaboration. Try providing detailed insights into how these unique situation-oriented questions will provide an understanding of the author’s objectives and how feedback will help them accomplish their self-directed goal.

3. Please ensure that you properly explain the implementation details. This will help in understanding the work-flow of the user interface you are trying to create. 
        
4. The comprehensive set of steps that you have provided for testing the implementation seems very practical. However, please include more details on the expected outcomes after each action. This will help you to ensure that the test is being carried out correctly.

Overall, you’ve made a solid start, but flushing out the aforementioned ideas will make your project much stronger. Keep up the good work and I look forward to seeing your revised work.

Best regards,
[Your Name]"
355,E1902,"<link> is an open source project developed using Ruby on Rails framework.Expertiza allows the instructor to create new assignments and customize new or existing assignments.The application allows students to submit and peer-review learning objects (articles, code, web sites, etc)[1].Expertiza supports submission across various document types, including the URLs and wiki pages. When students' accounts are created by importing a CSV file on the Users page, they receive e-mails with their user-ID and password. But if an account is created by adding them as participants to an assignment when they don't already have an account, e-mail is not sent. Students should receive e-mails upon account creation, regardless of how their account is created. So this involves adding a call to the e-mailer … or, perhaps, moving an email call from the Users controller to the point where an account is actually created. Second, evidently if a submission is revised after review, the system e-mails the reviewer saying to revise the review. This is just fine ... except if the last round of review is in progress.The message telling reviewers to revise their reviews should not be sent after the last review deadline has passed. It would also be nice to fix the message so it tells which review (Review 1, Review 2, etc.) has been revised, and gives the reviewer a link directly to it. Deadline reminders should include a link on where to go to perform the needed function. Modified Files 1.1. app/models/assignment_participant.rb 1.2. app/models/assignment.rb 1.3. app/models/course_participant.rb 1.4. app/controllers/submitted_content_controller.rb 1.5. app/mailers/delayed_mailer.rb 1.6. lib/tasks/background_email_reminder.rake 1.7. spec/models/assignment_particpant_spec.rb Implementation approach 1) Email sent when user is added as a participant to assignment : When students' accounts are created by importing a CSV file on the Users page,they receive e-mails but not when user was added as a participant to the assignment. We added a method in the assignment_participant.rb file (model) to send mails when a participant is added to an assignment on the assignment page by importing a CSV file. We have also added a method in the course_participant.rb file(model), to send the mail when a Course participant is added by importing a CSV file. Both functionalities are implemented using the method from the MailerHelper class i.e send_mail_to_user(). 2) Sending email to reviewer when new submission is availble: Added functionality to send email to the reviewer when new submission is available by making changes in the submitted_content_controller and assignment_participant model.The method handled boundary constraints like checking whether the round was valid and disabling email notification after the last round of review. Code to check if it was the valid round In the assignment_participant.rb, Firstly, fetched the topic_id from the SignedUpTeam class and got the next due date using the DueDate model Finally compared the round of the Due date with the number of review rounds of the assignments, to verify if its the final round. Extra functionality of specifying the current review round and providing the direct link to reviewer in the mail itself also implemented in the submitted_content controller using the ReviewResponseMap and Response class. In the submitted_content_controller.rb, We mapped the reviewer_id and reviewee_id, fetched from participants, using the ReviewResponseMap class. For all such mappings retrieved, we are fetching the last response id, which is then passed as the URL suffix to redirect the reviewer to the appropriate page. 3) Including a specific link for the deadline reminders email functionality for reviewers : Added a review_reminder_email method and mail_reviewers method in the delayed_mailer.rb file which implemented the functionality for sending deadline reminder mails which includes a link on where to go and perform the specific task. Prepared a hash named email_list using the email and participant_id, for each participant who is a reviewer. Using this hash, we are calling the review_reminder_email function. In this function, based on the due date for the deadline_type(i.e reviewer), we fetch the participant id of the same and add it as the suffix in the URL to be visited by the reviewer. Also, the logic of the copy of mail to the instructor is also taken care. Notice that the link in the instructor's email will contain the '?id=' field of the last participant fetched. In the background_email_reminder.rake file, Earlier only the emails for the participants were fetched, but now we are fetching the hash containing the email and response_id. The response_id field was fetched as per the below order in the code- participants.review_mappings -> allresponsemaps -> eachresponsemap -> response. For the reviewer assign_type, we have defined a separate method send_reminder_emails(), wherein we pass the response_id of the email_list hash, and add it as a suffix in the URL which will be accessed by the reviewer. NOTE: All the mails except the ones for the reviewer which are sent to mailinator are sent to expertiza.development@gmail.com ,as this is already set in the development environment. Testing We have used Rspec for testing the email functionalities.Using the test driven development(TDD) approach, we have added an Rspec test which checks whether the mail is delivered to the expected receiver upon creation of the account for the student. We have created a new assignment_particpant_ spec file for the above purpose.The spec uses double and stub features of rspec gem to fake user login. Since the smtp setting are set to test mode all mails go to expertiza.development@gmail.com and not the actual user.Hence when an email is sent the ActionMailer::Base.deliveries list gets updated.The last element in the deliveries list will be the email that was sent when the import method was invoked. Then using expect object we verify whether the email was correctly sent by checking the subject, from and to field. Additional Links 1.1. Git pull link: <link> References 1.1. <link> 1.2. <link> 1.3. <link> 1.4. <link> Team <link> <link> <link>. 1. app/models/assignment_participant.rb 2. app/models/assignment.rb 3. app/models/course_participant.rb 4. app/controllers/submitted_content_controller.rb 5. app/mailers/delayed_mailer.rb 6. lib/tasks/background_email_reminder.rake 7. spec/models/assignment_particpant_spec.rb. 1) Email sent when user is added as a participant to assignment : When students' accounts are created by importing a CSV file on the Users page,they receive e-mails but not when user was added as a participant to the assignment. We added a method in the assignment_participant.rb file (model) to send mails when a participant is added to an assignment on the assignment page by importing a CSV file. We have also added a method in the course_participant.rb file(model), to send the mail when a Course participant is added by importing a CSV file. Both functionalities are implemented using the method from the MailerHelper class i.e send_mail_to_user(). 2) Sending email to reviewer when new submission is availble: Added functionality to send email to the reviewer when new submission is available by making changes in the submitted_content_controller and assignment_participant model.The method handled boundary constraints like checking whether the round was valid and disabling email notification after the last round of review. Code to check if it was the valid round In the assignment_participant.rb, Firstly, fetched the topic_id from the SignedUpTeam class and got the next due date using the DueDate model Finally compared the round of the Due date with the number of review rounds of the assignments, to verify if its the final round. Extra functionality of specifying the current review round and providing the direct link to reviewer in the mail itself also implemented in the submitted_content controller using the ReviewResponseMap and Response class. In the submitted_content_controller.rb, We mapped the reviewer_id and reviewee_id, fetched from participants, using the ReviewResponseMap class. For all such mappings retrieved, we are fetching the last response id, which is then passed as the URL suffix to redirect the reviewer to the appropriate page. 3) Including a specific link for the deadline reminders email functionality for reviewers : Added a review_reminder_email method and mail_reviewers method in the delayed_mailer.rb file which implemented the functionality for sending deadline reminder mails which includes a link on where to go and perform the specific task. Prepared a hash named email_list using the email and participant_id, for each participant who is a reviewer. Using this hash, we are calling the review_reminder_email function. In this function, based on the due date for the deadline_type(i.e reviewer), we fetch the participant id of the same and add it as the suffix in the URL to be visited by the reviewer. Also, the logic of the copy of mail to the instructor is also taken care. Notice that the link in the instructor's email will contain the '?id=' field of the last participant fetched. In the background_email_reminder.rake file, Earlier only the emails for the participants were fetched, but now we are fetching the hash containing the email and response_id. The response_id field was fetched as per the below order in the code- participants.review_mappings -> allresponsemaps -> eachresponsemap -> response. For the reviewer assign_type, we have defined a separate method send_reminder_emails(), wherein we pass the response_id of the email_list hash, and add it as a suffix in the URL which will be accessed by the reviewer. NOTE: All the mails except the ones for the reviewer which are sent to mailinator are sent to expertiza.development@gmail.com ,as this is already set in the development environment. We have used Rspec for testing the email functionalities.Using the test driven development(TDD) approach, we have added an Rspec test which checks whether the mail is delivered to the expected receiver upon creation of the account for the student. We have created a new assignment_particpant_ spec file for the above purpose.The spec uses double and stub features of rspec gem to fake user login. Since the smtp setting are set to test mode all mails go to expertiza.development@gmail.com and not the actual user.Hence when an email is sent the ActionMailer::Base.deliveries list gets updated.The last element in the deliveries list will be the email that was sent when the import method was invoked. Then using expect object we verify whether the email was correctly sent by checking the subject, from and to field. 1. Git pull link: <link>. 1. <link> 2. <link> 3. <link> 4. <link>.","Good description of the changes to be made.  I would suggest writing ""Implementation approach"" in present tense. In contrast to many documents that have long sequences of code without any explanation, yours has explanations without any references to the code.  Showing code snippets would be helpful.","Your project demonstrates a good understanding of the Ruby on Rails framework and how to implement email functionalities in an application. You have done well addressing several issues within Expertiza that needed improvement, such as sending emails when a user is added as a participant to an assignment, refined review notifications, and adding convenient links to deadline reminders.

One thing to note is the clarity and organization of your report. It was quite thorough, but at times, it was difficult to follow due to the lack of clear section breaks. In future, try to use headings and subheadings to help readers navigate your assignment. It's also crucial to avoid repeating information verbatim unless might be necessary. 

Your utilization of the MailerHelper class and different models such as assignment_participant, course_participant, and delayed_mailer demonstrates a good grasp of the MVC (Model-View-Controller) concept in Rails.

Your testing method using Rspec and the TDD approach was comprehensive. It’s good to see that you're testing for the presence of appropriate fields in the email such as the subject, from, and to fields.

However, as much as your implementations added some functionality to the application, remember to always cross check and ensure they do not unintentionally affect any features previously implemented in the application.

In terms of references, ensure you provide proper credit to the original sources. From your report, it’s unclear what each link represents.

In conclusion, you have done a commendable job in this assignment. Keep practicing and refining your coding and technical writing skills."
356,E1509,"This page talks about an open source project based on Expertiza. As a part of contribution to Expertiza, this project aims to refactor SignUpController and SignUpSheetControllers, which lists topics available for an assignment, allows a user to sign up for topic, checks whether a user is signed up for a topic and so on. Refactoring is a disciplined technique for restructuring an existing body of code, altering its internal structure without changing its external behavior<ref> <link> </ref>. On refactoring controllers, there are some general principals listed on the <link> . For example, 1. <link> . Remove duplicated code as much as possible. And Locate methods in appropriate controllers or model classes. 2. Controllers should be written in a <link> style. Following the REST convention<ref> <link> </ref>, the controllers should perform the standard controller actions, using the standard method names as much as possible. <link> is a web application developed by <link> framework. It serves as a peer review system for professors and students at NC State and some other colleges and universities. Students can submit different assignments and peer-review reusable learning objects (articles, code, web sites, etc)<ref> <link> </ref>. It is also a powerful tool for professor to manage courses and assignments and so on. The Expertiza project is supported by the National Science Foundation. And it is an open source application and the source code can be cloned on <link> . Here is our <link> . For more details of the Expertiza project, including links to documentation and development, you can search on the <link> page. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.2. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.3. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link> 1.4. <link>. <code>. Lists topics available for an assignment, checks whether a user is signed up for a topic, allows users to sign up for topics. 1. These two controllers seem to do almost the same thing. They have many of the same methods. SignUpSheetController is much longer, and has many more recent mods, but some methods of SignUpController seem more sophisticated than SignUpSheetController . So, your first job is to figure out if both controllers are being used. If not, remove the unused controller. Or, move the functions to a single controller if that makes sense to do. 2. Neither controller is at all RESTful; i.e.., its method names aren’t the standard names new , create , edit , delete , etc. Functionality is divided differently than in a standard controller. <code> 1. Functionality that should be in models is incorporated into the controller. 2. Some methods are too long and appear to do more than one thing 3. This class interfaces with assignments_controller so that a list of topics can be displayed when one is editing an assignment. Please be careful that your changes do not affect the functionality on the Topics tab of editing an assignment. 4. Rename the controller(s) to SignupController and/or SignupSheetController . (“Sign up”, which gets written as SignUp in camel case, is a verb, whereas “Signup” is a noun.) 5. Some codes does not follow the <link> . After various analysis and test, we found SignUpController is never used. So we remove it. The reasons are listed as follows: 1. There is no code about SignUpController in route.rb file. The Rails router recognizes URLs and dispatches them to a controller's action. It can also generate paths and URLs, avoiding the need to hardcode strings in your views<ref> <link> </ref>. Rails default routing is resource routing, which allows us to declare all the common routes for a resourceful controller. In our route.rb , we found a matching resourceful route for SignUpSheetController , which asks the router to map it to the SignUpSheetController action. <code> This route creates several different routes in the application, all mapping to the SignUpSheetController controller. Here are some examples: <table> However, there is not a matching route for SignUpController . 1. In general, SignUpController provides ""Signup"" functions for a user (student), e.g., sign up a topic, drop a selected topic. SignUpSheetController provides all related functions not only for a user, but also for a administrator, such as managing a signup sheet for an assignment. We found SignUpSheetController has all seven methods in SignUpController with same name. We found these functions are completely achieved via SignUpSheetController . And we test and prove that codes in SignUpController never got executed in the following ways: 1.1. Find usages of each method in SignUpController . Right-click on each method's name, and choose ""Find Usages"", then we can find places calling these methods. 1.2. Writing puts sentences to test each method manually. We can find if the method is executed by checking the log on the Console. The purpose of the list method in the SignupSheet controller is to list all the topics in the specific assignment. According to RESTful rules, a method that returns a list of all available objects should be named as index . Therefore, we rename the list method to the index method in the controller and in all the files that have references to the list method of the signup_sheet_controller. Before Refactoring: Method: list <code> After Refactoring: Method: index <code> And we need to change some references to the method: <code> For some others, it is not good to combine some functions with the standard ones. For example, create function creates topics, which is one of the administrator’s functions. However signup creates a record that includes information for topic and student, which happens when student clicks signup button. We can see that create and signup are designed for different roles and different usages so it is not a good idea to combine them together. The controller connects the model with the view. In Rails, controllers are implemented as ActionController classes. The controller knows how to process the data that comes from the model and how to pass it onto the view. The controller should not include any database related actions (such as modifying data before it gets saved inside the database). This should be handled in the proper model. So we move all the database related functionality in the signup_sheet_controller to related models. The following files were modified: <code> Here are two examples on how these files changed. 1. replace ""where"" in the controller with a new method in related model. Before Refactoring: In signup_sheet_controller.rb : <code> After Refactoring: In signup_sheet_controller.rb : <code> Also add a related method in sign_up_topic.rb <code> 2. replace ""find_by_sql"" in the controller with a new method in related model. Before Refactoring: In signup_sheet_controller.rb : <code> After Refactoring: In signup_sheet_controller.rb : <code> Also add a related method in sign_up_topic.rb <code>. We’ve find that lots of methods do more than one thing so we separate a long function into several concise functions and call them in the original function. Here is an example: There are some preparation works and check works before or after the actual create operation. So we separate two functions update_topic_info and check_after_create from create . And we call these two functions in create method instead of executing these codes directly. Before Refactoring: Method: create <code> After Refactoring Method: update_topic_info , check_after_create , create <code> The method update_topic_info updates topics' some attributes according to received parameters, such as permitted max number of choosers and waitlisted users. This method is separated from function create because it doesn't really do any creation works. <code> The method check_after_create check if the assignment is a microtask and if it applies to staggered deadline. If these two conditions are met, then execute corresponding actions. These steps should be separated from create function because it doesn't actually do works related with creation. <code> In create method, the two separated methods were called. By this way, function create will be much shorter and some works do not belong to it can be finished by other methods. When we move the mouse on the Assignment, there is a ""Edit signup sheet"" button in the popup menu. It is a redundant button since there already has such a function in Assignment ""Edit"" menu. What's more it's more reasonable to put this function in ""Edit"" Assignment because signup sheet is a part of the assignment. So we removed this button. Sometimes after making some changes, the display topics function didn’t work due to some reasons. We’ve fixed those bugs and make sure it still works after our last change. We delete the following lines in app/views/tree_display/actions/_assignments_actions.html.erb <code> The origin popup menu is as following picture, there is a edit signup sheet button: <image> The new popup menu is: <image> After modifying, the other assignment functions all works well. <image>. According to the controller name convention<ref> <link> </ref>, a controller should be a noun. However, here SignUp in camel case is a verb. We should modify it to a noun written as Signup . As a result, we rename all class name SignUpSheetController to SignupSheetController . Then the controller name sign_up_sheet_controller is revised into signup_sheet_controller automatically. Here we also make sure every reference for this controller has been changed to match the new controller name. For example, in views/signup_sheet/_action.html.erb file, we must make sure this render path is correct as follows: <code>. According to Global Rules, there are some codes that need some improvements to make it follow the rules correctly. Here are some of what we have done: 1. change users_team.size == 0 to users_team.zero? <code> 1. Use key: 'value' , not :key => 'value' <code> 1. Use if (var) instead of if (var == true) <code> 1. Use good conditional statements <code>. <references/>.","Very good writeup.  One other wiki used a side-by-side display of changes that I thought made it easier to see what had been changed.  Other than that, yours is tops.
","Firstly, I want to commend you on the depth and breadth of your analysis on this project. You have clearly shown a solid understanding of refactoring controllers and the principles involved.

Your assignment shows a good understanding of the project requirements and is well organized. You have clearly described the reasons for modifying several files and the issues they had previously, which shows a thorough understanding of the project's goals. The before-and-after examples you provided after each refactoring step were particularly insightful and demonstrated a clear progression in your work.

There are a few points where your writing could use some improvement. There seems to be places that lack citation for the sources which could potentially lead to plagiarism issues. For instance, you cited principles from an unspecified link and more instances where references are missing for the content that seems to be picked up from somewhere else.

Also, the content seems to lack a conclusion, which prevents a clear-cut wrap-up of all the points discussed in the document you have written. It is generally helpful to provide a brief synopsis of your findings and how you see this work benefiting the Expertiza platform.

Make sure every single line of your document is proofread before submission to correct any possible errors and iron out any potential ambiguity. 

Overall, this is a solid analysis and I am pleased with the effort you put into this project. Keep it up!"
357,E17A2.1,"The implementation of a badging system provides a boosted visual motivation for the students to work towards achieving that badge. This has the ability to improve the overall class performance. Team: Ankit Jain Rajan Alwan Riken Shah Sanya Kathuria Mentor - Zhewei Hu,(zhu6@ncsu.edu). The aim of this project is to implement a badging system for Expertiza where certain students are awarded badges when certain criteria are met which may include exceptional academic performance in assignments, project submissions etc. We will be using Credly to make Badges. We will be working on building two badges: 1. Good Reviewer 2. Good Teammate. <image>. The use of badges will encourage students to have a visual motivation based on their achievements and thus perform better. For every assignment in Expertiza, we have students perform differently on a scale of 100 based on the reviews their projects receive from their peers. The topper badges will be used to honor the team(s) which scores the maximum for an assignment. We have developed two badges — ""Good Reviewer"" and ""Good Teammate"" but the design has been developed in such a way that the badging system can be easily extended to include more badges in the future. The ""Good Reviewer"" badge will be awarded to students who receive very high review grades. The ""Good Teammate"" badge will be awarded to team members who receive very high teammate review scores. By default, the ""threshold"" for earning these badges is set to a score of 95, but this value is configurable on a per-assignment basis by the instructor. A new ""Badges"" tab will be added for instructors on the ""Edit Assignment"" page where instructors can add badges and configure the badge criteria for a given assignment. Badges a student has earned can be seen when they view their ""Task List"" page, and an instructor will be able to view all badges earned by students when they view the ""Participants List"" page. <image>. “Good reviewer” is the badge that one student receives very high review grades assigned by teaching staff (by default 95). The criterion to assign badge should be configurable. After creating a new assignment, the threshold for the badges can be specified in assignments/edit page. The below image shows the how the page looks like. <image>. 1. We have created a table named “badges”, with the following attributes: 1.1. id: primary key 1.2. name: varchar 1.3. description: varchar 2. We have created a mapping table named “assignment_badges”, with the following attributes: 1.1. id: primary key 1.2. badge_id: foreign key 1.3. assignment_id: foreign key 1.4. threshold: int 3. We have created a mapping table named “awarded_badges”, with the following attributes: 1.1. id: primary key 1.2. badge_id: foreign key 1.3. participant_id: foreign key. 1. We have inserted the new code related to “Good Teammate” badge to teammate_review_response_map.rb. 2. We have inserted the new code related to “Good Reviewer” badge to review_response_map.rb 3. We have added badges to student_task/list page and a new column named Badge. 4. We have added badges to participants/list for the instructor to view. 5. We have added a tab to edit the badge attributes on the assignments#edit page. 1. As per requirement, the badges need to be displayed in the list view for both instructors and students. And thus, the list.html.erb has been chosen as the views to be modified. 2. The controllers student_task_controller.rb and participants_controller.rb are invoking the views as shown below. Thus, this list method in both the controllers need to be refactored to figure out what badges the team or an individual student needs to be awarded. 3. All business logic regarding badge assignment criteria will be put in teammate_review_response_map.rb and review_response_map.rb created for “Good teammate” and “Good reviewer” badge respectively. <image>. <image>. We have developed the project using the TDD methodology. We have thoroughly tested all the functionalities we have implemented by writing automated test cases in features/specs/badge_system_spec.rb file in Expertiza. The following are the testing scenarios and how we went along implementing them: 1. The assignments#edit page has a tab named badges. 1.1. We login using instructor6 1.2. Visit the assignments#edit page 1.3. Try to click the Badges tab 1. In the badges tab, allow the instructor to change the threshold value of the badges, above which the badges will be awarded to the students. 1.1. The badges tab is entered 1.2. The input field for Good Reviewer Threshold is filled with 96 from 95 1.3. The input field for Good Teammate Threshold is filled with 97 from 95 1.4. Check whether these values reflect in the database 1. Assign the “Good Teammate” badge to a student when the student receives a very high average teammate review grade (higher than 95 by default). 1.1. We change to student display 1.2. Obtain teammate review score from the AwardedBadge model's get_teammate_review_score method that we defined 1.3. Obtain threshold for that assignment 1.4. If the threshold is lower, we expect to see a Good Teammate badge on the page 1. Assign the “Good Reviewer” badge to a student when the student receives a very high review grades assigned by teaching staff (higher than 95 by default). 1.1. We change to student display 1.2. Obtain review score from the ReviewGrade model's grade_for_reviewer attribute 1.3. Obtain threshold for that assignment 1.4. If the threshold is lower, we expect to see a Good Reviewer badge on the page 1. Instructor can view all badges assigned to all participants. 1.1. Login as instructor6 1.2. Visit the participants#list page 1.3. Expect to see the badges column in the page <image> <image> <image> Command to run the testcase file : rspec badge_system_spec.rb. See the screencast at <link> . Pull request is available from <link> . Currently, the average score of all the reviews for each assignment is computed dynamically and not stored anywhere in the database. This incurs huge latency in loading the pages which query the score. This is the reason why ""Review Score"" page from instructor view takes a long time to load. For the topper badge, we need to query the average score of all the teams for all the assignments in a particular course and decide whether the current user is the member of the team having the highest score in any of these assignments. This involves a large number of computations and increases the home page load time of student view by an unacceptably large margin. Currently, a project is underway to fix this problem by storing the scores of teams in the database. Once this task is completed, we can refactor our Top Score method to take advantage of this change. This will significantly reduce the latency of the Top Score badge for both student and Instructor view.","The reviewers had several concerns.  One was that the design doc did not explain why the design choices were made.  That is true, but the project was constrained by the specs, which were pretty specific about the functionality to be implemented.  Another concern was that the test plan did not consider edge cases. This seems to be a good observation. Overall, the text is readable and gives a good idea of why changes are being made and what changes are needed.  So I like it better than the reviewers did.","Dear Team,

Thank you for your thorough submission. I appreciate the efforts you have put in to conceptualize and implement this badging system, which I believe will serve as an excellent motivational tool for students. 

The approach you adopted is solid. The way you have broken down the process, from establishing criteria to designing the badges, to displaying them, is superb. It is great to see that you have made the criteria configurable and all the functionalities you have added, such as the ability to edit badge attributes, are commendable.

The structure of your submission is user-friendly. Your initiative to include images to illustrate the visual aspects of the badging system is much appreciated. Please bear in mind to include alt text or image descriptions in future reports for those who may not be able to see the images. 

While reading through, you might want to ensure the coherency of your thoughts. At certain places, avoid numbering separately. Instead, you could integrate these points into one cohesive paragraph. Additionally, double-check for numbering errors, for instance in the schema you mentioned for “badges” and “assignment_badges”. 

Regarding your test scenarios, it’s great that you have considered various situations to ensure the badges function as expected. I note your point about the current computation of the average score causing latency in loading pages, and am glad you have already considered measures to remedy this. You did a great job acknowledging this limitation and proposing a solution. 

Overall, this was a comprehensive assignment. Your dedication to the project is clear. There are a few changes that need to be made but overall, you are on the right track. 

Best Regards,
[Your Name]"
359,E1743,"Expertiza has a feature that allows instructor i (or an admin) to impersonate a user whose account was created by i or recursively by a user that i created. This causes Expertiza to show what the impersonated user would see. It is good for tracking down bugs in what students see and also for accessing functionality that cannot be accessed from, or is too slow to access from, the instructor UI. Impersonating is currently performed by going to the pull-down menu at the top of the window and selecting Manage > Impersonate user. However, usually the instructor initiates impersonation after finding the student in some kind of list, like a list of users, or assignment participants, or as a member of a team signed up for a topic, etc. In this case, it is inconvenient to have to go to the pulldown menu and type in the user ID. It would be better if the instructor could just click on the ID in the list, and immediately have the impersonated user’s homepage show up. Here’s what it looks like: <image> The idea is to have more convenient options for instructors where a list of students is available, making it easier to both impersonate and view the details of any student with direct links. <image> We have made the following changes to the system as shown by the screenshot above. Red: The student ID previously had a link that directs to the user profile page. We have changed that to a link that would impersonate the user immediately. We did this by calling the impersonate function directly from this page and passing the user's ID as a parameter. Blue: The user profile page link was shifted to this column instead. This column originally did not have any link on it. Green: A link on the email address which now invokes a mailto: HTML link. This column also previously did not have any links. The following screens did not previously show the user-ID, but we have modified them to do so. - View scores (User IDs could be shown below names in the Contributor column.) - View review report - Author feedback report (available from the pull-down menu on Review report). - Teammate review report ( “ “ “) All these pages display some part of the user model, meaning they have all the data from the model. So, it was just a matter of displaying the appropriate user-ID. Changes: The changes we made on this part are the addition of lines printing the user-ID, and it was presented with a link which calls the impersonate function, using the user's ID as a parameter. The following snippet of code shows the exact lines we have changed. We have also switched the user profile link from the user-ID (what it was originally) to the user's full name. A mailto: HTML link has been added on the email address which generates a pop-up with the email ID. <image>. The second problem is that originally, the default for Manage > Users was to list all 6000+ users on one page, which lead to long delays. The default should be to show the first 25 users and there should be options to list 100, 250, or all users. Purpose: The reason behind adding this feature is also to make it the list of users easier to read, possibly reduce retrieval and loading time, and improve ease of navigation. <image> The yellow portion in the above screenshot is where we have added options to display 25, 100, 250, or all users at once, along with links to ‘previous’ and ‘next’ pages. Changes: There is a gem called will_paginate that adds a pagination library which integrates with ruby on rails. That gem is already added to the gemfile of expertiza, but was not used in this particular page. Once added, it provides a paginate method which automatically generates a paginated list with a per_page parameter. Then that list is passed to the view, which automatically displays the necessary links such as “previous”, “next”, individual page links, etc We have reduced the complexity of the logic that was originally implemented. Previously, it populated the user list by querying the course and assignment models. Here's what the code originally looked like: <image> As suggested by Dr. Gehringer, we add a user to the user list array only if the currently logged in user is able to impersonate them. Here's what we have changed that to: <image>. Most of the testing for this project is fairly simple. Manual: Problem 1: All of the altered links will need to be tested to ensure they link to the correct pages. Tests that check if the username link correctly initiates impersonation of that user, and that clicking the full name links to the right user profile. A test user needs to be created and the email link will be used to ensure emails are correctly sent. Problem 2: For the second part of the project, tests need to be set up to check that the correct number of students are being displayed for each display option, and that the user can display subsequent pages of users. Automated: Problem 1 includes changes in view files. Hence, we are not planning to create automated test cases for problem 1. Problem 2: Unit Tests: We will add unit test cases in user_spec.rb. Case I: Condition: page number = 4 and per page option = 25 Result: Ensure users list contain 25 entries. Case II: Condition: page number = 1 and per page option = 50 Result: Ensure users list contain all entries. Here's what we have added in the user_spec.rb file as test cases. <image> A summary of the above code: Firstly, the objects for the user, instructor, and admin are created. In the subsequent lines, we create mocks for the impersonation logic to move the test forward. In the third part, the logic is actually tested. Lines 74 to 83 test as an instructor, while lines 85 to 94 test as a super admin. A new object for a super admin was added in factories.rb <image> Also, we have added automated test case for negative scenario. In this case instructor is unable to impersonate any user and thus get_user_list method in user.rb returns an empty user list array.","This document explains the functionality well, but does not say how or where the link functionality is changed.  On pagination of users, it would have been good to discuss how much information was required to be displayed on each page, and how to avoid retrieving more information than is to be displayed.  As noted by reviewers, the test plan could have been described in more detail.","Dear student, 

Great job! Your submission was both detailed and well-structured, clearly showing the work you have done and the thought process behind it. 

Regarding the modifications you've implemented in the Expertiza system, I appreciate your efforts to improve user experience and efficiency for instructors. The clear delineation via colours in the screenshots made it quite easy to understand the specific changes you made. 

Also, the clear display of modified codes and the explanations behind each modification showed a good understanding of the system. 

Your attempt to also address how you tested the changes you implemented is commendable. However, you could provide more detail regarding how the testing was conducted. E.g. examples of sample data used in testing and the outcomes obtained from the tests. 

Other than that, your presentation of the assignment is clear and easy to follow. I was especially pleased with your addition of factory code to cover the case of a super admin. 

Please continue with your hard work and approach towards tackling issues systematically. 

Good job once again! 

Best, 
[Your Name]"
360,E2058,"Expertiza has Assignment objects, which represent an assignment that is done by some number of users. This project enabled instructors or TAs to customize viewing preference and fixed two bugs in their assigment management process. The goals of this project were to solve tow issues related to assignment management. 1. Issue 1384 : On the homepage, under the “Actions” column in the assignment list when a user (instructor orTA or admin) logs in and navigates to Manage -> Assignments (as shown below). <image> It looks crowded and is easy to be misclicked by some users. The goal of this issue is to add a preference option in user's profile where they can choose wether to show or hide detailed actions on the assignment management homepage. 1. Issue 1430 : What is wrong : 1. A TA or an instructor can assign an assignment to any course even when they don't have access to the course. 2. TAs can unassign an assignment from the course, and if they do so, they lose access to the assignment. What needs to be done : 1. Only those courses should be shown in the dropdown list of courses, the assignment is part of and the instructor or TA has access to. 2. Instructors, but not TAs, would then be allowed to change an assignment to be part of no course. tree_display.jsx profile_controller.rb users_controller.rb user.rb edit.html.erb list.html.erb assignment_helper.rb _general.html.erb assignment_creation_page_spec.rb instructor_interface_spec.rb. Before: <code> After: <code> ... Before: <code> After: <code> ... Before: <code> After: <code>. Before: <code> After: <code> ... Before: <code> After: <code>. Before: <code> After: <code>. Before: <code> After: <code> ... Before: <code> After: <code>. Before: <code> After: <code>. Before: <code> After: <code>. before: <code> after: <code>. Added: <code>. Added: <code>. Now in the user's (instructor or TA) profile page, we have two radio buttons to select from. If we choose not to show actions on the home page, and click 'save' at the bottom of the page: <image> Actions will not show up on the homepage as expected: <image>. Now if we want to assign this final project to another course, we can open up the dropdown list can choose CSC 216 (for example), and click save. <image> The action is successful. <image>. <link> Instructor username: instructor6 Instructor password: password TA username: test_TA TA password: password. 1. On the assignment homepage, if you click on the blank area of an assignment, the 'edit' icon will dispear. This issue is not in the scope of this project. Reload to get it back. 1. Other user email preferences can not be properly updated when rendering to another form, also it's a pre-exsiting issue.","In most places, there is little descripton of the changes made. Code listings occupy at least 2/3 of the document.  It would be better to use the Github diff view; with the Mediawiki boxes, it is very hard to determine what has been changed.","Hello,

Thank you for submitting your project on improving the assignment management of Expertiza. Here are my feedback and suggestions:

1. Well done on identifying the issues and providing possible solutions. Your goals in accomplishing this project were clearly stated. 

2. Excellent work on the functionality to allow user preference for home page viewing. This greatly improves user experience. Visual examples provided were very helpful. It would have been better if the mentioned images or screenshots could be seen to better understand how the changes were reflected.

3. Great job on addressing the issue with assignment access permissions for instructors and teaching assistants. This enhances proper controls and rights management.

4. It would have been useful if the code snippets you worked on were shown along with proper comments for easy understanding of changes made. In future, consider including these to give your reader a clear understanding of what was previously in place and what changes have been made.

5. Please ensure that the numeration of your points is accurate. This makes it easier to follow your report and the flow of your ideas. 

6. Always summarize your findings in a well-stated and brief conclusion. This would give the reader a good wrap up of your work.

7. The action plan for existing issues that were not part of the scope of this project was well documented. This shows an in-depth understanding of the project.

Good job overall!

Best regards,
[Instructor's Name]"
361,E1634,"Expertiza<ref> <link> </ref> is an open source project for school assignment management for instructors and students based on the Ruby on Rails<ref> <link> </ref> framework. Expertiza allows the instructor to create new assignments and customise new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and word documents. Expertiza provides a dashboard for all the assignments corresponding to a course and provides absolute control to the Instructors and Teaching Assistants. In addition to assignments, it encompasses peer reviews wherein participants are allowed to provide feedback anonymously about each other's work thereby providing scope for the better outcome. The due_date.rb file is responsible for informing the users about the deadline for submission of the each assignment. Due dates in Expertiza have their association with many other components like assignments, reviews etc. Code Climate<ref> <link> </ref> is a tool that runs static analysis on a GitHub project and outputs many details like test coverage, complexity, duplication, security, style, and more. There is a Google Chrome extension to integrate the Code Climate results generated directly into GitHub which is visible when browsing the repository on the browser. It allows us to see issues displayed directly inside GitHub's UI, to review which lines are covered in diffs and files, and add repositories and open tickets without changing your workflow. To install Code climate Chrome Extension that highlights the duplicated code. To refactor the following two files: 1. due_date.rb 1.1. Ternary operators must not be nested. Prefer `if` or `else` constructs instead. 1.2. Useless assignment to variable - `sorted_deadlines`. 1.3. Prefer `each` over `for`. 1.4. Use `find_by` instead of `where.first`. 1.5. Correct the use of Time function 2. deadline_helper.rb 1.1. Do not use `Time.now` without zone. Use one of `Time.zone.now`, `Time.current`, `Time.now.in_time_zone`, `Time.now.utc`, `Time.now.getlocal`, `Time.now.iso8601`, `Time.now.jisx0301`, `Time.now.rfc3339`, `Time.now.to_i`, `Time.now.to_f` instead. 1.2. Trailing whitespace detected. 1.3. Extra empty line detected at module body end. 1. Create respective RSpec<ref> <link> </ref> files in /spec/models/ and /spec/helper folder and write unit tests for each method in due_date.rb and deadline_helper.rb. DueDate is a Model class to manage the deadlines of an assignment. It has methods for setting due dates for an assignment, copying due dates from one assignment to a new assignment etc. DeadlineHelper provides helper functions that help DueDate perform certain tasks. The assignment focuses on refactoring some of the methods based on warnings received from Code Climate's static analysis and modifying the language to make it more Ruby-friendly. The assignment also involves writing unit test cases for due_date.rb and deadline_helper.rb in order to increase test coverage. The goal of this project is to attempt to make this part of the application easier to read and write unit test cases that the application must pass. Changes implemented involves refactoring the code and making it more understandable by adding comments in the code. The modified files are 1. due_date.rb (path: /app/models) 2. deadline_helper.rb (path: /app/helpers) Testing files 1. due_date_spec.rb (path: /spec/models) 2. deadline_helper_spec.rb (path: /spec/helpers). 1. Converted for..in loop to object.each in order to follow better Ruby syntax. 2. Unnecessary assignment to sorted_deadlines removed. 3. Nested ternary operators have been changed to if..else in order to make it more readable. <image> 1. Changed where(...).first to find_by(...) which is the newer recommended syntax. 2. Corrected the Time.now functions by adding the correct zones to them such as Time.zone.now. 3. Removed trailing whitespaces. <image>. 1. Time functions were changed to functions with zones 2. Extra line removed <image>. There were no existing tests for the functions in due_date.rb and deadline_helper.rb. We have added exhaustive set of RSpec tests to test all the code. We have added two new spec files 'due_date_spec.rb' and ‘deadline_helper_spec.rb’ which cover the testing scenarios for the functions in ‘due_date.rb’ and ‘deadline_helper.rb’. For both of these two files, all Travis CI<ref> <link> </ref> test cases have passed for all previous test cases as well as the ones added by us with the test coverage for the files due_date.rb and deadline_helper.rb reported as 100%. These RSpec files have 100% code coverage visible at: /coverage/index.html. This file is located at spec/models and tests the functionalities of the due_date.rb file located in app/models. There are 18 test cases in total which are listed below. 1. If the factory is successfully able to build the due_date objects. <code> <code> 1. If the function ""set_flag"" successfully sets the due_date flag. <code> 1. If the function ""due_at_is_valid_datetime"" returns nil (no errors) for a valid datetime in due_at (no invalid test cases can be added here because model does not allow invalid datetime to be set at all). <code> 1. If the function ""self.copy"" is able to copy due dates from one assignment to another. <code> 1. If the function ""self.set_duedate"" is able to create another due date by copying data from an existing due date object. <code> 1. If the function ""self.deadline_sort"" is able to sort the due dates in ascending order. <code> 1. If the function ""self.done_in_assignment_round"" returns the correct number of rounds for specific inputs. This involves an invalid test case as well for 0 rounds. <code> 1. If the function ""self.get_next_due_date"" works as expected. This involves several invalid test cases as well. <code> 1. If the function ""self.default_permission"" returns the correct default permissions for particular deadline and permission types. <code> <code> To test this file run the following command: <code> The output of this RSpec file is present in below screenshot: <image> Code coverage details of the above RSpec files is present in below screenshot: <image>. This is a test file for testing the functionalities of Deadline_helper.rb file located at app/helpers. Different test cases present in this file are: 1. Check if the factory<ref> <link> </ref> is valid: <code> 1. Fail if the due date is invalid: <code> 1. If new due_date object is created: <code> 1. due_at should be same for 0 offset: <code> 1. due_at is calculated correctly if offset is positive: <code> 1. due_at is calculated correctly if offset is negative: <code> 1. The offset is being converted to integer properly: <code> To test this file run the following command: <code> The output of this RSpec file is present in below screenshot: <image> Code coverage details of the above RSpec files is present in below screenshot: <image>. Run the following commands to test the new RSpec files created: 1. rspec spec/models/deadline_helper_spec.rb 2. rspec spec/models/due_date_spec.rb. 1. How to test creation of new assignment with due dates using U(username: instructor6, password: password)I: <link>. <references/>.","The writeup is somewhat helpful, but I am bothered by the long sequences of code without any annotation.  Also, while low-level changes are comprehensively described, there's no high-level overview of the changes made to classes and methods.  Was this just a set of very localized edits.","Dear student, 

Great job on completing the assignment! You have demonstrated a good understanding of the Expertiza platform and the process of improving its code. 

Your clear explanations for the changes you made in the due_date.rb and deadline_helper.rb files are appreciated. Your efforts in refactoring the code and ensuring it adheres to Ruby syntax are commendable. 

Also, providing rationales for the revisions you've made offers helpful insights into the logic behind your thinking. This crucially benefits in understanding how these changes contribute to improving the quality, readability, and testability of the software.

Your report was thorough, and the effort you've put into unit testing does not go unnoticed. Excellent work in creating RSpec tests for the methods. This not only verifies their functionality but also increases the project's overall test coverage. 

One aspect you should consider improving is your use of illustrations. Make sure to adequately embed images or diagrams in place of <image> placeholder to elucidate your points. Additionally, code snippets should be included within the <code> tags to provide a clearer view of the programming syntax used.

Lastly, be sure to explicitly mention that links will be helpful to provide substantive context and relevant sources for data or any references you've used. This will further support your writing and can provide important supplemental information.

Overall, your work on this assignment has been very satisfactory. Keep up the good work!

Best, 
[Your Name]
"
362,E1661,"Expertiza is an online system that is used by students to view/submit assignments and review others' work. Expertiza also provides tools to visualize the scores and gauge the improvements made during the course semester. It also facilitates and monitors team projects. It is targeted at educational and non-profit organizations. The project is funded by the National Software Foundation (NSF), NCSU Learning in a Technology-Rich Environment (LITRE) program, the NCSU Faculty Center for Teaching and Learning, the NCSU STEM Initiative, and the Center for Advanced Computing and Communication. Expertiza is an open-source project with the source code available as a public repository on GitHub. It is developed using Ruby on Rails and is increasingly becoming robust thanks to the innumerable bugs being fixed by the community. The project has a micro-blog on SourceForge where the developer community report bugs and document updates. The website used a JQuery plugin call to sort the elements of the various tables that contained the review scores. However, since the tables were dynamically generated, they carried the same ID. A call to the JQuery plugin function using the ID would only sort the first table with the given ID. The code was edited to call the JQuery plugin using the class, which calls the sort plugin for all UI elements with the class name. Invoking JQuery plugin using ID $(""#scoresTable"").tablesorter(); Invoking JQuery plugin using class $("".tablesorter"").tablesorter();. The link to 'Alternate View' was placed right next to View My Scores. This word 'alternate' means a choice over the current option and it is absurd that it is being displayed along with the link to the other choice. The link to 'Alternate View' was removed and placed inside the Classic View of Report Scores. <image> <image> Screenshots showing the replacement of the 'Alternate View' link <image> Highlighted code snippet showing the new position of the 'Alternate View' link. While reporting scores, the system did not differentiate between Checkbox and Score Criteria and simply displayed a 1 is place of a right icon and 0 in place of a wrong icon. This was corrected and tested. <image> Screenshot of the newly introduced Checkbox Criteria <image> Highlighted code snippet that showing the introduction of the Checkbox Criteria. At any time, a user must be able to view only one round of review. This was implemented using tabs where only the selected round of review was displayed and the others were hidden from user view. <image> Highlighted code snippet showing the introduction of Review Rounds in Tabs. With the testing we performed using the username ""student5404"", we did not witness any incorrect placement of report columns. However, a tabbed view was introduced in the ""Alternate View"" of review scores that should solve this issue. After implementing 'Tabbed View' of Report Scores and some UI fixes, this issue has been resolved. In this section we discuss the steps to test the features that are implemented as shown in the Section 1.2.1. The user can login as a student or as an instructor to test the individual features. The credentials are given below. Login as an instructor: Username: instructor6, password: password Login as a student: Username: student5404, password: password. 1. Login as a 'student' or as an 'instructor'. 2. Choose an assignment that is completed and has atleast two rounds of reviews. 3. Click 'Your scores'. 4. Click 'Alternate View' shown at the top of the page next to 'Hide Stats'. 5. You can view the tables with the review score, one for each round of review. 6. You can see the triangular up/down arrows for the columns, 'Criterion' and 'Avg'. 7. Clicking on the arrows/ column header sorts the table according to the current column values, ascending and descending order alternatively. 8. Sorting functionality works for all the tables now, whereas earlier it was working only for the first table on the page. 1. Login as a 'student' or as an 'instructor'. 2. Choose an assignment that is completed and has atleast two rounds of reviews. 3. Click 'Your scores'. 4. You can view the link 'Alternate View' at the top of the page next to 'Hide Stats'. 5. As 'Alternate View' is a part of viewing scores, it should be placed on a page where users view the scores in normal format and then should have the option to go to the 'Alternate View' rather than the link placed next to 'Your Scores' in the previous page as shown in step 3. 1. Login as a 'student' or as an 'instructor'. 2. Choose an assignment that is completed and has atleast two rounds of reviews. 3. Make sure that the review questions have at least one question of the checkbox type. 4. Click 'Your scores'. 5. Click 'Alternate View' shown at the top of the page next to 'Hide Stats'. 6. You can view the tables with the review score, one for each round of review. 7. Each row in the table corresponds to a review question. 8. The questions that have checkboxes are given scores 0 or 1 depending on whether they are checked or not, whereas the other questions have a score in the range 0-5. 9. It is not very intuitive that the particular question is a checkbox type question and it might give a false impression that the score is lesser although 1 is the max score for a question of type checkbox. 10. We implemented tick and cross marks representing 1 and 0 respectively and it can be viewed in the table for the questions of checkbox type. 1. Login as a 'student' or as an 'instructor'. 2. Choose an assignment that is completed and has atleast two rounds of reviews. 3. Click 'Your scores'. 4. Click 'Alternate View' shown at the top of the page next to 'Hide Stats'. 5. You can view the Round 1 table with the review scores. 6. At the top of the first table there are hyperlinks for viewing tables of other rounds. 7. Clicking on the links will load the table for the corresponding round. 1. Login as an 'instructor'. 2. Choose an assignment that is completed and has atleast two rounds of reviews. 3. Click 'Your scores'. 4. Click 'Alternate View' shown at the top of the page next to 'Hide Stats'. 5. You can view the tables with the review score, one for each round of review. 6. The reviews are appearing in the correct columns. 1. Login as an 'instructor'. 2. Choose an assignment that is completed and has atleast two rounds of reviews. 3. Click 'Your scores'. 4. Click 'Alternate View' shown at the top of the page next to 'Hide Stats'. 5. You can view the tables with the review score, one for each round of review. 6. The page seems to be stable. 1. Fixed a bug where the page that displayed comments failed if there were no comments. 2. Removed syntactical bug; enclosed <%= get_css_style_for_hamer_reputation(@participant.Hamer)%> within quotes. 3. The widespread belief in the industry that the user does not know what he/she wants. It is the smallest of the details like changing ""hide stats"" to Title Case - ""Hide Stats"" that will go a long way in improving the readability of websites. Several such changes were incorporated to render the website more readable. 4. Refactoring of several code snippets to make it easier to understand and reuse. 1. Establish a consistency in design. The system seems to have been developed by several developers that did not follow one single convention. For instance, links are capitalized, title cased or lower cased randomly. 2. Can add notification facility to remind students on approaching deadlines. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.","Very readable.  Good highlighting of code changed, but it would have helped if there were prose describing the changes made.  Screenshots show new functionality, but not how the different review rounds are shown.","The report is commendable in terms of explaining the functionality of the 'Expertiza' system and the descriptions of bugs and corrections are quite clear and understandable. You did a great job illustrating the necessary testing steps and laying out the rationale behind every decision made during the debugging process. The precision in creating test cases for each feature individually shows good understanding of the process and the diligence involved.

For enhancing the quality of your report though, it would be better if you could summarize your lengthy descriptions into shorter ones without compromising the substantial information, as it seems a bit repetitious and long winded at times. Graphical illustrations or diagrams can be used to simplify the complex processes, so incorporating such tools would also be appreciated.

One of the strong points of this report is the 'Next Steps' section where you talk about future improvements to the system. It is important, however, to look into feasibility and practicality of these changes- for example, how to ensure maintaining a consistent design while working with multiple developers, or the possible challenges and requirements for adding a notification feature would add even more value to your insightful thoughts.

Lastly, it is advisable to ensure all links and images are visible and correctly embedded within the report. It's difficult to get a clear sense of what is being referenced or intended when ""<link>"" or ""<image>"" placeholders are seen throughout the report. Make sure that all the images, screenshots, and codes mentioned are correctly inserted or embedded/linked. 

On the whole, this is an extensive and detailed report that displays a strong understanding of the subject matter you worked on. With a little more fine tuning, your work would become even more impressive. Keep it up!"
363,E1814.2,"Expertiza is an opensource web application maintained by students and faculty members of North Carolina State University. Through it students can submit and peer-review learning objects (articles, code, web sites, etc). More information on <link> . Collusion_cycle.rb is a part of the Expertiza project used to calculate potential collusion cycles between peer reviews. Our purpose is to write corresponding unit tests (collusion_cycle_spec.rb) for it. Collusion_Cycle is a model of Expertiza which is used to detect if there is a cycle among reviewers and to record the scores. At this time, it only has functions to detect the cycle up to 4 people. The file collusion_cycle.rb in app/models is used to calculate potential collusion cycles between peer reviews which means two assignment participants are accidentally assigned to review each other's assignments directly or through a so-called collusion cycle. For example, if participant A was reviewed by participant B, participant B was reviewed by participant C, participant C was reviewed by participant A and all the reviews were indeed finished, then a three nodes cycle exists. Cases including two nodes, three nodes and four nodes have been covered in collusion_cycle.rb. 1. n_node_cycles(assignment_participant) As we discussed above, this model can only detect the cycle up to 4 people. So there are three functions corresponding to two people, three people and four people separately. The basic algorithm of these detection functions is first to find a closed loop among reviewers. Take three people as an example, a closed loop means A is a reviewer of B, B is a reviewer of C and C is a reviewer of A. After finding the loop among reviewers, the functions will test the validation of the loop. Validation test is necessary because there may be a situation that A was assigned to be the reviewer of B but didn't do the review.That will create an invalid review response which will break the loop. Finally after the functions find a valid closed loop, the function will record all the reviewers and there scores in an array named collusion_cycles. 2. cycle_similarity_score(cycle) The function below is used to calculate the similarity which is the average difference between each pair of scores. For example, if we input a cycle with data like [[participant1, 100], [participant2, 95], [participant3, 85]] (PS: 100 is the score participant1 receives.), the similarity score will be (|100-95|+|100-85|+|95-85|)/3 = 10.0 . <code> 3. cycle_deviation_score(cycle) The function below is used to calculate the deviation of one cycle which is the average difference of all participants between the standard review score and the review score from this particular cycle. For example, if we input a cycle with data like [[participant1, 95], [participant2, 90], [participant3, 91]] (PS: 95 is the score participant1 receives.) and the standard scores for each are 90, 80 and 91, the deviation score will be (|95-90|+|90-80|+|91-91|)/3 = 5.0 . <code>. For all three functions of collusion detection, the tests can be divided into three parts: test the loop closure, test the review validation and test the final output result. 1. two_node_cycle <image> As shown in the figure above, Two_node_cycle is very simple. If two people both create validate review response to each other, a two_node_cycle is generated. The line response ab represents b's review of a's work. So for the unit test of this function, we first test no collusion situation that participant1 is not a reviewer of participant2. Then we test if response12 or response21 is invalid. Finally we offer the function a totally valid two_node_cycle and test its output. <code> Above is the code for two_node_cycle function test. It's easy to see the test is divided into 3 situations--no collusion, collude but one of the review responses is nil and collude and all responses are valid. These three situations are the basic format of two_node_cycles test, and the following functions are tested by the same way. The only differences are some details, such as the number of responses or how to set the no collusion situation. Theoretically speaking, this format is suitable for all n_node_cycles functions built in the same way as these three functions. 2. three_node_cycle <image> For three_node_cycle, we first test no collusion situation. And for no collusion test we don't have to test all the disconnected situation, such as participant2 is not a reviewer of participant1. We only need to test the last connection of the loop--participant1 is not a reviewer of participant3. Then we test validation of all the responses. Set these responses to be nil separately and see what will happen. In the end we input a valid three_node cycle to see if the output result is what it supposed to be. 3. four_node_cycle <image> Four_node_cycle is similar to three_node_cycle. The test for no collusion sets participant1 not to be a reviewer of participant4. Then set the responses to be nil separately to test the validation. Finally create a valid four_node_cycle and test the output result. 1. cycle_similarity_score(cycle) The code below is the unit test for the cycle_similarity_score(cycle) function in CollusionCycle class. The function is very simple, as it doesn't call any other functions. We only need to input the appropriate data and check whether the output is correct. So for each cases, 2 nodes or 3 nodes, I set different cycle as input and check the result of the function. <code> 2. cycle_deviation_score(cycle) The code below is the unit test for the cycle_deviation_score(cycle) function in CollusionCycle class, It calls review_score method from AssignmentParticipant class. This method will return a standard score of the participant. But in our project, how the review_score method works and whether the result of the review_score method is correct are not parts of our duty (PS: I think it should be tested in unit tests of AssignmentParticipant class). So I set the results of review_score method for each participant. And also set different cycles as input and check the result of the function. <code>. The following figure is the coverage result of our test. Obviously, we achieve a perfect coverage result. <image>. 1. This model can only test cycle containing up to 4 nodes, maybe functions for cycle with more nodes can be added. 2. Apart from adding more functions, combination of all these cycle functions into a new function with parameter n, which represents the number of nodes, will be a better choice. So that detecting cycle with different nodes can be realized by calling the same function with different parameter rather than adding a new function. 1. OODD: <link> 2. Expertiza Documentation: <link> 3. Expertiza on Github: <link> 4. Rspec-rails: <link> 5. Rspec Models: <link>.","This is a good description of what the module is doing, and also a good explanation of the tests.  The authors have included diagrams of the information flow and a screenshot of the running tests.  The only shortcoming is that the diagrams and screenshots would be more readable if they were smaller.","Dear Student,

Thank you for your comprehensive assignment. Your detailed explanation of how you incorporated unit testing into a web application project is commendable. Your examination of various scenarios, clear definitions of functions and in-depth analyses of results demonstrate a good understanding of the process and critical thinking.

Your testing methodology is commendable. You've tested actual classes, methods and their interaction, and your use of boundary analysis (such as testing with no collusion, with collusion but invalid responses, and valid collusion cycles) is a good practice.

However, consider handling edge cases more robustly - are there any exceptional situations you could consider? Also, in the next assignment or versions, explore implementing a DRY (Don't Repeat Yourself) principle, which could simplify the logic for `n_node_cycles` functions and improve the maintainability of your code.

Regarding the final observations and suggestions, I agree that there's potential for further growth and optimizations in this model, for instance, accommodating cycles beyond four nodes and refactoring the code into a more generalized function for better scalability.

Make sure to follow coding best practices like proper indentations, concise commenting, and terminology consistency. 

Overall, an excellent job! Keep up the good work.

Best Regards,
[Your Name]"
364,E1711,"<link> is a web based tool that allows instructors to create collaborative assignments where students can provide peer feedback on each others work. It provides instructors a system to manage assignments and different courses. The goal of E1711 was to refactor code found in the files delayed_mailer.rb and scheduled_task.rb . The following issues were identified as the scope of this project: 1.1. scheduled_task.rb duplicated most of its code from delayed_mailer.rb . Our objective is to reduce/remove the duplication in keeping with the DRY principle. 1.2. The perform method uses a giant case statement, instead we were to incorporate the use of polymorphism 1.3. The mail_signed_up_users is long and should be broken into smaller and better named methods 1.4. Add/modify test cases as we added/removed/modified areas of the code Information about the assignment can be found on <link> NOTE: All our changes and updates on the project is committed on the ""oss-branch"" in our remote git repository, not the ""master"" branch. <link>. As this was a purely refactoring effort, our testing consisted of confirming existing tests did not break, modifying existing tests to match our changes, or adding tests as needed. The below sections will cover each objective in detail and will include information on how testing was done for each of those changes. See each of the Our Testing sections. The following flowchart shows how to arrive at the tested scenarios. The charts refer to Scenarios by number. Below Summary table delves into details of the test cases. <image> <image> Instead the below table summarizes the test cases for delayed_mailer.rb Much of our work consisted of modifying the existing tests so they were more thorough and adding some tests. The selection of the added tests were to verify the functions that were restructured as a part of this effort. Functions that were not touched are out of the scope of this assignment so no tests were added there. Adding tests for other functions can be a future assignment. You can find the test cases in delayed_mailer_spec.rb Also you will note at the start of the tests, a lot of information is created in the DB. All these things need to be in the DB in order to verify that the mailer is successful. Also note that for each of the groups getting emails, the test cases only deliver one email. That is because the DB has a minimum amount of test data where each group to send the emails to only has one member and one email address. <table> Our team tried to improve the test file. If you see the delayed_mailer_spec.rb history, you notice the test cases were more like just creating a DelayedMailer object and putting that into DelayedJob queue, and then checking if the queue size has increased or not. Well..that was a very poor quality test from our perspective, because the actual functionality of sending emails per different deadline type was not tested and besides that, there were no assignment, no topic, no user, and etc in the test scenario at all. Now in our test cases we have created all the necessary objects and set their relations to create a fair test environment with an assignment, topic, team and user, then added test cases which actually test the ""perform"" method functionality (perform method is the major method of DelayedMailer which eventually sends emails to certain recipients per deadline type). Therefore now we claim our tests cases provide a higher confidence rather than before when they pass. An error occurred while attempting to extract the child content. The objective of this task was to clean up this method. It was identified as being badly named, long, and not taking advantage of good design. It is essentially a giant case statement where one of the variables passed into the DelayedMailer constructor determines the people who receives the email.. Some suggested ways to refactor this function was first rename the perform to better describe what it does and to use polymorphism in place of the case statement. The original thought was that polymorphism could be used to determine what was sent out in each email based on the type of the email. The first item we looked at was to rename the method. A generic name such as perform usually means that the method is doing too much or does not have a clear objective. Unfortunately, we found we could not rename the method because the delayed_job gem requires a method named perform in order to work on a custom job. See documentation <link> The second part of the planned refactoring was to use polymorphism to determine the content of the email. After simplifying much of the code in the file, we discovered that the content of the email was independent of the variables used to initialize the object. At that point, we weighed the complexity of new code to use polymorphism versus a significantly more simplified case statement, and because of the lack of existing tests, decided that the simplified case statement was not only short, it is also very simple to follow the flow through the code. We instead focused on DRYing out this code as a better return on immediate investment as opposed to adding polymorphism. There were six existing Rspec tests for delayed_mailer.rb , but the existing tests only verify that a new delayed job was added to the queue based on the type of deadline specified when creating a new DelayedMalier . We made the existing tests more complete by adding in sections that properly created the data objects. We also added verification that once the job is executed, the deadline type for the job is what we expected. We also added verification to make sure that the number of jobs were changing and the mail delivery counts were increasing as expected. The six existing tests that we modified were scenarios 1 to 6 listed above. We modified existing test cases for the perform method to be more thorough. We continuously would run these tests during development to make sure they continue to pass. The primary objective of this task was that the method is long and could be broken into smaller appropriately named methods. We replaced the existing single method mail_signed_up_users with a shorter version and a new method find_team_members_email_for_all_topics . We also heavily modified (including renaming) the existing method getTeamMembersMail , and it is now called find_team_members_email . As the naming of the methods suggest, there are still opportunities for DRYing the two functions to get team member emails, but exiting code makes it extremely difficult to combine the two functions exactly though they are extremely similar at first glance. Merging the two would require refactoring areas outside the scope of this assignment and a whole new set of test cases to verify a lot of basic functionality is not broken in the process. We recommend this is taken up as a part of a future assignment. See Future Refactoring Opportunities below. We did not find any existing automated testing targeting this area of the code. None of the six existing tests verified if the emails are being retrieved from the database so changes in the database schema would break the feature. We added test cases for each of the methods we changed. There are now 10 test cases that are covering this file. The four new test cases focus on verifying that the functions can access the database to protect against schema changes and making sure the right methods are called. Tests were not added for code that was not within the scope of this assignment but we recommend the remainder of the functions also get similar test cases. See details in Future Refactoring Opportunities below. Once we started to refactor the code, we found many additional opportunities to refactor the files that was beyond the planned scope. We note down some of the opportunities here and leave it to future projects to address. 1. Scheduled Task feature does not belong in the mailers. It needs to be a standalone file with new tests added. 2. There are still methods that look like they should be collapsed into one function and opportunities for DRYing out code once other tightly coupled methods are also refactored. 3. There were practically no tests for this area of the code. We added tests for what we modified but much code still remains that is not being tested. 4. There are many calls to the database for the same information in different methods. These repeated calls could probably be reduced to one call and save the result from the database. 5. We found out that all assignments in Expertiza are team assignments and querying if the assignment is a team assignment is hardcoded to return true. perform does have some business logic where the recipient of the email depends on whether or not the assignment is a team assignment. This business logic needs to be revisited by the Expertiza team before the method can be further simplified to ensure the correct mail goes out in the correct scenario. We kept the logic the same as it was out of our scope to change business logic. During our testing, we found that the ""create new late policy"" function was broken. It was throwing a ActiveModel::ForbiddenAttributesError on LatePoliciesController#create, as seen below: <image> To fix this, we had to add the following code to the private section of late_policies_controller.rb: <code> and change the argument in the LatePolicy.new() to just <code> After these two small changes, we were able to create new late policies from the UI.","Very good writeup, as far as it goes.  Good discussion of test cases and reasons for refactoring.  It would have helped to see some code snippets.  Good section on Future Refactoring Opportunities.","Dear student,

Great job on this detailed presentation of your code refactoring project. You've done particularly well on identifying the issues with the existing code and comprehensively discussing your approaches, decisions, and thought processes. Your individual breakdown of each part of the task in terms of both code and testing is very thorough and showcases your understanding of the project and coding principles.

In terms of improvements, there are a handful of points you might consider for future projects:

1. **Details of Code Changes**: Include the specifics of what changes you made to the code. It would be great to see some actual code examples alongside the abstract concepts you discuss. You’ve done excellent work in your explanations, but concrete examples would make it more understandable to both technical and non-technical readers.

2. **Define Acronyms**: You should define acronyms when you first introduce them. For example, DRY (Don't Repeat Yourself) principle. This will increase clarity for someone who might not be familiar with these acronyms.

3. **Visual Aid**: It would be useful to include any flowcharts or diagrams that could help in understanding the changes in the code structure aside from any verbal description.

4. **Clarity on Specific Changes**: Clear explanations concerning some apparent contradictions would be beneficial. For example, you mentioned that the use of polymorphism was to be introduced but later that a case structure with reduced complexity was chosen. Could there be more explanation why polymorphism was not the preferred choice?

Pointing out future refactoring opportunities shows thoughtfulness and breadth of understanding. Keep up the good work!

Overall, your assignment demonstrates good coding practices, clear communication, robust testing, and the careful consideration you put into this project. Thank you for your submission. Keep up the good work!

Best Regards,
[Instructor's Name]"
365,E1744,"We will add a new feature to provide Expertiza with Github metrics (for example, number of committers, number of commits, number of lines of code modified, number of lines added, number of lines deleted.) from each group’s submitted repo link. This information should prove useful for differentiating the performance of team members for grading purposes. It may also help instructors to predict which projects are likely to be accepted/rejected (even before the final due dates). This project is divided into two parts. One is to extract Github metadata of the submitted repos and pull requests. The second part to be built at a later time is to build a classifier (e.g., Bayesian) to do the early prediction on some projects that are likely to fail. This prediction is based on more than 200 past projects (Fall 2012- Fall 2016). Based on the meta-data from students repos/pull requests, we can warn both authors and teaching staff if our model predicts that some projects are likely to fail. The methodology of this project is to add a means to monitor the individual contributions of various team members throughout the duration of project in order to quantitatively access their work. This will aid the teaching staff and team members during the review process as well as improve visibility to a student of the work he or she has committed. When an instructor goes to the submission records page for particular team on a project, a link will be added below each hyperlink called ""View Github Metrics"" in order to request the metrics from Github on demand. <image> If the link is not a valid github page the controller will return a ""No Results Found"" page. <image> If the link is valid it will pull data from Github using the API described below and show the lines added, lines updated, and lines deleted. <image>. 1. First, get an access token from github. Here are the <link> 2. Save the access token in the environment variable 'EXPERTIZA_GITHUB_TOKEN' 3. Now, github data is fetched from github's <link>. This feature has similar functionality with a web crawler, which is crawling the data from a server and store locally. So that for the architectural style of our subsystem, we would like to choose client/server style, which segregates the system into two applications, where the client makes requests to the server whenever a user is looking for the metrics. In many cases, the server is a database with application logic represented as stored procedures, in our case, is Github. <image>. <image> A new table called github_contributors is created to store the data for each committer. The table contain's the committer's email, github_id and all the metrics associated with a project. At the moment we handle the following metrics: 1. Committer email - commiter_url 2. Committer id - commiter_id 3. Total number of commits - total_commits 4. Number of files changed - files_changed 5. Lines of code changed - lines_changed 6. Lines of code added - lines_added 7. Lines of code removed - lines_removed 8. Lines of code added that survived until final submission - lines_persisted. 9. submission_record_id - Foreign Key to submission_records table. An index on committer_id is added to enable search. The tests will use rspec to validate the unit testing of the system by testing the github contributor controller. To run the rspec test, from the top expertiza directory execute the following command ""rspec spec/controllers/github_contributors_controller_spec.rb"" to run the four unit tests. <table>. THIS WILL NOT BE IMPLEMENTED AS PART OF THIS PROJECT. This is future work to be done.","A pretty terse description of the changes to be made, but considering the Github documentation that is linked to, it is sufficient.  Reviewers did fault the authors on not having a detailed enough test plan.  Also, the document should have said something about how the new views would be integrated into the UI ... how instructors and students would navigate to them.  Would have liked to have seen smaller pictures, so it wouldn't be necessary to scroll to see the whole thing.","Dear student,

This is a highly detailed and ambitious project. The inclusion of Github metrics as a way to evaluate individual group member performance is an innovative idea that is extremely practical for computer science-based assignments/projects. The methodology has been coherently explained and shows deep understanding of both the features of Github as well as the architecture of the proposed system. 

The use of environment variables to store the access token is a good practice for protecting sensitive data. I also appreciate how this project will make the Github data accessible to instructors in an organized and readable format. I see that you have covered a wide range of metrics that will be helpful for evaluating the contributions of each team member, making this project useful and practical.

I would suggest that you also consider error-checking mechanisms to avoid cases where Github could be having issues returning information, or where the data provided by Github is incomplete or incorrectly formatted. Paying attention to edge cases and checking unexpected data will make your project robust.

Finally, please double-check the document for minor grammatical errors, and remove incomplete or ""NOT BE IMPLEMENTED AS PART OF THIS PROJECT"" notes before submitting your final assignment to ensure your proposal is as clear, precise and professional as possible.

This proposal reflects good work, and I'm excited to see the output of your project. 

Best wishes, 

[Instructor's Name]"
366,E1633,"Expertiza is a web application where students can submit assignments and quizzes and also peer-review learning objects (articles, code, web sites, etc). Expertiza achieves this using a web application with a straightforward user interface developed using Ruby on Rails. The Expertiza project is supported by the National Science Foundation. This project provides an opportunity for students with likeminded interests to collaborate and work as a team to enhance the existing source code of expertiza so as to improve functionality, remove bugs and implement altogether new features. This in turn provides students with a chance to showcase their skills in applying various concepts and techniques such as RSpec testing, code refactoring, CRUD design, testing strategies and other object oriented practices amongst many others. 1. Currently, Expertiza has a quizzing feature which allow student authors to create quiz questions and “test"" the peer-reviewers. The idea behind this is, if a reviewer can answer the quiz questions which were created by the author correctly, we assume that the reviewer has read the artifact carefully enough and thereby we trust the peer-review. 2. Quiz questionnaire is one sub type of questionnaire, so it should follow the design of other type of questionnaires. 3. However, there are quite a few inconsistencies lodged in the quizzing feature. 4. The number one reason that we plan to refactor the quizzing feature is that its design is not consistent with the current questions and questionnaires. 5. Repetition of source code can be observed in quite a few areas of the system, which can be avoided. 6. The system does not adhere to the Rails principle of Convention over Configuration and Ruby naming conventions are violated in certain segments of the code. 1. The logic of necessary components was moved to the model methods. The views were correspondingly changed to invoke the required model methods. 2. The different methods defined were edit, view_completed_question, complete and view_question_text. 3. The above methods generated the specified HTML content for the specified question types, namely : MultipleChoiceCheckbox, MultipleChoiceRadio, TrueFalse. 1. When the user chooses the ‘edit’ option in a quiz, the edit method is called. Based on our modification of the view, the edit method is now invoked from /view/questionnaires/_quiz_questionnaire.html.erb 2. When a user tries to take a quiz by pressing on ‘begin quiz’ in the UI, the ‘complete' method is invoked by the given view : view/student_quizzes/take_quiz 3. When a user chooses the option ‘view quiz’ or ‘view quiz questions' in the system, the view_question_text method is called which renders the view : view/questionnaires/view.html.erb 4. When the user decides to choose option ‘view’ on a completed quiz, the view_ completed_question method is called on view/student_quizzes/finished_quiz. The view_question_text method is called when the author of the quiz or the instructor views the quiz. The method is responsible for generating the HTML to display the question along with each of its choices. The correct choice(s) should be bolded. Prior to refactoring, this functionality was located in app/views/student_quizzes/review_questions.html.erb : <code> This logic has been moved to the respective models multiple_choice_checkbox.rb, multiple_choice_radio.rb, true_false.rb . Now the view simply needs to call the method: <code>. The edit method is called when the author creates or edits a quiz. It makes every element of the quiz editable. Prior to refactoring, the HTML was in app/views/questionnaires/_quiz_questionnaire.html.erb : <code> After refactoring, the same file looked like: <code>. Logic is written in multiple_choice_checkbox model for multiple choice checkbox question type. Similarly, same process is followed for remaining question types. To begin a quiz, complete is called from the model. <code>. The logic for viewing completed question and their answers was written in the view app/views/student_quizzes/finished_quiz.html.erb . <code> The app/views/student_quizzes/finished_quiz.html.erb was refactored by removing the logic from the view and making it clean by using a single construct which determines question type and answer type by calling view_completed_question method declared in quiz class as shown below. <code> Similarly, logic was written in models for each of the question types. Following code snippet shows view_completed_question for true/false question type. <code>. Since this project involved code refactoring, no new functionality was added. But here are tests for each method to verify they are working correctly. 1. Login as a student. 2. Select a quiz assignment. 3. Select ""Your Work"" 4. First you will have to create a quiz by clicking on the link ""Create Quiz"". 5. Select ""View quiz"". 6. You should see each question, followed by the choices. The correct choice(s) will be in Bold. 1. Login as a student. 2. Select a Quiz Assignment. 3. Select ""Your Work"" 4. If you haven't created a quiz yet, go ahead and create one by clicking the ""Create Quiz"" link. 5. Select ""Edit quiz"". 6. You should see each question, followed by the choices, each in an editable text field. The correct choice(s) will be checked. 1. Login as a student. 2. Select an assignment that has quizzing enabled (e.g. Quiz Assignment). 3. Select ""Your Work"" 4. If you haven't created a quiz yet, go ahead and create one by clicking the ""Create Quiz"" link. 5. Select ""Take Quizzes"". 6. Click 'Begin'. 7. You should see each question, followed by the choices. You can record your answers for each questions and then click 'submit'. Your answers will be saved. 1. Login as a student. 2. Select an assignment that has quizzing enabled (e.g. Quiz Assignment). 3. Select ""Your Work"" 4. If you haven't created/taken a quiz yet, go ahead and create one by clicking the ""Create Quiz"" link and take the quiz. 5. Find a finished quiz and click on 'View'. 6. You should see each question, followed by the choices. The correct choice(s) will be in bold and your recorded answer will be shown.","Most of the writeup consists of code snippets.  At the very least, these snippets should have been annotated to explain the changes that were made.  There was some explanation, typically 1 sentence, but it paled in comparison to the volume of code.","Your assignment demonstrates a clear understanding of the Expertiza system and your work on refactoring the code for the quizzing feature shows a solid application of your Ruby on Rails skills. I appreciate your meticulous detailing of the previous code structure and how you improved upon it in various aspects, such as moving necessary components to model methods, making the source code less repetitious and more aligned with Rails principles and Ruby naming conventions, and enhancing the user experience.

However, a few areas have room for improvement:

1. Proofreading: There are areas in your submission where phrasing is unclear and this might result in confusion. For example, in some sentences, the mention of <code> is confusing as actual code snippets are not displayed. 

2. Descriptions of changes: You've mentioned refactoring a lot but it would have been helpful if you could provide more details about specifically what was refactored, or share examples/publications that led to your solution. 

3. Test Cases: It's good that tests were performed for each method to verify they are working correctly. But, writing test cases or automated unit tests alongside could further increase the reliability of your code.

4. Future Scope: Although no new functionality was added, you could still share the impact of your refactoring on the performance or scalability of the program, or potential features that could be implemented after these changes.

Remember, explanation, encounter, elaboration, and extension compile a detailed and educative delivery. Keep learning and improving. Good work overall!"
367,E1666,"Expertiza is an open source web based peer review system developed and maintained by students and faculty at North Carolina State University. It enables students enrolled in a particular course to form online teams and complete assignments. A typical cycle of an assignment involves the following major steps: 1. A pool of topics is made available to the students to choose from and form team to complete it within a pre-set deadline. 2. After the development phase is finished, begins the peer review phase. Here students can review work of other teams, on the basis of some predefined factors and provide their feedback. 3. Members of a team can also provide feedback for the respective review done for their work. 4. In some projects there is a second development phase which allows team members to improve upon their work keeping past reviews in consideration. 5. After this second development cycle begins another review phase, where original reviewers can re-review the updated work and provide critical feedback. The purpose of this task is to write functional tests for team functionality. Once an assignment is out, a student can select this assignment and others can join in the team. To test this functionality we wrote functional tests for the various scenarios. One such scenario is : 1. Once the assignment is out and a student selects it, he/she can send out invites to other students to join the team. 2. Invited students can accept the invitation and join the team. Functional tests ensure that the functionalities of a software system are working as expected. To write our functional tests, we used the Capybara gem available for Ruby. Capybara gem allows a user to test their web application through simulations. In Expertiza assignments, the only way for a student to join an existing team is to be invited by the leader. Therefore, we will test whether the invitation function run smoothly. But before the test, we need to initialize some information. <code> Here, we created a team, and set the maximum students to 3. Because there can only be one student in each session of browser, we need to create different sessions for different students. The first session is for the leader who will be the first one who select this topic. <code> So far, a team has been created by ‘student2064’, who is the leader. Then, we will let him send an invitation to another user ‘student2065’. Now, let’s create a new session which allows ’student2065’ to log in. After the login, we need to test if he receive the invitation and if he accepts it, whether or not he will be in the team. If he is included in the team, he will be able to see the name of the leader, who is ‘student2064’. <code>. Same as the previous one, we set up the information at the beginning, and then let ‘student2064’ to pick up a topic and send an invitation to ‘student2065’. This time, we will let ‘student2065’ to choose to reject this invitation. If he declines the invitation, the invitation will disappear. <code>. The tests can be run on the terminal using the command: <code> Whether the test fails or succeeds, allows us to determine which parts of the system are functioning properly. <image> <image>. 1. link for forked repository [ <link> ] 2. Github link for original repository [ <link> ] 3. Github link for Capybara [ <link> ].","This is not a long wiki page, but one that does exactly what it needs to: explain the tests to be coded, explain how they are coded, and display the test code.","Overall, your assignment submission is clear, well detailed and exhibits good understanding of writing functional tests for the Expertiza system. Your explanation of the system and the methods used to test its functionality with Capybara gem is coherent and logical. Good job in demonstrating how to simulate the user behavior for two different student accounts. The scenarios you outlined provide meaningful insights into the testing process. The way you express the steps of the process makes it easy to follow along and understand what you're doing at any given moment.

However, there are still a few areas that could be improved:

1. It would be helpful if you could add more details on what the intended outcomes should be for each of the tests, and possibly mention what the expected errors or issues might be. It will better facilitate the understanding of what the test is exactly meant to achieve.

2. When you're sharing code, it is critical for readability to abide by proper conventions, making sure indentation, spacing, and organization are implemented. Unfortunately, your sample codes/comments are not visible in this submission, making it hard to understand how you've implemented your tests.

3. Also, you mention (several times) some images and a few GitHub links however, these are not correctly linked into your submission. Providing accurate references and images would give your document more context and would also support your findings.

4. Lastly, I suggest checking your grammar and punctuation. There are a few periods misplaced at the beginning of some sentences and missing at the end of others. It might be a good idea also to break the text into more paragraphs for better readability.

As a closing comment, you've made a decent beginning on this assignment, and with a few adjustments, this could be an excellent work. Keep it up!"
368,E1850.1,"<link> is an open source web based peer review system developed and maintained by students and faculty members at North Carolina State University. It enables students enrolled in a particular course to form online teams and complete assignments. <link> is a 'Domain Specific Language' (DSL) testing tool written in Ruby to test Ruby code. It is a behavior-driven development (BDD) framework which is extensively used in the production applications. The basic idea behind this concept is that of Test Driven Development (TDD) where the tests are written first and the development is based on writing just enough code that will fulfill those tests followed by refactoring. It contains its own mocking framework that is fully integrated into the framework based upon JMock. The simplicity in the RSpec syntax makes it one of the popular testing tools for Ruby applications. The RSpec tool can be used by installing the rspec gem which consists of 3 other gems namely rspec-core, rspec-expectation and rspec-mock. <link> is the model file of review response in Expertiza. Expertiza has a function called review, used to provide suggestion to the author of a particular project, hence, the author could give feedback to the reviewer. The review_response_map.rb is responsible for manages the data, logic, and rules of review response. The reveiw_response_map.rb did not has test file. We write RSpec test file review_response_map_spec.rb which tested if the model file run all function properly. The RSpec test tests all 14 methods in the model file with 26 test cases. The test covers lots of edge cases and tests real-life conditions. Also, by using RSpec test we found several bugs in the review_response_map.rb file, and thus author could fix it. 1. Source code <code> 1. Process This is to find certain questionnnaire. Help method: let(:assignment) { build(:assignment, id: 1, name: 'Test Assgt') } 1. Test code 1. when round is not nil <code> 2. when round is nil <code>. 1. Source code <code> 1. Test code <code>. 1. Source code <code> 1. Process This is to delete certain record. When delete, this function will return the record. 1. Test code <code>. 1. Source code <code> 1. Test code <code>. 1. Source code <code> 1. Process This is to export records to csv files. One review_response_map is a record. 1. Test code <code>. 1. Souce code <code> 1. Process This is to import certain record. We use a hash {reviewee: 'person1', reviewers: ['person2']} to do the test. When user or participant of reviewee is nil, ArgumentError will be raised. When they are not nil and team exists, we use reviewee_team, reviwee_user, reviewer_user, reviewee_participant, reviewer_participant to test the method. When the team doesn not exist, we need to first use TeamUser, TeamNode and TeamUserNode to create a reviewee_team. 1. Test code 1. when the user of the reviewee is nil <code> 2. when the user of the reviewee is not nil 2.1. when the participant of the reviewee is nil <code> 2.2. when the participant of the reviewee is not nil <code> 2.2.1. when reviewee does not have a team <code> 2.2.2. when reviewee has a team <code>. 1. Source code <code> 1. Test code 1. when there is no review responses and the response parameter is nil <code> 2. when there exist review responses or the response parameter is not nil and when author feedback response map record does not exist or there aren't corresponding responses <code> 3. when author feedback response map record exists and there exist corresponding responses <code>. 1. Source code <code> 1. Test code <code>. 1. Source code <code> 1. Test code <code>. 1. Source code <code> 1. Test code 1. when the review user is nil <code> 2. when the review user is not nil <code>. 1. Source code <code> 1. Test code <code>. 1. Source code <code> 1. Test code 1. when round number is not nil and is bigger than 1 <code> 2. when round number is nil or is smaller than or equal to 1 <code>. 1. Source code <code> 1. Test code 1. when the round is nil <code> 2. when the round is not nil <code>. The tests can be run on the terminal from inside the expertiza folder using following command: <code> The test coverage is 100% in 102 relevant lines. <link> <link> <link> <link> <link>.","Some of the tests are not described at all (there's just a bullet that says, ""Source code"").  Long tests (e.g., final_versions_from_reviewer) should have some prose describing the various steps in the test. Also, the outcomes should be described (why they pass or fail). It would also be good to motivate why the tests are listed in the order that they are.","Dear Student,

Thank you for your comprehensive write-up on your work with Ruby testing, especially in the context of the review_response_map.rb file. Your extensive use of RSpec testing tool and test-driven development (TDD) approach demonstrates a forward-thinking approach to coding. The detail you have provided in testing each method by considering all the scenarios and edge cases is commendable.

However, your assignment could be better organized and cleanly presented. Providing actual code examples would enhance understanding. It seems that you intended to share some code snippets but they aren't included in your submission. Make sure to check the formatting and content before final submission.

I am glad to learn that as a result of your tests, you have uncovered bugs in the review_response_map.rb file. It would have been beneficial if you could specify what these bugs were, how they were discovered, and what changes were needed to address them. 

The real-world applicability of the methods you've tested, from finding questionnaires to deleting and exporting data, is evident. However, the narrative would have a higher efficacy if it was a bit more linear and chronological. I would suggest focusing also on the why's behind some of your methodologies and interpretations, as they can contribute to a better understanding of your approach in testing.

Lastly, the phrase ""The test coverage is 100% in 102 relevant lines"" is quite impressive, but don't rely solely on this metric to evaluate your work. Dig further into the quality of the tests themselves. Do they check for all meaningful outcomes, edge cases, failure modes, and potential bug-inducing situations?

Keep up with your in-depth approach to testing and demonstrating your learning process. Consider the feedback and please revise and resubmit your assignment.

Best regards,
[Your Name]"
369,E1556,"This project is about testing and optimizing of SuggestionController of Expertiza system. Suggestion Controller is a module for students to suggest a new topic for their writing assignments, and instructor can approve the suggestion. Typically, there are three cases when instructor approves the suggestion. First, if the student already has a topic and when suggesting a new topic, he chooses 'Yes' in the signup_preference, he will enroll the new suggested topic automatically after the instructor approves the suggested topic. Second, if the student is in the waitlist of a topic, and when suggesting a new topic, he chooses 'Yes' in the signup_preference, he will enroll the new suggested topic and be removed from the former waitlist. Third, if the student is in the waitlist of a topic, and when suggesting a new topic, he chooses 'No' in the signup_preference, after the instructor approves the new topic, he will remain in the waitlist of former topic, and new topic is left as 'no chooser'. Besides, Suggestion Controller also needs to be optimized from two aspects. First, the syntax need to be upgraded from rails 3.x to rails 4.x. Second, refactoring the mailer part is necessary. The Expertiza project is software to create reusable learning objects through peer review. It also supports team projects, and the submission of almost any document type, including URLs and wiki pages. For the code to be coordinated with Rails 4 syntax, there is one major difference between Ruby 1.9 and 1.8 need to be change in the suggestion_controller.rb. The hash operator using the ""hash rocket"": <code> Need to be changed into: <code>. The approve_suggestion() method is quite long in the original code, and the send email function in the method is achieved twice, which doesn’t conform with DRY principle. The logic of the approve_suggestion() method is described as follows. First, approve the suggestion by create a new record in the SignUpTopic model, set relative parameters, and save the new record. Then send notification to the team. In the notification part, if the student doesn’t have a team, a new team should be created and assigned to the suggested topic. Based on the logic, the approve_suggestion() method can be clearly divided into two parts: approve suggestion part, and notification part. In the notification part, send email function can be written as a single method in order not to repeat. Besides, creating a new team can also be written as a new method. After refactor, there are four new methods: approve, notification, create_new_team, and send_email. Approve and notification are called within approve_suggestion, while create_new_team and send_email are called within notification. <code>. <link> was used to conduct all the tests. RSpec is a Behaviour-Driven Development tool for Ruby programmers. BDD is an approach to software development that combines Test-Driven Development, Domain Driven Design, and Acceptance Test-Driven Planning. RSpec helps you do the TDD part of that equation, focusing on the documentation and design aspects of TDD. The following steps can be used for testing suggestion controller in the UI side. For instructor, after log in, please click 'assignment' and click the pencil shape button to edit the assignment: <image> The open the suggestions function by check the second checkbox under 'topic' tab: <image> Click save button at the end of the page: <image> After a student suggestion as topic (see description below), click the archive box shape to view the suggestion: <image> You should be able to see the list of suggested topics. <image> For student users, first you need to login your account, find a certain course, and make suggestion <image> Then, based on your need, choose if you want to work on the suggestion you suggested. <image> After saving, there will be a flash message on your webpage, and the suggested topic would be shown. <image>. In the first test, we are going to test the result of approving a student's suggestion topic if the student is in a waitlist. He will be removed from the waitlist and added to the new list, if he selected the signup_preference to be 'Yes'. We choose 'Writing Assignment 1a' of 'CSC/ECE 517, Spring 2015' as test assignment. I simulate creating a new suggestion with student5717, in team 'Writing Assignment 1a Team14'. First, log in as Student5717 and suggest a new topic, and choose 'Yes' in signup_preference. <code> Then, log out Student5717, and log in with 'instructor6' account, who is the manager of this course. Then approve the suggest. <code> Finally, check if suggestion approved successfully. I need to check topic list with 'instructor6' account logged in and check the selected topic in student5717 account. <code>. For the second test, Writing Assignment 1a team1, whose team id is 23781, was chosen to perform a serial of action. Team no.23781 is holding a topic: Amazon S3 and Rails. And Writing Assignment 1a team5, whose team id is 23800, is in the waiting list of this topic. First, sign in as Student 5404 from team1, send a suggestion for new topic and indicate they want to choose their suggested topic. <code> Then sign in as instructor6 and approve the suggested topic. <code> Finally, to check the results. On the one hand, sign in as student5404 again and see if her/his team is holding the new topic. On the other hand sign in as instructor6 and check if team no.23800 is holding the old topic: Amazon S3 and Rails. <code>. The third test is similar to the second one. Team no.23781 and assignment no.711 are chosen for this test again. First, student no.5404 login to the system, visit the assignment page, and make a topic suggestion. In the suggestion, instead of choosing “yes” in signup preference, the student chooses “no” in order not to use the suggested topic. <code> After the suggestion is made, login as an instructor, find the assignment, and approve the suggestion. <code> In the final step, we check if the new topic is shown in the topic list, then login as student no.5401 again, check if they still hold their old topic. <code>. Here is the result of our tests. All test cases passed. <image>.","A bit long on the code snippets, but otherwise good. Clearly describes the motivations for the changes, and how changes were made.","Dear Student,

Thank you for your in-depth analysis on testing and optimizing of the SuggestionController for the Expertiza system. Fantastic work! I see a lot of effort put into understanding the functionality of different parts of the software, from the SignUpTopic model to the approve_suggestion() method.

Your review of the different user actions for both instructors and students was very detailed and instructive. Your proposed refactor of the approve_suggestion method into individual modules is well thought out and should certainly improve readability and maintainability of the code.

However, be aware that while removing the duplication of the send email function adheres to the DRY principle, we have to ensure that this does not noticeably impact the performance of the system. It's always a balance between efficiency and clean and manageable code.

The screenshots associated with the testing steps within the UI would have been useful if included, to help visualize the described steps in a better way. However, your description and instructions were clear and concise.

One thing I would recommend for future works is a bit more focus on the tests themselves, and perhaps some short explanation on how the RSpec testing framework operates on a high level, as this could provide more context for those unfamiliar with RSpec.

Keep up the great work, and I look forward to seeing more of your software analysis in future assignments!"
370,E1503,"Classes involved: <code> Modules involved: <code> What they do These class are responsible for calculating top 3 individuals which is to be displayed as the leaderboard for the class and generate a metric which aggregates peer review scores for all course assignments and then sorts individuals. What needs to be done Methods like getParticipantsScore and extractPersonalAchievements needs to be refactored as these single functions have multiple responsibilities. They can be modularized delegating single resposibility to single method. sortHash method is not an explicit leaderboard model and can be moved to helper methods. Some snippets of code are redundant and have no effect on functionality. They can be removed. Leaderboard model was having public methods containing more than one feature in each method. We refactored such public methods in necessary public and private methods. Since we didn't create any new public method, we used the existing test cases to validate the changes. We removed helper methods from model class to respective helper class and changed all the references in model and controller classes. <table>. <table>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. We didn't create any new public method as part of this project, instead we refactored the existing code. Existing test suit was suitable for testing our modifications. <references/>.",The wiki is good and indicates that they did decent work.,"Dear Student,

Thank you for your submission. You have demonstrated a clear understanding of the class and methods involved, and your reasoning for refactoring certain methods is compelling. It's good to see that you recognize the importance of a single responsibility principle and the need for clear, maintainable code. It's always good practice to work on these techniques and you have certainly grasped that.

One recommendation for improvement would be to include specific examples of redundant snippets of code that can be removed. This will strengthen the validity of your statement and aid your understanding of the subject matter. Remember that showing your work is just as important as telling your work.

Furthermore, your explanation lacks clarity due to the frequent use of placeholders (""<code>"", ""<table>"", ""<references/>""). For future assignments, ensure you replace these with real examples or clear explanations.

It's also unclear whether you implemented the changes you proposed or simply identified them. Providing more detail on this aspect would significantly improve the clarity of your submission.

In regards to testing, it's great that you have validated your changes with existing test cases. However, when code changes include moving functionalities from one class to another, writing new test cases may be required to ensure that the changes work effectively in their new context. Ensure the scope of your testing matches the scope of your refactoring.

Thank you once again for your submission and I am looking forward to seeing your progress in the future.

Best,
[Your Name]"
371,E1908,"This page provides a description of the Expertiza based OSS project. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.4. <link> 1.1.5. <link>. <link> is an open source project dependent on <link> structure. Expertiza enables the teacher to make new assignments and alter new or existing assignments. It additionally enables the educator to make a rundown of subjects the students can agree to accept. Students can shape groups in Expertiza to chip away at different undertakings and projects. Students can likewise peer audit other students' entries. Expertiza underpins accommodation crosswise over different record types, including the URLs and wiki pages. The following tasks were accomplished in this project: 1. Improved the clarity of code by improving the variable and parameter names. 2. Followed naming conventions throughout and renamed methods with inconsistent names including the calling methods. 3. Rectified several unwanted if-else conditions in methods and optimized the code. 4. Refactored all instance variables and removed unnecessarily defined variables. 5. Removed certain unwanted flash messages that occur for some user actions. 6. Included comments for functionalities throughout for better understanding. Sign-up sheet controller contains all functions related to management of the signup sheet for an assignment function to add new topics to an assignment, edit properties of a particular topic, delete a topic, etc are included here. 1. Problem 1 : Create method has an if-else condition determining if create or update should be called. Create method should not be responsible for calling update. Identify why the if-else condition exists. The if-else condition exists because the current implementation calls update if a signup sheet with the same name already exists. 2. Solution : Rectified this method by removing the call to update and flashing an error instead. <code> 1. Problem 2 : Update method has a plethora of instance variables defined before updating. These are not necessary (For e.g., look at update method of bookmarks_controller). 2. Solution : Refactored the variables not needed out. <code> 1. Problem 3 : Destroy has a misleading else flash message. 2. Solution : Refactored the mislleading flash messages not needed out. <code> 1. Problem 4 : Add_signup_topics_staggered does not do anything. 2. Solution : Renamed participants variable to 'teams'. <code> 1. Problem 5 : Several method names are renamed to be more intuitive. 2. Solution : load_add_signup_topics is renamed to get_assignment_data and ad_info is renamed to get_ad. <code> 1. Problem 6 : The list method is too long and is sparsely commented. 2. Solution : Added comments. <code> 1. Problem 7 : What are the differences between signup_as_instructor and signup_as_instructor_action methods? Investigate if they are needed and improve the method names if both are needed. Provide comments as to what each method does. 2. Solution : signup_as_instructor specifies the student and displays a new page called via a get request whereas signup_as_instructor_action is an action called via post request which aims to signup a student. 1. Problem 8 : Participants variable in load_add_signup_topics actually means teams that signed up for a topic. 2. Solution : Renamed participants variable to 'teams'. <code> 1. Problem 9 : Signup_as_instructor_action has if-else ladder. 2. Solution : It has been made more elegant using a helper function. <code> 1. Problem 10 : Delete_signup and delete_signup_as_instructor have much in common and violates the DRY principle. 2. Solution : Refactored them by moving the duplicate code to a helper function. <code>. As the project involved only refactoring variables and method names, only build tests and already existing unit tests were performed. 1. <link> 2. <link> The live Expertiza website.","To show the changes made, it would've been better to illustrate the difference between before and after, rather than just display the ""after"" code.  When you remove code, it should be removed rather than just commented out.  And the running text does not describe how the code works, just the changes made.  For someone following on, it would be much more useful to have a description of how the code works. ","Feedback:

Great job! You've clearly put in a lot of work on this assignment. The details of the tasks you achieved show your understanding of the code optimization process and the improvements you've incorporated in the Expertiza-based OSS project. It's impressive how you have tackled problematic areas of design and functionality.

The way you have systematically listed down the problems and their solutions is admirable. By improving code clarity and optimizing your code, you've made it easier to manage. Renaming variables and methods to make them more intuitive shows a concern for the coding best practices, which is commendable.

However, be careful with typo errors, for instance, ""alter new or existing assignments"" should probably be ""alter existing assignments or create new ones"". 

Your explanation of problems and solutions could sometimes use more detailed discussions of the process, including why you chose the solution you did. This would not only enhance the readers' comprehension but also showcase your problem-solving skills and worthy code implementations.

Your explanation of the necessity for tests in the conclusion is a bit thin. It's vital that you elaborate on the importance and role of these tests more thoroughly. Understanding the role and importance of testing in coding is crucial, so be sure to discuss how these tests work and what benefit you derived from running them.

Overall, excellent work! You are showing strong coding skills and a commitment to excellence in your coding practices. Keep up the diligent work, and continue to refine your detail in explanations."
373,E1551,"About Expertiza Expertiza is an open source project accomplished by NCState students. It was developed in Ruby on Rails. It has general features like forming teams, registering for topics in a project, uploading the final deliveries. After completing the project there is an option for submitting reviews as well and updating the reviews. There is an option for submitting new quizzes as well. What it does : response_controller.rb manages Responses. A Response is what is generated any time a user fills out a rubric--any rubric. This includes review rubrics, author-feedback rubrics, teammate-review rubrics, quizzes, and surveys. Responses come in versions. Any time an author revises work, and the reviewer comes back to review it, a new Response object is generated. This Response object points to a particular ReponseMap, which tells who the reviewer is, which team is the reviewee, and what the reviewed entity is. 1. To test the responsecontroller login as user:instructor6 with password:password 2. Go to assignments tab and choose any assignment from the assignments listed. 3. From there click on others work and choose any review among the reviews listed 4. Click on view or begin to start reviewing. 5. You can also test response controller in similar way by logging as student student2064 and password:password. Problem definition latestResponseVersion is misnamed. It returns all versions of a response, and anyway, the method name should use underscores, not camelcase. Solution summary Renamed latestResponseVersion to set_all_responses . Examining latestResponseVersion we were able to determine that it did the following two things: 1. Set the @prev variable to a relation of responses that correspond to the map id of the current response being created or edited. 2. Set the @review_scores variable to an Array version if the contents of @prev . Since the purpose of the code seemed to be to set variables, we renamed it to set_all_responses . We also simplified the method by using ActiveRecord::Relation's to_a to convert the relation to an array. There was some duplicate code in the scores function which we replaced with a call the set_all_responses . Problem definition get_scores has a Java-like name. It should just be scores . Solution summary The method get_scores was renamed to scores . Problem definition The 100+-line method rereview does not seem to be used anymore. The second-round review can be invoked in the same way as the first-round review. Remove it. Solution summary The method rereview was deleted. Problem definition create and update use completely different code. Factor the common parts out into a partial, thereby simplifying the methods. Solution summary There was not much actual overlap in these two methods. Minimal changes. The ResponseController controller has an overall problem in that it knows too much about the subclasses of ResponseMap . There is some major refactoring that needs to occur to clean up this controller's coupling with ResponseMap 's subclasses. We made an attempt to do this, but it was just to large a change to accomplish in the time allotted. Problem definition Authorization needs to be checked in the action_allowed method instead of in redirect_when_disallowed at the bottom of the file. Solution summary So the functionality is moved from redirect_when_disallowed to action_allowed . And also it is made sure that no one other than the author of a review (or another team member, in the case of author feedback) can edit it and then removed the redirect_when_disallowed method. Code before changing <code> <code> Code after changing <code>. Problem definition get_content is a complex method. It should be renamed to content and simplified. Comments should be added explaining what it does. Solution summary The get_content method was renamed set_content , simplified, and documented with comments. A review of the get_content method showed that it's purpose was to set various variables for use by the response views. As such, we renamed this method set_content to help clarify it's intent. We also extracted methods for the more complicated variables into their own methods, making the set_content method easy to understand at a glance. Problem definition This class contains SQL queries. Please change them to Active Record commands. Solution summary No SQL queries were identified. No changes. Major refactoring revolved around changing method names according to rails convention, using helper methods for avoiding duplication of code in controller methods. Duplications in Code Original duplications : 172 Post Refactoring : 21 Code Complexity (Compared on Code Climate) Original ResponseController <ref name=""originalresponsecontroller> Original responseController <link> </ref> <image> Refactored Responsecontroller <ref name=""Refactoredresponsecontroller> Refactored responseController <link> </ref> <image>. Some functional tests are written for this class using Rspec. The test coverage has increased from 19% to 24.1% To check these tests. 1. clone the github repository link provided above 2. run the command rspec spec/controllers/response_controller_spec.rb. <references>.","The level of coverage of your changes seems to be a little inconsistent; some bigger changes are not described in as much detail as small changes (e.g., rename get_scores).","Overall, this is a solid and thorough assignment. You have explained the purpose of the response_controller.rb well, the issues identified, the changes made to improve the code, and the impact of your refactoring on the code metrics. Here are a few areas that could use improvement:

1. Formatting and Presentation: The headings, subheadings, and lists could be more clearly distinguished making the presentation and readability better. It will make it easier to follow your argument and understand the action you have taken. Formatting changes can make a big difference in communicating your ideas more clearly.

2. For the 'Code before changing' and 'Code after changing' part, since the codes are not visible, please include them next time or give an explanation if it was intentional.

3. References: The section is seen but there are no provided references. Please provide any links or articles used as a reference.

4. Test procedures: It would be helpful if you can provide more details about the functionality of the tests you have written, the kind of scenarios and edge cases they cover, and any impact observed on the overall performance of the system.

5. Solution Clarification: In the 'Problem definition latestResponseVersion is misnamed' part, it would be much clearer if you elaborated further on why 'set_all_responses' is an appropriate name for the method.

Good work on this assignment! The refactoring made and the tests performed indicate your understanding and application of the concepts taught in class. Keep it up and aim to improve on the highlighted areas."
374,E1504,"Classes involved: <code> What they do: The bookmark model and controller work together to create and maintain user specific bookmarks, which can be added to different topics. Moreover, the user that created a bookmark can use his privilege to edit it at a later point in time. As a functionality added for convenience, any user can search bookmarks by either users who created them or their bookmark tags. What needs to be done: 1. The search methods in bookmarks model are being used used on a very granular level. This led to redundancy in bookmarks search methods. These methods include search_alltags_allusers, search_fortags_allusers, search_fortags_forusers, search_alltags_forusers . Hence duplicates in these methods are to be singled out. 2. Following the CRUD declaration in Ruby on Rails, where the method name should specify the pseudo use of itself,methods such as add_new_bookmark and edit_this_bookmark have violate this naming convention. Therefore, we need to change the names of these two methods to create and edit , respectively. Upon changing the names, all the dependencies need to be updated, as well. 3. Refactor add_topic_bookmark and add_this_bookmark by removing the repetitive code. These two methods differ only in 2 lines of code, which make it reasonable to merge them together into a single method that provides functionality of both individual methods. 4. Fix the bug in add_bookmark method where only bookmarks without topic_id can be properly created. We add the functionality to this method to allow it to also create bookmarks with provided topic_id . 5. Methods add_bmapping and add_bmapping_signuptopic need to be moved to their appropriate model (Bmapping model) rather than reside in Bookmarks model. Completing this task involves checking the dependencies and updating the function calls for these methods, accordingly. 6. Add user interface for Bookmarks as this functionality has not been a part of Expertiza 7. Create a functional tests suite covering the functionality of all the methods that have been changed by our team. 8. Create a Cucumber integration test to show the functionality of added user interface for Bookmarks. Single Responsibility Principle: As per Single Responsibility Principle, every class should have responsibility over a single part of functionality provided by software and that responsibility should be entirely encapsulated by the class. All the services and operations within the class should be aligned with that responsibility. Following this principle, we found that methods add_bmapping and add_bmapping_signuptopic were present in the Bookmark model, while they actually belong to Bmapping model. So we moved those methods to the Bmapping model and took care of all the dependencies. We created functional tests for these methods to prove that refactoring was successful. Polymorphism: We realized that the methods search_fortags_allusers , search_fortags_forusers could be combined into one method. Similarly, search_alltags_allusers and search_alltags_forusers could be grouped together into a single method. The reason for this is because these methods, essentially, offer the same functionality, but using different parameters. So, we wrote a common method which takes parameters and, based on the parameters passed, it provides the required functionality. <table>. <table>. <table>. The consistency of these two methods shows plenty of repetitive code. In order to effectively refactor these methods and reuse the code they both need, our team merged the two methods together by enabling add_this_bookmark method to handle creation of a bookmark when a topic id is provided (main functionality of add_topic_bookmark method). Once we implemented this change on add_this_bookmark method, we deleted add_topic_bookmark method as it became obsolete. Therefore, we retained the same functionality while reducing the method by 7 repetitive lines of code. Please note that these two methods only differ in a single line of code (line 6 and 16) where line 6 takes an extra parameter ( topic_id ). <code>. <code>. An error occurred while attempting to extract the child content. Both these methods contain almost the same code except for few conditional lines. search_fortags_allusers searches for all tags for all users whereas search_fortags_forusers searches only for those tags that belong to the user. The code for both these functions differed only in the query clause where at one place it checks for records returned for a specific user and at the other place, it does not have this check. <code>. <code>. The above two functions are merged into a single function named ""search_fortags function"" as shown below. If we want to search for specified tags for all users, the userid is passed as nil. If we want to search for the specified tags belonging to a particular userid, we pass that userid. <code>. <code>. <code>. The above two functions were merged into a single function ""search_alltags"" as shown below. If we want to search for all tags for all users, the userid is passed as nil. If we want to search for all tags belonging to a particular userid, we pass that userid. <code>. An error occurred while attempting to extract the child content. In order to inspect the changes made to the bookmark mode manually, you can visit our deployed Expertiza at <link> and use the following credentials: <code> As you can notice in the credentials above, you can type in any password you wish in order to log in as user2. We have accomplished this by disabling the authentication and the reason behind it was to have an easily reachable user account for test and development purposes. The below screenshots demonstrate the working of search features . Visit the url "" <link> "" and click on search button to view the results <image>. Visit the url "" <link> "" to view all tags for the user <image>. Visit the url "" <link> "" , enter the tags separated by comma (example - tag1,tag2) and then click on search button to view the results <image>. Visit the url "" <link> "" , enter the tags separated by comma (example - tag1,tag2) and then click on search button to view the results <image>. We have developed a suit of extensive unit tests covering all the functionality that we have add/modified in the forked version of Expertiza. The test suite consists of 9 tests providing 14 assertions that cover the functionality of all the method changes described in the former sections of this wiki page. The source code for these tests is stored in test/models/bookmark_test.rb file. You can run this test suite by simply navigating to expertiza project directory and running command: <code>. In addition to functional tests, we have also provided a Cucumber test as an integration test. The goal of this test is to show that a user can access the Manage Bookmarks page upon successful log in, proving that bookmarks view have been successfully integrated into expertiza system. The construct of this test can be found in following files: <code> To run this cucumber test, please navigate to expertiza project directory and run the following command: <code>. 1. <link> 2. <link> 3. <link> 4. <link> - This might not be available after May of 2015 5. <link> 6. <link> 7. <link> 8. <link>.","Well written, but does not mention design patterns or principles


The prose does explain what was done, which was good.  It covers the basics, and then launches into their changes.  However, it does not talk about the difficulties they faced and how they tried to overcome them.  Such a description would be very helpful to those who come after them.","Dear Student,

Thank you for the thoroughness of your work. Your understanding of OOP principles such as the Single Responsibility Principle and Polymorphism are evident in this assignment. Moreover, your ability to identify areas that required refactoring due to code redundancy is commendable. Your implementation of the merged search and bookmark creation functionality demonstrate a solid understanding of method refactoring in Ruby.

Still, some areas could use improvement.

The code snippets you mentioned could not be viewed. Besides, there were instances where you referenced links and images that were not included or visible. Please rectify these issues in order to provide a comprehensive understanding of your work.

Completeness-wise, the assignment is remarkable. You seemingly addressed all of the functionality required. However, the absence of the included code snippets, screenshots, and links, impairs a fair assessment of correctness and functionality.

Another aspect to bear in mind in future assignments is clarity. While thoroughness is appreciated, a succinct summary alongside a detailed explanation can go a long way in improving the comprehensibility of your task breakdown. 

Lastly, remember to follow the conventions for function naming in Ruby on Rails. The refactoring of function names to better align with CRUD operations is a positive step towards this.

Overall, I can appreciate the hard work you have put into this assignment. I look forward to reviewing this assignment again once the required corrections are made.

Keep up the good work! 

Best,
[Your Name]"
375,E1878,"<link> is an Open Source project based on the <link> framework, supported by National Science Foundation. It is the software to create reusable learning objects through peer review. It is a project where students can submit and peer review learning objects(articles, code, websites, etc). The users of this software include students and professors. Expertiza is used by select professors and students in North Carolina State University, for example. It supports team projects, reviews of projects/teammates, submission URLs, Wiki pages and certain document types. Instructors can create projects and the students can bid for the projects. The students can be assigned teams for a particular project or they may form their own team with fellow classmates. Peer-review systems like Expertiza utilize a lot of students’ input to determine each other’s performance. In the same time, we hope students could also gain knowledge from the reviews received thus improve their own performance. Currently, we have a few classifiers that could catch useful components of review comments, such as if it contains suggestions, etc. These classifiers are already ported into web services that we’d like to be integrated into Expertiza. As stated in the Problem statement, we get the response from the REST endpoints as given and integrate it with Expertiza. The suggestion detection algorithm from which we are getting the metrics is added in the ""References"" section in case more details are needed on it. According to the problem statement, we will be considering the ""Suggestion Detection Algorithm"" to be a black box, which take a json with text as input and returns a json with few metrics as given below. Input JSON to ""Suggestion Detection Algorithm"" <code> Output JSON the ""Suggestion Detection Algorithm"" <code>. 1. When a student submits a review, we call this web service with the student’s review as the input. We then tell the student whether their reviews contain suggestions or not, so they can make improvements based on the results of the web service. 2. We evaluate how much time this API is taking. We don’t want the system to be terribly slow. 1. app/views/response/response.html.erb. In its current state, the student directly writes their review in segmented text boxes under instructor specified questions with no further checks about the relevance of the review they have written as shown below: <image>. We are not modifying any models / adding any logic that requires an UML diagram. Most of our changes are on HTML. Our logic to be implemented is pre-processing the review and sending it as JSON to the Suggestion Detection API, getting the JSON response from API, post-processing the metrics to output the Suggestion Analysis. The overall flow of the logic is explained as follows: <image>. Following are the necessary steps needed to be set up in order to have the feature running : 1. Browser: Google Chrome 2. Cores plug-in (link in references) Before the JSON response is displayed, certain fields are first filtered out or formatted. For instance, the field ""text"" is filtered out as it is redundant to display it again. The field ""sentiment_tone"" is formatted with the help of another font color JSON depending on its value. Following is the code snippet of our implementation : <code>. <image>. Test: ViewSuggestionMetricsForReviewSegment <code> <code> <code> <code> <code>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.","I think that the Background Information could be better expressed.  For example, ""classifiers are already ported into web services"" is a rather confusing way of saying that we have written a web service that contains code to detect suggestions.  In the Prerequisites section, a large amount of code is pasted in with no real explanation, and only three 1-line comments.  I thought that the demo did a better job of showing the request that was transmitted to the web service and the metrics that were returned.","Hello,

I am highly impressed with your comprehensive work. You have done a commendable job in explaining the Expertiza software, its assumptions, its processes, how it integrates with the Suggestion Detection Algorithm. It is apparent that you have put a lot of thought into articulating this. The flow of your explanation so far is thorough and systematically ordered, which made the work easy to understand and follow.

However, there are certain areas which need improvement:

1. While you did a good job explaining the technical aspects of the project, it would be helpful to provide more context at the start of the assignment about the objectives and expected learning outcomes of this assignment. 

2. Avoid using placeholders like <link> or <code>. Make sure to replace them with the actual content before submission. 

3. Ensure you elaborate more on the diagrammatic representations (included in <image>) and avoid assuming that the reader will understand everything from the diagrams. 

4. While outlining the test ""ViewSuggestionMetricsForReviewSegment,"" you should properly introduce this section, including its significance, implementation, and the outcomes. 

5, Lastly, perhaps you could delve a little deeper into the topic of how the students can effectively use this feedback to enhance their work and improve future reviews - this would make your submission even more thorough and comprehensive.

Overall, the work shows dedication and diligence. Keep up the hard work!

Best Regards"
376,E1639,"Expertiza is a web application for educational purposes. It is an open source project based on Ruby on Rails framework. Expertiza has been created and maintained by faculty and students of NCSU. It helps teachers set up assignments for students who can then make submissions. Students can also review work of other students and give feedback to help incorporate improvements. The following OSS project deals mainly with the ResponseController. The goal of this project is make the code more readable, maintainable and to improve elegance of the code. We would like ResponseController to adhere to the DRY principle. It focuses on refactoring some of the more complex methods and removing some redundant code. At present, ResponseController has methods that would better be located in other controllers. The project relocates such methods to its appropriate Controller class. Response controller manages the responses entered by users. When a user fills out any kind of rubric (review rubrics,author-feedback rubrics,teammate-review rubrics,quizzes,surveys), a response is generated. Responses come in different versions. Any time an author revises his/her work, and the reviewer reviews it again, a separate Response object is generated.Each Response object points to a particular ResponseMap, which provides details about reviewer, reviewee and reviewed entity. 1) Refactor the update method which is too long and hard to read. 2) Refactor the saving method to improve the case handling of selfReviewResponseMap 3) Move new_feedback method from ResponseController to ReviewMappingController - ResponseController should only handle one kind of object 4) Modified functional tests for new_feedback method 5) Added functional test for update_method of response controller. Following files were mainly modified for this project namely: 1. response_controller.rb 2. response_controller_spec.rb 3. review_mapping_controller.rb 4. review_mapping_controller_spec.rb 5. routes.rb 6. _reviews.html.erb 7. _scores_submitted_work.html.erb 8. _self_review.html.erb. Update method is called when any kind of response is edited by the user. This method was very long and unreadable. It was checking the type of @map and round parameter to find out questionnaire using long if..elseif..else ladder, which did not look neat and elegant. There was a helper method 'set_questionnaire' which was being called indirectly by the edit method for retrieving the questionnaire.We called the same function. The intuition behind using this same method was that if it is an update, user is not filling a new rubric and the response object should be available.We can find the questionnaire from the question_id in answers.Hence, in this way the if-else block was eliminated by calling the already available function. Similarly, there were lines of code,which were creating score if not found or updating if an entry exists. The function 'create_answers' does exactly the same. Abiding by the DRY principle, we called this function which made the update method look concise and simplified. <image> <image>. Saving method is called to save the response when a user edits any particular response or creates one. It was assigning params[:returs] to 'selfview' if the @map type is selfReponseMap. This params[:return] value was then further used in redirection method to handle the selfReviewResponseMap separately. We removed the assignment params[:return]= ""selfreview"" from save method. Rather we are directly passing the :return parameter value from edit and new methods of _self_review.html.erb, a view of SubmittedContent controller which handles the selfReview functionality. app -> controllers -> respose_controller.rb -> def saving <image> app -> views -> submitted_content -> _self_review.html.erb <image>. new_feedback method is called when a user provides author feedback for any review. It was defined in the ResponseController earlier which was rather suspect. We moved the method to ReviewMappingController since ResponseController should only handle Response object, while new_feedback is dealing with FeedbackResponseMap object. <image> <image> <image>. We modified the test cases to accommodate changes of the new_feedback method and created new rspec file review_mapping_controller_rspec.rb. We added new test case for update method to test if it located the requested response. <image>. Following steps needs to be performed to test this code from UI: Testing the update method: Click on <link> to view testing screencast for testing the update method 1. Login as instructor. Create a course and an assignment under that course 2. Add say, two students as participants to the assignment 3. Create topics for the assignment 4. Sign in as one of the students who were added to the assignment 5. Go to the assignment and sign up for a topic 6. Submit student's work by clicking 'Your work' under that assignment 7. Sign in as a different student which is participant of the assignment 8. Give review on first student's work and simply click on save 9. Later click on edit and change the review. Click on submit 10. When you click on view, verify the changes made in step 10. If all changes are intact, update method worked successfully Testing the new_feedback method: Click on <link> to view testing screencast for testing the new_feedback method 11. Login as the first student to view feedback given in step 10 12. Click on ""Give Feedback"" to give author feedback ( feedback on the review quality) 13. You would be redirected to a form. Fill in the author feedback and save your changes 14. View your feedback for the review. If your changes are intact, new_feedback method worked successfully.","Very good job.  Figured out some changes that were not in the requirements, and clearly showed how they were accomplished.","Dear Student,

Great job on developing this open-source project using the Ruby on Rails framework. You've clearly shown an understanding of the concepts involved and have applied them effectively. The goal of improving the readability and maintainability of the code is an excellent one to pursue and it appears that you've worked hard to meet this objective. Highlighting the assignments and review aspect of Expertiza is an insightful approach.

Your detailed explanation of your tasks, such as the refactoring of the update and saving methods, and moving new_feedback method to a more suitable controller, demonstrates an impressive depth of understanding. Your commitment to adhering to the DRY principle is commendable, and it is obvious that you have thought carefully about how to reorganize the existing code to better fit this principle. 

The images, though not visible in the text, are assumed to be the demonstrations of your work. Make sure they effectively showcase the pertinent lines of codes and successful implementation of the new methods. 

Your description of the testing procedure is exhaustive and it seems like you've done a good job of considering many possible user interactions. However, ensure you account for all potential edge cases to make your application as robust as possible. 

You took a very systematic approach to your assignment and it is evident in every component. The document was professionally presented, well-formatted, and easy to follow. 

Keep up the outstanding work and continue to apply these principles to your future projects.

Best Regards,
[Your name]"
378,E2055,"<link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. This project in particular intends that the students collaborate with each other and work on making enhancements to the code base by applying the concepts of Rails,RSpec, DRY code,Test driven development etc. This provides an opportunity for students to contribute to an open source project and learn further about software deployment etc. RSpec is a unit test framework for the Ruby programming language. RSpec is different than traditional xUnit frameworks like JUnit because RSpec is a Behavior driven development tool. What this means is that, tests written in RSpec focus on the ""behavior"" of an application being tested. RSpec does not put emphasis on, how the application works but instead on how it behaves, in other words, what the application actually does.Each RSpec file contains one or more tests. Each test ensures if a particular feature of our website is working properly.The output of an RSpec run will tell you exactly what features aren't working. The benefit is that tested code is unlikely to break unnoticed.The tests are run every time someone makes, or updates, a <link> . Below are the tables that are related ti student task functionality <link>. The following is an Expertiza based OSS project which deals primarily with the student_task.rb and student_task_spec.rb. It focuses on writing RSpec unit tests for the code affected or added. The goal of this project is to attempt to add sufficient unit tests to this part of the application and increase its path coverage to above 90 percent. The following tasks were accomplished in this project: 1. Complete the insufficient unit tests for student_task.rb. 2. Increase path coverage from only 31.91% with 30 lines covered to above 90% coverage 3. Cover edge cases. 4. High branch coverage to be achieved. There are different tasks that a student can perform. 1. They can see all the assignments that they have been assigned to. 2. They can see details of each assignment like marks, their team, send invitation to student to join a team 3. Review other students' work. 1. Mock Objects to test: Create a series of mock objects that will be used throughout the testing process 2. The following are a list of the functions that were tested: 3. Topic name 1.1. Retrieves the topic name of an assignment 4. Complete? 1.1. Checks if a student task is complete 5. Incomplete? 1.1. If the assignment is not complete return true 6. Not started? 1.1. Checks if a student task is available to be worked on (i.e in submission/review/metareview stage) and if so has it been started 7. Revision? 1.1. Checks if a student task is now in the revision stage 8. Met reviews given 9. Teamed students 1.1. Returns a list of students that an individual has teamed up with 10. Get due date 1.1. Gets the due date for each assignment assigned to a student 11. Get peer review data 12. Get author feedback 13. Get submission data 14. Get timeline data. The following are our written tests in the order listed above: Details regarding what the test is testing can be seen as comments above each example block Here were are creating all of the mock objects to test the functionality of the student_task model. We are using these from the previous implementation <code> Here we just verify that topic name is stored and that any values for topic name that are falsey will be set to ""-"" <code> Here we are testing the different values that the student tasks status can take on <code> Here we are making sure the content has been submitted during the current stage of the process, only occurss when current_stage is equal to ""submission"" <code> Hyperlinks is modified based on the teams that a user is in. This will be updated if they are in a team or they already have hyperlinks it will remain the same <code> Simply testing to see if the incomplete status is checked correctly <code> Verify the stage of a task and that a started task is evaluated correctly <code> Returns the relative deadline if applicable <code> Checks if an assignment is in a stage where revisions can be made <code> Checks if a metareview was given in current task stage <code> Checks if a student task has been started <code> Checks the current work stage of an assignment <code> The following test returns a list of students that the user has teamed with up to this point. Returns an empty list if they have yet to team with anyone <code> This test returns the due dates of assignments assigned to a student <code> Here we fetch different timelines and account for edge cases where there are no reviews <code> Retrieves author feedback <code> Here we verify different states of submission data and hyperlinks <code> Here we are ensuring that the timeline data is empty when data has not been mapped <code>. 1. 94 relevant lines 2. 86 lines covered 3. 8 lines missed 4. Coverage = 91.49%. Some of the tests were rather shallow, get_timeline_data specifically needs depth added. <link> <link> <link>.","This document consists mostly of code snippets.  It does help the reader understand what has been added, but it could have been done more clearly.  First, you could have used subheadings in Mediawiki markdown to list the tests, e.g., as sections 6.1, 6.2, etc.  These headings would have been in the table of contents, which would make it easier to find things.  Second, you give a one-line description of what each test tests.  In some cases, comments in the test itself describe its workings in more detail, but in other cases, the reader would have to read the code to figure it out.  It would be considerably easier if you wrote a couple of sentences to describe the strategy used in the test, e.g., as in the comments for ""describe ""content_submitted_in_current_stage?"" "".","Hello,

Thank you for your thorough description of your project and its work. Congratulations on achieving an impressive coverage score of 91.49%. You've demonstrated a clear understanding of the project demands, as well as the importance of in-depth testing in software development. Here are a few points for your consideration based on your work:

1. **Unit Tests**: Completing insufficient tests for 'student_task.rb' and increasing path coverage significantly was a major accomplishment. Your test descriptions and what they cover are well explained.

2. **Mock Objects**: Your systematic use of mock objects to test functions shows good understanding of how they can be used for unit tests.

3. **Edge cases and branch coverage**: You've done well to cover edge cases and emphasize high branch coverage.

4. **Depth**: While it's great that you've written many tests, it would be beneficial for some of them to have more depth. For example, as you've mentioned, tests like get_timeline_data could be expanded. 

Consider this for future projects: While creating tests, it's important to not only test for normal or expected behaviors but also for possible incorrect/abnormal inputs or behaviors. This will help in achieving a robust and highly reliable system.

5. **Outcome-based**: It seems you have mostly focused on testing methods and functions within your code. This is certainly important but also consider testing that is outcome-based or behavior-based. It is important that higher-level behaviors of your system are working as expected.

Lastly, don't forget to document your tests. Documentation is as crucial as the code itself and ensures that your or others, who might need to maintain or expand your code in future, will understand what your tests cover and how.

Great job overall. Looking forward to your future projects!"
379,E2000,"Expertiza is a web application using Ruby on Rails framework. The creation and maintenance of this application is handled by NCSU students and faculty. The basic functionalities allow the instructor to create and edit, both new and existing assignments. Also it allows the publishing of surveys and peer reviews, while allowing students the opportunity to sign up for topics, teams, submit assignments and peer reviews. Assignment.rb is a large file, that has dozens of methods and fields. Some methods seem redundant, and some fields and string literals are repeated multiple times throughout the file. Ie. 'Finished'. Each method in the file is essential and provides different data, so the goal for my team was to rename and merge code where we could, while not affecting the end functionality. Due to the fragile nature of the methods in Assignment.rb, our team decided to focus on redundancy in the code and anywhere we could merge redundant code into common methods. Also there were quite a few strings that were used constantly in the file, ie. 'Finished' that we decided to make constants, to reduce complexity if the values ever changed. - One of the main issues I saw in the code was the reuse of string literals in comparisons. These would cause hige efforts to change later if there are hundreds of places where these strings are used. Instead I replaced all instances of these strings in the file with constants, to lower complexity. Added these constants to file: <code> Removed references to string literals and made constant values <code> - The next issue I found was in multiple places where the code was making the same boolean checks. Instead rewtiting tge checks each time I made a method to return True/False for the check. <code>. For testing, assignment.rb was already tested pretty well. According to Code Climate it had a B grade for test coverage. Thus the testing effort for this project was not heavy, but we did want to be sure that none of our changes broke any existing tests, and all of our additional methods were tested. Also there was a method response_map_to_metareview which was not being tested in case of an error, so I added a test case to be sure the exception was raised. For example, one new method we added was: <code> For this method we added a few tests to validate the method was returning the values we expect. <code> <code>.","The document is very short, but so are the changes to the code.  It is a straightforward explanation of the changes made, but it could have identified the places better (it didn't refer to the line numbers where the changes were made). ","You provide detailed and clear explanations about your approach to the assignment, which is great. I appreciate your focus on improving the readability and efficiency of Assignment.rb by eliminating redundancy and introducing constants. 

However, there are a few areas that could be improved. 

1. Proofread: There are a few spelling and grammar errors throughout the document. For example, ""hige efforts"" appears in the fourth paragraph, and ""rewtiting tge checks"" in the paragraph after. Correct spelling and grammar is essential in maintaining a professional and clear report.

2. Interpretable content: Throughout the report, you have written ""<code>"" multiple times in places where you might have intended to include actual examples of code you used or changed. Whenever you want to discuss specific code, make sure you include it so your reader can understand what you mean.

3. Clearer explanation of method function: In relation to the point above, when discussing the new method, provide more explanation than just saying it returns true/false. What does it check for? What is its purpose in the context of the program?

4. Test case explanation: For the response_map_to_metareview, you've mentioned that you added a test case to be sure the exception was raised. It would be helpful to explain what error case this handles, and what the desired outcome is.

Incorporate these tips next time for a more robust report. You've clearly done great work; the next step is making sure it's communicated effectively. Keep working on it!"
380,E2052,"The Expertiza project is software to create reusable learning objects through peer review. It also supports team projects, and the submission of almost any document type, including URLs and wiki pages. Expertiza has Assignment objects, which represent an assignment that is done by some number of users. For some assignments, students need to select a topic before submitting work. Topics associated with an assignment be reached as follows: 1. Log in as an instructor or a TA. 2. Select Manage->Assignments, which will bring up a list of assignments. 3. Click on “edit logo” under the “Action” column of an assignment. 4. Click on “Topics” tab in edit assignment page. If an instructor or a TA wants to delete topics, he has to delete one topic at a time and has to wait for the page to refresh and then (s)he can proceed to delete the next topic, topics can only be deleted one by one. 1.There should be a checkbox column, along with other columns in “Topics” tab, where a user can select the topics (s)he wants to delete. 2.There should be a delete button/link at the end of the topic table with the name “delete selected topics” to delete the selected topics after a confirmation, prompted post clicking the button/link. 3.There should be a button/link alongside “delete selected topics” by the name “Select all” so that a user can select all and delete them in one go after clicking on “delete selected topics”. 1. Beside ""Home"", click ""Manage..."", then click ""Assignments"". 2. Choose an Assignment ( 'Madeup Problem' is recommended).Then click ""Edit"" below Actions. 3. Click ""Topics"" tab. 4. Create some topics by clicking ""New topic"" on the bottom line. 5. Select them and click ""Delete selected topics"". Then click ""OK"". (It may take a while!) 6. Then you shall see that they are deleted. <code>. File: app/views/sign_up_sheet/_add_topics.html.erb Added 'Delete selected topics' button and 'Select All' checkbox We have also written a custom function 'deleteTopics' inside of <script> tag. This will collect all the topic id that we select via the checkbox and will send it to the sign_up_sheet controller for further processing. <code> File: app/views/sign_up_sheet/_table_header.html.erb Added 'Select' and 'Topic ID' header <code> File: app/views/sign_up_sheet/_add_signup_topics.html.erb We have changed one line of code in this file to add the 'id' parameter in the table tag <code> File: app/views/sign_up_sheet/_add_signup_topics_staggered.html.erb We have added a check to see whenever there is no signup topic , it should not show the link for 'Show Due Date' <code> File: app/views/sign_up_sheet/_table_line.html.erb Added checkbox fields for each row and each checkbox has an id called 'topic_check'. Each topic identifier has an id tag = 'topic_id' <code>. File: app/assets/javascripts/signup.js selectAll function checks all checkbox of topics in the table. <code>. File: app/controllers/sign_up_sheet_controller.rb It defines the following functions: delete_all_selected_topics : This function deletes all the selected topics load_all_selected_topics : This function loads all the rows ( tuples ) from sign up topics which have the selected topic ids. <code> File: config/routes.rb Added route for delete_all_selected_topics in signup_sheet_controller <code>. We can see that we have a check-box coloumn in the table. We also have a 'Select All' option at the end of the table. <image> We can select a few topics in the table by clicking on the appropriate check-box <image> We can select all topics in the table by clicking on the 'Select All' option <image> When we click on the 'Delete Selected Topics' button , we get a popup asking for conformation. <image>. File: spec/controllers/sign_up_sheet_controller_spec.rb We created assignment with id '1' and topic with id ['E1732'] and passed it as params to post function of delete_all_selected_topics. The test expects a success flash message 'All selected topics have been deleted successfully. Then it expects to redirected to '/assignments/1/edit#tabs-2' <code> File : spec/features/assignment_creation_topics_spec.rb This test checks the presence of 'Select All' checkbox and expects to check if all the checkboxes are selected when 'Select All' is checked. <code> This checks that if none of the topics are selected and nor the select all checkbox is checked, if the 'Delete selected topics' was clicked the topics would still be present and there would be no change to the page. <code> File : spec/features/staggered_deadline_spec.rb We created an assignment with assignment name 'Assignment1665' and added 3 topics to it (Topic_1,Topic_2,Topic_3) and for each of them we have added staggered due dates. The test expects to select all the topics by checking 'Select All' and delete all the topics after pressing 'Delete selected topics' button. The test checks, that all topics are deleted by checking if the 'Topics' tab has disappeared from the window. <code>.","Document is readable with a good outline for the contents. A couple more relevant screenshots of system before the changes would have been good. Some streamlining needed in the doc (It contains all the relevant information but not arranged the way it should be).  OTOH, there are very good descriptions of the code changes that have been made, and the snippets are short enough to be readable.  This will be a big help to anyone who follows on to this project.","Dear student,

Thank you for submitting this in-depth assignment on Expertiza project software and your potential work on adding functionality for deleting selected topics. Your report is comprehensive, and the steps provided for both implementing the feature and operating the feature are precise and easy to follow.

It is clear that you have put a commendable effort into improving the end user experience. The addition of the checkbox column, delete button, and select all button would greatly streamline the process for users. 

Your description of the code and the logic used are precise and clear. The details given about the routes, functions, and file changes are extensive and shows a proper understanding of the backend logic along with the frontend changes. 

I also appreciate the addition of screenshots throughout the description. These give a valuable visual context to the changes that your code is making and give the reader a better understanding of the results.

However, your assignment seems to be missing an explicit evaluation or discussion of the results. Did the implemented function perform as expected? Did you encounter any problems or areas for improvement while testing? Providing insight into your testing process and the outcome would greatly benefit your report.

The test coverage seems comprehensive, but it would be beneficial to include tests for some edge cases. For example, what happens when you try to delete a topic that does not exist? How about when you select some topics and then click ""Select All""?

Lastly, don't forget to proofread your work as it suffered from typos and missing punctuation at times, which can make it harder for the reader to follow your thought process.

Your work so far has been excellent and I am looking forward to seeing your continued progress.
Keep up with the good work!

Best regards,
[Your Name]"
381,E2007,"<link> is an open-source that project that is supported by the students and faculty and NC State. It enables a peer review and social networking platform that empowers students to approach development projects through a real-world structure by allowing them to sign-up or bid on the projects they desire to work on, create collaboration teams, and provide constructive feedback on other students projects. In the fall of 2019, <link> was done well but the team did not write any tests for their code. Because of this, their branch cannot be considered for merging into the master Expertiza branch. For this collaboration, we implemented appropriate tests for the majority of the methods using RSpec. Refactor review_mapping_helper.rb contains about 25 methods for helping assign reviews and calculate scores some methods had exceeded the limit on the lines of code and was missing proper comments on the functionality of each method. Cyclomatic complexity of most of the methods was way too high as defined in the <link> . <link> is a behaviour-driven development framework written in Ruby to test Ruby code. For our tests we used RSpec to create the test cases for the methods in question. Because the helper file contained methods that couldn't be appropriately tested within the RSpec framework, only the methods that were testable within RSpec were addressed. In total, we wrote 22 tests to verify the methods in review_mappping_helper.rb. The test framework mocks a number of objects and active record entries in order to provide appropriate inputs to methods being tested. Also, a number of methods had bugs that had to be resolved before the test suite could be implemented. Each test has different preconditions to ensure the tests run appropriately, however, most of them included creating active record entries for participants, grades, the review response map and assignments. See below for an example of what this looks like. <code>. The methods below had bug fixes applied in order to ensure proper functionality. tree_display_controller.rb : Added logic to check if child_nodes is not an array object. <code> review_mapping_helper.rb : Refactred submission_state so color.push in in obtain_team_color. <code> response.rb : Added provision to add an empty comment if there is no additional comment, and still maintain array size. <code>. Below is a list with all the classes and methods that were testable within RSpec framework. Included is a short summary of what the method does, and how its functionality is being tested. This method checks if a link was updated since last round submission. The test verifies that it will return false if the link was not updated, and true otherwise. <code>. This method checks if a review was submitted in every round and gives the total responses count. The test verifies that it returns false if there are not enough responses for rounds, and true otherwise. <code>. This method checks if work was submitted within a given round. The test verifies that if no work is submitted it should return false and true otherwise. <code>. This method returns hyperlink of the assignment that has been submitted on the due date. The test checks that if no link is submitted the method returns nil, and when a link is submitted that the right link is returned. <code>. This method returns when a web page was last updated in a date-time object. The test verifies that the method is returning the correct object type. <code>. This method gets the response map data such as reviewer id, review, object id, and type for the review report. The test verifies that the response maps are appropriate for a given dataset. <code>. This method checks the submission state within each round and assigns team colour. The tests here check that the correct colours are being assigned by the method based on the submission state. <code>. This method sorts the reviewers by the average volume of reviews in each round, in descending order. The tests here checks that the method is properly sorting reviewers. <code>. This method returns the average feedback score for an author. The tests check that if the team size is greater than one that the returned object is empty, and if the max team size is one it returns the author score. <code>. This method moves data of reviews in each round from a current round. The test check that the elements are properly initialized. <code>. This method returns review and feedback responses for all rounds for the feedback report. The tests check the number of responses returned by the method is the same as those in the ActiveRecord. <code>. This method sets the values of instance variable. The tests verify the instance variables are properly set. <code>. This method returns review and feedback responses for a certain round for the feedback report. The tests here verify that the feedback responses for the feed back report, adn the associaated information to identify them are properly being handled by the method. <code>. <code>. <code>. The following methods either had functions that existed beyond the scope of what is testable withing RSpec or where not utilized at all in Expertiza, therefore these methods have no tests associated with them: create_report_table_header get_review_metrics initialize list_review_submissions display_volume_metric list_hyperlink_submission display_volume_metric_chart get_css_style_for_calibration_report. <link> <link> <link> <link>.","The documentation shows the changes to the code, but does not explain how the logic has been fixed.  The test plan lists the methods linearly (22 of them), but does not group them into categories that would be easier to understand.  American spelling should be used in the documentation and code; however British spelling seems always to have been used.","Dear Student,

You have done an impressive job on your coding project and your detailed and intensive report truly speaks for your hard work and dedication!

Among the strengths of your work are the detailed explanations given for each method and the thoroughness in handling bugs before applying your test cases. It is apparent that you have sound knowledge on the principles of software testing and have put that into practice quite well. This has resulted in increasing the reliability of the code and also in the identification of quite a few bugs which were effectively fixed.

There are few areas for improvements that I would like to highlight:

- Your writing contains a significant number of grammar mistakes. Please ensure to proofread your work before submission as proper grammar is as crucial in your write-up as it is in coding. You may consider seeking assistance from a peer or using online grammar check tools.

- You’ve given a very detailed explanation about the functionality of the methods, their errors, and how they are tested. But I suggest including a broader explanation about the code, your approach and the challenges faced during the testing and refactoring process.

- The details on the issues you encountered, how you resolved them, and how you implemented the RSpec tests are insightful. However, adding a step-by-step description of the same would give a more comprehensive understanding of your debugging process.

- I noticed that few methods are send without tests. Although you’ve explained that they contained features that couldn’t be tested within RSpec or were not required in Expertiza, it would be beneficial to explore if there might be alternative methods or testing libraries suitable for these type of methods.

Please take account of these suggestions when you work on future assignments. Keep up the good work!

Best Regards,
[Your Name]"
382,E1749,"Expertiza is a website that is used and developed by NCSU students and faculty. Coded using Ruby on Rails the source code is readily available on Github -> <link> . The website is used by students for organizing teams, signing up for topics, reviewing other teams and another bunch of tasks. The faculty i.e. Instructors and TAs use this website to set new tasks, add new questions and a few other tasks. One of several ways to set up the environment and the one we adopted is:- Ubuntu-Expertiza image (.OVA) [Recommended] This is the link for the image. ( <link> ) And you can install VirtualBox (free) and import this image into VirtualBox. Some machine may require you to enable virtualization and then run the following commands. <code> <code> <code> <code> 1. For logging in as an instructor:- Username: instructor6 Password: password. 1. questionnaire_controller.rb 2. questionnaire_controller_spec.rb. 1.1. questionnaires_controller.rb is a fairly complex file. 1.2. It contains a lot of methods that are long and hard to understand, these methods need to be broken down into simpler and more specific methods that are easier to read/understand. 1.3. Also, the few instances of code duplication that exist should be removed. 1. Complete pending tests in questionnaires_controller_spec.rb, and write integration tests for newly-created methods. Please finish one set of pending tests first before refactoring corresponding methods. 2. Refactor create method 1.1. Write failing tests first 1.2. Split into several simpler methods and assign reasonable names 1.3. Extract duplicated code into separate methods 3. Refactor update_quiz, save_choices method 1.1. Write failing tests first. 1.2. Use polymorphism to replace the long switch statements 1.1.1. Move if conditions to corresponding subclasses (eg. MultipleChoiceCheckbox.rb, MultipleChoiceRadio.rb) with same method name 1.1.2. Replace the conditional with the relevant method calls 1.1.3. Remove duplicated code 4. Use find_by instead of dynamic method 1.1. Write failing tests first 1.2. L68, L385, L386, L559, L560. 1. Testing 2. Refactoring Testing. For testing methods, we don't have to check the preconditions, as we have been assigned with refactoring the methods and testing those refactored methods properly. We check the file questionnaires_controller_spec.rb, and test the methods required to be refactored based on our modifications we have to carry out in the spec file for the testing methods. <table>.","There really isn't enough prose to explain what you have done.  For example, there's no prose description of the tests, or the strategy you used in creating tests.  For most refactorings, the before & after code is shown, with no real description of why & how the code was changed or improved.","The assignment contains a good amount of information on the tasks to be performed. You seem to have a clear understanding of Expertiza and it's functionality. The steps provided on how to set up the environment and how to refactor code are well detailed. However, there are some areas you need to improve on for better presentation and understanding. 

1. Try to use clear numbering for the tasks to avoid confusing on which steps to follow. For instance, I see you repeating '1.' in many places. This can make tracking of the tasks difficult. 

2. Also, ensure to properly format and separate your paragraphs. This makes it easier to read and follow along. For example, ""Login as an instructor:- Username: instructor6 Password: password."" stands on its own and should be given it's own space.

3. In your description of the tasks, I think you should standarize your format when listing the steps to follow for each task. Some places you have given clear numbering and sub-steps within steps while other places you have not.

4. There are lines of ""<code>"" that are not followed by any code, it is necessary to remove them to avoid confusion.

5. In the assignment, you've outlined various tasks, like refactoring create method, update_quiz, save_choices method. However, the task is incomplete without specifying what the initial problem is with these methods and why they need refactoring.

6. Finally, you should provide a conclusion summarizing the tasks and an explanation of how they will improve the overall system.

Please adjust your assignment according to the feedback above. Once you've made these changes, your assignment will be much more ""reader-friendly"" and easy to follow for anyone trying to understand it."
383,E1852.1,"<link> is a web application designed for academia. The users of this application are instructors and students. A user as an instructor can create new assignments as well as customize existing assignments for students. Students can submit assignments, view assignment deadlines, bid for an assignment topic, create a team and peer-review learning objects (articles, code, websites, etc). The Rspec file participant_spec.rb existed with test cases for name and fullname methods and provided path coverage of 36.08% for the participant model. The test cases must be written so that the path coverage is above 90%. Also, ensure that the branch coverage is as high as possible for many edge cases. The files to be worked upon are: 1. app/models/participant.rb 2. spec/models/participant_spec.rb. The task is to write unit test cases for testing the participant model file. The procedure for project planning included :- 1. Setting the Expertiza environment. We used NCSU VCL image of [CSC517, S18] Ruby on Rails/Expertiza. 2. Understand the functionality of model file in participant.rb 3. Understand the linked data attributes being used, like assignment, topic, questionnaire 4. Writing testing conditions for different functions. 1. Reserve a NCSU VCL image of [CSC517, S18] Ruby on Rails / Expertiza. 2. Connect to the reservation using SSH and enter your campus credentials for User ID and password. 3. Commands executed for setup in terminal of VCL image: <code>. <link> is an open source project written in Ruby, hence it uses <link> which is a unit test framework for the Ruby programming language. To access the effectiveness of our testing, we have used <link> , a code coverage analysis tool. Test responses A Participant has many ResponseMaps that map a connection between this participant as a reviewer and as a reviewee. Each ResponseMap has many Responses associated with it. When responses method is called on a Participant, it should return an array of responses associated to this Participant. <code> The test below will test a participant with no corresponding mapping. Hence the result of the responses provided by the participant is a nil list <code> Test name The method name returns the name of the participants <code> The test below will return the name of the participant. A factory build initializes the participant with the name as student and calls the function to expect student as the outcome <code> A Participant is a User. When name method is called on a Participant, it should return the name of this User. <link> Test fullname A Participant is a User. When fullname method is called on a Participant, it should return the full name of this User. <code> The test is done similar to name that it expects a name which was loaded in the factory build <code> Test delete and Forced delete The method deletes a participant team if the participant is not associated with any team. It makes a call to force delete when the argument is true A single test case can validate the positive scenario of delete method <code> <code> The test case will attempt to delete the participant. Since the participant is not having association it will call the forced delete function and returns participant for deleting. <code> Test topic_name The method return the name of the topic which the participant has been assigned with. <code> The test will check for the error when the participant is having an assignment without a topic, unnamed topic and with a topic. <code> Test able_to_review A simple method which gives the status on whether participant can review. <code> When able_to_review method is called on a Participant, it should return true if it can review and false otherwise. <code> When scores method is called on a Participant, it should return the total scores it received for a given number of questions. Test get_permissions This method returns a hash of the boolean value based on the authorization. The result of the boolean determined the ability to review , take quiz and submit. <code> The test case here checks whether the output hash will have the correct combination of trues and false for the authorization <code> Test get_authorization The method get authorization basically determies the role based on the ability to submit, review and take quiz <code> The test cases below are designed to validate whether the method produced the 3 desired outcomes. The first test case validates the outcome to be reader, second one check for the outcome submitter and third will check if its a reviewer <code> Test sort_by_name Participants are Users. When self.sort_by_name method is called on a Participant, it should sort a given set of participants based on their user names. <code> The test builds participants using <link> methods and assigns name as specified. Then a function calls for sorting and the expected outcome is matched with the result <code> Test Scores The method scores calculates the score based on the number of the round. <code> The first condition is when the round is nil <code> The second condition is when it is not nil <code> Test Email The method here sends a email to the participant with the appropriate message, <code> <code>. We have a coverage of 94.05%. To achieve the coverage for scores(questions) method in participant.rb, we had to comment out the overriding method scores(questions) in its sub-class assignment_participant.rb. The test running can be seen at <link> The repository having the modified model files can be viewed at <link>. 1. <link> 2. <link> 3. <link> 4. <link>.","Some of the tests are described very well, explaining what they test and what the outcomes are.  Other tests have little description.  Tests like the one for topic_name are long, so the various steps should be explained.","Dear student,

Thank you for your detailed account of developing test cases for the Expertiza model file – the participant.rb file attached to your assignment. You have demonstrated excellent skills by showing clearly how you've set up the environment, understood the model file and its functionalities, and crafted well-described test cases. 

Given that you have achieved a coverage of 94.05% on your test cases, you have met the assigned task's requirements admirably. It is a good practice to ensure the highest possible test coverage in order to discover potential issues – kudos on that. 

Your elaborations on various testing scenarios - name, fullname, responses, delete and forced delete, topic_name, able_to_review, get_permissions, get_authorization, and sort_by_name - are thorough and show your understanding of the model's functionality. 

With regards to your description of test scenarios and test cases, it is commendable how well you've explained them. This level of meticulous detail benefits both you and any future developers working on the project. 

However, a few suggestions for potential improvements: 

1. The scores(questions) method's description could be better detailed. Your explanation doesn't fully articulate the functionality of the component and why you had to comment out the overriding method in assignment_participant.rb.

2. Your description for the email method test is missing. Please provide a description for this method in your assignment revisions.

3. It would be helpful to further comment your code for clarity.

4. It's good practice to avoid ""magic numbers"" and instead refer to these constant variables at the beginning of your test suite, making the tests easier to maintain.

Overall, great job on your assignment! Please make the necessary changes and submit for a re-review. Keep up the excellent work!
"
384,E1466,"This wiki deals with our implementation of a controller in expertiza: <link> for the Expertiza Project using Ruby on Rails. Expertiza is a web application where students can submit and peer-review learning objects (articles, code, web sites, etc). It is used in select courses at NC State and by professors at several other colleges and universities. Classes involved: grades_controller.rb What it does: This class lists the grades of all the participants for an assignments and also their reviews. Instructor can edit scores, calculate penalties and send emails for conflicts. What needs to be done: 1. Modify calculate_all_penalties method which is too complex and long. 2. Put the get_body_text method in a mailer rather than in the grades_controller. 3. Refactor conflict_nofication method to conflict_email and make it delegated to the mailer. 4. Refactor view_my_scores method to grades_show and delete the unnecessary variables. 5. Try not to query for reviews and meta reviews in grades_show method. What we have done: 1. Modify calculate_all_penalties method. 2. Refactor the conflict_notification method to conflict_email method. 3. Simplify sending email function and make it delegated to the mailer. 4. Send a conflict email to the reviewer automatically when instructor click the button ""email reviewer"". 5. Remove get_body_text and send_grading_email method from grades_controller. 6. Refactor conflict_nofication method to conflict_email and make it delegated to the mailer. 7. Use Design Pattern Delegation in ConflictMailer. 8. Refactor view_my_scores method to grades_show method. 9. Search for the key reasons which lead to huge waiting time for getting score. 10. Refactor get_assessments_for method in response_map.rb and lead to more than 90% off the current waiting time. 11. Eliminate the search for reviews and meta reviews during the grades_show method. 12. Delete unnecessary instance Variables. Current System (After Refactoring Grades_controller): <link> <code> Student: user1600 and user1601 Password: test Original System (Before Refactoring Grades_controller): <link> <code> Student: user1600 and user1601 Password: test All our test result based on the following test cases on expertiza, please follow these step to get it. Instructor: (Searching ""Program 2"" using ""Ctrl + F"" will be convinient for you.) <code> Student: <code>. <code>. <code> <code> <code> <code> <code> <code>. Set JAVA_HOME for the rjb gem: Your path may be different. You can generally find out the path by looking at the symbolic link at /etc/alternatives/java <code> This outputs something like '/usr/lib/jvm/java-6-openjdk-amd64/jre/bin/java'. Only part of this path may need to be set to JAVA_HOME. In this instance, it is '/usr/lib/jvm/java-6-openjdk-amd64'. <code> <code>. <code> <code>. <code>. <code>. <code>. <code>. <code>. We have modified the calculate_penalties method and implemented all the functions it originally has. After our modification the method shrinks from 45 lines to 32 lines of Ruby code. Originally, the method includes a lot of unnecessary if and unless statements which makes the method uneasy to read and seems to have a difficult logic to calculate the penalties. According to the <link> which calculate the complexity of the method, originally, it has a complexity of 85 , however, after we modified it, the complexity goes down to 65 . Please check at <link> , <link> We have done the following to the original methods: 1. Used for loop with selective choice to create penalty attributes and put it into the CalculatedPenalty Table, instead of duplicating the almost same code. 1. Used Object-Oriented Design patterns of Ruby: let the array respond to the method min which returns the minimum number in the array and get the logical penalty other than using if statement.(max_penalty if total_penalty is larger than max_penalty, total_penalty if total_penalty is smaller than max_penalty) 1. Eliminated the unnecessary if statements to make the code clear to read. 1. Modify if statements: Before Refactoring: <code> After Refactoring: <code> 1. Using Objected-oriented Pattern Before Refactoring: <code> After Refactoring: <code> 1. Using loops rather than duplicate same code Before Refactoring: <code> After Refactoring: <code>. We refactored the conflict_notification method to conflict_email method. When instructor click the button ""email reviewer"" whom he thought give a unfair review, the system should be able to send an email to the reviewer automatically.The get_body_text and send_grading_email were removed from the controller. The sending email function is well simplified and delegated to a conflict_mailer. Delegation: The conflict_email should be able to send email. The class ConflictMailer works as its delegate .The conflict_email calls the send_conflict_email function to take the job of sending an email. UML: Draw UML graph for Grades_controller. The old conflict_notification action queries an email address list of a certain kind of reviews. In its view conflict_notifiction.html.erb, A email form contains email list for instructor to choose from and email content. <image> Before Refactorring , in conflict_notification: First,Get the instructor email address as sender <code> Then,Based on submission of review, the action query all the reviewers' email address <code> The email list is for instructor to choose from. The process_response method queries the email address. <code> The get_body_text method construct email content which should be removed from controller. <code> The conflict_notification action requiring another two method ""process_response"" and ""get_body_text"" method to get the recipient email list and email content which contributes to extra complexity. The instructor only have to click the button ""send email"" in conflict_notifiction.html.erb and turn to send_conflict_email action, then he/she can send the email. If the instructor want to send another email, the process will repeat again,which will be terrible when reloading the ""view"" scores page. After Refactoring :The querying reviews actually have done in our show_reviews action, and we can get the individual reviewers' email address.In the reviewer table,we add extra button ""email reviewer"".Now the instructor could send to reviewer email directly. <image> In _review_table.html.erb,we add the link to send email. The review_id is passed to the conflict_email action taken as the recipient. <code> In our new conflict_email action: We still need the instructor as the sender <code> The reviewer_id is passed from the link,we can query his/her email address to send the email <code> The responsibility of sending email has been delegated to a new mailer conflict_mailer. And the email content was constructed in the mailer. <code> Take a look at new conflict_mailer, it define a send_conflict_email method. the email was sent from sender's email and to reviewer's email.Some instance variables were used in view. In conflict_mailer.erb <code> In its view send_conflict_email.txt.haml, we edit the email content.By this way, we deleted the get_body_text and well followed the rule of MVC design <code> The link ""email reviewer"" request a ajax,so the current view page will not refresh when the action done <code> If an email was successfully sent,The instructor should get the alert window by ajax. <image>. We refactored view_my_scores method to grades_show, deleted many unnecessary instance variables along with several review and meta reviews methods inside it. Therefore, the system will only search for scores in the database rather than search for scores and reviews, which wastes a lot of time during the grade show process. After refactoring, the complexity on this decreased from 53 to 35 . We also optimize get_scores method to improve the efficiency of showing scores by students and instructors, which cost us most of the time during the project. After refactoring this method, the time cost of views in grade controller decreased by more than 90% . We have done the following to the original methods: 1. Refactored view_my_scores method to grades_show method. 1. Searched for the key reasons which lead to huge waiting time for getting score. 1. Refactored get_assessments_for method in response_map.rb and lead to more than 90% off the current waiting time. 1. Eliminated the search for reviews during the grades_show method. 1. Deleted unnecessary instance Variables. 1. Deleted the unnecessary instance variables Deleted Code: <code> 1. Deleted query for reviews and meta_reviews Deleted Code: <code> 1. Modify get_assessments_for method in response_map.rb After doing this, the time cost of view function decreased by more than 90% Before Refactoring: <code> After Refactoring: <code> 1. Add a new method into grades_controller.rb Add Method: <code> 1. Change view_my_score.html.erb into show_reviews.html.erb in views. 1. Add in views(show_reviews.html.erb) <code>. 1. The following test results based on the test case on Expertiza(Assignments: Program 2 style) <table> 1. Original Time for Instructor to View all scores <image> Original Time for Instructor to View all scores 1. Time for Instructor to View all scores after Refactoring <image> Time for Instructor to View all scores after Refactoring 1. Original Time for Student to View all scores <image> Original Time for Student to View all scores 1. Time for Student to View all scores after Refactoring <image> Time for Student to View all scores after Refactoring. 1. <link> 1. <link> 1. <link> 1. <link> 1. <link> 1. <link> 1. <link>.",Good writeup; could use a bit more narration,"Dear user1600 and user1601,

Thank you for the thorough assignment. It is evident that you have put a lot of effort and thought into this work, your documentation is very well detailed. Your optimized solution on the Expertiza platform using Ruby on Rails is quite impressive and the before-and-after comparison shows significant improvement.

In terms of your refactoring implementation, it seems you've made critical adjustments to several methods in the grades_controller file. Adjustments like getting rid of unnecessary if statements, introducing loops to eliminate duplicated codes have indeed improved the efficiency of the system. Moreover, the idea of moving the conflict_notification method to a delegate model shows a good understanding of Object Oriented design. Overall, your performance optimization and refactoring work demonstrate a clear understanding of the MVC framework.

While the detail is appreciable, the presentation of the assignment could use better organization for clarity. It's a bit challenging to follow through due to the bulk of content. Breaking down the content into smaller parts or using formatting tools (like bullet points, subheadings, etc.) to segment the information would make it easier to digest. 

Also, it is not recommended to share log-in credentials publicly even in test environments. To assist in your demo, you could create temporary or guest accounts but avoid putting passwords in texts for security reasons.

Lastly, it would be useful for you to include more details about the testing methodology and the issues you experienced during this implementation.

Congratulations on successfully reducing runtime by over 90%. This could significantly improve the user experience for the Expertiza platform users. Remember that even after successful refactoring, it's important to maintain quality control and keep testing the system for any unknown bugs that might have been introduced.

Overall, excellent work! Keep it up.

Best regards,
[Instructor's Name]"
385,E1838,"In Expertiza, if the instructor doesn’t specify the assignment directory for a submission, the directory defaults to the home directory. This can lead to multiple assignment submissions being in the same place and creating confusion. The aim of the project if to handle all the scenarios that can arise when the instructor is not specifying any directory name. Issue #391: In Expertiza, if the instructor doesn’t specify the assignment directory for a submission, the directory defaults to the home directory. This can lead to multiple assignment submissions being in the same place and creating confusion. Please take a look at the Github issue for suggestions on how to solve this. Issue #1190: An issue with conflicting directories for copied assignments was fixed. You need to write the test to verify that this issue doesn’t recur. This test should check that the assignment directories for copied assignments are distinct from the original directories. Issue #1201: Expertiza has the feature to auto generate the directory names for submissions from the assignment name. However, this may be concerning if two assignments have the same name, in which case the submission folders would be the same and this would again create a problem. This needs to be fixed. 1) /app/views/submitted_content/_submitted_files.html.erb 2) /app/controllers/assignment_controller.rb 3) /app/views/assignments/edit/_general.html.erb. -> When the instructor has not specified a directory path, there is no directory where the files can be stored. -> Hence we allow only links to be submitted in such an assignment. -> In the view of submitted content controller we disabled the button to upload files in such assignment where the directory path is null. -> We displayed the message 'Fie submissions are disabled' whenever anyone tries to upload files to such assignment. Pseudo Code: Added following logic in /app/views/submitted_content/_submitted_files.html.erb <code> Explanation: If the assignment directory path is specified by the instructor then the button to upload files will be displayed else the warning message 'File submissions are disabled will be displayed'. Expertiza has the feature to auto generate the directory names for submissions from the assignment name. However, this may be concerning if two assignments have the same name, in which case the submission folders would be the same and this would again create a problem. Approach taken to solve the issue: Logic for Auto generation of the directory names: Append assignment_name, assignment_id, course_id to make the directory name unique. Files modified: /app/controllers/assignment_controller.rb /app/views/assignments/edit/_general.html.erb 1) /app/views/assignments/edit/_general.html.erb Pseudo code: <code> Explanation: Added a checkbox in the view for creating an assignment. An instructor can select if file submissions are allowed. If he selects 'yes' then if the instructor has given an empty directory path, the name of the directory for the assignment will be auto generated. 2) /app/controllers/assignment_controller.rb <code> Explanation: If the check box is checked, it will pass the value ""on"" to the assignment controller and the directory name will be auto generated. <image>. Link to ScreenCast Bug #391 : <link> Link to ScreenCast Bug #404 : <link>. Steps to test Issue #391 and #1201 1) Login as Instructor 2) Click on Manage , select assignments. 3) New public assignment/ New private assignment 4) Fill in the details 5) Select if you want to allow file submissions 6) If 'yes', then file directory name will be auto generated as 'assignment_name'_'assignment_id'_'course_name' 7) If 'no' 8) Login as a student and you can see that only links can be submitted and file submissions are disabled since the directory is not specified. Following RSPEC Code is added to assignments_controller_spec.rb: The below code RSPEC snippet tests for the issue where in the assignment which is duplicated does not have the same directory for submissions as the original assignment. <code>.",The wiki is not detailed at all. They do not have any screenshots for their functionality. The test plan is not detailed and doesn't include any borderline cases.,"Dear Student,

I can see you have done a good job at working on these issues and problems related to directory defaults in Expertiza. The detailed explanations of the issues and your proposed solutions are appreciated. It seems you've worked diligently on the issues and explain your approach well. 

However, throughout your assignment, there is a need for cleaner formatting and language proofreading. There are some repetitions, which makes it hard for reader to clearly understand your points. Plus, the codes aren’t presented as per the assignment requirement, making it hard for me to observe their functions. As a general tip, consider adding comments inline with your code. You may find that this helps articulate your code's logic more clearly to the reader.

For your future assignments, you might want to take a step-by-step approach, starting from the problem explanation, your approach to solution, the logic behind your implemented solution, details of the tests conducted and their results and perhaps a small conclusion about how your solution impacts the overall system.

In terms of testing your solution, I appreciate the detailed steps to reproduce your tests. However, you should describe them in terms of “test cases” along with their expected results to have them more organized and understandable.

With regards to your RSPEC snippet, remember to explain what the test does in more detail so that anyone replicating the test can understand its purpose and expected result more clearly.

Despite the need for improvements, your assignment shows that you worked hard and put lots of thought in your solution. Keep working at it, and I am sure you will improve even more! 

Keep up the good work!

Best,
[Instructor's Name]"
386,E1461,"Expertiza is an open source web application created by NCSU give a interface for team learning and peer review. Expertiza allows students to create and communicate with teams as well as an easy platform for online assignment submission. Another feature of Expertiza is its framework for allowing a peer review system on assignments, creating an easy way to give and receive feedback on assignments, allowing for improvement and re-submission based on classmates constructive feedback. One part of the OSS project for Fall 2014 was refactoring of different sections of Expertiza. Our team was tasked with refactoring of the StudentTeamController. Most people who are new to working on Linux and Github can have issues working, so these links and instructions can help you setting it up on your computer for final project or other purposes. Setup was done first on Windows and because of lot of gem conflicts with windows, Linux 14.04 was used instead. <code> <code>. Modifications were made to routes pointing to student_teams views by adding helpers as well as changing to new bracket initializers and removed unnecessary parens. Changes were made inside StudentTeamsController.rb as well as anywhere that used routes pointing to StudentTeamsController which consisted of: 1. advertise_for_partner_controller.rb 2. invitation_controller.rb 3. join_team_requests_controller.rb 4. reports_controller.rb 5. response_controller.rb 6. app\views\advertise_for_partner\show.html.erb 7. app\views\student_task\view.html.erb 8. app\views\student_teams\view.html.erb The routes changed were as follows: Before Refactoring: <code> After Refactoring: <code>. All where method calls in the controller were refactored to reflect current style guidelines. These calls were changed from the older style more closely resembling a sql WHERE statement to the more conventional style. In addition, the check variables used in the create and update methods were changed to existing_assignment and matching_teams to better reflect what they represent. Finally, in places where "".where"" was being used to find just one instance, it was instead changed to ""find_by"". The changes made are shown below: Old Where Method Calls <code>. <code>. <code> They were changed to: <code>. Replace <code> With <code>. Different method refactoring techniques were used to make clarity and understanding of code very easy and simple. For example, Rename method technique was used for ""remove"" method which didn't mean anything to more understandable name ""remove_advertisement"". ""Leave"" was changed to ""remove_participant"" which is more helpful for reader. <code> <code> Pull up method refactoring technique was used to DRY up the code and avoid duplication. For example, statement in code below was used at 3 different places in original code so pulling up that command in one method and calling ""team_created_successfully"" at all places made it easy to read code. <code>. Two lines were repeated in multiple methods in the StudentTeamsController, one to set the @student instance variable and one to set the @team instance variable. The setting of the @student variable is used in the view, update, edit, create, and leave methods while @team is set in the edit and update methods. The setting of these variables was moved to methods which cache the values to set the local variables lazily. These methods had to be used as before_actions in order to be usable by the view and edit views. Finally, in order to standardize the setting of the instance variable, the name of the :id params value was changed to :student_id in all redirect calls. Old Code <code> Refactored Code <code>. Commented out code can be restored from the repository. It only serves to clutter the class. Blocks like the one shown below were removed <code>. There is much work left to be done with this controller. Some of the changes have wider scope than just this class. The correct name for the view method is show. This was noticed at the last minue, and because of the use of ""view"" throughout rails simple refactoring tools were not enough to fix this. The largest function by far in this controller is the remove_participant (formally 'leave') function. <code> Everything past the 14th line of code is bookeeping that should be handled by the model itself. In large part, relationships could solve all of the checks if members exist or are empty and destroy them with dependent_destroy. In addition, the current TeamsUser model should be removed entirely and replaced with the had_many_and_belongs_to relationship. The system currently only has limited RSpec tests. The team was only able to implement rudementary tests. Additional tests are required to ensure good code coverage. Instructions to Manual Testing: 1) Open Expertiza Website <link> 2) Login using Username: user2 and Password: password 3) Click on Assignments on Top Bar 4) Choose assignment Team Test 2 5) Click on Your Team 6) From this next page, 4 methods can be tested: <code> <image>. There is no such construct as a ""Student Team"". In fact, ""Student Teams"" can currently have members who are not students (instructors), though the permissions for the instructors actually doing anything in the controller are tied off. A more accurate name of the class, and more accurate roles for the class, could be defined by ""AssignmentTeamsController"" which is the actual focus of this class. The current permissions scheme forces the permissions to be checked at the beginning of the controller. This makes it so that the controller has the dule role of interfaceing the views with the model AND managing its permissions. The inheritance structure currently forces `action_allowed?` to happen before any other before actions. This causes any prerequisite or dependent conditions in action_allowed? to have to be set inside `action_allowed?`. However, this method is not called in the case of a Super User login, and therefore these types of members need to be set both in the action_allowed? and before the view is shown. Finally, the current permissions scheme causes the odd structures we see in the ""View"" call. <code> As you can see, the view method checks permissions again in this call (outside action_allowed?). In addition, this is not very dry, as the are defined here copies of the actual permissions set in the InitiationsController. This could be addressed to clean up the beginning of the controller. However, this is a sweeping change across the whole codebase. There exists a bug in the create call. Currently, Ruby throws: <code> on <code> This hapens with the unrefactored codebase (Git Rev d2144d13a6fd26203e464a90beaaaceb69506c6f) as well. Dynamic Finders (find_by_xxx_yyyy) are depreciated in Rails 4. They should be replaced by `where(xxx: ,yyy:).first` or by `find_by` (non-dynamic find_by is not depreciated). <link> <link> <link> <link>.","Very detailed writeup, with suggestions on what should be done next.","Good day,

Thank you for submitting your assignment on the Expertiza project. Your detailed overview and analysis were quite comprehensive, and your process of identifying and addressing potential problems is commendable. The inclusion of free flow text alongside code blocks makes the document easy to navigate and understand. 

However, there are a few places where we need clarifications. Firstly, the code snippets used in illustrating your points are not visible in the document, and it would be beneficial to include these for a more complete understanding. Explaining these code snippets and why specific changes were made would also make a good addition. 

In your description of the changes made to the naming conventions, it's great to see that you are considering readability and maintainability by other developers. It might be beneficial to elaborate more on how these changes improve the overall codebase. 

Regarding the tests, it would be helpful if you could elaborate a little on what type of tests you implemented and why further tests are necessary for complete code coverage. It would also benefit us if you could share more about any challenges you encountered when implementing these tests and how you overcame them. 

When talking about potential improvements and existing bugs, offering a potential solution would go along with the problem statement. It would be insightful to include your thoughts and suggestions on how these issues could be dealt with in future iterations.

One suggestion for improving the structure of the document is to perhaps include subheadings or to structure your document in a manner that quickly orients the reader.

Nevertheless, this work shows strong analytical and problem-solving skills. Keep up the effort! 

Looking forward to seeing your final project.  

Best,
[Your Name]"
387,E1948,"This page gives a description of the changes made for the review_mapping_helper.rb of Expertiza based OSS project. Expertiza is a web application where students can submit and peer-review learning objects (articles, codes, websites, etc). Instructors add and grade the assignments submitted by students to Expertiza. Students can be assigned in teams based on their selection of the topics. It has functionalities such as peer reviews in which students can provide feedback on other's work which helps peer in better developing the project. It is supported by the National Science Foundation. The review_mapping_helper.rb has multiple functions with a high complexities namely - Cognitive, Perceived, Cyclomatic, Assignment Branch Condition size (ABC size) and Lines of Code (LOC). The review_mapping_helper.rb has methods which exceeds the limit on lines of code Also, it is missing proper comments for each functionality. Cyclomatic complexity of most of the methods is way too high as per the standard defined in the <link> . The following process is carried out to complete the project- <image>. The comments about the internal functionality of the following functions were added : get_review_metrics , get_review_metrics , get_review_metrics , get_review_metrics , get_review_metrics and their sub-functions. Example : get_review_metrics function Before <code> After <code>. The method get_review_metrics had cognitive complexity of 6 and ABC size complexity 25. It was refactored using .dig() function and removing .to_s function by changing the variable type. Before: <code> After: <code> The method get_awarded_review_score had ABC size complexity of 19. It was refactored using .dig() function and creating new variable for redundant computations. Before: <code> After: <code> The method get_team_color had Cyclomatic, Perceived, Lines of Code and ABC size complexity. It was refactored by breaking the logical functionality into two sub functions and the main (get_team_color) function. Before: <code> After: <code> The method get_each_review_and_feedback_response_map had high ABC size complexity. It was refactored by breaking the logical functionality into a sub function and the main (get_each_review_and_feedback_map) function. Before: <code> After: <code> The method get_css_style_for_calibration_report had ABC size complexity of 19. It was refactored using .dig() function and creating new variable for redundant computations. Before: <code> After: <code>. There were refactoring changes made in the function. Testing was carried out to check the Cognitive, Cyclomatic, Perceived, Lines of Code and Assignment Branch Condition (ABC) size complexities of these functions. Rubocop was used to test these complexities of the functions. We also did automated testing using RSpec. Also, Travis-CI build of each pull request merge was checked to ensure that the code is working properly after refactoring. Rubocop testing results for ""get_review_metrics"" function after refactoring. <image> Rubocop testing results for ""get_awarded_review_score"" function after refactoring. <image> Rubocop testing results for ""get_team_color"" function after refactoring. <image> Rubocop testing results for ""get_each_review_and_feedback_response_map"" function after refactoring. <image> Rubocop testing results for ""get_css_style_for_calibration_report"" function after refactoring. <image>. Travis-CI Build Test of the beta branch after a refactored function is merged in the beta branch. <image>. We carried out automated testing using Rspec for the files where we made changes to, during the project. All the 14 test cases in the spec file successfully passed. Note: In some cases, to resolve the code climate issues we have broken down an existing long function into logical smaller functions. In these cases, we are neither manipulating any instance or class variables nor are we manipulating any values being fetched from the database in any way. Hence we decided it would not be practical or useful to write RSpec tests to test inbuilt Ruby and Rails functionalities. We followed ""The Magic Tricks of Testing by Sandi Metz - Rails Conf 2013"" [ <link> which asserts the importance of not adding any unnecessary new tests as well as getting rid of any kind of unnecessary tests. Link to Rspec Testing Video: <link> <image>. 1) <link> 2) <link> 3) <link> 4) <link> 5) <link> 6) <link> 7) <link>.","1) Document is detailed. Could have explained why they made the changes they did.  Comments such as ""# Setting values of instance variables"" and ""# Iterating though the list"" would be pretty obvious to the reader.  For example, what is in the list, and WHY do we need to iterate through the list?
2) Explained properly what changes they made.
3) Added screenshot and code of what they did and how it was before
4) They could have removed few GIT screenshots. Not required here
5)It is good that you added comments.  But comments like, ""# Iterating though the list"" just tell how the code is structured, and do not say what the loop is doing.  The reader needs to understand what the loop is doing, and this comment does not help.
6) Likewise, for the comment, "" # loops through the number of assignment review rounds and obains the team colour"", the reader would like to know WHY it is important to get the ""team color.""
7) The get_team_color method uses American spelling for some names and British spelling for others.  American spelling should be used throughout.","Dear student,

Your assignment demonstrates strong understanding of complex concepts and your practical execution is impressive. You clearly outlined how your methodology was applied to review the codebase, including the steps taken to enhance efficiency by refactoring various methods. You also made certain to underscore the importance of keeping comments up-to-date when amending pre-existing code, an excellent practice.

You showed a thorough comprehension of code complexities such as Cognitive, Perceived, Cyclomatic, ABC size, and Lines of Code. It was great seeing how you strategically used the .dig() function to reduce complexity and improve code quality.

The explanation of how certain methods were refactored and split into sub-functions for a better manageable cyclomatic complexity is laudable. Similarly, the approach to handle the Lines of Code by tackling redundancy is appropriate and commendable.

In addition, you demonstrated good practices in software development, such as automated testing with RSpec, checking the build status using Travis-CI, and adhering to coding standards using RuboCop.

However, an area for improvement could be in your documentation. It would be useful to provide the actual code excerpts 'before' and 'after' refactoring so that your changes could be visually compared and studied in detail. Including the actual images or screenshots would also provide a better context to your explanations.

Also, links provided in your submission were not functional. Please ensure to cross-check and provide working URLs next time. 

Overall, this was a highly insightful work. Keep up the good work!

Best regards,
[Instructor's Name]"
389,E1709,"Expertiza<ref> <link> </ref> is an open-source web application to create re-usable learning objects through peer-reviews to facilitate incremental learning. Students can submit learning objects such as articles, wiki pages, repository links and with the help of peer reviews, improve them. The project has been developed using the Ruby on Rails<ref> <link> </ref> framework and is supported by the <link> . Expertiza assignments are based on a peer review system where the instructor creates rubrics for an assignment through questionnaires which students use to review other students' submissions. The author of the submission is given an opportunity to provide feedback about these reviews. All questions in the questionnaire have an assigned grade which is based on a pre-defined grading scale. Instructors can see a report on the scores of a student given by reviewers, on the score of feedback given to the reviewers and many other reports. Based on these reports (which are all on separate pages), the instructors grade the student. These reports are, however, on separate pages and it is difficult for an instructor to navigate to many pages before grading the student. The first requirement is meant to solve this problem by merging the review scores with the author feedbacks on the same page. Furthermore, there is no way for an instructor to evaluate the rubric he/she has posted on assignments. Students may consistently be getting negative reviews for a rubric which might not be totally relevant to the assignment thereby reducing their scores. A report of average class scores for each rubric in the questionnaires would help instructors refactor their rubric and understand where students generally perform well and where they struggle. This new report forms the second part of the requirement. We are not modifying any of the existing functionalities of Expertiza. Our work would involve modifying the review report and creating a new report for average class scores. The project requires completion of the following tasks: 1. Integrate review data with author feedback data to help instructors grade the reviewers. 2. Create a new table for review and author feedback report. 3. The new table should have the following information: reviewer name, the number of reviews he has done, length of reviews, review summary, whether there is a link or a file attached, Average author feedback rating per team, Author feedback summary and a field where an instructor can give his grades and write comments. 4. Add interactive visualization to show the class performance of an assignment to an instructor. 5. Create a new route/view/controller for class performance. 6. Add a new link to point to the new controller created. This new link will be created per assignment. 7. Create two new views, one for selecting rubric criteria and second to show the graph. 8. Create graphs to show the class performance as per the rubric metrics selected dynamically. Iterator Pattern<ref> <link> </ref>: The iterator design pattern uses an iterator to traverse a container and access its elements. When we are implementing the response and author feedback report, we will be iterating through each reviewer to get the review performed by them and then each author based on the feedback given for each review. This iteration will occur with the data returned by the ResponseMap model for all of the review and feedback information. For the class performance report, we will be iterating through each questionnaire per assignment, and thereafter each question per questionnaire. The same iteration will also be required to get answers per question per reviewer. MVC Pattern<ref> <link> </ref>: In the MVC design pattern a controller processes the request, interprets the data in model and then renders particular view. For rendering response and author feedback report, we check the the data, in the form that was submitted from the UI, in the ResponseMappingController. Depending on the data, we process various models and then display a particular view. <image>. 1. When the instructor will select the show review report, it will show him the screen shown below. <image>. This report is an enhancement of the review report. 1. A new metric filter is provided so that the instructor can select the average author feedback, average length of comments, check and open the file if it is added by the reviewer. 2. For the above implementation we have modified the following files: 1.1. /app/views/review_mapping/_review_report.html.erb 1.2. /app/views/review_mapping/_searchbox.html.erb 1.3. app/controller/review_mapping_controller.rb 1.4. app/helper/review_mapping_helper.rb 3. The instructor can now also sort the reviewer by the name. 4. We have taken the data from ReviewResponseMap, FeedbackResponseMap, AssignmentParticipant, Response models. 5. From ReviewResponseMap and AssignmentParticipant, for each reviewer we will get number of reviews completed, length of reviews, summary of reviews and whether reviewers had added a file or link for their review. 6. From FeedbackResponseMap and Response, we will get the number of author feedbacks given to a reviewer. Using this we will get the average feedback score for a particular reviewer from all the feedbacks. For this we created a new method called as ""get_author_feedback_score_hash"", that will return a hash consisting of reviewer id and round number as composite key and the score for each round as value. 7. All the above data will be rendered in ""/app/views/_review_report.html.erb"". 8. Hyperlinks are provided where necessary, so that the instructor can view additional details. For e.g. to view review summary or author feedback summary. The demo for the Review report can be seen here: <link> The pull request is here: <link> . <image>. 1. The instructor can view the class performance on assignments by clicking on the graph icon on the assignments page as shown below. <image> 1. Once you click on the graph icon, it will take the instructor to the page shown below where the instructor can select various rubric questions used for evaluation of that assignment. <image> 1. Once you click on the graph icon, it will take the instructor to the page shown below where the instructor can see the performance of the class based on various selected rubric questions. <image>. In order to implement the above functionality for the class performance report, we have finally implemented the following: 1. We added a new controller ClassPerformanceController . 2. We added the following two new views. 1.1. A view to select_rubrics . This view will allow instructors to select a number of rubrics to evaluate the class performance on. 1.2. A view to show_class_performance . This view will display the class performance using relevant graphs to represent the information clearly. 3. Routes for each of the views created. We need to provide a link to the instructor to see this view. As shown above, this will be a button in the assignment management page routed at tree_display/list which corresponds to the function list in the controller TreeDisplayController.rb . The button we added here routes to the newly created select_rubrics view. The select_rubrics view receives the following parameters. <code> The controller gets all the questionnaires related to that assignment from the AssignmentQuestionnaire model. It then gets a list of all the rubrics used in those questionnaires from the Questions model. These are displayed to the instructor. It then routes the instructor to the show_class_performance view upon selection of rubrics. It will pass the following parameters to the show_class_performance view. <code> The controller will take the list of questions for the assignment and find all the answers of those questions. It will then calculate the average score per question for the entire class from those answers and pass this to the view. The show_class_performance view will use the <link> in order to provide an aesthetically appealing visualization of the data. The demo for the class performance report can be seen here: <link> The pull request is here: <link>. 1. View Review and Author Feedback Report as Instructor : As an instructor, he can see the different metrics of reviews and average feedback rating received per student done for an assignment or a project. 2. View Class Performance as Instructor : As an instructor, he can select 5 rubric metrics used per assignment. The instructor is able to see the graph to check the class performance based upon the metrics selected. 1. For use case 1 , test if the instructor can see the text metrics of reviews and author feedbacks received for an assignment or a project per student. 2. For use case 2 , test if the instructor can any number of rubric metrics used for an assignment. Also, test if the instructor can view the class performance from a graph using the metrics selected by the instructor. While software and hardware requirements are the same as current Expertiza system, we will require following addition tools: 1. Tools: Gruff API in addition to the current Expertiza system. <references/>.","A few reviewers said that the design doc explains the requirements, but not how your team is going to achieve them.  We agree.  Most of the changes are changing names, which doesn't require any explanation.  The doc should focus on what you are going to create, rather than show what is in the current system.  You're going to add an ""Update"" link for the expert reviews, but didn't say anything about what code will be changed to do this.  And there is no testing plan.","Thank you for your detailed assignment on Expertiza using the Ruby on Rails framework. You have successfully outlined the purpose and functionality of this project as well as proposed solutions and new features to be implemented. 

Your proposal and explanation was comprehensive, well-structured and detailed, providing clarity on the functionality of each component. I especially appreciated the inclusion of specific tasks required to complete this project and the description of how the iterator and MVC patterns are used.

You demonstrated good understanding of the Expertiza system. Your reasoning is sound and the steps outlined to integrate review data with author feedback, create new evaluation metrics and visualizations to monitor class performance are well-thought-out and practical. 

Your assignment also does an excellent job incorporating visuals, providing hyperlinks for additional information and specifying the tools required for implementation, such as the Gruff API and Expertiza system. 

However, there are a few areas that need some adjustments:

- The images or screenshots you mentioned are missing and need to be added for better understanding. 

- There are some formatting errors, for example multiple sections are numbered as 1. Ensure each point has its own unique number.

- There are few tags like <link> and <code> used without any references or content. Make sure all your tags are properly filled or removed if not relevant.

Also, providing a brief description and motivation for using the Gruff API and any other tools would help in understanding the benefits of those tools for this project. 

Overall, this is a high-performing piece of detailed analysis, and I look forward to seeing how these solutions and features are implemented to improve the Expertiza system. Keep up the good work!"
390,E1681,"Expertiza is an online system that is used by students to view/submit assignments and review others' work. Expertiza also provides tools to visualize the scores and gauge the improvements made during the course semester. It also facilitates and monitors team projects. It is targeted at educational and non-profit organizations. The project is funded by the National Software Foundation (NSF), NCSU Learning in a Technology-Rich Environment (LITRE) program, the NCSU Faculty Center for Teaching and Learning, the NCSU STEM Initiative, and the Center for Advanced Computing and Communication. Expertiza is an open-source project with the source code available as a public repository on GitHub. It is developed using Ruby on Rails and is increasingly becoming robust thanks to the innumerable bugs being fixed by the community. The project has a micro-blog on SourceForge where the developer community report bugs and document updates. Student-generated quizzes is the feature that students use for writing quizzes for the Wikipedia contribution assignment. In this project, we need to do refactoring and create functional tests for this feature. We need to refactor questionnaires_controller.rb and write the Rspec tests file in /specs/ folder. <image>. There is some problems in valid_quiz method which is in questionnaires_controller. For now, this method checks the questions one by one. We will refactor it to make it able to create the quiz_question objects and quiz_choice objects. Then we need to call “quiz_question.valid?” to check whether the question is valid. The code below is how we do refactoring: def valid_quiz <code> The code above is what we changed in questionnaire_controller. And then we created a new method in 3 types question model. <code>. We will test the following functionalities: 1. The instructor can set up an assignment which supports quizzing feature by 1.1. Checking the “has quiz” box 1.2. Setting the # of question for each set of quiz 1.3. Setting in which deadline can student reviewers take the quizzes 2. Student authors can create quizzes and edit them: 1.1. They can create quizzes on the “Your work” page 1.2. They can edit the quiz questions. 1.3. They can view the quiz questions. 1.4. If the quiz question has something missing, the system will flash an error message, either: 1.1.1. The name of quiz is missing. 1.1.2. The question text is missing for one or more questions. 1.1.3. The choices are missing for one or more questions. 1.1.4. The correct answer(s) have not been provided. 3. Student reviewers can take the quizzes on the work they have reviewed/they need to review 1.1. They need to request the artifact to review first. If this artifact has a quiz associated, they can take the quiz in the round which quiz-taking is allowed. 1.2. They can click “take quiz” then request quizzes to take. 1.3. They can fill in their choices on the quizzes. 1.4. After taking the quizzes, and submitting, they will see their grade on the “Take quizzes” page 1.5. On the “take quizzes” page, they can see their question-by-question scores for finished quizzes by clicking “view” 4. Instructor can view the quiz questions and quiz scores on the tree display by clicking “view quiz questions” icon. Let's see an example of how we wrote functional tests: <code>. 11/07 - 11/15 Design work 11/14 Discuss with instructor 11/14 - 11/20 Write first version 11/20 - 11/25 Debug and test 11/25 - 12/02 Final deployment. Refactor: Yi Wei Test: JunYi Liu(Last 2 bullets), Zhongzhi Qi(First 2 bullets) Deployment: Lei Zhang Document Writing: Everyone.","The document describes the workflow, but not the changes that will be made to individual files.  This is an important part of the design, so that readers can see that appropriate principles and patterns are being used.  OTOH, it does have a very detailed testing plan.","Dear Student,

Great job on your assignment! I appreciate your thorough research and the clear explanation of your plans to improve Expertiza's quizzing feature. Your in-depth understanding of the project, its core features, and the technology stack involved is commendable. I can see that you've detailed a roadmap on how to approach the refactoring and testing, which shows thoughtful planning.

However, there are some areas for improvement. Firstly, consider incorporating more explanation of the importance of the structural refactoring you plan to undertake. Explain why and how this will improve the function of Expertiza. Secondly, your testing plan is quite detailed, but it would help further if you defined specific objectives for each test, covering both functional and non-functional requirements. 

Also, the assignment lacks a brief introduction at the start to give the reader a context of what you aim to achieve with this project. There also seems to be something probably amiss in your numbering of functionalities and sub-functionalities, as there are multiple numbering errors throughout the document. Please fix this to avoid any confusion. 

Lastly, make sure you clarify which tasks each team member is responsible for. It will help illustrate each person’s contribution to the project. Please make these edits and revisions to improve the assignment. 

Keep up the good work!

Best regards,
[Your Name]"
391,E17A5,"Expertiza is mainly a peer-assessment system for the students to review submissions made by their peers. For a similar system for journals and conferences, there is one stark difference from the standard peer assessment system. For journals and papers, we need to allow the user to create an account to submit the paper, unlike the standard system where the instructor is supposed to create account for all the students. Also, when a user wants to add a co-author for his/her paper/submission, he should be able to invite them irrespective of the fact that the invited user has an account or not. If the invited user does not have an account, a new account must be created for him/her. For the new system, submitting and reviewing is same as the peer assessment system. This project aims at extending the application of the expertiza system towards reviewing of journals and conferences by peer authors and relevant users. Hence, it enhances the utility of the expertiza platform for better knowledge sharing beyond the simple assignment submission and reviewing. 1. Any non-Expertiza user can sign up, for submitting his/her work 2. Document upload privileges for that user. 3. Adding co-authors to a paper being submitted for reviewing. 4. View for scores/reviews submitted by reviewers. <image> <image> Name: Sign up Actor: Writer Other Participants: None Precondition: He/she should not have existing account on Expertiza Primary Sequence: 1. Go to Conference Reviewing section 2. Provide information in form for signup Captcha 3. Activate account by opening link, provided via e-mail Name: Add contributors Actor: Writer Other Participants: None Precondition: Writer must have uploaded a paper for reviewing Primary Sequence: 1. Sign in 2. Select the uploaded document 3. Select option to add contributors 4. Add information of co-authors. Email, Name, etc Name: Create a submission Actor: Writer Other Participants: None Precondition: The user is logged in and wants to submit a paper. Primary Sequence: 1. Selects the “Submit your work” button 2. Enter the details of the paper, like track of paper (which can be selected from a dropdown). 3. The writer is redirected to an upload page where the user can upload the submission. Name: Upload Paper Actor: Writer Other Participants: None Precondition: The writer has already created a submission window and is at the upload page. Primary Sequence: 1. The writer clicks the “Upload paper”button. 2. The writer selects the paper to be submitted from local device. 3. The writer clicks the “Submit” button. Table to handle many to many relationship between contributors and paper writer. <image> We have reused the users database tables to save the writers and the co-authors by simply assigning a new role to the system and saving that role in the roles database. The assignments database was not reused for the papers as the extra attributes needed for the papers would result in many holes in the database and hence wastage of memory. The database design of the papers is: <image> The teams database could not be reused because in this case the team size is not fixed. Thus, the limited size constraint was not put up. The design of database stays same, just without the constraint. <image>. 1. new_writer_signup.html.erb : /app/views/users/ Needed to allow the author/writer of paper to signup to expertiza. As signup is not part of the current system, this needs to be explicitly created. 2. writer_homepage.html.erb : This is the homepage of the writer. He can view his submissions and access the functionalities available to him. 3. add_coauthors.html.erb : This file is needed to allow the writer to invite co-authors for his/her paper. The writer enters the details of the co-author to be invited in this page. 4. writer_paper_mapping.rb : This is the model needed to map the papers to their authors. As papers and writers have a many to many relation, it needs to be handled by this model. 1. users_controller.rb <code> 2. assignments_controller.rb <code>. Here is a sample code snippet: View: <code> Controller: <code> <code>. The designing practices used will be determined as the project proceeds and the requirements are handled. But for starting the project we will be following the following standard design practices: 1. Model-View-Controller architecture 2. Using standard naming convention for variables and methods, like name_variable, singular words for class name, etc. 3. Try not to violate DRY principle. The automated tests will be implemented based on final implementation of the project as many functions to be used are already defined and tested. But for manual testing, the following test plan can be used. Test plan for Publishing a paper 1) Click on the link from conference website 2) Enter name, password, and email ID 3) Publish paper 4) Fill in the details for the paper to be published 5) upload paper 6) add collaboraters (enter name and email of contributors) Test plan for editing paper attributes 1) Login 2) Select paper from displayed paper list 3) update attributes and save. 4) Logout. <image> The User Signup screen: The user needs to signup to submit his/her paper for reviewing. The user can signup using this signup page. <image> The Login Screen: The user, after signup, will be redirected to this page. The account successfully created notification will be displayed on the top. Now the user can login to his/her account from this page. <image> To submit a paper for conference reviewing, the writer needs to create a paper and provide details about it like conference where it is being presented, primary topic of the papers, etc. The user can upload multiple papers related to a particular conference to this single paper instance created. <image> Once the paper has been created, the user sees the above screen as a confirmation that the paper has successfully been created. <image> The home screen of the user displays all the paper submitted by the user. The user thus can view all of them and edit them using the SHOW link provided next to each paper. <image> The show button is provided next to the listing of all the papers for a particular user. This button redirects to the page where one can edit the details of the paper uploaded. The user can edit details like paper name, date, contributors, etc. as well upload or change the files submitted. <image> The user can upload the files from this page. The user can click on browse button to select a file from the local computer and upload it as a part of the submission. The files uploaded by the writer will be uploaded to the given upload path: pg_data/research_paper/paperID.paperName <image> The user can select a file from personal computer device to upload it for conference reviewing. <image> The user can add contributors to add their inputs to a paper. The user can enter the email address and name of the contributor to send an invite to join the system for contribution. <image> As this is not a deployed version, the invite email sent out cannot be checked from email account, but can be checked on the terminal. This is a screenshot of a typical mail that will be sent out to the contributors when invited by the author of the paper. <image> Once the contributor has been added, the user can see all the contributors in the Your Team section. The User himself is also listed as a contributor. Link to Screencast: <link> For further queries, contact: adupadhy@ncsu.edu dkamin@ncsu.edu vnpatel@ncsu.edu uparikh@ncsu.edu.","With regard to the db changes, what is the table that maps contributors to authors?  Why couldn't the same function be served by the teams table?  What is the new role you created?  Why aren't the existing roles (author, reviewer, etc.) sufficient?  Creating a new table parallel to assignments is a serious violation of the DRY principle, since the functionality is so similar. Don't worry about a few unused words in each record.  The test plan is not sufficiently detailed. It does not say what should be observed at each step.  Also, you have reimplemented a lot of existing model functionality, and should define tests for it.  Your series of screenshots does serve to illustrate the functionality nicely.","You've made a lot of progress with your Expertiza system project. Your detailed explanation of the work done so far shows your proficiency. You have utilized comprehensive user stories, sequence diagrams, and screenshots which demonstrate the functionality of the project. I appreciate the detailed explanation of the database schema you've used, as well as the various views, models, and controllers required for your system. This gives a clear indication of the structure of your project.

As you proceed, I suggest the following areas for improvement:

1. Testing: Your proposed test plans are useful, but you should also consider incorporating automated unit and integration tests. As your system evolves, these tests will be helpful in ensuring previously implemented features continue to work as expected.

2. Review your grammar and sentence structure: There are some areas in your write-up with grammatical errors and unclear sentences, so ensure you proofread your work before submitting it. Clear and effective communication is key, especially when presenting your project to others.

3. Clarify the requirements: Some parts of your write-up, such as the ""new_writer_signup.html.erb"" section and the ""users_controller.rb"" section, are not clear. Make sure to explain these areas in detail and note their significance.

Overall, you are on track with your project. Keep up the good work and continue improving it."
393,E1679,"Currently, the functionality of calibration is limited. It does not support varying-rubric-by-round feature. And for student side, there is no way to notify for an author to tell that a particular review that they received was submitted by an expert. Moreover,if an expert (instructor or TA) has reviewed an assignment, the students should be able to see how that expert rated the assignment, just like they can see calibration results for calibrated assignments by clicking on the “Show calibration results” link. Snapshots of what is currently implemented: 1.Log in as instructor6 and edit an assignment. 2.In “General” tab, check the box of “Calibration for training” and save the change, then “Calibration” tab will be shown. <image> 3.Go to “Calibration” tab and the a list of student works will be given and the instructor can select one of them to begin a calibration review. <image> 4.The review rubrics for calibration is the same as student reviewing and the instructor can make his own review. <image> 5.After the instructor submitted his review, the student can see the detail of this review in his “score” section. But currently, there’s no way to distinguish student reviews and expert reviews. In addition, the instructors cannot implement a multi-round review and vary the rubrics for different review rounds. <image>. 1.app/views/student_review/_responses.html.erb 2.app/views/assignments/edit/_calibration.html.erb 3.app/views/student_review/list.html.erb 4.app/views/grades/_reviews.html.erb. Change the “is_calibrated” field in assignment table to “has_expert_review” Change the “calibrate_to” field in response_map table to “expert_review_to” A new DB migration file would be added to change name of the two existing columns in the DB to a new one and all related search of these 2 column in the files involved above have to be changed to the new name. In assignment setting page (“General” tab), change the checkbox title from “Calibrated peer-review for training?” To “Add expert peer review?”. The related page is at app/view/assignment/index.html.erb. <image>. When instructor clicks that checkbox, there will be a new tab named “Calibration”. Change the tab name from “Calibration” to “Expert review” on the assignment setting page and also change the partial file name from “_calibration.html.erb” to “_expert_review.html.erb”. <image>. To make second round review with different rubric, we can refer to the “/student_review/list” page by impersonating a student, clicking a vary-rubric-by-round assignment and then clicking the “Others' work” link. A student can conduct second or third round review by clicking the update link, then new review form with different rubric will be shown. The related page is at app/view/assignments/edit/_calibration.html.erb. On this page, an update link would be added when an assignment has the second round review as it is in student review page. <image>. Remove “@assignment.is_calibrated == true” condition from app/views/_responses.html.erb, line 80, which means this link will show if expert peer reviews are available no matter whether this assignment is a calibration assignment or not. After this condition is removed, the “Show calibration results” will always be presented to students in their review list rather than the assignment itself also have to be “calibrated”. <image>. <image> As the image shown above, among all the reviews received by the students, if Review 1 is the expert review by the Instructor, two asterisks will be added ahead of its name to indicate that it’s an expert review by the instructor rather than a normal student review.","Design approach is well defined. Could've used observer pattern to log the events. should've listed the location of the source code where the events are to be logged. Testing could be elaborated more than just saying ""RSpecs will be written wherever required"". List the test cases, e.g., filtering user ID, date...","Dear Student, 

Firstly, I appreciate your effort to look into the software's features with such thoroughness, and your intent to improve the experience for users is commendable. Thank you for your detailed and meticulous presentation of each issue and potential solutions.

A few points to consider in your approach:

1. Oversight: Your assignment is very technical and you have provided a lot of detail on the implementation part. However, try to include a synopsis or overview at the beginning of your document. This would allow readers to understand what issues you're addressing and the proposed improvements without getting lost in the details.

2. Justification: While your solutions seem effective, you haven't stated why you have chosen these specific changes. Always include a justification and explain how these improvements will be beneficial in solving the problem at hand.

3. Maintain Consistency: There are instances where your naming of variables lack consistency. For example, ""is_calibrated"" and ""has_expert_review"" - choose either is_xx or has_xx and stick with that. This ensures readability and improves quality of code.

4. Images: You mentioned several times about included ""<image>"", however, the images are not visible here. Do ensure your images are correctly embedded when you're presenting your assignment.

5. Punctuation: Be careful with punctuation and grammar to improve clarity in your writing. For instance, placing periods outside ""<image>"" could be confusing.

6. Software Practices: It seems like you are modifying a database column directly to solve the problem. This might not be a good practice as it may break backward compatibility. It may also cause issues with stored data, so explore alternative solutions.

Overall, good job taking a deep dive into the software function. Continue to develop your technical audit and problem-solving skills to create the most effective solutions possible."
394,E1686,"In this project, We will keep track of timestamp records for students' submissions and updates of artifacts (links to google doc/wikipedia/github), reviewers' submissions and edits of peer-reviews and author feedbacks.We will also create a timeline view for each artifact, showing when it was submitted/resubmitted and when it was reviewed. With our work, users (students and instructors) can see: 1. when do the authors submit and update their artifacts. 2. when do reviewers submit peer-reviews. 3. when do reviewees send author feedback. 4. when do reviewers update their peer reviews. <image> From a perspective (both instructors and students), users should be able to see such a timeline with all the events for each submission of an assignment. The events can be - 1. add/edit events of various submission links/files 2. Reviews 3. author feedbacks 4. peer reviews Each of these artifacts can be edited and updated multiple times. Because we want to track when these artifacts are updated, we have to store their information in the database. We use the table suggested in the problem description “submission_histories”- 1. Id :: integer- primary key for this table. 2. team_id :: integer ← foreign key to the teams table 3. submitted_detail :: string ← details of the event. This can be one of x values. 1.1. Link - if it is a assignment submission link. This can further be of 4 types - 1.2. Google Docs 1.3. Wikipedia 1.4. Github repository 1.5. Any other web link 4. Review ids - if the event is a review submission 5. Author feedback id - if the event is an add or edit operation on author feedback. 6. Peer review id - if the event is an add or edit operation on peer review. 7. Submitted_at :: datetime ← to store the timestamp of the event 8. Type :: string ← field which distinguish between different types of events - to be used for polymorphism. 9. Action :: string - add / edit / delete based on the event. These are the common components under which each component in the timeline can be classified. Each of these components are explained in detail on how it fits into the timeline and its significance and types listed. Data stored in submission_histories table 1. Google Document, Wikipedia article, Github repository url : All of these are types of links given by the team during their submission. Through the url, we will identify which type of a submission is this, and then create an object of the particular class using the factory pattern. Each of these classes will implement their own “getLastUpdatedTimestamp” method, using the suggested APIs, through which we can get the required timestamp. 2. File path and any other web link - These are also a part of main submissions, but since there is no way of tracking changes to these artifacts, we just take the time of the system when the link is added or removed. 3. Peer Reviews, Author feedback: Peer reviews and author feedbacks are updated into the submission history table for every edit that takes place. The “updated_at” field acts as the current timestamp for edits in the Peer Reviews and Author feedbacks and the “created_at” field marks the start of these Events. Data retrieved from existing tables 1. Reviews: Timestamp for assignment reviews are taken from “responses” and “response_maps” table. The responses table contains round field and when “is_submitted” flag is true, the submission appears on the reviewee timeline where the “reviewee_id” retrieved from response_maps table. The reviews attached to the respective reviewee are collected and updated_at field gives the submission timestamp which is used on the timeline. Each review is collected and is added to the single Event map. 2. Timeline Parameters: Values corresponding to an assignment which are common for a given Assignment are retrieved from the assignments table. And the timeline parameters are obtained by calculating from the created_at which is the start date for the assignment and the field rounds_of_reviews determines the deadline by adding up the value stored in days_between_submission field of the same table. The Events - Start Date, Submission Deadline and Revision Deadline and Final assignment deadline exists for each assignment. All the components are then added into one single map - Event -> Timestamp which is sorted on timestamp values and is displayed on screen. <image>. Models 1. assignment Rufus scheduler is an in-memory scheduler for Ruby on Rails applications. It works on threads and not crons, hence it is lightweight and easy to use. However, because it is in-memory, a server shutdown will result in the loss of all scheduled jobs. We used it for its simplicity and because it mapped very well to our requirement. An even better scheduler would be resque scheduler, because it uses a Redis backend. <code> <code> 1. files_submission_history <code> 1. github_pull_request_submission_history <code> 1. github_repo_submission_history <code> 1. github_submission_history <code> 1. googledoc_submission_history <code> 1. link_submission_history <code> 1. submission_history <code> 1. wikipedia_submission_history <code> Controllers 1. submitted_content_controller <code> Views 1. submitted_content/_main.html.erb <code> 1. submitted_content/_submission_history.html.erb <image> <image>. 1. Unit Testing of controllers This involves unit testing of following controllers: TeamsController, because we will have to change some methods. 1. Unit Testing of Models This involves writing rspec test for all the newly created models like submission_history, google_doc_submission_history, etc. Tests for team model are already written. 1. models/github_pull_request_submission_history_spec.rb <code> 1. models/github_repo_submission_history_spec.rb <code> 1. models/link_submission_history_spec.rb <code> 1. models/submission_history_spec.rb <code> 1. models/wikipedia_submission_history_spec.rb <code> 1. UI Testing 1.1. Login as student/instructor. 1.2. Go to Assignments Home Page. 1.3. Here you will find a timeline with several tags like submission, review, resubmission, rereview. 1.4. Also, There will be a tags for the authors submitting and updating their artifacts, reviewers submitting peer-reviews, reviewees sending author feedback and reviewers updating their peer reviews. 1.5. As UI would be modified a lot, more testing part would be added after the implementation. 1. <link> 2. <link>.","Screenshot is too big. I am not quite understand ""Refactor files"" section; more narrative description is needed. Section ""The file we need to edit"" should be ""Files we need to edit""","This is a well-laid out project plan with a strong technical focus. You have included an immense amount of detail and it demonstrates extensive forethought. The use of database tables and the data storage system demonstrates a comprehensive understanding of database manipulation, and your communication of the process is very clear.

The attention to testing is commendable. With specific testing for controllers and models, as well as a UI testing plan, your quality control is thorough and robust.

Your proposed use of specific tools, like the Rufus scheduler, shows that you've tailored your toolset to the requirement very effectively, and your explanation of why this is the best tool for the job underpins your decision.

Just a few suggestions for improvement:
- This assignment is very technical and while your technical clarity is generally excellent, it might be helpful to provide a bit more context or explanation of certain concepts for less tech-savvy readers.
- Make sure to include figures and diagrams where appropriate, and make sure they are properly labelled and introduced in the text.
- Contextualize your project more within the broader academic or industry landscape. Who will this project benefit, and how? What is the 'big picture' impact?
- Also, it would be beneficial to dig deeper into potential challenges that may arise during the implementation and how you plan to handle them to demonstrate further understanding of the project’s potential obstacles.

Overall, great work on this! Your deep dive into technical specifics is commendable, as is your thorough testing plan. Keep it up and continue paying attention to both the fine details and the larger context."
395,E1457,"Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.5. <link> 1.1.6. <link>. It is time consuming to assess project work in a large classroom environment, and one of the best techniques to achieve this is to have students assist in this assessment. If each student is asked to assess a few (say, one to five) other students or student teams, the task requires a reasonable amount of effort; and that effort does not increase as the class gets larger. "" Expertiza is a system for managing all kinds of communication that is involved in assessment: double-blind communications between authors and reviewers, assessment of teammate contributions, evaluations by course staff, and surveys of students to assess the assignment and the peer-review process. "" <ref> <link> </ref> ""Expertiza project uses peer review to create reusable learning objects. ""<ref> <link> </ref> Students select from a list of tasks to be performed, with several students selecting each task. Then they prepare their work and submit it to an electronic peer-review system. The work is then reviewed by other students, who offer comments to help the submitters improve their work. The best submissions for each task are then selected for use in later courses. Expertiza gets students working together to improve others’ learning experiences. It helps them learn, by making them think through the lecture material and apply it to a real-world situation, just as they might do in an on-the-job situation. These learning objects can be improved iteratively; for example, the next year’s class can be presented with the examples developed by students the previous year, and asked to identify shortcomings and develop improved examples.<ref> <link> </ref> More information on Expertiza can be found <link> . Refactoring helps to<ref> <link> </ref> 1. Understand what led to poor code design 2. Fix code which is difficult to understand 3. Express each idea “once and only once” 4. Recognize missing or inadequately formed classes 5. Simplify overly complex relationships between classes 6. Achieve the right balance of responsibilities among objects 7. Make code easier to test and more maintainable. We identified the following categories of code smells in the helper module: 1. Lengthy Definitions : These are the methods that have too many responsibilities and collaborators. As a result of which, their overall length has grown too long reducing the maintainability and readability. 1. Duplicated Code : These are those pieces of code that does almost the same functionality of some other piece of code leading to a bad design style. They are usually too error prone since not everyone identifies all the code responsible for the same task and does the changes whenever the need arises. 1. Bad method names : A good method name is expected to adhere to the Ruby style and design style guidelines. It is expected to convey a reasonable amount of responsibilities handled. A good method name in combination with good practices should resemble a user story. 1. Used and unnecessary methods : These are those methods that were useful when the code was first developed. But, they lost their functionality as the code got updated and new functionalities were added or existing ones were modified. There are many documented refactoring techniques, and a few common ones are below.<ref> <link> </ref> 1. Rename Method : Renaming identifiers can reduce the need for code comments and nearly always helps to promote greater clarity. 2. Introduce Explaining Variable : So here is a technique specifically based around the premise of renaming. For example: <code> Should be: <code> 1. Extract Method : It consists of breaking up long methods by shifting overly complex chunks of code into new methods which have very descriptive identifiers. For example: <code> Becomes: <code> 1. Inline Method : Sometimes you want the opposite of the Extract Method technique. Imagine a method exists whose content is already simple and clear, and whose identifier adds no extra benefit. So to fix this problem we'll convert the method invocation into an inlined piece of code. 1. Pull Up Method : When you have duplicated code across two separate classes then the best refactoring technique to implement is to pull that duplicate code up into a super class so we DRY (Don't Repeat Yourself) out the code and allow it to be used in multiple places without duplication (meaning changes in future only have to happen in one place). For example: <code> Becomes: <code> 1. Introduce Named Parameter :When method arguments are unclear then convert them into named parameters so they become clearer (and easier to remember). We were supposed to refactor two controllers, the ReportsController and the DynamicReviewMapping Controller. The ReportsController was thought to be generating reports for students, showing all their scores in a single page. The DynamicReviewMapping Controller is actually a helper to the ReviewMapping controller. The review mapping controller maps reviews to each user. Currently, there are two ways to assign reviews to user: The user can either select a submission himself, which he wants to review, or the site can suggest a review to the user. Currently, the user can give more than two reviews. The ReviewMapping controller had a method so that all the users are assigned reviews automatically. Originally, the plan was to assign only a fixed number of reviews to each user. The dynamic review controller helped the review mapping controller assign reviews so that the reviews are never mapped such that the last user does not have any review to map, except his own. For example, consider three users, U1, U2 and U3. If U1 is assigned U2's work and U2 is assigned U1's work, U3 would not have any work to review. The dynamic review mapping controller makes sure that such a condition does not occur. We were supposed to refactor these controllers. The ReportsController did not have any known use, and the DynamicReviewMapping Controller had changes to be made to make it conform to standards. After searching through various controllers, looking for references used in the controller, we figured out that the code in the ReportsController was actually copied from the ResponseController, in December 2013. The ResponseController has been refactored since, and thus is an updated version. As of the usage, only the ResponseController has been referenced, and the ReportsController had never been used. We also extracted an older version of the ReportsController, that is, the one before it was replaced with code from the ResponseController. The code had a single method, and the method did not have any useful functionality. It was, thus, decided that the ReportsController should be removed from the Expertiza project, and that removing it would not have any effect on the overall project. Keeping it in would, on the other hand, create confusion for other people who would work on the project later. 1. The code block between line 808 to 825 was duplicated in 3 places in this file. We have refactored the code to remove this bad smell. We have created a method called create_message to avoid duplication in the code. (Violated the DRY Principle. Eliminated duplication in code) 1. Method assign_metareviewers, assign_reviewers_team were too long. We have made two new methods (check_assignment_for_review and show_message_for_review_count) that does just one task and does it perfectly instead of large methods to do multiple tasks. (Violated the Single Responsibility Principle and the DRY Principle. Eliminated lengthy methods and meaningless method names) 1. Method assign_reviewers_individual was not used anymore. We have checked for its functionality and deleted it since it did not play any role in the final application. (Eliminated unnecessary methods) 1. We have changed if to unless wherever necessary. 1. Changed "" == 0"" expression to "".zero?"" 1. Used if (var) instead of if (var == true) 1. We have used array checking and made changes according to the following rules: 1. 1.1. Use [].empty? instead of [].length == 0 or [].length.zero? 1.2. Use [:foo].any? instead of [:foo].length > 0 1.3. Use [:foo].one? instead of [:foo].length == 1 1.4. Use [:foo].first instead of [:foo][0] 1.5. Use [:foo].last instead of [:foo][-1] 1. We have used && and || rather than and and or to keep boolean precedence. None of this would actually change the functionality of the code. To make sure, we tried to look for the usage of the code. Again, after extensive searching, we figured that the code was never used. The DynamicReviewMapping controller, as stated above, depended on a set of rules that were not applicable anymore. The controller exists so that it is available, in case the rules are reverted to the original one. As such, currently the Controller is not used. We made the changes, but we have no way to check the code. We did the best we could, and we are sure that there are no errors in the refactored code. 1. <link> 2. <link>. <references/>.",Very little of the writeup refers to changes made by their project.,"Dear Student,

Thank you for the considerable effort and attention to detail that you have put into your assignment. Your understanding of 'Peer review', particularly the Expertiza system, and how it helps in creating a collaborative learning environment is commendable. All your points related to Expertiza like peer-review system, selecting student tasks, and iterative improvement of almost real-world situations demonstrate your solid grasp of the subject matter.

However, your essay seems to slightly deviate from the usual essay format. It seems to be a blend of a technical paper and research project. I appreciate your ability to provide an in-depth examination for code 'refactoring'. Your list of code smells and a detailed solution in the form of refactoring techniques are very impressive and makes it easy for the reader to understand the purpose and practicality of code refactoring. 

The case given for ReportsController and DynamicReviewMapping provides a good example of refactoring practicality and potential outcomes of the process. However, I felt the essay was slightly heavy on technical jargon and code snippets, and this might've made it more challenging to grasp for a reader less versed in the technical language. 

To improve your future work, consider setting a clear overarching structure for your work such as an introduction, main body, and conclusion, while clearly defining each section's purpose. Also, including a brief explanation for jargons and technical terms might make your work more accessible for everyone. 

Please make sure to revise your referencing format. Though you have diligently provided the reference links, they could have been placed in the text in a more standard format to make it clearer for the reader.

Overall, you have demonstrated an impressive knowledge and understanding of the subject, and your practical examples are very appreciated.
You should be proud of your work.

Best,
[Your Name]"
397,E1981,"The rubrics in expertiza are created by instructors. These Rubrics only contain questions that are related to the existed topics. Now, Expertiza only supports students to pull questionnaires is specific rubrics to get some help. Even that they can ask about anything that is relevant to all the projects that will be submitted But when students encounter difficult problems which are not in the existed topics, and they want to get special advice on that new field, the demand for creating supplementary review questionnaire raises. This project (E1981) aims to solve this problem by allowing students to add questions to the standard instructor generated rubric so that they can get specific feedback on from the reviewers. The github repository is <link> . And the demo video in youtube is <link>. We will add the Supplementary Review Questions to the current Review Questions, and show these student-generated questions under the rubric given by instructor. Even though these questions won't be graded, they will eventually provide diversity for feedback. It will increase the benefit that each team gets because they can get feedback that is specific to their project. Goal: In Expertiza, all kinds of rubrics and surveys are subclasses of Questionnaire. A Questionnaire can contain “questions” of several types (e.g., checkboxes, dropdowns, text boxes). We'll add a new subclass of Questionnaire called, say, SupplementalReviewQuestionnaire. 1. there should be a checkbox when creating the whole questionnaire to indicate whether this questionnaire will have supplemental review questions or not. 2. there should be a button that has the content ""add supplemental questions"". <code> <code> 3. After the reviewer finished the review, student can find the supplemental questionnaire in the review page. How we will do this: 1. add a variable in the questionnaire class. 2. add another file for a supplemental questionnaire and save them to the database. 3. add a method to get the corresponding supplemental questionnaire and to add questions into the existed questionnaire. 4. we should add another method to show the supplemental questionnaire in the review page. 1. Assignment Creation Page in Instructor's Account We plan to implement a check box under the column of Rubrics in the assignment creation page indicating whether the instructor allows students to add specific questionnaires with respect to their projects. 2. Your Work Page in A Student's Account We plan to implement a link or button on the Your Work page of an assignment of a student whose assignment is enabled to create supplementary review questionnaires by the instructor, in order to redirect to the Review Rubrics Creation page. 3. Review Rubrics Creation Page In this page, students are able to create supplementary review questions regarding the specifics of their own assignments. 4. Review Page In the Review Page of reviewers, the supplementary review questions created by the owner of the assignment will be shown to reviewers along with the standard review questions created by the instructor. 5. Review Results Page The Review Results Page should display the results of standard questions created by the instructor as well as the results of supplementary review questions created by the instructor. <image>. 1. There should be no link for ""Supplementary Review Questionnaire"" for team members or reviewerss, if the instructor disables this section in Assignment Creation Page. 1. If the instructor enables this section, the link for ""Supplementary Review Questionnaire"" should appear in the ""Your Work"" section of a student, and redirect to Review Rubrics Creation Page. 1. After created or edited, the supplementary review questions should appear as part of the whole review question sheet in Review Page (along with the standard review questions created by the instructor), to team members, reviewers, and the instructor. 1. After a reviewer saves or submits, the responses to the supplementary review questions should appear when (s)he views the responses. 1. After review deadline, all responses to the supplementary review questions of reviewers should appear in My score page of students. spec/controllers/supplementary_review_questionnaires_spec.rb Test if the link of ""Create Supplementary Review Questionnaire"" correctly redirects to the right page. <code> spec/features/supplementary_review_questionnaire_spec.rb Test if a supplementary questionnaire can be created, modifid and stored. <code> spec/models/team_spec.rb <code>. 1. When a new assignment is created, the instructor can enable supplementary questionnaire via the highlighted checkbox. <code> <image> 2. In the submit stage, all team members can create and edit one supplementary quetionnaire to their team. <code> <image> <image> 3. In the review stage, reviewers will get one complete questionnaire (including both the regular questionnaire created by intructor, and the supplementary questionnaire created by the team) and do the review. <code> <image> 4. After review stage, team members can view the list of all the scores and responses of the complete questionnaire of their team. <code> <image>. All modifications are included in the <link> . A new class SupplementaryReviewQuestionnaire (subclass of Questionnaire) is created. app/controllers/supplementary_review_questionnaires_controller.rb app/models/supplementary_review_questionnaire.rb app/models/questionnaire.rb A new boolean column :is_supplementary_review_enabled is added to Assignment. db/migrate/20191126025227_add_is_supplementary_review_enabled_to_assignment.rb Routes related to SupplementaryReviewQuestionnaire are updated. config/routes.rb A new integer column :supplementary_review_questionnaire_id is added to Team. app/models/team.rb db/migrate/20191126032312_add_supplementary_review_questionnaire_id_to_team.rb Supplementary questions are found and added into controllers and views. app/controllers/grades_controller.rb app/controllers/questionnaires_controller.rb app/controllers/response_controller.rb app/helpers/grades_helper.rb app/models/response.rb app/views/response/response.html.erb Modifications on view pages including checkbox and links. app/views/assignments/edit/_review_strategy.html.erb app/views/submitted_content/_main.html.erb Tests added or modified. spec/controllers/questionnaires_controller_spec.rb spec/controllers/supplementary_review_questionnaires_controller_spec.rb spec/controllers/supplementary_review_questionnaires_spec.rb spec/factories/factories.rb spec/features/supplementary_review_questionnaire_spec.rb spec/models/assignment_spec.rb spec/models/team_spec.rb. Expertiza on Github: <link> Pull Request: <link> Pull Request History: <link> <link> <link> <link> <link> <link> Video: <link>.","Good description of what is needed, but as to what was done, code files are displayed with no explanation of the strategy followed.  It would be just as easy to read a code listing.  This is also true of the automated tests.","Dear Student,

Your assignment is quite detailed regarding the new functionality you are trying to add to Expertiza. Your documentation is incredibly thorough, which is quite beneficial for everyone involved. I have a few comments and suggestions to improve it.

1. Goals: The goal of your project is clearly stated. It was easy for me to understand your focus on expanding the breadth and applicability of the review rubrics on Expertiza, particularly moving towards a more specialised review process. 

2. Approach: You have given a concise summary of how you plan to approach the problem. I appreciate the use of list-items, which makes it easy to follow the various steps you will take. However, you could still make it clearer and more straightforward. For example, what does “add a variable in the questionnaire class"" mean? Could you elaborate on what kind of variable and for what purpose?

3. Structure: Some of your numerated lists are unorganized. Some items start at 1, while others keep on counting. Please rectify this in order to maintain consistency and reduce confusion.

4. Details: It was great to see that you have factored in both cases of the instructor allowing and disallowing the supplementary questionnaire. This supports your goal of diversifying feedback.

5. Test Cases: You have thought about testing, which is a crucial aspect of building reliable software. Please give more details regarding what each test does.

6. Proposed Changes: You have a thorough list of files to be changed and their roles. Be sure to keep this updated as you make changes to the system.

7. References and Links: Please make sure that all your ""<link>"" placeholders act as accurate references for the context they are used in.

I look forward to seeing the progress and improvement on your project. Great effort! 

Keep up the good work!

Best,
[Your Name]"
398,E1450,"What it does: Change UI of Expertiza to support varying rubric feature (allow instructors to specify different review rubrics for different review rounds). Expertiza is a web application where students can submit and peer-review learning objects (articles, code, web sites, etc). The Expertiza project is supported by the National Science Foundation<ref> <link> </ref>. The Expertiza project is software to create reusable learning objects through peer review. It also supports team projects, and the submission of almost any document type, including URLs and wiki pages<ref> <link> </ref>. JavaScript is a dynamic programming language of the Web browsers. Despite some naming, syntactic, and standard library similarities, JavaScript and Java are otherwise unrelated and have very different <link> . The syntax of JavaScript is actually derived from <link> , while the semantics and design are influenced by <link> and <link> programming languages<ref> <link> </ref>. This mix of features makes it a multi-paradigm language, supporting <link> , <link> , and <link> programming styles. Classes involved: controllers/assignment_controller.rb (488 lines) views/assignment/edit.html.erb (55 lines) in production branch (not in master branch) What needs to be done: This project requires JavaScript knowledge. 1. A checkbox “Review rubrics vary by round” should be added to the “Rubric” tab in the view of creating/editing assignment. No corresponding field in “assignments” table is necessary. We can tell if this checkbox should be checked by checking “assignments_questionnaires” table by current assignment_id. If there is no record with a non-null value in “used_in_round” field, this assignment is not using this feature and the checkbox should not be checked. (if one assignment has 2 rounds but they are using the same set of rubrics, for each type of rubric there should be only one entry with “used_in_round” field null)R 1. There should be a editable “deadline name” for each due date on “due date” panel if this type of review is specified to be “varying by rounds” in the “rubrics” tab (the input should be recorded in deadline_name field in due_dates table) 1. Another “description URL” text box should be editable when this type of review is specified to be “varying by rounds” in the “rubrics” tab (the input should be recorded in description_url field in due_dates table) 1. The ""deadline_name"" and ""description URL"" could be hidden when you change the status of the checkbox in Due_Date tab 1. A drop-down box which help instructor to select review rubric should be added for a review round when this type of review is specified to be “varying by rounds” in the “rubrics” tab (the input should be recorded in assignments_questionnaires table) 1. There are no tests for the code. Create appropriate functional and integration tests. Since we are developing on the Production branch, in stead of the Rails4 branch, the environment for us would be different from the majority of the class. Here is the list: Ruby: 1.8.7 Rails: 2.3.15 Java: 1.6 Openjdk: 6.0 Database: expertiza_scrubbed_2014_03_14.sql. No checkbox for ""Varying Rubric by Round"" on the general tab for Instructors. In the views / assignment / edit / _rubric.html.erb, we added a checkbox, which can read the value of used_in_round_flag. In Rubrics Tab, add a Review rubric varies by round checkbox, when checked, it displays corresponding number of rounds of Review round 1 to Review round n; when unchecked, it displays as usual. At the same time, it will store new data in the table into database, in assignment_questionnaires table, it will add 1,2,3...n to used_in_round column if the review rubric varies by round; if not, it will store NULL. Everytime webpage refreshes, the checkbox is checked or not according to the value of used_in_round column in the assignment_questionnaires table. In the assignment_controller.rb, we added a method to load the value from database to used_in_round_flag: <code> In the _rubrics.html.erb, we added a javascript function to handle the click action: <code>. No test_box for ""deadline_name"" and ""description_url"" on due_date tab. 1. Add Due Date Name and Description_url to the table, users can fill in blanks and store them in DB 2. Rewrite set button function calling, everytime the button is pressed, it calls submit_form() and update in assignment_controller, then change the @assignment.rounds_of_review value in order to make changes in the DB instantly, which will help Rubrics tab display correctly 3. Add a Change name and description url checkbox. If checked, the Due Date Name and Descripton_url will whow up; if unchecked, the two columns will hide. 4. Everytime when webpage refreshes, the checkbox value will be set according to whether there’s value that is not empty in the deadline_name or description_url columns in due_dates table in DB. In the assignment_controller.rb, we added a method to check if the name and url are NULL in database to make a decision in the initial display (or after webpage refreshes). If there are contents in the DB, which means someone has typed in some texts, it will display the two columns; on the contrary, it won't display to make the table simpler.: <code> And at any time, users can hide/show the two columns by checking the checkbox. Here are the main changes in _due_dates.html.erb: <code> In the end corresponding changes should be made in the end of _due_dates.html.erb, after which the webpage will display corresponding contents (hide or display name and url columns according to whether they are empty): <code>. Existing methods have no enough parameters we want, or they are not returning out results we want. 1. Make small changes to them to fit the new methods we write without interfering the previous methods. The slight changes of functions are small, trivial and less important to readers to understand what we have done. So only examples are shown to convey the ideas, and all the detailed modification can be found at our <link> (on branch production). <ref> <link> </ref> Here's the example: We need to add a round_number for the questionnaire() method in order to make it return different values (actually from different rows of the assignment_questionnaire table) because there're more than 1 rounds now and each round may have different values. previous method of questionnaire(): <code> current method of questionnaire(): <code>. A few cucumber tests are added to perform the functional and integrated test for our project, such as: Scenario 1: An instructor can set the ""Review Rubric Varies by Round"" for an assignment, and set due dates for all of submissions and reviews, as well as different rubrics would be used Scenario 2: A student should see the review rubric for 1st round in the other's work link Scenario 3: The instructor change the due date to start the 2nd round of review Scenario 4: A student should see the review rubric for 2nd round in the other's work link. In app/features/instructor/Vary_Rubrics_by_Round_Test.feature: <code> In app/features/step_definitions/review_rubric_varies_by_round.rb: <code>. Here are the screen shots of the final layouts. <image> <image> As you can see, a Review rubric varies by round checkbox will make a difference, which makes sense. <image> <image> As you can see, a Change name and description url checkbox will make a difference, which makes sense. <references/>.","The screenshots are at the end, which is too far down.  They should be near where the screens are talked about.  I don't think the Javascript functions are adequately defined.  Exactly what do they do (and it looks like they are too long)?","Assignment Feedback:

Dear student,

That is an impressive amount of work you have provided in this assignment! You have explained your process very clearly and in detail, which makes it easy to follow your line of thought. Your overall approach towards updating Expertiza's UI to support varying rubric feature is well thought-out, and shows a clear understanding of the project's needs and requirements.

Moreover, your understanding and usage of JavaScript, Ruby, and the Rails framework is clearly demonstrated in this assignment, particularly in how you've implemented changes and described them. Adding screenshots to show the final layouts is an excellent choice as it gives a clear visual representation of your accomplishment.

One minor issue to consider is the numbering of your action points - they all seem to be labeled as '1.' which could lead to some confusion when someone else is reviewing your work or trying to understand it.

Additionally, while you have adequately explained your code in text, it would have been more helpful to actually embed the code within the text, rather than simply referencing it with <code>. This would provide a more direct way to understand the changes you're making.

Finally, the functionality and integration tests you plan to add are very specific, which is great. Please ensure to provide the results of those tests too in your final submission.

Keep up the good work!

Best,
[Your Name]"
399,E1405,"This model allows for much of the functionality the student requires to interact effectively with expertiza. Here a student is able to sign up for topics, form teams, submit assignments, review other students' work, and check his or her own scores. Initially, there were 26 tests with errors. Many tests required functionality or fixtures that were likely changed by people working on expertiza over the years. Many fixtures required to correct the tests were missing, and had to be added or created. Additionally, several tests were referencing deleted elements of fixture files which were added in order to correct test functionality. Finally, there were certain elements of the code itself in the controller file which had to be corrected in order for tests to run. All tests now pass without errors, failures or deprecation warnings: ......................... Finished in 1.235192136 seconds. 25 tests, 26 assertions, 0 failures, 0 errors, 0 pendings, 0 omissions, 0 notifications. After digging into the code, it became clear that what's needed isn't more tests, but better tests. The existing tests were very obtuse and frequently broken. They are now much more maintainable. There is no current unit test file for student_task, which means there aren't unit tests. Such tests should be added in the future in order to ensure proper functionality. With regard to student_task_controller_test.rb, it really should be refactored more than expanded. It has reasonable test coverage, what it needs is easier to understand, more elegant tests.","Very short, only gives a vague idea of what was done.  You really have to read the code to tell.","The information you've provided on fixing the functionality tests and the overall improvements on the existing system is quite detailed and well-structured, which shows your understanding of the topic at hand. The efforts you've put into this are commendable. I agree with your analysis that merely adding more tests wouldn't have made a significant difference compared to having quality tests that effectively check for system functionality. It's great to see that your proactive approach has improved the tests' maintainability. 

The suggestions you proposed for the student_task_controller_test.rb were also insightful. However, it would be more beneficial if you could have provided more details about why it needs to be refactored rather than expanded. Examples on how refactoring could be done would also be helpful to further support your assertion. Additionally, your observations about the missing unit test file for ""student_task"" is crucial and well noted. Going forward, I would recommend that you include specific steps to follow while adding these tests and how they would improve the system's functionality. 

Overall, you have done a thorough job with this assignment. I suggest that in future assignments, it might be helpful to delve deeper into suggestions for improvement and providing more context for those suggestions. Great work! Keep it up!"
400,E1986,"If the choice of which submission to review is left to student itself, he/she would choose to review those topics which are related to their project or whatever they are highly interested in. This would benefit both the reviewer and reviewee because From a Student's Perspective: 1. Because he/she does not have to spend a lot of time understanding what is going on. 2. The Student would be more focused on giving the review and hence judgment made tend to be more objective than subjective. 3. This would improve the quality of reviews and will also be helpful for the reviewer. 4. By implementing the color-coding feature, the student at any point knows which topic/s are more likely to get and he/she optimizes between ""what they want"" and ""what they can get"" 5. Also, Bidding in Fun !!!!!!! From the Instructor's Standpoint: 1. Because opinions expressed in the reviews are a result of informed decisions, the inference made from the Machine Learning models trained on these data sets would make more sense. When an assignment participant wants to review others’ work, they will be asked to choose an assignment topic. The participant will be allowed to choose from among those assignment topics that have not been already assigned to 10 other participants. If they choose the ‘I do not care about the topic I review’ option, a random topic will be chosen from all the available topics and will be assigned to them. That is, the reviews are being allocated on a First Come First Serve basis. <link> <link>. To understand what's wrong, first consider the differences between Teams Bidding for Assignments and Students Bidding for Reviews. Both of these are Matching or resource Allocation Problems. The former can be modelled as a one-to-one matching problem. (i.e team and assignment has one-to-one correspondence). <image> However, Students and Reviews have many-to-many relationship (a student can choose multiple submissions for review and a submission can be given to multiple students for review) <image> The Mathematical formulation is itself wrong in E1856 and E1928 and they have used the below shown diagram to represent the relationship. <image>. Since they have modeled the problem on the same lines, they have used the same version of the Gale-Shapley or Top Trading Cycles Algorithm used for one-to-many or one-to-one approach. Famous Problems Dealt on these lines. <link> (One-to-One) <link> (One-to-Many). E1928 1. Once the bidding for review topics is done, the selections need to be saved to the database which is not happening and when the page is refreshed, the UI does not retain the bids. 2. The button responsible for running the algorithm cannot be checked and it is a hunk-like icon. 3. The button appears multiple times on the page. 4. The algorithm needs to be implemented in the web service which should be ideally be used from the lottery controller which is not they have tried to implement. The entire code is written in Ruby. 5. The algorithm needs to skip the review topic that the user has worked on. This Code already exists for topic and again written in the new implementation that needs to be integrated into the existing one and hence needs refactoring. 6. Proper tests need to be written. Taken in reference from <link> (Basically a Gale-Shapely version for many-to-many matching situations) We have a set of students S = {S 1 , ..., S n }, and a set of topics T = {T 1 , ..., T m }. Each student must get exactly q S topics (The threshold in our case is q S = 4, it’s up to the student to decide how many of these they want to actually review.), while each topic must be assigned to at least q T reviewers. Students will submit a list of preferences over the set of topics in linear order. If they submit the preferences for only a certain topics, the rest of the topics will be appended to their preference list in a random order. The topics shall have (possibly different) linear order preference over the set of students according to the timestamps of their time of bid and the total number of topics they have bid for. Students with lower timestamps and who bid for lower number of topics will be given higher preference. To begin, we will try to obtain a matching with an approximately equal number of students reviewing each topic, which we call uniform distribution. If no uniform stable matching exists, our mechanism will nonetheless return a stable matching, provided one exists for a given profile of preferences. The average number of reviewers assigned to each course will be <image> where n is the number of students, and m is the number of courses. Clearly, this number is not necessarily an integer. Let us assume that <image> where <image> Matching 𝝁 is a mapping which assigns exactly qS different topics to each student in Sand at least qT different students to each topic in T. We denote the set of topics assigned by matching 𝜇 to the student si and the set of students who were assigned the topic tj as 𝜇(si) and 𝜇(tj),respectively. Blocking Pair (Defined according to our problem): A pair (s, t) is called a blocking pair, if the student is associated with the topic (If he/she is in the group which works on topic t). A Matching Set M is considered Stable if it does not have any blocking pairs. The matching is (pairwise) stable if there are no blocking pairs. Mechanism: First we calculate k, p|, and p|. The goal is for each topic to be assigned to either p| and p| students, and to assign exactly qS courses. The algorithm: 1. Step 1: Each topic proposes to accept the first pI students in its preference list. Each student accepts no more than qS proposals according to his/her preferences, rejecting the rest. 1. Step k: Each course that has z < pI students proposes to accept pI - z students it has not yet proposed to. Each student accepts no more than qS proposals according to his/her preferences, rejecting the others. The algorithm stops when every topic that has not reached the maximum quota pI has proposed acceptance to every student. <code>. 1. routes.rb 2. app/views/student_task/view.html.erb 3. app/views/assignments/edit.html.erb 4. app/controllers/student_task_controller. 1. app/controllers/review_bidding.rb 2. app/models/review_bidding_controller.rb 3. app/views/sign_up_sheet/review_bid.html.erb 4. Source Code for the Web Service <link>. 1. A new link is added in the student_task/view.html.erb file, so that the user can be redirected to the review bidding view to bid for a review topic. 2. The UI looks similar to topic bidding but the catch here is that any participant should not see his own topic either inside the selection or topics table, which is handled in the review_bidding_controller methods of set_priority and review_bid. <code> <code> 1. We are assigning color based on number of people who have chosen for that particular topic, this is handled in Review_bidding_controller.get_quartiles(topic_id) method 2. In the equation for the average number of reviews assigned to each course, we can compute n and m which are essentially #number of participants and #num of topics, the value is qs is taken from @num_reviews_allowed parameter which is associated with every assignment. if the number of students who have chosen that topic is less than k/2 then the color is shown to be green if it's greater than k/2 and less than k, then the color is yellow if the value is greater than red, then red is shown. <code> 1. These Bids are stored in new ReviewBid Model created. <code>. 1. A new link was added in the app/views/assignments/edit.html.erb which redirects to the Review_Bidding_Controller.assign method. <code> 1. This method inturn serializes the data stored in ReviewBid Table and sends that to the service. The service responds back with the participant-review mappings. 2. It is guarenteed that every participant would have recieved a certain number of reviews based on the hyperparameter @num_reviews_allowed defined for every assignment in the Assignment 3. Inputs for the service is as follows: <code> 1. Output is a map of arrays where every user has a list of topic id's that are to be done. 1. The reviews are stored in the table associated with the ResponseMap Model. Reviewed_object_id is the assignment_id. 2. This is handled in the assign_matched_topics method. <code>. A REST client was used to test the web service. Three kinds of inputs were given: 1) The ideal case where most of the reviewers have different bids with different timestamps and where no reviewer has included their own project id in their preferences. 2) The case where all the reviewers select only one project and all of them select the same project, with the same timestamps. 3) None of the reviewers have participated in the bidding. The web service does not produce any error in any of the above-mentioned cases. 0) We were not able to deploy the service on any web server, which could expose the app to the internet. Although, the application was perfectly running on the flask default server. 1) Our tries failed both for gunicorn and Apache Web Server. We are writing this guide just so that it'll be helpful for someone who is deploying this application. 2) Flask Default Server is not advisable to be used in the production environment. 3) Guide using gunicorn server: <code> 4) Guide for using Apache Web Server <code> <code> <code> <code> <code>. <link> <link> <link> <link>.",This is an excellent description of the problem and the mathematical basis for a solution.  What it is missing is a description of how the tests work.,"Dear Student,

Great job on this assignment, you’ve demonstrated an impressive level of comprehension on the topic. The logical flow of your discussion and your clear proposition offer a coherent argument on the mechanism of review allocation and bidding for review topics. Your work shows significant depth in understanding Gale-Shapley's algorithm and its application in this scenario, particularly with your detailed explanation and formulation models.

However, your assignment could benefit from a couple of improvements:

1. Avoiding Over-complication: You've included a significant amount of detail in your assignment, which can sometimes make your points challenging to follow. Aim for more clarity and simplicity in your arguments. For example, the distinctions between many-to-many and one-to-one relationships could be simplified into more digestible concepts.

2. Extraneous Information: Some parts of your discussion seemed to be superfluous to the main point of your assignment, diverting attention away from your main argument. It would help if you aimed for a more concise and focused approach.

3. Structural Organization: Consider restructuring your assignment to create a clearer logical flow between your points. It wasn't always clear in your assignment how one point flowed into the next — a clear structure would help rectify this.

4. Use of Visual Aids: You've mentioned using images and diagrams in your work. In a complex topic like this, they can prove beneficial for better understanding. Make sure they are properly embedded and referred to in your text.

5. Code Explanation: When you provide pieces of code, try to accompany them with more explanations in layman's terms. This would make your presentation more accessible to people who might not have the same level of familiarity with the code as you do.

6. Proofreading: While your grammar and punctuation are generally good, a few confusing sentences and some typos distracted from your overall message. Regular proofreading will help you spot and correct these.

7. References: Ensure that all sources are properly cited and check the validity of the links included.

These are the areas you need to work on for an even better grasp and presentation of your subject matter. You've made a great start so far, and these improvements should help take your work to the next level. Keep up the good work! 

Best Regards,
[Your Name]"
401,E1572,"This page provides a description of the Expertiza based OSS project. Expertiza is an open source rails application developed on ruby and rails. The application allows students to submit and peer-review learning objects (articles, code, web sites, etc). The instructors can create assignments using this application and customize and manage them. It also helps to introduce the peer review system by which students can review the projects of their colleagues. We were expected to write a feature test which mocks the creation of an Assignment. For Expertiza Assignment management is the central part of the workflow. Goals: 1. Understand the flow of the Assignment creation by instructor manually. 2. Mock the same steps using capybara 3. Create multiple assignments with different options and testing their existence. 1. <link> 2. <link> 3. <link>. Visit <link> for the repository URL. Make sure you're logged in if you have commit access, because the URL will be different. <code> See <link> for help on setting up git, authenticating with SSH keys, and checking out a repository. In the expertiza directory: <code>. 1. Go to the expertiza directory. <code> 1. Create the development and test databases. <code> 1. If available, import the database dump that you received in class to pre-populate your database. eg: <code> 1. Run the Expertiza database migrations. This should populate your database with the current tables of the schema. <code>. 1. Go to the expertiza directory if you are not already there. 1. Run the test <code> Note : As our project involves implementation of feature tests for assignment creation rather than refactoring, we do not test the new code via UI (as the new code added are themselves tests). Note : Travis CI build fails because we are directly using the development database for our tests, thus Travis CI is not able to locate the login information. This was done because it was not possible to create factories or fixtures for our tests. So, please don’t consider the build failure in the pull request to be a valid error. 1. To solve this, make sure that you have java installed on your system or else you could do that from <link> . 2. Then set the JAVA_HOME environment variable by typing this on the terminal <code> 1. Run bundle install again. 1. To solve this, we have to install PostgreSQL. 2. Then type in the following set of commands in the terminal <code> 1. Run bundle install again. 1. Here is the link of Expertiza scrubbed DB ( <link> ) 2. Download the file, unzip it and dump to MySQL. 3. Then type <code>. For any other kind of errors faced during setting up the repository, you can write to us at any of the following ids. 1. aslingwa@ncsu.edu 2. gmeneze@ncsu.edu 3. vpaul@ncsu.edu. 1. assignment_creation.rb 2. spec_helper.rb 3. rails_helper.rb The assignment_creation.rb contains the feature tests written to test the creation of the assignment. The rails_helper is copied to spec/ when you run 'rails generate rspec:install'. All the rspec-expectations config goes into the spec_helper_file. We have used Capybara and RSpec to test our application. Capybara helps you test web applications by simulating how a real user would interact with your app. One of the major reasons for selecting Capybara to write our tests was that it has an intuitive API which mimics the language an actual user would use and also we can run tests from fast headless mode to an actual browser with no changes to our tests. No matter which combination of parameters are selected in the creation of the assignment, the test cases should pass. Following are some of the scenarios which we have tested. 1. Create Assignment with Has teams parameter 2. Create Assignment with Has quiz parameter 3. Create Assignment with Wiki assignment parameter 4. Create Assignment with Micro-task assignment parameter 5. Create Assignment with Reviews visible to all other reviewers parameter 6. Create Assignment with Is code submission required parameter 7. Create Assignment with Available to students parameter 8. Create Assignment with all options 9. Create Assignment with no options 10. Create Assignment with Has teams and Has quiz parameters 11. Create Assignment with Micro-task assignment and Reviews visible to all other reviewers parameters 12. Create Assignment with Is code submission required and Available to students parameters 13. Create Assignment with Has team, Has quiz and Wiki assignment parameters 14. Create Assignment with negative scenario. 1. Create Assignment with has teams parameter 2. Create Assignment with has quiz parameter 3. Create Assignment with has Wiki Assignment parameter 4. Create Assignment with has Micro-task assignment parameter 5. Create Assignment with has Reviews visible to all other reviewers parameter 6. Create Assignment with has Is code submission required parameter. <image>. <code> Given above is a portion of the code which we have to execute before testing each scenario. This is encapsulated within before(:each). In order to be able to create assignments, the instructor has to first login. So we set up the environment of logging in in the before(:each) block and navigating to the page where assignments can be created. We have written a total of 27 test cases in the assignment_creation.rb testing all the permutations and combinations with which an instructor can create an assignment. Listed below are a few of those test cases for the creation of a private assignment. <code> <code> The test cases written also contain tests for the creation of public assignments. Listed below are the following tests. Once again we need to sign in the instructor before he can create any assignments. <code> <code> <code>.",Organization is poor.,"Dear Student,

Great work on your submission! It's clear that you are demonstrating a deep understanding of the Expertiza open source software project highlighting the various functionalities of the software and you've executed several detailed test scenarios in the assignment_creation.rb file.

Here are some thoughts and potential areas for improvement:

1. Structure: Your submission was detailed and thorough but lacked clear layout. Each section was not clearly defined which makes it a bit difficult to navigate the document. Please consider using headers to separate each section (i.e., Introduction, Main Goals, Instructions, Important Notes, etc.). 

2. Code Explanation: While you included code snippets in your report, you had minimal explanation accompanying it. Including line by line explanation or comments within the code would improve understanding, especially for someone who is not in your team and unfamiliar with your code.

3. TravisCI: You mentioned that build fails because you're using the development database for tests. While you explained why, it's better to avoid build failures in your code, so finding a solution to this problem would benefit your work greatly.

4. Proofreading: There seem to be some formatting inconsistencies like code not clearly identified in some places and some sentences aren't clearly finished. 

5. Communication: You did a good job in providing your contact details which fosters a good communication culture. 

Once again, great job on the depth content of your work! Paying attention to the comments made and properly restructuring your work will make your document more reader-friendly and help you effectively communicate your ideas and outcomes. 

Keep up the good work! 

Best,
[Your Name]"
402,E1527,"This project is developed as part of Expertiza project <ref> <link> </ref>. The automated metareview tool identifies the quality of a review using natural language processing and machine learning techniques (completely automated). Feedback is provided to reviewers on the following metrics: 1. Review relevance: This metric tells the reviewer how relevant the review is to the content of the author's submission. Numeric feedback in the scale of 0--1 is provided to indicate a review's relevance. 2. Review Content Type: This metric identifies whether the review contains 'summative content' -- positive feedback, problem detection content' -- problems identified by reviewers in the author's work or 'advisory content' -- content indicating suggestions or advice provided by reviewers. A numeric feedback on the scale of 0--1 is provided for each content type to indicate whether the review contains that type of content. 3. Review Coverage: This metric indicates the extent to which a review covers the main points of a submission. Numeric value in the range of 0--1 indicates the coverage of a review. 4. Plagiarism<ref> <link> </ref>: Indicates the presence of plagiarism in the review text. 5. Tone: The metric indicates whether a review has a positive, negative or neutral tone. 6. Quantity: Indicates the number of unique words used by the reviewer in the review. Contents 1.1. <link> 1.2. <link> 1.3. <link> 1.4. <link> 1.5. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.4. <link> 1.6. <link>. Currently, Autometareviews project is used as a gem<ref> <link> </ref> in Expertiza project. Purpose of this project is to migrate this gem to a web service<ref> <link> </ref> and expose its methods on web, which can be consumed by any application as web service. Older gem was dependent old libraries<ref> <link> </ref> such as Stanford-core-nlp, rwordnet, etc. We will migrate them to new libraries without breaking the existing feature-set. We are also going to refactor the source code of this gem file to promote readability, reduced complexity, and code redundancies. We will fix any bug or bottleneck that we can find to improve the performance of this service. We will not add any new feature to the existing feature set provided by the gem. Before making any modification to the existing features, we will present them before Dr. Gehringer and his Expertiza team. There are three separate scope items in this project - 1.1. Migration of existing gem application to a web service 1.2. Refactoring the existing ruby classes 1.3. Migrating to newer libraries, wherever possible. The classes that we propose to refactor are - 1.1. tone.rb 1.2. degree_of_relevance.rb 1.3. wordnet_based_similarity.rb 1.4. sentence_state.rb 1.5. cluster_generation.rb 1.6. plagiarism_check.rb 1.7. graph_generator.rb 1.8. predict_class.rb 1.9. review_coverage.rb No new feature will be developed as part of this project. Any major code change due to inclusion of newer libraries will be communicated to Expertiza project team. Existing code will be tested to ensure the functionality does not change. All developed code will adhere to the ruby on rails coding guidelines<ref> <link> </ref>. Metioned below are the tasks we will perform as part of this project.<ref> <link> </ref> This system is still in nascent stage and have many performance related issues. It takes a long time (about 2 minutes) to generate single meta-review. This is an unacceptable performance statistics for Expertiza. We propose to re-factor code and identify the areas that affect the overall performance of the system. Few areas we identified in preliminary review are: 1.1. Reading seed data from csv in each pass takes up a lot of time. We can move this data into Mysql and use ActiveRecords to speed data fetch. 1.2. WordNet based semantic matching takes a lot of time. We will review the method used and present our finding about areas of concern. 1. Efficient Loop constructs. Description: Many loops over models are implemented using generic “for” loops. Solution: As specified by Ruby guideline, we plan to use efficient ruby loops, such as “each” and “find_each”. 2. Very large methods Description: Several methods have huge amount of code, which makes them difficult to understand and debug. Solution: In most cases, large methods can be shortened through the use of smaller helper methods. Such methods could be reused across different components. 3. Ambiguous method names Description: Many methods have ambiguity between the name used for them and the feature implemented by them. Solution: We will rename such methods to clearly state the feature implemented by them. 4. Legacy Code Description: As the system has been modified for bug fixes and enhancements, unnecessary code has accumulated. Solution: Isolate and remove all dead code. 5. Code beautification Description: Coding style used in gem is not based on Ruby on Rails style, which makes it difficult to read for any Ruby programmer. Solution: Beautify the code with a consistent standard of documentation, and style. The libraries used by gem are very old. We plan to migrate the dependent libraries to their latest versions. Libraries, we have identified are: 1.1. stanford-core-nlp <ref> <link> </ref> 1.2. rwordnet <ref> <link> </ref> 1.3. rjb <ref> <link> </ref> 1.4. bind-it<ref> <link> </ref> We will also migrate the project to use Java 8<ref> <link> </ref>. Expertiza system tries to evaluate each review using an automated meta-review system. This system is packaged as a library and used by Expertiza. Automated Metareview system is an independent entity and can be used by other peer review systems as well. There are many other peer review systems, which can benefit from this system, if this is available for them to evaluate their rubrics. We are working on migrating this system from a library to a web service. The Metareview system is Natural Language Processing based system that compares the reviews written with the original article. The webservice will expose the ""AutomatedMetareview"" method. <image> Web Service Design The request JSON object to the method will have the following parameters : 1.1. original article 1.2. review written for this article 1.3. rubric used during article review. The web service will return the meta-review as a JSON object. The response JSON object will have the parameters mentioned below: 1.1. plagiarism 1.2. relevance 1.3. content_summative 1.4. content_problem 1.5. content_advisory 1.6. coverage 1.7. tone_positive 1.8. tone_negative 1.9. tone_neutral 1.10. quantity <image> Interaction between Client and Web Service. For the project, the code that is being modified is assumed to be correct and meet all feature requirements of the system. Interactions modified due to refactoring will not change the underline system definitions. We will be using the existing test suite used by gem to test any new code modification. We will be writing new test cases for web service implementation and any new public method exposed by existing classes. <references/>.","Very clear (and correct!) description of what needs to be done. All tasks that will be done are well described. Rather abrupt beginning, fails to show where the project fits in the context of Expertiza and other PR systems.","Dear Student,

You have provided a comprehensive architectural overview of the Expertiza project, along with proposed refinements, and the processes to be followed. Your plan is logically structured, commencing with reviewing the existing system properties, proceeding to the identification of potential areas of improvement, and concluding with the proposed changes. You have also primarily targeted the three key areas of project scope, system efficiency, and coding regulations, which shows your significant understanding of software development principles.

Nevertheless, there are certain aspects that can amplify the clarity and quality of your submission:

1. Clearer Description: The challenge of complex task descriptions can be diminished by breaking down the details into bullet points or headers. This technique can be employed in several sections, for instance, when detailing the metrics provided by the automated metareview tool.

2. References Links: Make sure to fill out actual webpage links where it says <link>. Leaving it blank decreases the credibility and verifiability of your information.

3. Image integration: Mention of images in a line of texts is quite ambiguous. If you aim to include images in your project, ensure they are correctly linked or embedded into the text, in the appropriate context.

4. Spelling and Grammar: Ensure your work is free of typographical errors. The misspelled ""Metioned"" needs amending to be ""Mentioned"". Always proofread your work to eliminate such errors.

I appreciate your hard work and diligence in preparing this assignment. With attention to the above suggestions, I'm confident that you'll improve the overall quality and readability of your work. Keep up the good work!

Best Regards,
[Your Name]"
403,E1979,"1. In Expertiza, peer reviews are used as a metric to evaluate someone’s project. Once someone has peer reviewed a project, the authors of the project can also provide feedback for this review, called “author feedback.” While grading peer reviews, it would be nice for the instructors to include the author feedback, since it shows how helpful the peer review actually was to the author of the project. 1. Currently, the instructor can only see several information, including numbers of review done, team the student which have reviewed, about author feedback. The current view report can be shown as below. <image> 1. However, the instructor has no easy way of seeing the author-feedback scores, so it would be far too much trouble to include them in grades for reviewing. 2. So the aim of this project is to build more feedback information into the reviewer report. So that the instructor of the course is able to grade reviewers based on author feedback and review data. 1. We need to implement the integration of review performance which includes: 1. # of reviews completed 2. Length of reviews 3. [Summary of reviews] 4. Whether reviewers added a file or link to their review 5. The average ratings they received from the authors 6. An interactive visualization or table that showed this would be GREAT (We may use “HighChart” javascript library to do it.) 1. After analysis the current code, we found that the number of reviews, summary of reviews and visualization of length of reviews have already existed in the system. So we only need to finished the following tasks. 1. Whether reviewers added a file or link to their review 2. The average ratings they received from the authors 1. As the description of our object, the average ratings part of this project has been done last year. And they add a new column (author feedback) to review report. But their functions still have some drawbacks. So we also need to improve the several functions of author feedback. 1. Fix code to calculate the average score of feedback 2. Make the author feedback column adjust to existing view. 1. So here is our plan and solutions to finish this project. <image>. The basic design of this project can be shown in the UML flow chart below. <image>. 1. We decide mainly change the page of ""Review report"" (Log in as an instructor then go to Manage -> Assignments -> View review report.) from three aspects. 1. We are planning to add one more column to show the average ratings for feedback for a student's review of a particular assignment. The logic for calculating the average score for the metareviews would be similar to already implemented logic for the ""Score Awarded/Average Score"" column. 2. We are planning to improve the column of review length. Now it is just bare data and average data. We will make the review length into visualized chart by using “HighChart” javascript library. So that length of review will become more clear for instructors. The chart will be shown like below. 3. We are planning to add all links which attached to their reviews below Team name. If there are links in the review, the links will be shown below. The Controller design is based on the data we need for view. As we found that the links and files in review are both stored as URLs, so we only need to list url in reviews. So We change following methods. Specify changes will be shown in File Change. 1. calcutate_average_author_feedback_score 2. list_url_in_comments. Here is the file we have changed. 1. _review_report.html.erb We add a new column to show average score of feedback score. <code> Then we use new-added method to show all URLs below each Team name. <code> 2. review_mapping_helper.rb We first fix calcutate_average_author_feedback_score method. <code> Then we add a new method called list_url_in_comments to shown all urls. <code> 3. review_mapping_helper_spec.rb 4. review_mapping_spec.rb Finally, we add some tests for the changes made. The specific test cases will be shown in Test Plan. We will use unit test and functionally test with Rspec, and integration test by using TravisCI and Coveralls bot. As we add new column for Average Author feedback, we add corresponding Rspec test in review_mapping_helper_spec.rb. <code> During the testing process, we found that there are no tests for other columns as well. So we also add some tests for number of reviews completed, length of reviews and summary of reviews in review_mapping_spec.rb <code> <code> <code>. The coverage of Coveralls is 24.272% for whole expertiza. 1. Log in as an instructor 2. Click Manage and choose Assignments 3. Select the Assignment you want to further check, for example, Final project (and design doc) 4. Choose review report and click view 5. Check ""Average Feedback Score"" column, for example, student5061 have reviewed Team_BEND_Final_Project and his Average Feedback Score is 13 of total score 15. 6. Check urls below each ""Team reviewed"", for example, student5698 have reviewed Final project(and design doc)_Team_113, and there is a URL about reactkungfu in his review The anticipated result can be same as below. <image>. 1. <link> 2. <link> 3. <link>.","I think it would have been clearer to start out by describing what you were going to do, and then explain what you didn't need to do, rather than the other way around.  The code snippets provided from _review_report.html.erb don't really give enough context to see what is being done.  When you said you fixed something, it would be helpful to say what was broken and then highlight what fixes it, rather than just giving a code sequence.","Thank you for your comprehensive assignment submission, it provides a good starting point for assessing where you are with the modifications on the reviewer report within Expertiza. I can see that you have a good understanding of the changes that need to be made.

However, the numbering in your assignment appears to be incorrect - there are multiple repetitions of point 1. This makes it difficult to clearly identify and understand the sequence of your points. Please revise and number your points correctly in future work. This will not only make your work easier to understand, but will also improve its professional appeal. 

Don't forget to include any missing information such as the diagrams/images mentioned but not provided in your submission. Including these visual examples will greatly enhance the understanding and context of your work.

Lastly, there are a couple of sections where you go into details about the coding, suggesting changes, and how to fix them. While this is valuable content, it would be even more beneficial if you could provide a brief summary that highlights the key changes made in layman terms for readers with varying levels of technical expertise. 

As for your project plan, it is impressive to see how systematically you have proposed changes to solving the issue. Your plan clearly demonstrates that you have a good understanding of the current coding environment and where the issues lie. 

I urge you to continue that train of thought and ensure each step is properly executed to effect the desired improvements. Also, remember to clearly document each change you make and explain its impact on the performance or functionality of the platform. This will help when you start the testing phase of your project. 

Overall, great effort on your assignment! It is evident that you have put thought into this project. Continue practicing professional and clear communication in your future work. It sets the tone for high quality outputs. Don't forget to implement these feedback and keep up the good work."
404,E1738,"Given that submissions to Expertiza are digital in nature, the opportunity exists to utilize tools that automate plagiarism validation. One of these such tools is called <link> . SimiCheck has a web service API that can be used to compare documents and check them for plagiarism. The goal of this project is to integrate the SimiCheck API into Expertiza in order to allow for an automated plagiarism check to take place once a submission is closed. . This project has been worked on before in previous semesters. The completed code from previous projects did not clearly demonstrate successful integration with SimiCheck from Expertiza, and was not deemed production worthy. Based on this feedback, we started our development from scratch and utilized the previous project as a resource for lessons learned. 1. Create a scheduled background task that starts a configurable amount of time after the due date of an assignment has passed 2. The scheduled task should do the following: 1.1. Fetch the submission content using links provided by the student in Expertiza from only these sources: 1.1.1. External website or MediaWiki 1.1.1.1. GET request to the URL then strip HTML from the content 1.1.2. Google Doc (not sheet or slides) 1.1.1.1. Google Drive API 1.1.3. GitHub project (not pull requests) 1.1.1.1. GitHub API, will only use the student or group’s changes 1.2. Categorize the submission content as either a text submission or source code 1.3. Convert the submission content to raw text format to facilitate comparison 1.4. Use the SimiCheck API to check similarity among the assignment’s submissions 1.1.1. Notify the instructor that a comparison has started 1.1.2. Send the content of the submissions for each submission category 1.1.1.1. We will experiment with how many documents to send at a time 1.1.1.2. Note that each file is limited in size to 1 MB by SimiCheck 1.1.3. Wait for the SimiCheck comparison process to complete 1.1.1.1. We will provide SimiCheck with a callback URL to notify when the comparison is complete, however if this doesn’t work well will revert to polling 1.1.1.2. We will also provide an “Update Status” link to manually poll comparison status 1.1.4. Notify the assignment’s instructor that a comparison has been completed 3. Visualize the results in report 1.1. We will edit view/review_mapping/response_report.html.haml to include a new PlagiarismCheckerReport type and point to the plagiarism_checker_report partial. 1.2. Since SimiCheck has already implemented file diffs, links will be provided in the Expertiza view that lead to the SimiCheck website for each file combination 1.3. Comparison results for each category will be displayed within Expertiza in a table 1.1.1. Each row is a file combination with similiarity, file names, team names, and diff link 1.1.2. Sorted in descending similarity 1.1.3. Uses available data from the SimiCheck API’s summary report. The majority of the updates are handled in new background tasks. Therefore, there weren't many modifications to existing Expertiza files. The current New Assignment interface has two new configuration parameters, which have also been added to the Assignment model. SimiCheck Delay (hours) and SimiCheck Similarity Threshold (percentage) were added. The Plagiarism Comparison Report was added to the ""Review Report"" interface's select box for a selected assignment. Given that this project revolves around integration with several web services, our team is planning to follow the <link> to allow Expertiza to make REST requests to several APIs include SimiCheck, GitHub, Google Drive, etc. This pattern is commonly used to abstract complex functionalities into a simpler interface for use as well as encapsulate API changes to prevent having to update application code if the service changes or a different one is used. We feel this is appropriate based on the requirements because we can create an easy-to-use interface within Expertiza that hides the actual API integration behind the scenes. With this in place, current and future Expertiza developers can use our simplified functionality without needing to understand the miniscule details of the API’s operation. There is no need to store the raw content sent to SimiCheck. We added ""simicheck"" and ""simicheck_threshold"" properties to the the existing Assignment model. The ""simicheck"" property accommodates the number of hours to delay the execution of the Plagiarism Checker after the assignment's due date. ""simicheck"" is -1 if there is no Plagiarism Checker scheduled, and between 0 and 100 (hours) if the assignment is to have a Plagiarism Checker Report. The ""simicheck_threshold"" property is a percentage that filters the Plagiarism Checker's Similarity results. The threshold refers to the percentage of text that is the same between two documents. This model belongs_to the PlagiarismCheckerAssignmentSubmission model. It stores the file IDs returned from SimiCheck, the percent similarity between them, the Team IDs, and a URL to a detailed comparison (diff). This model has_many PlagiarismCheckerComparison models. It represents the results of the comparison among submissions for the assignment. As such it will contain all of the relevant fields that are shown in the view as described in the requirements. Typical overall system operation: <image> Class heirarchy in the fetchers: <image>. The current assignment configuration UI has been modified to contain 2 new select boxes. These select boxes determine how long to delay the Plagiarism Checker after an assignment's due date, and on what similarity percent to filter the Plagiarism Checker Comparison results. After the results have been aggregated they can be viewed in a results report page. This report includes the submission names, the responsible teams, the similarity percentage, and a link to view the similarity results. The Plagiarism Checker Report UI looks similar to this: <image> To view the interface changes, login to Expertiza as an instructor; navigate to Manage... Assignments. Click ""New public/private assignment"". The last two fields on the New Assignment page say ""SimiCheck Delay"" and ""SimiCheck Similarity Threshold"". In ""SimiCheck Delay"", select a value between 0 and 100 to enable the Plagiarism Checker. In ""SimiCheck Similarity Threshold"", select a percentage value to filter the Plagiarism Checker Comparison results. The percentage refers to the percent of same text between two documents. After the assignment ends and the delay period has passed, you can view the Plagiarism Report. Click the ""View review report"" icon containing a magnifying glass and two people (in the third row of per-assignment icons). Select ""Plagiarism Checker Report"" from the select box, and click ""Submit"". If there is any plagiarism to report, it will load. In Expertiza there already existed functionality to schedule or queue tasks for the task system. We have hooked into that system by adding a new task type declared as ""compare_files_with_simicheck"" and then providing the correct date/time configuration. When a task deadline occurs, there is a method that invokes logic based on the task type. Once this task type is detected on a scheduled task, the SimiCheck comparison is initiated. The following code was added to app/mailers/delayed_mailer.rb/perform: <code>. We wrote unit tests for the new functionality that we implemented, this included models, helpers, SimiCheck logic etc.. In order to properly unit test we mocked all interfaces and black box tested the new functionality. Our test cases can be found in the following locations: 1. spec/models/website_fetcher_spec.rb 2. spec/models/google_doc_fetcher_spec.rb 3. spec/models/http_request_spec.rb 4. spec/models/simicheck_webservice_spec.rb 5. spec/models/submission_content_fetcher_spec.rb More specifically the fetcher model tests check that they will accept the proper URL only, and that an empty string is returned on request failure. Since the GitHub and Google Docs API fetchers do not do any scrubbing of the content after receipt there is no need to test this functionality. The website fetcher on the other hand is passed a mock response that includes HTML tags, and the test ensures that they are stripped. The fetcher factory checks that the correct fetcher is returned for a range of URLs, and nil for an unmatched URL. The test for HttpRequest checks that it will accept all possible valid URLs (exceptions like unresolved IP addresses are noted in a comment), since this static method is used by the fetchers to only accept valid URLs. Its get method to start and process a GET request is not unit tested since that is a wrapper for the Net::HTTP::Get. Lastly a unit test is provided for the Simicheck webservice to ensure that the logic we added to handle the API works. There is a delay during the testing of 30 seconds to prevent bombarding their servers with requests, also because the comparisons are not instantaneous. Essentially the test creates a comparison and runs it through the methods used to interact with the Simicheck REST API to ensure that it still works. One caveat is that a network connection is required which could lead to a false failure. All of the above unit tests here can be improved by using a gem that is designed for testing external APIs, like VCR for example, that will mock out low level calls to Net::HTTP::Get, etc, and can replay API responses. This is the best long term solution, however was not implemented in order to not break compatibility with the existing toolchain versions by adding another gem. A high level test using Capybara could also be added to click through the UI and using the factories to create test data as submissions, but there are many complexities to consider there and we opted not to implement here until an API testing gem would be added to the code to replay API responses and calls.","The issues found by the reviewers appear to have been addressed.  This is a well written design doc.  Some of the diagrams could have been a little narrower for the sake of readability.  The document could have addressed the parts of the Expertiza code that were modified.  And it could have included a screenshot or two.  But, it flows much better than most docs and includes almost all of the important issues.","Dear student, 

Your assignment submission is comprehensive and shows that you have put considerable thought and effort into this project. The integration of SimiCheck into Expertiza and creating an automated plagiarism check is an ambitious task but you have explained well how you plan to undertake it. You have addressed the objectives and sub-points with thoroughness, and the incorporation of visuals (images) to help explain your points is commendable.

Your ability to derive lessons from past unsuccessful attempts and tag the project with updated strategies signifies your problem-solving skills. You have clearly outlined the functionality you've planned, but including some software deployment-level details would enhance the write-up even further.

The thorough technical explanations demonstrate a strong understanding of the systems you're working with. Discussing the testing aspect of your project was informative, but you should also consider possibly presenting the expected results of your tests.

Your style in presenting your solution - from creating a scheduled background task to the use of APIs like Google Drive, GitHub, and SimiCheck - is quite impressive. However, the point about striping HTML from the content or providing an “Update Status” link to manually poll comparison status could have been elaborated, as could the consequences of a failed comparison or the pros, and cons of the whole system.

Overall, the assignment is informative and well presented. It is clear that you're understanding the complexities of software development and are considering the probable issues and their resolutions. Well done!

Keep in mind that the user interface changes should be described more thoroughly to give a clear idea of the changes made to the system. Also, the explanation at times is a bit wordy, which could be simplified for clarity. 

Finally, the suggestions about test optimization using gems like VCR are very insightful. I appreciate the forecasted challenges and solutions.

Great work, looking forward to your next assignment! 

Best, 
[Your Name]"
405,E1792,"<link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Instructors can also use Expertiza for interactive views of class performances and reviews. This project aims to improve the visualizations of certain pages related to reviews and feedback in Expertiza in the instructor's view. This would aid the instructors to judge outcomes of reviews and class performance in assignments via graphs and tables, which in turn would ease the process of grading the reviews. 1.1. Issue 1 : The scale is blue to green, which does not make sense. And colors will change randomly each time loading the page. It will be better to scale from red to green. 1.2. Issue 2 : Two adjacent bar represents the response in round 1 to round k. It makes sense only if the rubrics in all review rounds are all the same. If the instructor implements the vary-rubric-by-round mechanism, this visualization will not make sense. 1.3. Issue 3 :The table is presorted by teams in the page View Scores, but you can now also sort alphabetically. The cell view looks way too long, and should be divided into partials. 1.4. Issue 4 : An interactive visualization or table that shows how a class performed on selected rubric criteria would be immensely helpful. It would show the instructors what they need to focus more attention on. <image>. Description: The scale is blue to green, which does not make sense. And colors will change randomly each time loading the page. It will be better to scale from red to green. Approach: Here the color coding is blue to green and also it changes randomly which one color in one graph may represent some other score in the next graph. To fix this issue, we have redefined the highchart_colors data structure to contain the colors defined in the grades.scss file (already defined earlier) as suggested by the Professor. This way no matter what scale is being used it will always have appropriate color coding. Also, the color legend is now appropriate to explain correctly the color-code used. <code> Related screenshot <image>. Description: Two adjacent bar represents the response in round 1 to round k. It makes sense only if the rubrics in all review rounds are all the same. If the instructor implements the vary-rubric-by-round mechanism, this visualization will not make sense. Approach: Here the problem was that the data was represented rubric-wise, that is, if there are 5 rubrics, there would be 5 graphs. A graph for a particular rubric would show the performance of a team in that rubric in all rounds of submissions. This is fine when the rubrics are same for all the rounds. But, since rubric 1 of round 1 may not be same as rubric 1 of round 2, therefore this representation seems illogical. In our approach, the graphs are rendered submission-wise, the performance of a team in all rubrics in a particular round are shown in one graph pertaining to that round of submission. We create an array called chart_data to hold the information for creating the highchart stack charts. Data is now stored in the highchart in form of hash-maps which contain the score as key and score pertaining to different rounds of reviews as value. Earlier, data was stored in the hash map in a way that in the value scores pertaining to different rubrics were getting stored. Our process facilitates the graph/chart formation submission/round-wise instead of rubric-wise (earlier approach). This guarantees the data is represented logically. In the earlier approach, data was represented rubric-wise. A graph for a particular rubric would show the performance of a team in that rubric in all rounds. But, since rubric 1 of round 1 may not be same as rubric 1 of round 2, therefore this representation seems illogical. Now, the graphs are submission-wise, the performance of a team in all rubrics in a particular round are shown in one graph pertaining to that round of submission. This addresses the problem of varying rubric by round. We can now have different number of rubrics in different rounds without affecting the visualizations for instructors. <code> vm is an object of the model 'VmQuestionResponse' (was already defined earlier). It contains the following information: <code> Here we build the 'series' array which is used by the highchart object to render the graph. This array holds the actual data for the chart along with the legend name. By introducing the counter count_rounds corresponding to the counter for rounds, we are able to compress the legends of highchart to a standard form, showing only what is required. Also, we have redefined the highchart_colors data structure to contain the colors defined in the grades.scss file (already defined earlier) as suggested by the Professor. <code> Related screenshot <image>. Description : The table is presorted by teams, but you can now also sort alphabetically. The cell view looks way too long, and should be divided into partials. Approach: Here we can sort the select query with appropriate column alphabetically, or we can sort the table automatically according to user criteria using dynamic table format. And the long view issue can be solved by using paging. Related screenshot <image>. Description: An interactive visualization or table that shows how a class performed on selected rubric criteria would be immensely helpful. It would show me what I need to focus more attention on. Approach: The issue is about getting the performance of the entire class graded using the 5 rubrics criteria.Scores will be color coded for each of the rubrics in each of the submissions. When hovered over the graph , for each score, the instructor should see the number of students , the percentage of students that has scored that particular point in that rubric in that submission. The code snippet used to fix Issue 4 is same as that used to fix Issue 2. The graphs that we are rendering by making use of highcharts addresses this Issue. Related screenshot <image>. 1. 1) Login as instructor 2. 2) Create a dummy assignment and come dummy reviews for the same.Log out. 3. 3) Login as a student. Attempt the assignment. Log out. 4. 4) Login as another student and repeat step 3. 5. 5) Login as either student and attempt the review. Logout. 6. 6) Login as instructor. Go to Review grades page and check the table. If color code ranges from red ( for least score) to green ( for highest score), then test passed. 1. 1) Login as instructor. 2. 2) Create an assignment. Select 2 reviews. Also select different rubrics for both reviews. 3. 3) Login as a student (""A"") and submit the assignment. Repeat this for another student(""B""). 4. 4) Login as student A and perform review. Do this for student B too. 5. 5) Now resubmit assignment as student A and B again. 6. 6) Resubmit reviews as student A and B again. This time the rubrics will be different from the previous round. 7. 7) Now login as instructor and see the visualization of the reviews. You can see the different graphs for different submissions. 1. 1) Login as instructor 2. 2) Create a dummy assignment with some teams. Logout. 3. 3) Login as a student and attempt the assignment and logout. 4. 4) Repeat step 3 for all dummy teams. 5. 5) Login as instructor. 6. 6) Go to View Scores page. Check the grade table. 7. 7) Click on a column header and check if data in it is getting sorted alphabetically. If yes, then the test passed. 1. 1) Login as the instructor 2. 2) Click on the button to compute graphs 3. 3) Compare the bar graphs with separate scores of students in each assignments. 1. <link> 2. <link> 3. <link>.","Excellent textual description and explanation of changes to be made.  Only issue is that screenshots are too large relative to the rest of the text, and the reader needs to zoom out to see them all.  Would be nice to update doc to reflect changes made in project.","The student demonstrates a good understanding of the project and the identified issues. The explanation about the objective and purpose of the Expertiza tool is clear and concise. The issues identified in the Expertiza tool are well-articulated, along with suggestions for improvements.

Your presentation of the code changes, especially for issues 1 and 2, is detailed and demonstrates your understanding of the functionality and organization of the software code. For the first two issues, the mention of changing the color-coding system, and restructuring of the graph displays are insightful ideas with established reasoning.

The solution proposed for the third issue focuses on table sorting and view modification. While this idea is practical, you could have elaborated more on how this can be achieved.

Regarding Issue 4, the idea of an interactive graph for class performance seems helpful. However, this part needs a bit more detail about how you implemented it and how it would work.

Finally, the step-by-step testing approach you provided is very thorough and would be useful for anyone trying to use your solutions for similar problems in the future.

One area that is lacking is the testing on various aspects like scalability, efficiency, and robustness. This could have been touched upon more, having potential for significant impact in real-world usage scenarios.

 Remember to balance technical details with the big-picture implications of your assignment/project. Keep up the good work. Your technical competence and ability to troubleshoot software systems is commendable."
407,E2023,"Expertiza is an open source software project created using Ruby on Rails. Expertiza allows instructors to craft new assignments and edit existing ones. This flexibility ensures that each round of students gets an experience that is appropriate to the given situation. It also allows the instructor to create a list of project options and have the students bid for their favorite project. While their are a plethora of benefits for instructors, students also gain some benefits when using Expertiza. They are able to form teams and keep track of the past peers they have worked with, and are also able to manage the progress and submission of their assignments. Understanding how much time a student spends reviewing another's work is beneficial in order to better estimate the quality of said review. It is important that functionality be added so Expertiza can track and display the given amount of time a student spends on a review. The time spent on each review is a summation of multiple sources: 1. Time spent of the Expertiza review itself 2. Time spent looking at external links 3. Time spent looking at downloadable files The overall amount of time directly spent on the review is most important. One can track the amount of time spent on the review by tracking the amount of time from when the page is opened untill when the review is saved/submitted. Therefore, being able to track the time from once a resource is opened till when the review is saved/submitted will provide a reasonable estimate of the amount of time spent on each resource. This has the benefit of only needing to track information interacted with on the Expertiza review page, as opposed to other external files and links. The following tasks need to be implemented: 1. Time spent on an Expertiza review must be tracked 2. Time spent on external links and resources should be tracked/estimated 3. Overall time spent on the review should be displayed in a ""user friendly manner"". Thus far, Expertiza does not have the completed aforementioned feature. Previous attempts to implement this functionality have been made but the work was not merged into Expertiza code base for various reason. These previous projects are summarized below: 1. <link> identified how to track the active time of windows opened from the submitted links. 2. <link> provided detailed insights on how they planned to track time taken by a student in viewing a submission and possible edge cases. Further, they also implemented popups and figured out a way to open downloadable files. However, the details are rendered in a not-so-friendly manner and hence it was not merged. 3. <link> tried to solve this by incorporating the statistics in the review reports page, but their UI made the page cluttered and not friendly. Further, it was hard to identify which statistic belonged to which review, and there were almost no tests. ( <link> ) 4. <link> tried to solve this by building off of <link> . The team took the base code and attempted to implement the ability to track time spent on the review page, as well as other external links, however the code was not merged due to a large amount of white-space, as well as difficulty in distinguishing actual code changes. In review of previous iterations of this project, it was found that project <link> would prove to be a good reference for completion of this project's requirements. This build has already implemented necessary functionality that helps track of time spent viewing external pages. The code also has an existing user-friendly UI. The reason it was not integrated into expertiza was due to large amounts of white space in files, confusing commit history, and complicated merge of E1791's code, who's repository fork is no longer existing. To achieve our goals outlined in the <link> , many changes needed to be manually implemented using a new commit history. We were able to add the following functionality, while reducing project size from 5000 line changes to less than 1000 line changes: The time spent on the Expertiza assignment review page needs to be tracked. 1. Due to Expertiza generating report text boxes with HTML iFrames, we will track whether or not the document hasFocus() to determine when a student is on the page or not. 2. After 5 minutes of mouse/keyboard inactivity, a popup is displayed asking if the user is still working. At that point, the time contributed towards the total by the Expertiza page is paused until the user interacts with the popup to indicate they are still working. This is already implemented in project <link> . The time spent viewing the external links/downloadable files needs to be tracked or estimated 1. Currently, if a student has an external link open as well as the Expertiza page, time is being tracked for both. Tracking of external links may be unnecessary for the project, and instead an estimation approach may be taken. Either way it is likely that this measurement will be altered throughout development of this project. 2. There are a few solutions one could implement to fix such an issue, such as marking both the start time and end time for when an external link or application was accessed by a user. Another solution which we will attempt in our first iteration of development is to track the time that an external link was clicked, and use the submission time of the review as our estimated end time for the external link. We thought of this design choice because once the report is submitted, the access time to external links should be stopped since the review is complete. The overall time spent on the review needs to be displayed in a ""user friendly manner"" on the ""Review Report"" page. 1. Due to complaints about the use of a tabular method that was implemented in <link> , stating that the review report table becomes too cluttered, we intend to create a pop-up window that will display the results in a table or graph of some sort. The proposed pop up will display all necessary information in a neat and simple self contained form. The exact display is undetermined, however proposed solutions include another tabular design, bar graphs, pie charts, etc. The following section outlines the predicted user interactions with our software. Two potential users have been identified; users and instructors. Students will be interacting with the implementation when filling out a review. A similar workflow from <link> is used, however small edits were made to provide clean code and a trackable commit history. Initially, the user will click on the review they want to complete. Once the link is clicked the time will start to be logged. Upon the clicking of an external link another another timer will begin tracking it. This process repeats until the submission is saved/submitted or the page is exited out of. In the case where a review was previously saved, the timer will pick up from the last tracked time. The diagram below displays the flow of interactions visually. <image>. Instructors will be interacting with the implementation when the are observing student reviews. Once again, a similar story from <link> will be used for the instructor with minor changes. Firstly, the instructor will navigate to a page that displays all current and previously reviews. They will then be able to select a review from the given list and look at statistics about resources accessed and time spent on each resource. Saved reviews and already submitted reviews will be tagged differently. The diagram below displays the flow of interactions visually. <image>. The following section shows various alterations to the Expertiza user interface in order to display information about time spent on a given review. Additionally, some alterations were made to the student's user interface to assist them in their review. 1. Added time value to the table on ""Review Reports"" page. Found in ""Team Reviewed"" column of the table 1. Added a pie chart to show breakdown of where time was spent during the review. <image> 1. Added a timeout reminder that asks the student if they are still performing the review after 5 minutes of the computer idling. <image>. Our datatable is named submission_viewing_events . The attributes and their descriptions are provided in the spreadsheet below. We use map_id to join response_maps table for storing the primary information. Round contains an int variable associated with the specific round review, link contains a character string storing the external link the reviewer clicked on, start_at contains the starting time the external link was pressed, while end_at contains the time when the link was closed. <image> Below shows the database relationship with other tables. submission_viewing_events will be touching response_maps . The highlight demonstrate which field correspond to response_maps key. <image>. Our implementation builds off of the work done in E1989. This previous project has a substantial amount of the functionality already completed for tracking and viewing external pages and certain types of files. The primary error in this implementation is that when multiple files are open, the times at which they record reviews are overlapped creating inaccurate review reports. The displayed review report will also need to be edited to present review reports in a visually appealing manner. The following changes were made: The Rspec file tests each of three methods in the created SubmissionViewingEventsController, for a total of 5 tests. The rspec file can be executed using the following command from the expertiza root directory: rspec /home/[UNITYID]/expertiza/spec/controllers/submission_viewing_events_controller_spec.rb Rspec Test Cases: 1. One test case for action_allowed? (E1791) 2. Two test cases for record_start_time (E1791) 3. One test case for record_end_time (E1791) 4. One test case for mark_end_time (E1989) Rspec results: <code>. 1. Log in as instructor Username: Insturctor6 Password: password 1. Click on ""Manage..."" and select ""Assignments"" in the drop down list 2. Navigate to ""Test Timetracking (FINAL)"" assignment 3. Click on ""View Report"" Icon 4. Ensure drop down reads ""Review Report"" and click ""View"" button 5. This will display a table with information about reviews for the assignment 6. Select one of the reviews and click on the time value hyperlink 7. This should display a pie chart and table with a break down of time spent on review 8. Click on ""Manage..."" and select ""Impersonate User"" in the drop down list 9. Enter ""student74XX"" where the XX can range from 90-99 10. Navigate to ""Assignments"" tab 11. Select ""Test Timetracking (Final) review"" 12. Complete the review and write down about how the it took 13. Click the ""Revert"" button in the header to go back to an instructor 14. Navigate back to the ""Review Report"" table 15. Confirm appropriate entry was added to the table and matches, or is near, the personally recorded time. <link> <link> <link>. <link> <link> <link> <link>.","The narrative portion of this document is fine.  It is descriptive and easy to read.  The listing of files edited should be more than just a list of filenames.  At the least, it should have a link to the Github diff view for the file.  That would not be hard to add.  The test plan should describe the tests, not just say, one test for this, two tests for that.","Dear student,

Your assignment is comprehensive. It reflects deep thought and meticulous attention to detail. I appreciate your in-depth examination of Expertiza software, with a clear emphasis on the need to add functionality to track student interaction with the software during a review process.

The clarity of your explanation regarding time assessment and its importance in estimating the quality of review is commendable. The three sources of summation for review time provide a good base for your analysis.

Your comprehensive idea of how to measure and track student interactions, both on Expertiza and on external resources, is noteworthy. Your task implementation is very detailed and focused, and you've correctly identified and outlined the main factors of your project scope. The project's requirement breakdown is orderly and precise, making it easy to follow through with your thought process.

Your detailed review of previous attempts to implement this feature and the reasons they didn't proceed is helpful for learning. It provides a rich historical background enabling you to differentiate your strategy and improve on past undertakings for a successful implementation. 

This assignment demonstrates detailed planning, predicting user interactions, and the anticipated alterations to the Expertiza user interface. The description of the database relationships and the rspec test cases strengthens your testing procedures, ensuring that your implementation meets the intended requirements.

However, you have a few incomplete references such as <link> and <image>, it would be much clearer when you replace these with the actual references or images.

Also, you could emphasize more on the potential limitations or challenges of your proposed solution and discuss the steps you can take to overcome them. It is always better to anticipate possible obstacles upfront.

Besides these minor issues, this is an excellent assignment. Your hard work, creativity, and high standard of professionalism come across clearly in every aspect. You are demonstrating thorough problem-solving skills, a good understanding of the task at hand, and an impressive perspective on how to innovate and improve upon existing works.

Well done! I look forward to your implementation of these concepts.

Best,
[Your Name]"
408,E1848.1,"assignment_team.rb is the child class of team.rb. It is used to handle multiple problems relates to team in the assignment. Its responsibilities can mainly fall in three categories: participant of the team, reviews of the team, and the operation for the whole team. For the participant, it can be used to decide if a participant is in a given team and view the members of the team or remove a member. For reviews, it deals with the problem that getting the reviews for the team, assign reviewer for the team and get if the team has been reviewed by a specific reviewers. For the whole team, we can delete the team or view the scores, etc. by using this class. Make sure assignment_team.rb provides all functions as expected is important for the whole system. It requires enough tests for all the functions and the edge cases may occur. However, there are not enough unit tests for this model in expertiza. The following tests are added to assignment_team.rb in this project. To make sure we can cover as many conditions as we can(the objective for this project is getting at least 90% coverage rate), we first design test cases. The following factors are taking into considerations: the expected functions for each method, the possible edge cases and the pre-conditions for each cases. Then we get the unit test plan and complete the test following test steps. Jianshu Zhang Wanjing Kuang Wei Wu. 1.app/models/assignment_team.rb 2.spec/models/assignment_team_spec.rb 3.spec/factories/factories.rb. 1. two test cases for method ""include?"": When the team includes a given participant and When the team doesn't include a given participant 2. one test case for method ""parent_model"": It returns ""Assignment"" when the method is called. 3. two test cases for method ""self.parent_model(id)"": When it's given a correct id and When it's given an incorrect id. 4. one test case for method ""fullname"": When the participant has an full name. 5. one test case for method ""review_map_type"": It returns ReviewResponseMap when the method is called. 6. one test case for method ""self.prototype"": It returns an new instance of AssignmentTeam when the method is called. 7. two test cases for method ""assign_reviewer(reviewer)"": When the team has an assignment and When the assignment record can not be found. 8. one test case for method ""reviewd_by?"": When it gets correct reviewer and returns true as an result. 9. one test case for method "" topic"": When it returns the correct id. 10. three test cases for method ""has_submissions?"": When the team doesn't submit any file or link, when team submits a link instead of files and when the team submits some files. 11. two test cases for method ""participants"": When no participants in this team and When adding some participants and get all the participants. 12. one test case for method ""add_participant"": When adding an participant, it will return an instance of AssignmentParticipant. 13. two test cases for method "" delete and destroy"": Testing delete and destory. 14. one test case for method ""get_first_member"": Let a team have two members, the first assigned member is expected to be returned by this method. 15. two test cases for method ""hyoerlinks"": the current teams submitted hyperlinks and not submitted the hyperlinks 16.three test cases for method ""submit_hyperlink"": the hyperlink is empty, the hyperlink is not empty and it calls the method on NET::HTTP,the hyperlink is not empty and it raises error 17.three test cases for method ""team"": the participant is nil, the participant exists and the team user exists 18.two test cases for method ""export_files"": an exception is expected if team is not exist or a new exported file is expected. Rspec. expertiza/spec/models/assignment_team_spec.rb. 1. Create unit test cases in the assignment_team_spec.rb 1. run rspec spec/models/assignment_team_spec.rb under expertiza directory 1. the rspec outputs the number of test cases that are passed and those that are failed. 2 test cases are designed to test this method: 1. The team includes a given participant. <code> 2. The team doesn't include a given participant. <code>. 1 test case is designed to test this method: <code>. 2 test cases are designed to test this method: 1.When it's given a correct id. <code> 2.When it's given an incorrect id. <code>. 1 test case is designed to test this method: <code>. 1 test case is designed to test this method: <code>. 1 test cases is designed to test this method: <code>. 2 test cases are designed to test this method: 1. When the team has an assignment. <code> 2. When the assignment record can not be found <code>. 1 test case is designed to test this method: <code>. 1 test case is designed to test this method: <code>. 3 test cases are designed to test this method: 1.The team doesn't submit any file or link. <code> 2.The team submits a link instead of files. <code> 3. The team submits some files. Stub is used to emulate the scenario that the team has submitted a file. <code>. 1. No participants in this team <code> 2. add some participants and get all the participants <code>. <code>. <code> <code>. 1. import a team to a non-existing assignment and expect an exception <code> 2. export teams into a csv file <code>. <code>. 2 test cases are designed to test this method: 1. when the current teams submitted hyperlinks <code> 2. when current teams did not submit hyperlinks <code>. <code>. 3 test cases are designed to test this method: 1. when the hyperlink is empty <code> 2. when the hyperlink is not empty and it calls the method on NET::HTTP <code> 3. when the hyperlink is not empty and it raises error <code>. <code>. 2 test cases are designed to test this method 1. when the team_name equals false <code> 2. when the team_name equals true <code>. <code>. 3 test cases are designed to test this method 1. when directory_num >= 0 <code> 2. when the directory_num does not exist and it gets max num <code> 3. when the directory_num does not exist and it updates attribute <code>. <code>. There is screenshot of the coverage page. <link>.","The test plan simply lists 18 tests.  It would have been very heplful to separate them into groups and describe the motivation for each group.  It's hard to remember 18 items that are not connected to each other.  The rest of the documentation mostly copies the test code, with a one-line description of each test.  It would be better if the reason for the test was explained, along with what condition the test will succeed (or fail) on.","Dear Student,

Great job on your assignment. You've put effort into writing very detailed test cases for the child class of team.rb and have done a commendable job of covering all the functions, taking into consideration edge cases and pre-conditions for each test case. This kind of comprehensive testing is crucial for ensuring robust and reliable software.

However, for future assignments and for the sake of improved readability and organization, I suggest the following improvements:

1. Make your explanations more concise: While it is important to be detailed in software testing, try to clearly state the goal of each test case in as few words as possible. This will make your descriptions easier to read and understand.

2. Organize your Work Better: Using headings, subheadings, and bullet points can make your work easier to scan quickly and understand.

3. Proofread: Proofreading for grammar and punctuation errors can help improve the clarity of your writing, making it easier for others to understand your work.

4. Pseudocode: Sometimes, a bit of pseudocode or a flowchart to describe the logic of the test could help in understanding your approach better. 

5. Any references or screenshots you mentioned were not included in your submission. Please make sure you attach them before submitting your work.

In terms of the implementation, you've covered a wide range of scenarios. Yet, always remember to add negative tests as well and to test and validate the input data as well in your unit tests. 

Also, make sure you always clean up your resources in test cases to prevent clashes with other tests.

Keep up the good work and look out for these points in your future assignments. If you have any queries or need any help, please feel free to reach out.

Best regards,

[Your name]
"
409,E2101,"There are various types of questionnaires that a user can create in Expertiza. These questionnaires assist in evaluating submissions and teammate contributions. Questionnaire is a superclass to many different types of questionnaires offered in Expertiza. The Questionnaire controller is responsible for creating, displaying and managing these items. Therefore, due to the importance of this controller, refactoring it was of interest to help improve the readability of its features. 1. Replaced literal values with defined constants to aid in the understanding of code behavior. 2. Investigated whether the method create_questionnaire is used. 3. Fixed the methods that have a questionnaire_id as a parameter, as it is not needed, since those methods should be contained within the model class anyways. 4. Removed one of three checks for QuizQuestionnaire. 5. Corrected the dropdown's default alternatives to reflect the questionnaire's min and max question score. 6. Updated the dropdown's RSpec test to reflect the change in behavior. 7. Discovered more software faults. 8. Moved three of four private methods from the controller to the model. The reason for this method is when there is a teaching assistant that is creating a questionnaire for an instructor, the questionnaire's instructor_id field is assigned to be the instructor of the course, instead of the user's (in this case, the TA). The RSpec test for this method expects that the application will be redirected to tree_display after calling this method, therefore it is unclear if the application could instead redirect to questionnaires/edit, or if it has to redirect to tree_display. The normal create function assigns the questionnaire's instructor_id as the id of the current user, and redirects to questionnaires/edit. However, we have not seen an instance where create_questionnaire is used, except in the RSpec test. Thus, it may be possible to move some of the code from create_questionnaire into the create method, if the RSpec test can be safely deleted. Though, we do not know if that is the case. Some methods in the Questionnaire controller had a parameter called questionnaire_id, and it was suspected that we could use params[:id] instead. However, we found that those methods were also private and should instead be in the model class. By moving those methods to the model class, we were able to remove the questionnaire_id parameter, and in some cases replace it with a params argument instead. The Questionnaire controller checks to see if the questionnaire type is QuizQuestionnaire, and it is believed that this may be unnecessary. We were able to eliminate one of three checks in the code, namely, the method save_new_questions which has been moved to the model class. Before our refactoring, the dropdown had a default literal value of '0|1|2|3|4|5' which was an error. This is an error because it is possible it exceeded the default value of the questionnaire max question score or allowed for points below the questionnaire min question score. Instead, this was replaced with code to make the dropdown's alternatives more responsive to the Questionnaire's min/max question score. However, we noticed that when the Questionnaire's min/max question score is edited after it has been created, the dropdown's alternatives could violate the new constraints, and also upon adding a new item e.g. dropdown, the edited (but not saved) min/max question score is reset to the initial values that were set upon creation of the Questionnaire. Upon fixing the dropdown's behavior, the RSpec test did not meet the expected behavior since before the alternatives were hardcoded in. So, now the dropdown code requires the min/max question score to be set in the questionnaire it is assigned to, so that the default value for the dropdown's alternatives do not violate the constraints of the questionnaire. See Dropdown default alternatives . Three of the four private methods that were in the controller were able to be removed and placed within the Questionnaire model class. The remaining private method called save was left in the controller since RSpec tests expected to find it in that location, and it appeared to be tightly coupled with existing functionality.","In the problem statement, I don't see that you did some of the items that you said you did, e.g., removing a questionnaire_id parameter.  The diff (https://github.com/expertiza/expertiza/pull/1912/files) of the pull request shows that a ""params"" parameter has replaced questionnaire_id in delete_question, but that's the only change I see.  If anything was moved from the controller to the model, I missed it.  There are many discrepancies with what has actually been implemented in the pull request.  The design doc could help by showing (and describing) code, but it does not.

As far as the documentation is concerned, an introduction is needed to explain why the changes were made.  As it is, the prose jumps right into describing the methods without putting them in context.

Testing is not covered.","Hi there,

I appreciate the effort you put into refactoring the Questionnaire Controller. The detailed changes and the thought process behind each refactoring in your assignment is impressive as this is what proper code refactoring entails.

1. Using defined constants in place of literal values boosts readability as those constants typically carry a semantic meaning which helps in understanding the code behavior. Good job with this.

2. Your curiosity and critical thinking to investigate the function of the `create_questionnaire` method can foster a cleaner or more optimized code.

3. You recognized the violation of separating concerns principle (Controller vs Model tasks). Moving methods that are supposed to be the responsibilities of the Model class from the Controller class is a valid step in the right direction. 

4. Reducing the number of checks for `QuizQuestionnaire` eliminates unnecessary complexity and improves clarity in the controller. 

5. Correcting the dropdown's default alternatives is a fundamental bug fix since they should reflect the questionnaire's min and max question score. It's crucial though, as you have identified, to ensure this editable field does not allow values that violate the constraints on future iterations.

6. Of course, upon code changes, it's important to update RSpec tests to reflect the modifications. So, well done for doing that.

7. Your proactivity in identifying other possible faults is commendable as it represents good software engineering practice.

8. Moving private methods to the Model class and recognizing the specific one that couldn't be moved is insightful. 

You've given an accurate analysis of the `create_questionnaire` and `save_new_questions` methods and have identified the tight coupling of the `save` method, which could be prime candidate for future refactorization.

Great job on all aspects mentioned above. For future assignments, it would be helpful to be more succinct and structure your work into sections for each point you worked on to make it easier to follow. Keep up the good work!
"
410,E1795,"Description of the problem statement can be viewed on this <link> . To understand the problem statement, let us first understand the terms used in the problem statement: 1. Peerlogic: Peerlogic is a service provider for education peer review systems. The project exposes a number of microservices or web APIs that can be consumed by peer assessment systems. It provides services for reputation algorithms, metareview metrics, etc. To give an example, a peer review system like Expertiza leverages Peerlogic APIs to assess whether a given review was competent enough or not. There are a dozen of such systems that leverage Peerlogic’s APIs for a number of purposes. More details on Peerlogic can be viewed <link> . 2. Expertiza: Expertiza is a peer assessment system that is build to help students review each others work and provide feedback, facilitating learning. Expertiza uses Peerlogic’s services for various purposes. 3. Single Sign On Portal: Single sign on portal is the system that E1795 aims at building. This will serve as an authentication layer between Peerlogic and all other applications using its API. Currently Peerlogic’s services can be used by anyone calling them. There is no system to check if an application accessing the services is actually allowed to do so. It is essential to have a system in place to authorize applications to avoid a number of security breaches that could occur using these open-to-all services and prevent them from being hacked. The proposed solution is to create a “Single Sign On Application” that will be responsible for providing authorization and authentication for the Peerlogic APIs. This application have two major modules: 1. User facing portal: The user facing portal will be a deployed application with an user interface that a user/admin can use to register himself, request an API key for his/her app (in case of user), approve API keys (in case of admin), manage keys, and other similar functions. 2. REST APIs for Peerlogic: There will be REST API created which Peerlogic can call to check whether a request received by Peerlogic is authorized and authenticated. This API is a core feature because it is responsible for actually putting the security system in place. If the API fails to return the correct result, an application not authorized to access Peerlogic may do so, leading to a security breach. In order to understand how the whole system will work, have a look at the figure given below. <image> The system includes a SSO portal, Peerlogic and different apps trying to access Peerlogic services. The types of users are admin and generic user (who will be responsible for creating a client account with SSO. Note: In the following description, client has been used interchangeably with app. 1. Once the client users registers himself/the client, and client account is created. He can now request a client ID and a client key to be used by his/her app. (Step 1) 2. SSO sends this request forward to the admin, who either approve/reject this request. The admin tells whether the request is to be approved or not and forwards this information back to peerlogic. (Steps 2 and 3) 3. If the admin, approves the request, SSO generates a client ID and a client token that will be used by the client to send requests to SSO. (Step 4) 4. This client ID and key is seen by the consumer and they add this to the client app. (Steps 5 and 6) 5. When the client app decides it wants to call Peerlogic web services, it communicates with SSO, sending a request for a token, this request includes the client id and client key in order to let know SSO know he is a valid requester for token. (Step 7) 6. SSO generates a unique, one time use token for the client and passes it back to him. (Step 8) 7. The client now calls the Peerlogic web service and adds this token in the request as a header. (Step 9) 8. Peerlogic, after receiving the client request, sends a request to SSO with the token, asking if the token is valid and is allowed access to the service that client is requesting. SSO, at this point, checks does authorization and authentication. If all okay, it returns so. (Steps 10 and 11) 9. If Peerlogic receives a positive response from SSO, it lets client use its API, else returns an unauthorized/unauthenticated access error. (Step 12). Looking more deeply at the SSO, here are few key points that specify how we are going to implement the SSO: 1. We will use both google sign in and our own sign in to allow a user to create an account and log in. 2. We will use a random generator to generate the key for every client once the admin approves the request for the key. As a proposed solution we will use SecureRandom for this purpose, which is an algorithm to generate a random string. Although it is not optimized for uniqueness, if we are generating a 32 bit key, collision is very less likely to happen. 3. AES encryption algorithm, one of the safest encryption algorithms, will be used to generate the token for every client. This token will hold information including the client key, access rights and the time the token was generated. 4. When we decrypt the key, we will check whether we have such a client key in our database and whether they are allowed access to whatever it is that they are requesting. (This constitutes the authentication and the authorization portion) 5. We shall have a RoR application to handle all of this, and a database (whose model is discussed below). The following diagram shows the database that will be in work for the SSO application. 1. API will store information about the different APIs and has two attributes: API_id and and the API name. 2. Clients will store information about the clients. It will store which client id has what key. Also the owner of the client will be stored in this table. 3. Access Rights will store information about which client has access to what APIs. This table will be used when we are checking the authorization of a particular client. 4. Users will store information about the users/ The term user here is used to represent the entity which will represent the client. So a user account is nothing but a client facing account. 5. Keys will store the value of the keys used and generated for encryption. Since we are using AES encryption algorithm, we need two values IV and Key. This values will be stored here along with the timestamp when they were generated. Why we have incorporated timestamp is because in future we might like to implement a TTL (Time to live) concept in the generation of token, in which case we can also use different keys for different times. <image>. We have successfully implemented the following components from the solution architecture. 1. SSO App The user will login to the Single Signon App and can ask for keys and enable the APIs for using Peerlogic services. Similarly the admin can approve the keys requested by the user, can view the information of the users and add APIs. Credentials for admin login: email: admin@gmail.com password: admin Please do not change the password of the admin so that another user doesn't get blocked while testing. 1. SSO REST APIs Once the key is approved by the admin, the Apps which use the Peerlogic service will use this keys to communicate with the REST Endpoints. A token will be generated from this which will be used by Peerlogic to authenticate and authorize the app. => To get the token: (Called by the app) <code> => To authenticate and authorize: (Called by Peerlogic) <code> In cases where authentication fails, status will come as 401 with appropriate message giving the reason for failure. 1. Demo App We have made a Demo App to show how the API calls to Peerlogic work and token validation. 1. 1.1. A token is generated when you click on the 'RequestToken'. This token will be sent in the header of the request to Peerlogic while making an API call. 1.2. Peerlogic verifies this token with SSO. 1.3. Clicking on 'GetRainbowURL' generates a URL for that service through which we can access it. 1.4. 'getGraph' shows the visual graph of Rainbow Service. 1.5. Changing anything in the token will make it an invalid one and the service wouldn't be accessible. An error output will be displayed. <image>. To test the app, follow the steps listed below: 1. Go to the single sign on app, login. 2. Create a new app, and request the client key for that. 3. Wait for admin approval. 4. If you have the admin credentials, login as admin, go to clients page, and approve the request you just generated. 5. Once the approval is done, copy the client key and keep it somewhere safe. 6. Now, to access the rainbow graph API, send a request to the SSO for token along with client key. 7. After the token is sent to you, you can use the token as Authorization header in the Rainbow graph API. 8. If the token is correct, you should be able to access the API, else an error will be thrown for unauthorized access. There are a couple of challenges we have identified: 1. Creating a client id and key and storing it: Given the rise of open source software, it is essential that the client id and key that is generated for an app is stored in a secure place, invisible to the world. We will be looking into ways how open source apps do this and good practices to do the same. 2. Making sure the database is secure: Since our database is going to store the encryption key and IV, it is of utmost importance that the database is secure and not prone to attacks. In future we would like to use multiple keys for encryption rather than just one constant key for a lifetime. These multiple keys will have a time to live. This will make the system more secure as now they will be different keys used at different times, so in case a key is leaked or even if it isn't, it won't last for much time, and soon a new key will be in place, bringing the system back to its initial secured position.","This isn't the most readable document, and I didn't see why until I realized that most of it is a set of lists. It would help to have the lists preceded by prose to give a general overview.  Other than that, ti does not have any obvious deficiencies.","This is a well-designed project with a clear understanding of the problem, implementation, and goals. Here are a few points to consider for improvements:

1. Definition: You have done an excellent job explaining the different components involved in your project including Peerlogic, Expertiza, and Single Sign On Portal. This foundation forms a good understanding of the integrated system you are aiming for.

2. Goals: You have presented the goals of the project clearly. They are consistent with the problem definition and provides a clear path to implement the designed solution.

3. Solution Architecture: The detailing in describing the proposed solution is commendable, such as the modules of User facing portal and REST APIs for Peerlogic, the functionality of Admin and Users in SSO, and a detailed walkthrough of steps and interactions between system components. 

4. Technical Details: The use of Google sign in, SecureRandom for key generation, AES encryption for creating tokens, RoR application framework is detailed out correctly. The information on how the database tables, keys, user and client details will be organized and used in the implemented solution is also explained rightly.

5. Implementation: The completion of SSO App, SSO Rest APIs, and demo app forms a solid base for the next iteration steps to be worked upon.

6. Testing: The steps for testing of the application comes out very handy and easy to follow. It shows the robust feature set of the application in a very interactive manner.

7. Future Challenges: Contemplating on future challenges like security and storage of keys, database security, and assigning time-to-live for the encryption keys shows your active thinking in terms of scalability and robustness of the solution over time.

Recommendations for the future sections might include more attention to the optimization and handling of any potential edge cases or failure scenarios. Overall, excellent work so far! Keep moving forward with this momentum."
411,E2071,"The Expertiza project is software to create reusable learning objects through peer review. It also supports team projects, and the submission of almost any document type, including URLs and wiki pages. As an instructor, you are able to view tables with information on student performance across the various courses they are taking and their assignments. Currently, these tables always show the same information and you are not able to specify if you only want to see certain data. Furthermore, the source code has some variables names that are not clear to what their purpose is in the code. 1.There should be a dialog that appears before navigating to the pages where the table views are that contain a list of checkboxes to allow the user to choose which columns they would like to see. Selectable columns: 1. Instructor Assigned Scores 2. Peer Grades 3. Topics. File: app/views/tree_display/_dialog.html.erb This file is a ruby view partial that contains the html for the checkbox dialogs. <code> File: app/assets/javascripts/tree_display.jsx Added functions to toggle dialog. <code> Added buttons to replace links that trigged dialog popups. <code> File: app/views/assessment360/all_students_all_reviews.html.erb, app/views/assessment360/course_student_grade_summary.html.erb Added conditionals to show selected columns for the html tables <code>. File: app/controllers/assessment360_controller.rb Added Variables to check if corresponding columns should be shown. <code>. File: app/controllers/assessment360_controller.rb Renamed @teamed_count to @total_unique_teammates <code>. File: app/controllers/assessment360_controller.rb Added ability to calculate average peer review score for each student in a course. <code> <code>. Before navigating to aggregated teammate and meta reviews, a dialog shows to allow the user select which columns they would like to see. <image> Similarly, before navigating to course grade summary, another dialog shows to allow the user select their columns. <image> <image> <image>. There was an existing test case for the assesment360 controller. We have added the test scenarios for our implementation of the average_peer_review_grades and all_students_all_reviews_all_grades. We tested url parameters as well as the average score pertaining the peer review of a student. Following steps needs to be performed to test this code: 1. cd expertiza 2. rspec spec/controllers/assessment360_controller_spec.rb. <link>.","In the description of the changes, you gave only ""after"" snippets of the code.  It would be clearer if these were contrasted with ""before"" snippets, e.g., by using screenshots of the Github diff view.  Each change was described in a single sentence.  Often a more detailed description, explaining the strategy, would have been helpful.  The screenshots of the output also don't have prose describing what they show.  Test scenarios should have been included in the document.","Dear Student,

Thank you for your submission. You have done an admirable job detailing the changes you have made to this codebase. It’s evident that you have put a lot of thought into resolving the existing issues and improving the functionality. 

Your approach to customize the table views by adding dialog feature is an excellent solution that improves the software's interactivity and user-friendliness. You’ve done commendable work in not only speaking about the changes made but also associating those changes with the impact they have. 

The variable renaming you did is an important detail - such changes can greatly enhance the readability of the code and make it easier for future developers to maintain. 

Having created new tests for system evaluation further reflect on your understanding of the topic. It would, however, be helpful if you could add more insights related to the testing process. Was the output satisfactory? Were there any bugs? What parameters led to the final version of the function, considering there could have been trials and errors?
 
One thing I would recommend for next time is to make sure that you provide more description of the images. Adding a brief caption or summary will allow anyone who is reviewing your document to understand what you're illustrating, even if they can't see the images. 

Also, remember to properly close your `<code>` tags to ensure that the code blocks render correctly in the webpage. 

Lastly, keep up your coding habit clean and precise, it can speak volumes about your programming style and thinking process.

Good job once again. Looking forward to your next project!

Best,
[Your Name]"
412,E2024,"Currently, Expertiza has no way to associate mentors with teams. For assignments with topics, like the OSS project, mentors are associated with topics, and then whichever team is assigned to the topic inherits the mentor for that topic, However, for assignments without topics (like Program 2), there is no good way to “automatically” assign mentors to projects. The instructor needs to watch teams being formed, and every time a new team is formed, a new mentor needs to be assigned, outside of Expertiza. This leads to a lot of work for the instructor, as well as sometimes long delays before a team is assigned a mentor. Develop a trigger that: 1. Is activated when any team has been formed that has k members, where k is greater than 50% of the maximum team capacity 1.1. ex. max members = 4, trigger activated when the team size reaches 3 2. Assign a mentor to the team. Mentors should be evenly assigned to teams, so a good strategy is to assign the mentor who has the fewest teams to mentor so far. 3. Notify the mentor via email that they are now assigned to a specific team, and provide the email addresses of the team members. 4. Possibly notify the team members that they have been assigned the mentor with contact information. Since the trigger they implemented would need multiple handlers and each of the responses in different actions, they decided to use Chain of Responsibility as the design pattern. Chain of Responsibility is a behavioural design pattern that lets you pass requests along a chain of handlers. Upon receiving a request, each handler decides either to process the request or to pass it to the next handler in the chain. The reason to take this approach is we have a certain question which needs to be answered, based on the answer the flow moves. It follows a sequence which follows this behaviour pattern well. <image> <image>. <image> <image> Assignments with or without a topic could be assigned with mentors automatically <image>. <image> Files Modified Controllers: 1. app/controllers/submission_records_controller.rb 2. app/controllers/student_teams_controller.rb Models: 1. app/models/assignment_team.rb 2. app/models/assignment_participants.rb 3. app/models/team.rb 4. app/models/team_users.rb Views: 1. app/views/student_task/view 2. app/views/student_teams/view 3. app/views/shared_scripts/_add_individual 4. app/views/participants/_participant 5. app/views/assignments/list_submissions.html.erb 6. app/views/mailer/notify_member.html.erb Rspec: 1. spec/features/staggered_deadline_spec.rb 2. spec/models/assignment_team_spec.rb 3. spec/models/team_spec.rb Mailers: 1. app/mailers/mailer.rb I. Refactor Code to follow good coding practices Example: 1. Rename method names more meaningfully and intuitive. <image> 2. Reduce the number of conditional statements checking for mentor. 3. Rename variable names to reduce confusion like changing lowest_team_no to lowest_number_of_teams. 4. Make the code DRYer <image> II. Correct Previous Design 1. Remove mentors from being included in a team's number of members count. 2. Change the View to make mentor separate from the team. BEFORE <image> AFTER <image> 3. Change the conditional statement that checks if a mentor has to be added to the team. (The strength of the team has to be greater than 50% of the team size). <image> 4. Fix the SUBMIT button issue during role selection <image> <image> III. Code placed in the wrong locations to be moved to the desired locations. Example: 1. The email code moved to the email module. 2. Code written in team file moved to the assignment team file. 1. The mentor should be able to check submissions of his team. This is a new functionality, where a mentor when logged in , would be able to view all the teams assigned under him for an assignment, when he clicks view and manage teams. Additionally the respective teams submissions and submission histories could be viewed by the mentor (if and only a submission is available).Existing functions and classes were reused. <image> <image> 1. Email notification for mentor/ team members This functionality aims at generating an email notification to the mentor/ team member when a team is created giving details about the team name and the team members/mentor they have been assigned with. Additionally a notification is generated for every team member that is newly added to the group. <image> <image> 1. Accommodate changes in team members/assigned topics after a mentor has been assigned. This is planned to be addressed as per the new flow diagram, where a check will be performed to see what type of a team it is, new or modified one. If the strength of the team reduces below the threshold, the assigned mentor is removed and a new mentor is added when the threshold is reached again. <image>. 1. Some existing test cases have been modified, which have been reverted. 2. Run and pass the existing RSpec Tests. 3. Test the UI for the deployed project. Part 1: 1. Login as the instructor6 2. In the assignments view, select the add participants icon. 3. Now, all the existing participants and their roles and permissions are visible. Add a new participant or change permissions. This could be a member or mentor for our case. 4. Fix the max team size of the project. This size will decide when to add a mentor. (Here set as 4) Part 2: 1. Login as student575 (added to the program by the instructor) 2. In the assignments view, select program 1. Within that select your team link. 3. Currently there is no team. Create a new team. 4. Invite student573 (who's also a participant in this project) 5. Invite student574 (who's also a participant in this project) Part 3: 1. Login as student573. 2. In the assignments view, select program 1. Within that select your team link. 3. There will be an invite from user575, accept it. 4. Will be added to the team and a mentor is assigned. (here it is 563) 5. Check for a received email regarding team information. <image> <image> Part4: 1. Login as student574. 2. Steps are the same as Part3. The difference will be in the email received. No new team formed or mentor assigned. Only 574 is added to the team and he alone gets the email. Part5: 1. Login as student563. (Mentor) 2. In the assignments view, select program 1. Within that select your team link. All the mentor's teams for that project will be listed. 3. The mentor would have gotten an email when a new team is formed and they are added as the mentor. <image> <image>. 1. Rubrik for a Mentor has to be implemented. Since this functionality has multiple dependencies, it could not implemented this time. 2. If a mentor is removed from an assignment, reassignment of mentor has to be done. (edge-case) 3. Rspec for email functionality needs to be implemented. <link>.","I would prefer that you not start with what the last team did, because this means that to understand your work, someone needs to read the previous design doc.  In the listing of files modified, it would be very helpful to say why they needed to be modified, and what changes were made. The test plan should describe the tests that you modified or reverted.","Hello,

You have approached the assigned task in a very methodical, detailed and systematic manner. Your explanation of the issue regarding the existing system and the step-by-step presentation of how you tackled each one is commendable. I appreciate your decision to use Chain of Responsibility as the design pattern, explaining precisely why it fits your needs.

The division of your work into refinements of existing code, corrections of previous design, code relocation, adding new functionality, and handling email notifications demonstrates a thorough consideration of the full scope of the problem. Your design decisions, such as removing mentors from a team's count and independent email notifications for each new team member, effectively address the requirements of the assignment.

The section where you mentioned about testing your changes and analyzing the UI is noteworthy. Additionally, the explanatory images you included at each step make it easier to understand your work.

However, here are a few points for improvement:

- Although you identified some areas where future work is needed, it would be even better if you could provide a prospective solution or plan to address those issues.
- It would make your work more readable if you could elaborate on the sample programs you used for testing at different stages. 
- Make sure any place where you've written 'image' or 'link' has the actual image or link inserted and that they are functioning correctly.
- I see that in certain areas, for example renaming method names and variables, you could have provided more examples or rationale behind why you selected the new names.
  
In conclusion, you have done an excellent job with the assignment. Well done!"
413,E1648,"This page provides a description of the Expertiza based OSS project for Fall 2016. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link>. <link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. The following tasks required completion in this project: 1. Adding past due assignments to the task list. 2. Highlighting the next immediate due date on the assignment list. 3. Correcting the stage deadline of finished assignments. 1. Assignments that are past due are not present in the task list The assignments that the user is a participant of and are past the deadline but not yet completed are not part of the task list of the user. Currently only tasks that are not yet started by the user are being shown in the task list. 1. Next immediate due date As per the current implementation, it is hard to pick the when and which assignment has the next immediate due. 1. Stage deadline of a finished assignment According to the existing implementation, the stage deadline of any finished assignment is being shown as one year from the current time which is misleading from the actual final stage deadline of that assignment. 1. Problem 1: next_due_date is being assigned string value instead of DueDate object While finding the current stage of the assignment, the next due date returned from the DueDate model currently returns nil for the assignments which have their due dates past the current time. Then, if the next due date is found to be nil or 'Finished' it is being assigned the value 'Finished'. In the list.html.erb of the student_task view, the stage deadline of the student task for an assignment is fetched as the due_at attribute of the next due date object. As the finished assignments have a next due date as a string they are being caught as an exception and rescued by showing the stage deadline as an year from the current time. 1. Problem 2: While fetching next_due_date from the DueDate model, it returns next due date from the assignments which have due dates greater than current time. If the due date is past, next due date is nil. The past due dates are not being retrieved in case if the next due date is nil. 1. Solution: If the next_due_date of an assignment is found to be nil while finding its current stage, its past_due_date is retrieved and name of the deadline type is looked up from the DeadlineTypes model with the deadline_type_id attribute of the past_due_date. 1. The method find_current_stage looks up for the past_due_date if the next_due_date is nil and returns it. Else it will return the found next_due_date. <code> 1. The get_current_stage method returns the name of the deadline type from the DeadlineType controller with the deadline_type_id key. For this the deadline type 'Finished' is maintained in the deadline_types table. <code> <code> 1. The late tasks are collected into latetasks by selecting the tasks which are in the 'Finished' stage but does not have any submitted content. These are shown in the student task view in the task list. <code> <code> 1. The next immediate deadline from the current time is fetched from the student_task controller and compared with stage deadline of every assignment while iterating to find and highlight the assignemnt that has next immediate due. <code> <code>. No new tests were written in rspec as there are existing tests on the same piece of code. The steps to be followed to test the changes manually from UI are: 1. Login as a student. 2. Check in the task list present on the left side of the screen. 1.1. There should be an extra section named 'Late Tasks'. 3. Check the list of assignments in the table below. 1.1. The assignment that has the next immediate due date from current time will be highlighted with bold font weight. 1.2. The stage deadline column shows past time for the assignments with current stage as 'Finished'. If there are no assignments in the task list, we can test the functionality by following below steps 1. Login as instructor and create an assignment. 2. Assign the assignment to the student user we are testing for. 3. Adjust the due date of the assignment such that it is the next immediate due date in the assignment list. 4. Login back as student. 1.1. The assignment should be highlighted in bold font. 5. Login as instructor. 1.1. Adjust the due date such that the due date is past the current time. 6. Login back as student. 1.1. The assignment now shows up in the late tasks section in the task list. 1.2. It is no longer highlighted in the assignment list. 1.3. The stage deadline of the assignment will now show the due date that we have set now,which is past. 1. <link> 2. <link> 3. <link>.","There was not too much to say on this wiki page, as solving the problems did not require writing much code.  But the team was responsive to reviewer suggestions, and created a pretty readable descrption of what they did.","This assignment has a strong level of detail and it's clear that you've thoroughly analyzed the issues with the Expertiza interface's handling of assignment due dates. You've provided thoughtful solutions to these issues and explained these solutions clearly. Your proposed changes to the system should make it easier for students to track their tasks and due dates.

However, there are several areas where your assignment could be improved:

1. Structure: The report is dense and long-winded, making it difficult to follow. Break down the large blocks of text and use bullet points to make your findings more easily digestible.

2. Use of links: Instead of repeatedly writing '<link>', you should replace with actual text to clearly illustrate what you want to point out.

3. Writing and Grammar: Some sentences are unclear and hard to understand. Be sure to double-check your writing for clarity and grammatical correctness.

4. Testing: While it is noted that there are existing tests in the area you modified, it would have been wise to at least verify that those tests are still passing after you made your changes. Also, writing a new test case targeting specifically your modification proves that there is a success of your solution implementation.

Please revise your assignment considering these points. Good job on digging so deeply into this issue.
"
414,E2106,"The student_task/list page is the page displayed to a student after logging in into expertiza. It has mainly two div(s), one to show the upcoming tasks along with some important information, another div is to display all the assignments and their information in which the student is participating. We have to modify the view to remove extraneous information and make it clearer and more concise. 1. Modify the view to remove extraneous information and make it clearer and more concise 2. Add checkbox to Publishing Rights column, when checked the permission_granted boolean variable is set to true 3. In general, no column needs to be shown if there are no values in it. This would apply to “Badges” if no assignments in the list contain badges. 4. Also, it doesn’t make sense to have a column for Review Grade, and not for the grade for submitted work (“Submission Grade”). 5. We should consider the cases where a student might be enrolled in assignments from more than one course. In this case, assignments should be grouped by course, with the course name given before the listing of the first assignment. (This allows for the column for course to be removed, making the display more compact. Log in to Expertiza as any of the students mentioned below. Without the changes the original view is as shown below. 1. instructor6 1. student7487 1. student7490 1. student7496 Password for logging in for any student/instructor is : password Once logged into the page click on ""Assignments"" tab. A modified view is observed as compared to the earlier view <image> To address issue 1 we added CSS style properties and removed the unnecessary space between two divs by using HTML comment. <image> The modified view is as shown below <image> To address issue 2, we did the following modifications 1. In app/assests/javascripts/submissions.js, we have added an ajax call to update the permission_granted boolean variable in Participant table <image> 1. In app/controller/student_task_controller.rb, we are defining a method named permission_granted which routes the action from checkbox event <image> 1. app/views/student_task/list.html.erb, we have added code to include an information banner on Publishing Rights column and checkboxes <image> 1. In config/routes.rb, we have added a functionality to route the checkbox event to permission_granted action in student_task_controller.rb <image> After all proposed modifications, we see the below shown view <image>. Since this project involved mostly UI changes it was not necessary to write test cases for the same. So there is no test plan. 1. <link> 1. <link> 1. <link> 1. <link>.","This page would have been easier to follow if you had (1) numbered the issues in Section 2 (I changed it to a numbered list) and (2) mentioned briefly what you were addressing in Section 3 (not just ""issue 2"", but ""issue 2, adding a checkbox for publishing rights"").  Also, the code changes are described in the Functionality Testing section, which is not right.","You've delivered a comprehensive summary of your assigned task and the steps involved in executing it. Here are a few points for your consideration:

1. Clarity and Organization: Your report is orderly and well-structured. However, for better readability, consider adding headings and subheadings, and group related information together.

2. Content: The content is informative and it's evident that each aspect of the task has been addressed meticulously. However, remember to replace placeholders like <image> and <link> with actual images and link references.

3. Technical Approach: Your technical approach seems to be precise and you've demonstrated a good understanding by indicating exactly where modifications are needed and how to implement them. 

4. Testing: While this project may mostly entail UI changes, it is important to remember that even minor changes can introduce bugs or unintended behavior. Hence, it would be good practice to contextualize any reasons for not needing a test plan and if possible, atleast perform some basic functional testing by manually checking the modified interfaces and features.

5. Screenshots: Do not forget to include screenshots of your work. They will be incredibly valuable in demonstrating what changes have occurred.

6. Referencing: It seems you have referenced additional resources. Ensure to provide accurate links and descriptions of these resources. 

Keep up the good work. You have evidently given significant thought and effort to this task. You would only need to address these minor points in your next assignment."
415,E1567,"The Expertiza project is a web application to create reusable learning objects through peer review. It supports various features such as team projects, and the submission of various documents including URLs and wiki pages. It is being extensively used across various universities for select courses. The page describes the various changes and modifications done to improve the source code of the application. The changes were accompanied by unit/functional test cases written in RSPEC to affirm no breakage in code. Just a note for the reviewers, for this project, we had done all the necessary forks, modifications and pushes. But after creating a pull request, there were some merge conflicts with the code. Since this can't be changed at our end(as we dont have the access rights), we are in touch with the people at expertiza. Please consider this situation while reviewing. Thanks. Users Controller is one of the controllers in the Expertiza Rails Application. It is used for the basic CRUD operations - creating new users, updating the details for an existing users or deleting an existing user in the system. It is also used to determine the role of particular user in the system. The role could be one of the following - Administrator, Instructor, Student, Teaching Assistant, Super-Administrator or Unregistered User. The associated model class for interacting with the user table is the User model. It is also used to verify the various access privileges for each user, import or export users. The VCL image of the project is : <link>. 1. users_controller.rb 2. user.rb 3. user_spec.rb. Code refactoring is process of changing the existing computer code to make it more maintainable, without changing the external functionality of the code. Some of the reasons for performing refactoring are: <code>. The User_controller file was subject to code modifications and refactoring. The objective was to implement DRY code principles and reducing code complexity. The following were the suggested changes according to the Design document. 1. Initially, various functions were calling the same redirect method to redirect to the same controller. This was inimical to the code reusage principle. Following the DRY code principle, instead of calling the same link, with the action and controller as arguments, a method(redirect_to_home) was created and called from the 3 different methods namely show, index and key . <image> 2. Initially, the create method in Users_contoller was being used to send emails to new users by passing strings as arguments to the mailer template. The strings were harcoded as arguments, this was modified so that varaibles were passed as parameters to the mailer template. This helped remove hardcoded code while maintaining the functionality. <image> 3. Initially, in the destroy method, queries were being executed directly from the controller method , which doesn't follow Ruby on Rails code ethics. So the queries were moved to a new method destroy_user in User Model file and the method was called from within the delete method in controller . <image> <image>. 1. Initially, the code had a very long method called get_users_list . It has now been broken down into several simpler methods namely, fetch_users_for_super_admin , fetch_users_for_course , fetch_users_for_assignment , fetch_participants_for_courses and add_children . <image> 1. The search_users method had a complicated if-else ladder. The method has now been optimized using a case statement. The original method also had a repetitive way of forming a search query. This has been refactored in accordance to the DRY principle into a new method named fetch_results that returns the list of users based on role, user_id, letter, search_by parameters passed to it. <image>. <link> is a <link> (BDD) framework for the <link> , inspired by [JBehave] <link> . It contains its own mocking framework that is fully integrated into the framework based upon JMock <link> . RSpec was made in 2005 as an experiment by Steven Baker, with early contributions from Dave Astels and Aslak Hellesøy. David Chelimsky joined the team that summer, and accepted leadership of the project in 2006. David also built rspec-rails, which provided tight integration with Ruby on Rails. Test cases were written for the user model. <code>. <code>. <code>. <code>. Login Credentials for review : username: administrator5 password: password To setup the local environment do the following steps: 1. Clone the repository using git clone <link> 2. Run bundle install 3. Run rake db: migrate RAILS_ENV = ""test"" to migrate the test database. 4. Make sure there is a test database created in mysql. 5. Run the rails server using rails server in the root directory of expertiza. To run the test cases, follow the steps given below: 1. Open terminal 2. Navigate to the expertiza root directory. 3. Run the command : ""rspec spec/models/user_spec.rb"" 4. All the tests should pass with the message ""n examples, 0 failures"". 1. Login using the credentials mentioned above. 2. Hover over the manage link in the top navigation bar & click on the Users option in the dropdown. 3. You can now do the following actions : create a new user by clicking the ""New User"" link. 4. Click the name of the user to see/edit the user details and/or delete the user.",Very nice writeup.  An intuitive description of the changes.  Good display of code.  Remember to skip a space before open paren (except in parameter lists).,"As an instructor, I am quite pleased with the level of depth and detail you've put into this assignment. I would like to give you a few pointers to enhance your work even further:

1. Organize: The organization of the assignment could be improved. Make sure your assignment has a clear introduction, body, and conclusion. Place the instructions at the end with clear headings so they are easily distinguishable from the main body of text. 

2. Clarity: Some parts of the assignment seem to be overly detailed or technical, making them difficult to follow. I recommend simplifying phrases and breaking down complex sentences.

3. Images and Links: You've referenced to images and links multiple times in your assignment, without actually including them. Be sure to insert any necessary visual aids, code snippets, or relevant links directly into your assignment.

4. Code Snippets: While it's clear that you used a handful of code snippets in your assignment, they were not formatted properly. When it comes to sharing your code, always be sure to set it apart from your regular assignment text, preferably in a different font or format, to make it easily recognizable.

5. Proofread: There are a few grammatical errors and typos, such as ""varaibles"" instead of ""variables"". Be sure to proofread your work before submitting to ensure it is error-free.

6. Explain Jargons: Avoid using jargons, or at least provide explanations for technical terms. Remember your assignment should be accessible to someone who might not be as familiar with the specific language or framework you're working with. 

Great effort and keep improving!"
416,E1993,"The <link> project takes advantage of peer-review among students to allow them to learn from each other. Tracking the time that a student spends on each submitted resources is meaningful to instructors to study and improve the teaching experience. Unfortunately, most peer assessment systems do not manage the content of students’ submission within the systems. They usually allow the authors submit external links to the submission (e.g. GitHub code / deployed application), which makes it difficult for the system to track the time that the reviewers spend on the submissions. CSC/ECE 517 classes have helped us by “tagging” review comments over the past two years. This is important for us, because it is how we get the “labels” that we need to train our machine-learning models to recognize review comments that detect problems, make suggestions, or that are considered helpful by the authors. Our goal is to help reviewers by telling them how helpful their review will be before they submit it. Tagging a review comment usually means sliding 4 sliders to either side, depending on which of four attributes it has. But can we trust the tags that students assign? In past semesters, our checks have revealed that some students appear not to be paying much attention to the tags they assign: the tags seem to be unrelated to the characteristic they are supposed to rate, or they follow a set pattern, like repeated patterns of one tag yes, then one tag no. Studies on other kinds of “crowdwork” have shown that the time spent between assigning each label indicates how careful the labeling (“tagging”) has been. We believe that students who tag “too fast” are probably not paying enough attention, and want to set their tags aside to be examined by course staff and researchers.. We would like to modify the model reflecting review tagging actions (answer_tag entity), adding new fields to track the time interval between each tagging action, as well as revise the controller to implement this interval tracking functionality. A few things to take into consideration: A user might not tag reviews in sequence, they may jump through them and only tag the one he or she is interested When annotator tags 1 rubric of all reviews then move onto the next, their behavior will be much different compared with those who tags 4 rubrics of each review. Sometimes an annotator could take long breaks to refresh and relax, some even take days off, these irregularities needs to be handled. A user may slide the slider back and forth for a number of times, then go to the next slider; they may also come back and revise a tag they made, these needs to be treated differently. The first step would be to examine the literature on measuring the reliability of crowdwork, and determine appropriate measures to apply to review tagging. The next step would be to code these metrics and call them from report_formatter_helper.rb, so that they will be available to the course staff when it grades answer tagging. There should also be a threshold set so that any record in the answer_tags table created by a user with suspect metrics would be marked as unreliable (you can add a field for that to the answer_tags table). We propose to use `updated_at` in `answer_tags` model for each user to calculate gaps between each tagging action, then use `report_formatter_helper` together with `reports_controller` to generate a separate review view. Filtered gaps would be presented in the form of line-chart, with the `chartjs-ror` gem connecting the `Chart.js` component in front end. This specific project does not require a design pattern, since it only requires using same type of class in generating same type of objects. <image> <image>. To create a chart within the front end, we went through the list of already installed gems to avoid enrolling complexity to the existing environment. We did find a gem chartjs-ror and decide to bring out our implementation with the package. What chartjs does is it takes a series of parameter and compile them into different kinds of graphs when getting called in front-end, so this project is divided into several components: 1. Extracting data 1.1. First we would need to see what data is needed in generating report, we found that: 1.1.1. We would need student information to generate report for the specific student 1.1.2. We would need Assignment information to generate report for assignment (currently the report button is under each assignment) 1.1.3. We would need Review data to see what could be tagged 1.1.4. And we would need tagging information to generate time associated with it 2. Compiling chart parameters 1.1. This stage requires understanding of the gem, this particular gem takes two piece of information 1.1.1. Data, which include the data to be presented on the chart as well as labels associated with axis's 1.1.2. Options, which captures everything else, including size of chart and range of data to be displayed 3. Calling gem to generate graph. 1. Data Data is stored across multiple tables, specifically if we need to gather Assignment, review, tagging, and user data, we would need at least Tag_prompt_deployment and answer_tags table. The report_formatter_helper file (which is in charge of generating reports) calls the assignment_tagging_progress function while generating rows (taggers) within a report, so we added a function within to calculate time intervals of everyone's tagging actions： <code> We extracted each student's tagging information of reviews towards a specific assignment, sorted the tagging action in order and calculated intervals between each action, this information is passed back to the report_formatter_helper in a VmUserAnswerTagging data structure, so we added a new field as well as reader and writer within it: <code> While from the front-end, the _answer_tagging_report partial who's in charge of generating report table would call the user_summery_report function within the report_formatter_helper to generate information for each user, we made sure that the interval information is passed to it and correctly evaluated: Helper: <code> Front end: <code> 1. Parameters for the chart gem The other big component is to generate information for the gem to use <code> In this step, we filtered out intervals that are larger than 30 seconds, because as we were testing this function, we found having more than 30 second's interval in the graph would affect the scale of it and making smaller time intervals visually indifferent to viewers. To create a visual effect that is similar across all users, we set the y axis to always start from 0. Besides the basics, we've also plotted a average time spent on each tag (with abnormalities filtered) to provide additional visual cue for the teaching team. 1. Plotting graph As could be seen in the code block above, we called the function as well as the implementation from the gem in our front end and plotted interval graphs for each student tagger: <code>. Automated testing is not available for this specific project because: 1. To test the review tagging interval one has to 1.1. Create courses 1.2. Create assignment 1.3. Setup assignment dues dates as well as reviews and review tagging rubrics 1.4. Enroll more than 2 students to the assignment 1.5. Let students finish assignment 1.6. Change due date to the past 1.7. Have students review each other's work 1.8. Change review due date to the past 1.9. Have students tag each other's work, with time intervals (pause or sleep between each review comment, having at lease one interval longer than 3 minutes) 1.10. Generate review tagging report 1.11. Generate review tagging time interval line chart And you cannot verify what's on the line chart with Rspec since it's a image, we wouldn't be able to see if the interval greater than 3 minutes is filtered Each time this script runs, it would take minutes to test, let along having the intervals, and each time Expertiza runs a system level testing, this script would be included, adding who knows how long to the already too long testing process. Thus we propose to verify this function in non automated ways. <image> As described, we tested this feature in the following sequence: 1. As instructor 1.1. Create courses 1.2. Create assignment 1.3. Setup assignment dues dates as well as reviews and review tagging rubrics 1.4. Enroll more than 2 students to the assignment 2. As Student 1.1. Finish assignment 3. As instructor 1.1. Change due date to the past 4. As Student 1.1. Review each other's work 5. As instructor 1.1. Change review due date to the past 6. As Student 1.1. Have students tag each other's work, with time intervals both over and under 30 seconds 7. As instructor 1.1. Generate review tagging report 1.2. Generate review tagging time interval line chart The result is shown in the graph above, manual testing showed that intervals greater than threshold did get filtered and students without any tagging activities are dropped in graph creation. We did try to auto mate this process, but is stopped in the last step while validating the graph created, as the function is wrapped in the gem and cannot be accessed from RSepc: <image> You may also want to see our testing video [ <link> ] We'd also like to suggest a refactor of the code, since some old functions are spread from model to controller to view and parts of it is been run for unnecessary times, too much data is getting passed back and forth including data that shouldn't be given to the view.","All in all, I don't think this documentation makes it clear what was done.  Long code sequences are given with only a few sentences' explanation.  It says that automated testing doesn't make sense, but that's not true.  Given a set of records of tagging actions, tests could make sure that the averages and other statistics about tagging times were calculated correctly.","Dear Student,

Thank you for your comprehensive exploration and analysis for this assignment. Your approach is quite methodical, and you've clearly paid careful attention to detail in explaining the process and each step involved.

You've done well to factor in different scenarios in the user experience and to outline how those scenarios would impact the tracking and measuring system. Your understanding of how to use the gem to generate a graph is quite accurate, and your code for extracting, compiling, and analyzing the data- as well as for generating the graph- is well-done.

However, while I appreciate your attempt to automate the testing process, much emphasis should also be placed on creating automated tests. Despite the challenges identified, these are integral to maintaining code quality over time, and understanding how to navigate these complexities is a crucial part of your learning experience. Hence, I would encourage you to keep trying to figure out how to automate testing of features like this, despite the intricacies involved.

One major concern is about redesigning the system without the use of design patterns. Design patterns provide reliable, tested mechanisms for navigating complex design situations and it would be useful if applied to streamline the general system structure.

You could also include a walkthrough with the instructor, explaining the user steps involved for easier understanding. It would also be beneficial to utilise diagrams and flowcharts to represent the different components you described.

In the refactor aimed for the final part of your project, make an attempt to cut down on the unnecessary passing of data back and forth and keep in mind the importance of a secure model-view-controller framework.

All in all, this was an impressive effort, further work in the areas mentioned will make it exceptional. You are making good progress towards mastering these concepts. Keep it up!

Best regards,
[Your Name]"
417,E1939,"Expertiza is an educational web application created and maintained by the joint efforts of the students and the faculty at NCSU. It’s an open source project developed on Ruby on Rails platform and the code is available on Github. It allows students to review each other’s work and improve their work upon this feedback. Students and Instructors (including TA's) use this application though their credentials. Instructors can add new projects, assignments etc as well edit the previous ones and at a later stage can see the student submission and grade them. They can even put a time limit (deadline) for submitting the assignment. Students can form teams for the projects, submit their work through handles (Wiki page, link to a video etc). Students can even review their teammates and other peers, as well give them any suggestions if required Review Assessment Credentials The credentials for Peer review assessment for Bookmark Enhancement project are Instructor Login: username => instructor6 password=>password Accounts for Impersonation: username => student6340, student6341 Assignment => Exercises, CSC456, Fall2015. Expertiza features the bookmarking functionality which allows users to help the author of the project by suggesting insights. Let’s say there are five topics that I’m interested in and would like to contribute to, but I can only choose one. Well, for the other topics, I’m allowed to submit hyperlinks to pages that I think would help the author do the work. On each line of the signup sheet are two icons, one for adding a bookmark to the topic, and another for viewing bookmarks on the topic. The bookmarks are attached to each project topic and user can suggest by filling up a questionnaire. As soon as a user creates a bookmark, the project author is able to view all the bookmarks that are created for his project. The author can give a feedback on the bookmark that he has received which helps even the user know the usefuless of his bookmark. The Bookmark functionality in expertiza is in its nascent stage which allows user to provide feedback on the projects that he is interested in. It also allows the author to rate the bookmarks that he has received for his project. Project Juniper Bookmark Enhancements is an attempt to make the bookmarks more user-friendly and credible. We have improved the functionality for an author to descriptively evaluate the bookmark that he has received on his project using rubrics as set by the instructor. 1. Fixing the “Back” button 2. Validations on the form for adding bookmarks were missing 3. Allowed the creator of bookmark to rate himself and fixed the logic for calculating average rating 4. Bookmark Rating Questionnaire could not be created. Fixing the Back button: When user visits “Create Bookmarks"" and ""View Bookmarks"", the back button was not functional which refrained the user from going back to the Signup-sheet. Now this issue has been fixed which in future will allow to any contributor to use this back functionality. Earlier: <image> Files Changed: app/controllers/bookmarks_controller.rb <code> <code> app/views/bookmarks/list.html.erb <code> The changed code can be found <link> The screencast can be found <link> Bookmark Validations The form for creating a new bookmark allowed malformed URLs to be entered into the system. Now, the bookmarks can be added only when user enters legitimate URL as well as all the fields are completely filled. Validations were added as a security measure to prevent misuse. Files Changed: app/controllers/bookmarks_controller.rb <code> app/models/bookmark.rb <code> The changed code can be found <link> The screencast can be found <link> Self Rating of Bookmarks and average calculation When reviewing the bookmark, the average rating for that bookmark shown was calculated wrongly and showed average rating for the bookmark that wasn’t reviewed. Also, the user who created the bookmark could rate himself. Now, the user cannot rate his own bookmarks and the average rating is calculated perfectly after one or more people have reviewed it. Files Changed: app/models/bookmark_rating.rb <code> app/views/bookmarks/list.html.erb <code> app/controllers/bookmarks_controller.rb 1. method to check if a dropdown is used for rating bookmarks <code> The changed code can be found <link> Review bookmark using rubric functionality The bookmark functionality earlier only allowed for the users to rate the bookmark and not give feedback about the the quality of the Bookmark. Now, feature is added so that the instructor can decide whether to allow for bookmark to be just rated or a have a rubric . The instructor can customize the questions in the rubric. The rubric once created by the instructor can be used for multiple assignments and also multiple rubrics can be created for different types of assignments. Files Modified app/controllers/bookmarks_controller.rb <code> app/controllers/questionnaires_controller.rb <code> app/controllers/response_controller.rb <code> The screencast can be found <link>. 1. Enable Bookmarks 1. After logging in as instructor, go to Manage > Assignments 2. Select Edit under Actions for assignment 3. Under Topics Tab select 'Allow participants to create bookmarks?' to allow bookmarks 4. Go to Rubrics tab, under 'Bookmark Rating' select the Bookmark review questionnaire to use the rubric for reviewing the bookmarks , select None for dropdown. Note : When 'Bookmark Rating' is 'None', the error the error 'You did not specify all the necessary rubrics. You need [BookmarkRating] of assignment Exercises before saving the assignment. You can assign rubrics here.' is out of scope of the current project and the error can safely be ignored from point of view of this project ' 1. Fixing the back Button & Validations 1. Log in as an instructor and impersonate as a student using the credentials given above 2. Select ‘Exercises’ assignment and go to the Signup sheet 3. We can see a list of projects with 2 columns to add or remove the Bookmark, select any of them 4. You’ll be redirected to the corresponding page where the back button will be visible 5. Select add bookmark and the form can be tested for Validations. 1. Create new Bookmark Rating Rubric 1. As an instructor, go to Manage>Questionnaires and select Bookmark Rating field 2. Create a new rubric with required details 3. Start adding questions. This can be done by manually entering into the system or importing Questionnaire. 1. View Bookmarks 1. Log in as an instructor and impersonate as user using the credentials mentioned above and then select assignment ""Exercises"" 2. Add bookmarks to other topics. 3. The owner of that project should be able to see all the bookmarks created for his project and can rate the bookmark through the way instructor has defined it (rating or rubric). The current version of expertiza did not have any test for the BookmarksController and the Bookmarks model. Using the test driven development(TDD) approach, we have added an exhaustive set of RSPEC tests for BookmarksController, to test all the modifications we have done to the code of the controller class. We have also added unit tests to the bookmarks model. The tests can be executed using the ""bundle exec rspec filename"" command as shown below. <code> Rspec testing videos can be found <link>. This application with the mentioned changes have been deployed on VCL and can be found at <link>. 1. Giving credit to the author of the bookmark for his contribution. 1. Github Link: <link> 2. Pull Request: <link> 3. <link> 4. Expertiza on Github <link>.","My biggest concern is that the code changes are shown, but not explained.  It would be easier to read them from the pull request than from the documentation.
Better to use the Github diff view to show code rather than the monochrome box provided by MediaWiki.  Video is useful, but should contain audio; too hard to follow it without audio.
The test plan is incomplete; it says there are a lot of new tests, but does not say what they test.","Dear Student,

Your work shows immense comprehension and understanding of the project at hand, and I am pleased with the work you have presented. Your advancement of the bookmark functionality in the Expertiza platform showcases your ability to not only understand the existing system but also to develop it further.

The detailed description of the process, coupled with the relevant changes in specific files, is very comprehensive and offers insight into the level of work you have put into the operation. The inclusion of the screencasts links provides a visual guide on the tasks carried out and is a definite plus.

However, there are a few things you could improve in your assignment:

1. Clarity: Though your report is thorough, it could benefit from better organization and clarity. You could divide your paper into clear sections such as ""Introduction"", ""Methods"", ""Results"", ""Conclusion"", etc., to make it more readable. 

2. Citation: When discussing the previous versions of the platform, you might want to add specific sources or reference links to give your statements more credibility and authenticity, and for readers to better understand the context.
   
3. Sensitivity Checks: It would also be highly beneficial if you could include details about any sensitivity checks you performed during the development process. It would imply a more thorough understanding and implementation of your work.

Overall, your report is comprehensive and shows depth in understanding and application. I look forward to seeing your improvements in the final draft. Great job!

Best,
[Instructor's Name]"
418,E1631,"When a participant of a team reviewed an assignment, his/her review is independent of his teammate’s reviews. To allow teammates to discuss and review together, allowing teams to submit reviews for the team as a whole should be allowed ideally. We intend to do this in our project. 1. Currently all reviews in Expertiza are done by individuals. This is true regardless of whether the assignment is done by individuals or teams . 2. There are occasions when it's advantageous to review projects as a team . 3. It helps foster discussion and thereby improves the process of learning. This project comprises of the following steps : 1. Objects of ResponseMap record the information of who reviews whom. The field reviewee_id refers to the team who is being reviewed. The field reviewer_id refers to the individual/team performing the review. # We added a boolean field ""reviewer_is_team"" to identify if the review is being performed by a team or an individual. 2. The review strategy is assignment specific and hence we have added a field reviewer_is_team to the assignments table as well 3. For an Instructor to specify whether the review is a Team/Individual based review, we have provided a dropdown on the Review Strategy tab of assignment creation. 4. If reviewer_is_team field is true the reviewer_id in the response_map is set to the corresponding team_id of the user 5. Ensure that features such as ""view my scores"", or the ""alternate view/heat map"" continued working. Model View Controller In an MVC model, a software application is divided into three major components: Model, View and Controller. Model - Keeps data, logic and relations between objects and the database. It also handles validations, associations and transactions. View - Displays the data received from the controller in the user interface. Controller - Accepts the client's input and converts it into action points for the model or view. Other responsibilities include querying models and organizing data in a structure that is displayed by the view. Name: Specify review type on Review Strategy tab. Actor: Instructor. Description: The instructor specifies whether this review is an individual review or a team based review on the Review Strategy tab. Name: Perform Review. Actor: Individual Student/Team. Description: The individual/team will perform a review for the Assignment. <image>. 1. The below fields have been modified in the response_maps table: <table> The description of the fields of the database for ResponseMap: i. reviewer_id: Based on the reviewer_is_team flag in the assignments table , the assignment team or the participant id is added in this column. ii. reviewer_is_team: If this field is ‘true’, the reviewer_id refers to the id of the “AssignmentTeam” to which the participant belongs. Else, it refers to the id of the “Participant” itself. 2. The below fields have been modified in the assignments table: <table> 1. reviewer_is_team: - This field is set based on the discretion of the instructor who decides if the assignment is a to be reviewed individually or as a team. Below are the key files modified: 1. review_mapping_controller.rb: 1. We have added a check in the assign_reviewer_dynamically method that checks if the assignment is a team_reviewed assignment to fetch the respective row from the participants or the teams_users table <image> 2. Also while redirecting to the student_review controller the participant_id or the team_id is passed based on the type of review <image> 1. response_controller: 1. Below is the get_reviewer_from_response_map method that returns the team or participant id based on the type of review . Also this value is passed forward to the respective controller we redirect to. The get_participant method returns the row from the participants table corresponding to the current user. <image> <image> 1. student_review_controller: 1. Same logic as applied in the review mapping controller to obtain the reviewer. <image>. 1. assignment_team.rb: 1. A row is being created in the response_maps table depending on if it's a team or individual review. The same logic is being applied to check and retrieve the appropriate row form the response map. <image> 1. assignment.rb: 1. The logic to not allow reviewers to review their own work has been modified to include scenarios when it's a team based review. <image>. 1. assignments/edit/_review_report.html.erb: 1. Added the below drop down so that the instructor can select the review strategy for the assignment. <image>. RSpec is a testing framework for Rails, and is a Behavioral-Driven Development tool. It is a domain specific language(DSL). All the tests can be executed by rspec spec command, or can also be executed individually using the command ""rspec spec/models/assignment_team_spec.rb"". We intend to write unit tests using RSpec for all the methods which we modified/created. Factory Girl is used for creating Assignment and Team objects to be used for testing. Factory Girl is a replacement for fixtures. Fixtures have to be updated whenever we change a data model whereas adding and removing fields is much easier in Factory Girl. Fixture definitions are global whereas Factories can be local, so isolated cases can be tested. Factories are defined to create objects for testing. <code>. 1. If the instructor selects ""Review by team"", check if the review is done by a team member, not by participant. 2. If one teammate is working on a review, another teammate should not be able to edit it at the same time.","Design doc is mostly screenshots of code, which don't explain enough about why the project was coded the way it was. ""There are too many checks of """"reviews_is_team"""".
Login issue with action_allowed as pointed out during demo. 
There are too many screenshots of the code changed in the design doc.""","Dear student,

Thank you for your submission. Your dedication to this project and thoroughness of your plan is admirable, I see a lot of effort and thought put behind your proposed changes. The aim to transform individual reviews into team reviews in the Expertiza platform is an innovative concept that holds great potential for intermediate learning.

Your explanation of modifying fields in 'response_maps' table as well as 'assignments' table to accommodate for team reviews is clear and logical. I can follow your proposed process due to your explanatory sentences which are well-articulated.

Furthermore, your introduction of a Model-View-Controller (MVC) model and its relevance to your project provides a solid conceptual understanding of the task at hand to the reader.

However, to maximize the clarity of your assignment, try to organize your work better by using sub-headers, bullet points, and number lists to ensure that each step in your process is easy to follow.

Also, while you presented images and codes in your assignment, you did not provide them. Next time, you should visually support your statements with the relevant images and codes. 

I'm pleased that you intend to write unit tests for all methods that you modified or created. Please be sure to submit these with your final version of the project.

Lastly, your description of the roles of actor: Instructor and Individual Student/Team is quite brief. Consider expanding on these descriptions to provide more detail about their specific roles and actions within the specified model.

Your proposal is promising, and your attention to detail is commendable. I'm looking forward to seeing your finished project. Please revise your assignment based on the above comments and resubmit.

Best Wishes,
[Your Name]"
419,E1560,"Code refactoring is process of changing the code to make it more maintainable, without changing the functionality of the code. Some of the reasons for performing refactoring are: 1. To remove duplicate code. 2. To make the code more maintainable. 3. To divide functionality of the class. Expertiza is a web application where students can submit and review learning objects like code, writings, etc. It gives scope for creation of reusable learning objects. Students submit assignments, which can than graded through peer reviews. The Expertiza project is supported by the National Science Foundation. JoinTeamRequestsController and InvitationController. invitation_controller.rb is used by a user to invite other users to join his/her team. It performs validation before creating a request. Following chunk of code checks whether the user is allowed to get the invite or not. <code> Now, invited user can accept or reject the request. Once the user has accepted the request, he can be seen as a part of the team. join_team_requests_controller.rb is used when user decides to join a team. This is achieved by creating an advertisement for the team. Once the advertisement is created, it is shown in the Topic Selection section. The user who wants to join the team can send a ""Request"" to the members of the team. The members can then decide whether to send him/her an invite or decline the request. The invitation_controller.rb is doing the required task but it is difficult to understand the code, hence it becomes difficult to maintain the code. And the functions in the accept and create method can be broken down into separate methods. In join_team_request_controller.rb has duplicate code in various methods which can be removed by creating a separate method for this common code. invitation_controller.rb 1. Rename to Invitations_Controller.rb, as is not in accordance with current naming convention. 2. Add comments explaining what each method does, and comments on how important variables are used as currently there are no comments. 3. Refactor create and accept methods. Shorten and clarify them by adding private methods, as create and accept methods currently have a lot of code. 4. Change the find_by_sql call(s) to Rails (Active Record) statements. 5. Make sure that it can be used by a user with a TA or instructor account, if they are participating in this assignment. 6. Change grammatically wrong or awkward flash messages. join_team_requests_controller.rb 1. Add comments to the code. 2. Remove duplicate code, from create and accept methods. 3. Decline and destroy method should check for successful operation before returning. 4. Change grammatically wrong or awkward flash messages. The controller renaming had to be incorporated in different files of the project. The table contain the file names along with the lines before and after the changes. <table>. <table>. <table>. <table>. To test the functionality of join_team_request_controller and invitations_controller, please follow the steps provided in the video below. This video covers the functionality of how these controllers work. This will help in manually testing the functionality. <link>. <link> <link> <link> <link> <link>.","Writeup does not clearly show changes.  In long code sequences, code removed, changed, or inserted could have been highlighted.","Dear Student,

Thank you for your submission. Your understanding of the concept of code refactoring and how it applies in the context of the Expertiza web application is commendable. Your reasons for performing refactoring are both pertinent and well-explained.

However, I would have appreciated more granular detail in your explanation of the pieces of code requiring refactoring. Also, while you did include a series of adjustments to be made to clean up code, increase understandability and avoid repetitive coding, it would have been beneficial to provide examples or demonstrate the changes you intend to make.

In terms of explaining the functionality of both join_team_request_controller and invitations_controller, you've done a nice job of highlighting the functions of each, but your descriptions could be more concise and efficient. Additionally, your test methods are clear but could be expanded upon to ensure thorough testing and validation. It would be important to highlight some potential test cases, expected results and how to deal with potential errors or exceptions. 

Lastly, do not forget to closely justify and explain your decisions related to refactoring to showcase your understanding of the topic. Also, you might want to add an explanation for why you chose to rename the invitation controller.

In overall, you have provided a comprehensive assessment of the codebase that we are dealing with. With the few adjustments mentioned above, you would significantly enhance the clarity and comprehensiveness of your submission.

Keep up the good work!

Best,
[Your Name]"
420,E1994,"For assignments with topics, like the OSS project, mentors are associated with topics, and then whichever team is assigned to the topic inherits the mentor for that topic However, for assignments without topics (like Program 2), there is no good way to “automatically” assign mentors to projects. The instructor needs to watch teams being formed, and every time a new team is formed, a new mentor needs to be assigned, outside of Expertiza. This leads to a lot of work for the instructor, as well as sometimes long delays before a team is assigned a mentor. Github Pull Request: <link> Video Presentations: <link> <link> <link> Deployment: <link>. Develop a trigger that: 1) Is activated when any team has been formed that has k members, where k is greater than 50% of the maximum team capacity 1. ex) max members = 4, trigger activated when the team size reaches 3 2) Assign a mentor to the team 1. Mentors should be evenly assigned to teams, so a good strategy is to assign the mentor who has the fewest teams to mentor so far. 3) Notify the mentor via email that they are now assigned to a specific team, and provide the email addresses of the team members. 4) Possibly notify the team members that they have been assigned the mentor with contact information (further discussion here). Since the trigger we implemented would need multiple handlers and each of them responses in different actions, we decide to use Chain of Responsibility as the design pattern. Chain of Responsibility is a behavioral design pattern that lets you pass requests along a chain of handlers. Upon receiving a request, each handler decides either to process the request or to pass it to the next handler in the chain. <image> Implementation for our project <image>. For assignments without a topic, there is no way to assign a mentor to the team on Expertiza system but to manually assigned one via Email out of the system. <image> In the above case, there is no mentor role for the current Expertiza system, only to assign mentor manually. Assignments with or without a topic could be assigned with mentors automatically <image> Also, mentor and team members will be notified by Emails (Results showing in UI Test). General workflow and specific add member workflow <image> <image>. The solution we proposed generally follow the chain of responsibility and the work flow The solution will follow steps list here: 1. Allow instructor to assign mentors for assignments without a topic 2. Check the topic of assignment and number of team members whether reach the requirement or not 3. Assign mentor for the team automatically 4. Notificate both mentor and student 5. Team member added after the mentor assignment will also get a email notification about mentor. Since we implemented a whole new feature and kept the original work flow unchanged at the meantime, most modifications are in models: Models: 1. app/models/assignment_team.rb 2. app/models/assignment_participants.rb 3. app/models/team.rb 4. app/models/team_users.rb 5. ... Views: 1. app/views/student_task/view 2. app/views/student_teams/view 3. app/views/shared_scripts/_add_individual 4. app/views/participants/_participant 5. ... Here we present some essential codes with explanation <image> First, add mentor role for assignment. Set authorization for mentor which could not do review, take quiz or submit. <image> Add a mentor role for instructor/admin when add participant for assignment <image> To assign a mentor, there are several requirements: 1. There should be at least one mentor in this assignment 2. The current team size is greater than half of max size 3. The team do not have a mentor yet <image> Always assign mentor with lowest number of mentoring teams, in order to do so: 1. First, get all mentors for this assignment 2. Traverse all mentors and calculate how many teams he/she mentored, store the one with lowest number 3. Return mentor with lowest number of team she/he mentored <image> Use Mailer class to send email notification about mentor and team members information(method used to send email notification for student is similar to this). To make sure the refactor code can work correctly, we need to run the original rspec test code and add some new test. Besides, we are plaining to test from UI to make sure all the features work. The test results are shown below. 1. Run and pass existing RSpec Tests after Modification 2. Develop New RSpec Tests for the new features 3. UI testing on the deployed project. 1. Add new participant type mentor in factories.rb <image> 2.Test new added method in team_respec, like half, add_member, size... <image> <image>. 1. Instructor/Admin add mentor for specific assignment <image> 2. Student create team and invite others 3. When team size greater than half of max size, assign mentor and send emails <image> <image> 4. When student accept from a team which has already been assigned with mentor, he/she would receive a email <image> 5. Also we extend our work to make all teams visible to mentors <image>. 1. Mentor could not see teams' submissions since authorization control is working on the view assignment page and mentor does not have rights to submit 2. Rspec Test for email functions.","You motivated the project, and described its functionality.  Along with the code snippets, there should be a description of what changes have been made and why.  Ditto for the tests, which show the code, but don't describe what is tested.","Overall, this is a very comprehensive and well laid out assignment. The detailed explanation of Chain of Responsibility as the chosen design pattern for the task is commendable. 

However, the text is somewhat dense with several details which can be difficult to track without more paragraph spacing or bullet points. For future assignments, aim for a more structured layout which makes your points clearer to the reader.

The images are not visible in the assignment, but I am sure you've done a good job in the visual representation of your project. Next time, please ensure to test the assignment submission to confirm the images are loading correctly. 

Your solution steps are well defined. Make sure to elaborate more next time on how exactly you've implemented the designed steps in the code. 

Again, you did a great job by adding the testing elements to your assignment, including creation of new RSpec tests for the new features and UI testing on the deployed project.

Good to see you've identified a potential issue, like the mentor not being able to see teams' submissions because of the authorization control. Continue to think forward and identify any potential roadblocks or issues in any system you design or work on. 

In summary, your work on this assignment is commendable and well done. You've gone to great lengths to communicate and explain your thoughts and the process behind your design decision. A little more effort on the readability of your assignment will go a long way in effectively communicating your ideas. Keep it up!"
421,E1849,"This class acquires reviews from a given questionnaire and assignment, and creates a heat map visualization of the review scores a reviewee received from other people (reviewers) for an assignment. There are currently no test cases for vm_question_response.rb. We seek to create unit tests to attain at least 90% coverage by line. app/models/vm_question_response.rb spec/models/vm_question_response_spec.rb. Testing VMQuestionResponse hinges upon collaboration verification, so that we know VMQuestionResponse is getting the right messages from the right classes, so that it can appropriately create its data structures. We first went through each method of the VMQuestionResponse class and determined whether the method was a command, or query and whether the method was incoming, outgoing, or sent-to-self. For each method we will write tests for valid and invalid inputs as well as edge cases. Here is an outline of our implementation strategy: To describe VMQuestionResponse 1) Test initialize 1. in the context when VMQuestionResponse is initialized with a review questionnaire 1. in the context when VMQuestionResponse is initialized with any other questionnaire type 2) Test add questions 1. in the context when VMQuestionResponse is given a list of questions 3) Test add_reviews 1. in the context when VMQuestionResponse is initialized with a review questionnaire 1. in the context when VMQuestionResponse is initialized with a author feedback questionnaire 1. in the context when VMQuestionResponse is initialized with a teammate review questionnaire 1. in the context when VMQuestionResponse is initialized with a metareview questionnaire 4) Test display_team_members 5) Test add_team_members 6) Test listofteamparticipants 7) Test max_score_for_questionnaire 8) Test add_answer 9) Test get_number_of_comments_greater_than_10_words. 1. initialize : This tests that the VmQuestionResponse is initialized with the appropriate round number. <code> 1. add_questions : This tests that the VmQuestionResponse adds questions from a given review <code> 1. add_reviews : This tests that the VmQuestionResponse adds reviews and reviewers from a given review <code> 1. display_team_members : This tests that the VmQuestionResponse can print out the appropriate team member names. <code> 1. add_answer : This tests that the VmQuestionResponse adds all of the review scores from its reviews to VmQuestionResponseCells in VmQuestionResponseRows. <code> 1. get_number_of_comments_greater_than_10_words : This tests that VmQuestionResponse only finds comments that have at least 10 words. <code>. We have now attained 97.25% coverage. <link> <link>.","What is here is good, but I think it should be enhanced by describing under what conditions tests succeed or fail, and for long tests (e.g., add_reviews) the general structure and funcion of each context should be described.","Dear Student,

Your plan for testing various aspects of the VMQuestionResponse is well-structured and comprehensive. I appreciate your attention to both valid and invalid inputs along with the consideration for edge cases. 

Though the plan seems solid, I find a little bit of lack of clarity in certain areas. When testing each function, ensure to provide a more elaborate description of what exactly you're testing for and why. This will make it easier to follow and detect whether any aspect has been left out in the testing process.

It is also essential to document any assumptions you made while writing the tests. For instance, you mentioned testing the ""add_reviews"" method. It would be beneficial to specify what the method is intended to accomplish and what type of data it should be able to handle. 

Double check your numbering system under ""To describe VMQuestionResponse"", they all start with ""1."" which can make it difficult to follow. 

Lastly, you've mentioned achieving a 97.25% coverage which is impressive. Make sure this result includes all vital aspects of the operation and critical edge cases. 

Keep up the good work! 

Best,
[Your Name]"
422,E1608,"Four models is related: criterion.rb, scale.rb, checkbox.rb, questionnaire_header.rb, upload_file.rb. There are 4 methods “edit”, “view_question_text”, “complete” and “view_completed_question” correspond to different views. 1. edit ~> when instructor add/edit new questions 2. view ~> when instructor view existed questions 3. complete ~> when students do peer reviews 4. view_completed_question ~> when student view existed peer reviews. 1. Choice question 1.1. Scored question 1.1.1. Scale 1.1.2. Criterion 1.2. Unscored question 1.1.1. Dropdown 1.1.2. CheckBox 2. TextResponse 1.1. TextArea 1.2. TextField 3. UploadFile. There are some issues in each file, such as security, complexity, duplication, etc. And currently there is no unit tests for [question_type].rb. 1. Refactor these [question_type].rb files and fix issues. 2. Keep the inputs and outputs of these methods (edit, view, complete, view_completed_question) the same as before. 3. Write unit tests for [question_type].rb listed above. 4. Create RSpec files for each question type in /spec/models/ folder 5. Create multiple tests to check valid and invalid cases, such as input including special character double quote (“”). 1. Method has too many lines: Line 35 - 158 [106/30] Wrap the specific code into different instance methods. 1. Cyclomatic complexity for complete is too high: Line 35 - 158 [28/6] Wrap the code into different instance methods to reduce cyclomatic complexity <code> 1. Identical code found in 1 other location: Line 20 - 32 (mass = 89) Also found in app/models/scale.rb:17…28. The following method is removed from subclass: criterion and added to their superclass: scaled_question <code> 1. Identical code found in 1 other location: Line 135 - 139 (mass = 50) Also found in app/models/scale.rb:50…54. Wrap the duplicated code into an instance method and add the instance method into superclass: scaled_question <code> 1. Identical code found in 1 other location Line 13 - 14 (mass = 40) Also found in app/models/scale.rb:10…11. Wrap the duplicated code into an instance method and add the instance method into superclass: scaled_question <code> 1. Similar code found in 1 other location Line 103 - 105 (mass = 26) Also found in app/models/criterion.rb:107…110. Wrap the duplicated code into an instance method <code> 1. Similar code found in 2 other locations Line 152 - 153 (mass = 22) <code> <code> 1. Similar code found in 3 other locations: Line 130 - 134 (mass = 18) Also found in app/models/criterion.rb:145…149, app/models/scale.rb:45…49, app/models/scale.rb:60…64. Wrap the duplicated code into an instance method and add the instance method into superclass: scaled_question <code>. 1. Cyclomatic complexity for complete is too high. Method has too many lines <code> 1. Identical code found in 1 other location: line 17-28 app/models/criterion.rb:20…32, def view_question_text. The following method is removed from subclass: scale and added to their superclass: scaled_question. <code> 1. Identical code found in 1 other location: line 50-54 app/models/criterion.rb:135…139. Wrap the duplicated code into an instance method and add the instance method into superclass: scaled_question. <code> 1. Identical code found in 1 other location: line 10-11 app/models/criterion.rb:13…14. Wrap the duplicated code into an instance method and add the instance method into superclass: scaled_question <code> 1. Similar code found in 3 other locations: line 60-64 app/models/criterion.rb:130…134, app/models/criterion.rb:145…149, app/models/scale.rb:45…49. Wrap the duplicated code into an instance method and add the instance method into superclass: scaled_question <code>. 1. Method has too many lines. By moving codes to private methods outside this method, this problem can be fixed together with the following one. Here is the new complete method together with two additional private methods: hasAnswer(html, answer) and nextQuestionTail(html, next_question). The source codes are listed as below. <code> 1. Cyclomatic complexity for complete is too high. This problem can be solved by moving branches outside to other private methods. See source code above. 1. Similar codes in edit method are found in 2 other locations. (questionnaire_header.rb and upload_file.rb) Such code duplication can be eliminated by moving the identical part of the similar edit method to a new function, named edit_prefix(html, count) to their common superclass, which is Question (question.rb). Here is the source code of the added edit_prefix method in question.rb: <code> The original code are commented out and insert the function call of the above function, html will be returned in the above function, see codes below: <code> 1. Similar codes in view_question_text method are found in 4 other locations. (dropdown.rb, questionnaire_header.rb, text_response.rb, upload_file.rb) The solution to this problem is the same as above one, below is the function added in the most common superclass, which is Question, that contains the common parts of the codes found in the view_question_text methods in all five classes. <code> The original code are commented out and insert the function call of the above function, html will be returned in the above function, see codes below: <code>. All problems in this file are solved after solving the problems found in checkbox.rb. All problems in this file are solved after solving the problems found in checkbox.rb. One contribution is to write unite test for four question types. For each of the four required question types: 1. criterion.rb, 2. scale.rb, 3. checkbox.rb, 4. upload_file.rb, there are four unit tests for the following four functions: 1. edit , 2. complete , 3. view_question_text , 4. view_complete_question_text . These four functions are tested since they are the only methods that the question types class can perform. The output of those four functions is HTML format string. We test if the output string is matched with the expected given certain conditions. Here are the spec files git hub links: 1. <link> 2. <link> 3. <link> 4. <link> .","The wiki does not include the information on how to test the code manually.
And it is quite mechanical, with little explanatory prose.
However, the text that is there manages to do a very good job of drawing attention to what was done.","Dear Student,

Thank you for submitting your assignment. From your submission, it demonstrates a broad understanding of the course, particularly pertaining to how different models are interrelated and the methods that correlate to different views. I appreciate your detailed explanation of how these models and methods work in this context. This shows a good level of comprehension and practical application of the course material.

However, your assignment seems confusing and disjointed. It appears as though you're offering a solution to reduce code duplication and cyclomatic complexity, but it's not clearly stated. I suggest to work on your structuring and organizing content to improve clarity and readability. 

Ideally, an assignment should start with an overview of what you intend to do or solve, followed by the main body that demonstrates how you plan to achieve this, and finally, a conclusion summarizing your work and its significance.

Additionally, you have noted that there are problems with certain files but did not mention what the specific issues were. It would be worthwhile to specify what these problems are and what measures you have used to solve them. This will not only be clearer to me, but also can potentially be instructive for you as well when you review this work in the future.

Finally, I would recommend including some of the actual code you have written or modified, rather than just describing it. This can be more substantial and provide clear evidence of your ability to write code.

Keep working hard, refine the areas mentioned, and I am confident your future assignments will be even better.

Best Regards,
[Your Name]"
423,E2113,"Most of the projects and assignments in CSC517 and on Expertiza are peer-reviewed, and these peer-reviews are graded by the teaching staff. When the staff grade reviews, they are viewed in the review-grader interface. The staff can assign the score and provide feedback using the textboxes provided in the right columns of the table. The staff are also allowed to read the reviews in the summary view. There appears to be certain sections of the main review-grader page as well as the summary page that are not working correctly or there is a desire for them to be updated. These issues have to do with calculation of a student's score / average score, the visual representation of the scores, efficient usage of space within the view, and a need for rows of the table(s) to be numbered. We go into further depth about the issues later in this document. Certain aspects of the UI and minor score calculation logic of the review grader system in Expertiza need to be enhanced/refactored. These issues are not major and mainly have to do with UI, and therefore should not require the development of new unit tests. Below is a detailed description of actionable issues that will be addressed in this work. <image>. 1. This project eventually morphed into a bug-fixing and beautification project. There were some serious inconsistencies, bugs, and syntax issues with the beta branch review grader section. These were found and solved to the best of our ability. 2. Fix the “Score awarded/average score” column so that it is populated with the correct numbers. It is supposed to report the score by the current student reviewer in the first round, the average score by all reviewers in the first round, and ditto for the second round. If the number of rounds ≠ 2, then the number of scores should be adjusted appropriately. 1.1. There is a bug having to do with ""Avg. score"" not being calculated sometimes, like when the team that was reviewed should definitely have an average score to be displayed, even if the current student reviewer did not complete the review. This bug will have to be examined further. 3. Number the rows of the table (e.g., “2. Student 8370”) so it is easy to count the lines. This will help assign each TA (and the instructor) an equal number of reviews to grade. 1. The ""Scores"" issue. Unfortunately, this task was more complicated than we originally believed. The team was advised to try to find out as much as possible about the bug, and fix it if possible, but it involves many different classes within Expertiza. 1.1. The variable @avg is computed in the file app/models/answer.rb, and is initially set to nil if an assessment is not present. The variable @avg is also set to a placeholder ""----"" in the file app/helpers/review_mapping_help.rb. If ""@avg_and_ranges[team_id][round][metric]"" is not nil, the ""@avg"" will be set to the average scores. The ""@avg_and_ranges"" is set to the result returned by method compute_avg_and_ranges_hash in method ""review_response_map"" in file ""app/helpers/report_formatter_helper.rb"". The method ""compute_avg_and_ranges_hash"" is defined in file ""app/models/on_the_fly_calc.rb"". 1.2. The ""Score awarded/average score"" column in the table is actually composed of two rendered partials: views/reports/_team_score.html.erb and views/reports/_team_score_score_awarded.html.erb. Within these partials, the method get_awarded_review_score is called, which is defined in the /helpers/review_mapping_helper.rb helper file (line 138). It is within this helper file that the @avg instance variable is also defined. It appears as though the previous team spent some time tracking down the source of the bug in the presentation of the ""Avg. score"" in the table, but were unable to fix it. 1.3. The @avg instance variable is defined in the method get_review_volume, found in line 152 in /helpers/review_mapping_helper.rb - however, in the beta branch, the method that is called within views/reports/_team_score.html.erb and views/reports/_team_score_score_awarded.html.erb is called get_review_metrics. It appears this error is not present in the master branch of Expertiza. 1.4. Another issue with the scores was that a ""nil"" value was showing - this issue was simply due to a forgotten check that needed to be added into the app/views/reports/_team_score.html.erb. 2. In the _review_report.html.erb file, Line 61, we need to replace the 'each' method with 'each_with_index' to make sure that all rows are indexed. In line 69 add a line to display the index number and make sure that the value of the variable must be index+1, since the values are zero indexed. This project mainly focuses on the UI, so no specific GoF design pattern is particularly being considered. Comments will be added where deemed necessary to further illuminate the functionality of the code. If needed, (if new methods/classes/views are added) this will be updated to reflect those changes. <image>. 1. Checkbox items take up far too much space. Remove duplicated header lines and show just columns of checkboxes to the right of the “questions.” Also, it is unnecessary to prefix each by “[Question]”. 2. Adjust column width intelligently. The “Reviewee” and “Score” columns are much wider than necessary. The “Comments” column is also too wide for easy reading. So consider how the page might be reorganized to take better advantage of the available space. One option might be to show the comments vertically, astride each other, rather than horizontally, above and below each other. Mock up your proposal and discuss it with your mentor. 3. Get rid of “Review: Round1”. It should be, “Review Round 1”. 1. To get rid of the duplicated header lines, we will modify view_review_scores_popup.html.erb either by implementing comments vertically, astride each other or by displaying the header columns only once. To tackle the problem of Checkbox items taking up too much space we plan to implement the following mock up.""[Question]"" would be deleted. Original : <image> <image> Mock_up: <image> 1. Concerning column width, we will play around the preset width in /app/views/popup/view_review_scores_popup.html.erb, the previous team went with 10% for ""Reviewee"", 5% for ""Score"" and it looks reasonable. 2. ""Review Round"" header is located at /app/models/review_response_map.rb, and can be easily modified by adding white space. Below is a rough list of files that we estimate this particular action item will involve: 1. /app/views/popup/view_review_scores_popup.html.erb 2. /app/models/review_response_map.rb 3. /app/assets/stylesheets/grades.scss. Most of the changes in this project are UI focused. Due to this, most of the testing was done via manual functionality testing. However, because of the changes in review_mapping_helper.rb, we did have to make changes to the review_mapping_helper_spec.rb file in order to reflect this. The code diff is shown below, and the process for manual testing is also displayed. <image> According to Expertiza Bot, our code test coverage increased by 3.6%. Just for reference- The processes for testing accessing the review reports: 1. Login using an instructor account, such as: instructor6 / password 2. Go to ""Manage >> Assignments"" and choose one assignment with reviews, i.e., ""Program 1"", and click on ""View Reports"". 3. There will be a dropdown selector to choose which report to view - select ""Review report"" from the dropdown, and click ""View"". 4. Check to make sure that the ""Avg. score"" for reviewed assignments is being shown correctly. 5. Check if column widths are appropriate. Make sure the text ""Score awarded / Avg. score"" instead reads ""Score / Avg. score"". 6. Verify the bar graph display of scores. Below is a rough list of files that we estimate this particular action item will involve: 1. /app/helpers/review_mapping_helper.rb 2. /app/views/reports/_review_report.html.erb 3. /app/views/reports/_team_score.html.erb. The review mapping helper is a module that is used extensively throughout the peer review system in Expertiza to perform a number of things (perhaps too many) including calculating scores, finding team colours, preparing grade data visuals, and other useful computations. In this project, we wanted to fix the inconsistencies between the beta and master branch with specific regard to the get_review_volume() and get_review_metrics() method. These performed the same computation, yet get_review_metrics was called but not defined in the beta branch. This was fixed, and the code diff is presented below. The comments were added later, and a separate picture is shown below. <image> Comments: <image>. The addition of indices to each of the reviews for this assignment was a simple fix. Replacing each with each_with_index and printing to HTML solves the issue. <image>. Below is a rough list of files that we estimate this particular action item will involve: 1. app/views/popup/view_review_scores_popup.html.erb 2. app/assets/stylesheets/grades.scss 3. app/models/review_response_map.rb. <image>. 1. We decided to fix all of our issues with summary page like columns taking too much width, header texts like ""Reviewee"" and ""Score"" repeated unnecessarily by reorganizing the page to take better advantage of the available space. We placed the questions vertically, astride each other, rather than horizontally. 2. ""Scores"" and ""comments"" column were merged together for aesthetic reasons and to improve readability. The scores are displayed with a colorful background indicating its value. Before Modification <image> After Modification <image> 1. “Review: Round1” was changed to “Review : Round1”. Also the title ""Review scores: student5061"" was changed to ""Review scores by student5061"" as its more indicative as a title. Before Modification <image> After Modification <image> <image>.","Very good description of design strategy, and changes are nicely described and illustrated with screenshots.","Overall, this is a well-documented and thorough assignment. The descriptions provided are clear, and the codes provided seems to address the issues identified in the assignment description. From this documentation, it shows a good understanding of the functionalities of the project and its development requirements. Nice to see that you've also taken steps to identify and fix bugs, refine the user interface, and make the whole system more efficient.

However, to improve your documentation further, here are few suggestions:

1. Break down your explanations in simpler terms where possible to allow for easier digestion of the complex material you're discussing. The assignment is a bit long and quite detailed, making it a bit overwhelming to read at times.

2. Make sure to explain exactly what each piece of code or function is doing. It can be difficult for a reader to follow along if they are not familiar with the codebase.

3. Your methods for testing are a bit unclear, you would provide more details on the testing procedures followed to ensure the correctness of your work.

4. While the images have been marked as placeholders, there isn’t a real image provided. To truly understand how your changes affected the user interface, the actual images would have been useful for me as an instructor.

5. While discussing your UI implementation, it would be nice if you could have discussed in great detail why you chose a certain type of display layout or why you made certain aesthetic decisions.

The points presented above are just tips to further enhance your solid work. The functionality appears to be working as expected based on your code and description. I am impressed with the quality of work and level of detail put into this assignment. Well done overall!"
425,E2064,"<link> is a peer review based system which provides incremental learning from the class. This project has been developed together by faculty and students using <link> framework. Expertiza allows the instructor to create, edit and delete assignments, create new assignment topics, assign them to a particular class or selected students, have students work on teams and then review each other's assignments at the end. For the students, they can signup for topics, form teams, and submit their projects and assignments. Students then review the work done by other students and give suggestions to improve. Teams after reviews are allotted scores and they can refer to the peer comments to further improve their work. It also supports submission of different file types for assignments, including the URLs and wiki pages. Expertiza allows student work to be peer-reviewed, since peers can provide more feedback than the instructor can. However, if we want to assure that all students receive competent feedback, or even use peer-assigned grades, we need a way to judge which peer reviewers are most credible. The solution is the reputation system. Reputation systems have been deployed as web services, peer-review researchers will be able to use them to calculate scores on assignments, both past and present (past data can be used to tune the algorithms). For this project, our team's job is to refactor the file: reputation_web_service_controller.rb. This file is the controller to calculate the reputation scores. A “reputation” measures how close a reviewer’s scores are to other reviewers’ scores. This controller implements the calculation of reputation scores. reputation_web_service_controller.rb is a fairly complex file. It contains a lot of methods that are long and hard to understand (for e.g. send_post_request). These methods need to be broken down into simpler and more specific methods that are easier to read/understand. Also, the few instances of code duplication that exist should be removed. 1. There is a lot of unused/commented code, which should be removed. 2. Figure out what the code is doing and write appropriate comments for it. 3. Rename bad method names such as (db_query, json_generator). Method names should be verbs, and should say what the method does. Method names should not be so general that they could apply to many different methods.. 4. In the case of db_query, the name should say what it queries for. Also, this method not only queries, but calculates sums. Since each method should do only one thing, the code for calculating sums should be in another method. And there should be comments in the code! 5. json_generator should be generate_json. There needs to be a method comment saying what the parameters are. 6. In send_post_request, there are references to specific assignments, such as 724, 735, and 756. They were put in to gather data for a paper published in 2015. They are no longer relevant and should be removed. send_post_request is 91 lines long, far too long. 7. There is a password for a private key in the code (and the code is open-sourced!) It should be in the db instead. 8. Fix spelling of “dimention” 9. client is a bad method name; why is stuff being copied from class variables to instance variables?. <code> Method names should not be so general that they could apply to many different methods. The other problem with the method was that it did not follow the good practice of having each method perform only one task. This method got the review responses with a db query. Also, it iterated over the review responses to perform a calculation of peer review grades. We have split the method into two to have the review responses do only the get responses part. <image>. <code> We also added a comment to indicate the calculate weighted sum part. <image> <code> <image> Similarly, we have changed db_query_with_quiz_scores to calculate_quiz_scores <image>. <code> Also,there needs to be a method comment saying what the parameters are. We have added the method comments with parameter information as seen below. <image>. <code> We observed that encryption of request being sent to evaluate Algorithm and decryption of response is written in ( send_post_request ) only that is why send post is 91 lines long. We have created two separate methods ( encrypt_request ) ( decrypt_response ) In the image below we can see that we have separated Encryption functionality from ( send_post_request ) to ( encrypt_request ) <image> On the similar lines we have separated Decryption functionality from ( send_post_request ) to ( decrypt_response ) <image> ( encrypt_request ) has been refactored as follows <image> ( decrypt_response ) has been refactored as follows <image>. <image>. We changed the class variables in the code to instance variables because we realized that the send_post_request method and client method were the only methods using the class variables. A client.html.erb file was used to call our controller to fill out a form for send_post_request which set values of class variables then immediately redirected control to the client method which set the instance variables to those class variables. The instance variables were then used in the rest of the client.html.erb file. The process of setting class variables to instance variables with a function was redundant, so we removed simply set the instance variables within the send_post_request method and took them out of the client method. The client method did have a few actions that it completed besides setting class variables which we have left in the method until we can find a solution to replacing them. <image> Old client method <image> Newest client method The reason why we kept the client method's name is because the routes.rb file specifies the client method in the code and we haven't fully tracked down the impact of that yet. There was no existing tests available for the Reputation web service controller. Since we are refactoring it, Our testing plan is to have an automated testing to ensure that the refactoring such as splitting a method into separate methods does not affect the existing implementation. We also added steps for the manual testing to make sure the page loads as expected after the refactoring. For the automated testing, We are using Rspec tests. We have tested the two new methods created during refactoring and also a renamed method. The test coverage has increased a bit by 0.6% to 44%. The tests we created can also be manually run with command rspec spec/controllers/reputation_web_controller_spec.rb. <image>. The steps to test our branch are below, but they are failing right now due to errors that are in other files of the beta branch. To test our program you must login to the site here: <link> Username: instructor6 Password: password Then the page ""Manage content"" doesn't show up, go to Manage... -> Assignments <image> Then on the CSC 517, Fall 2017 Row, click on ""Add Participants"" in the actions column. This is also indicated by a blue shirted person. <image> Once in there, copy on of the student names (such as student7487) and then go to Manage... -> Impersonate User and enter their name (student7487) into the text field. <image> After impersonating them, you should be able to see their assignments. Click on any of their assignments such as ""Program 1"", then click on ""Alternate View"" to the right of ""Your Scores"". <image> <image>. reputation_web_service_controller.rb. reputation_web_service_controller_spec.rb. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link>.","The changes are for the most part clearly described.  When you say you ""refactored"" something ""as follows,"" you could also describe the changes you made; that would make it easier to follow.  But, the code is still clearer than a lot of code in the system.","Dear Student,

Thank you for completing your assignment on refactoring the 'reputation_web_service_controller.rb' file. 

Your work demonstrates an outstanding commitment to understanding the original code base, breaking down its complex components, and refactoring it to make it more manageable, understandable, and efficient. Your use of proper conventions when revising method names helped make the functionality more transparent. It was also good to see you implementing coding best practices by ensuring that each method only performs a single task.

The methodical explanation on why you changed class variables in the code to instance variables, which showed understanding of redundant processes, was well thought out. You have also taken data security seriously by moving a private key from an open-source code to the database.

Moreover, the creation of separate methods for encryption and decryption makes it more readable and adaptable for future edits. This is a significant improvement over the original formatting. The reworking of the 'client' method was handled adeptly, and you provided a sound explanation for why the method name was preserved.

It is commendable that you have not only conducted refactoring but also focused on testing by implementing both automated and manual testing plans. Nevertheless, it's critical that you resolve the errors that are causing the tests to fail.

You have provided detailed, well-explained screenshots and steps for testing, which would be highly beneficial for someone else looking to test the code. It would be a great addition, if possible, to link any resources or guides used to approach and complete this refactoring task. This way, you can assist other developers who may be doing a similar task in future.

Overall, I'm impressed with the quality of your work and the diligence you displayed in analyzing, refactoring, and testing the code. Please ensure that you continue to utilize the same level of attention and precision in your future assignments. 

Looking forward to seeing more of your work!

Best Regards,
[Your Name]"
426,E1778,"This page provides the documentation of the UI fixes for assignment creation in Expertiza. Expertiza allows the instructor to enable and disable different features to be used in an assignment. Some of these setting e.g., allow peer review to be done in iterations, allow third party to assess the quality of the peer feedback, can be changed from manage>assignment and click on edit icon. Some of the UI to enable and disable these features were broken and the aim of this project was to fix the following issues. The following issues were fixed in this project: 1. Issue <link> : While editing an assignment, changing the number of review rounds doesn't work in Expertiza. 2. Issue <link> : Once an assignment is duplicated from another assignment with metareview enabled, metareview deadline cannot be disabled. 1. Issue <link> : was already fixed before the start of this project. A working demo of the fixed issues can be found <link> . The changed code can be found in the pull request made <link> . The first two actions of enabling and disabling metareviews show the fixed issue #961. The action of reducing the rounds of reviews shows our fix to issue #972. The main problem as stated in the problem statement is that .last() does not exist for the array. This method was used to identify the last element in the array of elements. This was solved by identifying the last element as the (array.length - 1)th element of the array. The issue was the instructor was not able to change the rounds of reviews for an assignment. The reason for this issue was found to be the actual rounds of reviews was overridden by the maximum of submissions and review count in the database. This constraint was introduced to restrict the instructor from resetting the rounds of reviews lesser than the submissions count. The constraint was not necessary for some scenarios which should have allowed the instructor to reset. To solve this scenario, we introduced a warning message with a confirmation option to allow the instructor to override the rounds of reviews. After realizing the actual location of the code that was causing the bug, we realized that assuming the current rounds of reviews by the maximum amongst the submissions count, reviews count, and the rounds of reviews led to a scenario where even when the instructor wanted to update the rounds of reviews, he wasn't allowed to do so. This was a problem because, there would have been a certain situation where the instructor had to override the existing value because of a previous error (maybe even typographical). Thus, a confirmation message with a warning was the way to go. The problem was the need for metareview could not be disabled while editing an assignment. This was because the DueDate table was not updated with the necessary cascade actions. This issue was solved by implementing the cascade action manually in the update action in the assignment controller. After realizing that the issue was caused by the cascade action not being implemented, implementing it was the way to go. After the implementation in the update action of the Assignment controller, the instructor was able to update the metareview required or not checkbox. 1. Go to the edit action in the assignments controller. ( <link> 2. Click on the due dates tab. 3. Change number of rounds of reviews to a value less than 3. (At this stage, our fix would throw a confirmation message with a warning) 4. Upon pressing submit, the rounds of reviews will not be updated. (In our fix, the rounds of reviews will only change upon accepting the confirmation). 1. Go to the edit action in the assignments controller. ( <link> 2. Click on the due dates tab. 3. Uncheck the metareviews allowed checkbox. 4. Upon submission, the update will not be visible. (Our fix would allow this action and the update will be visible). 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link>.",Straight forward description. No automatic test was defined. Think of using selenium in the future. ,"Dear Student,

You've done an excellent job on this assignment. It's clear that you've understood and resolved the Expertiza software issues. Your explanations of the problems and your fixes for each are articulated well. I particularly appreciate the step-by-step breakdowns of the process involved in both instances and your explanation on the pages where the issue occurred. 

Despite your considerable strengths in understanding the problems and finding efficient solutions, there are a few areas that you should consider for future assignments:

1. In a document like this, which is filled with technical jargon and methodical explanations, it might also be beneficial to provide an overview or a brief summary for each issue and resolution in layman terms before diving into the technical details. This can help non-technical readers understand what you're talking about.

2. Secondly, this assignment would have benefitted from a bit of proofreading. I noticed some grammatical errors and awkward sentences that could be improved. Be sure to read over your work, or even better, have a peer review it. They'll spot things you might miss.

3. Lastly, your report lacks explainable links instead of just <link>. Make sure to replace it with actual URLs with a brief description for what to expect after clicking on the link. This would greatly enhance your documentation by making it easier to understand and follow.

Keep up the great work on your analytical and problem-solving skills. It is good to see your commitment and hard work reflected in the quality of your work. Keep practicing your reporting skills and you will surely make good progress.

Best Regards,
[Your Name]"
427,E1787,"This project involves revision of score calculation bug of Expertiza homework reviewing mechanism. Sometimes when a reviewee of a project or homework fills out the review form, he or she may leave certain review question blank. When taken into score calculation for the project or homework, the application instead fills in 0 on blank answers. This behavior is incorrect as the blank review answers should never be used when used to calculate final score. Issue - <image>. Solution - <image>. Git Original link 1. <link> Pull request link 1. <link> Git Revised link 1. <link>. The scores are not calculated on dividing with total reviews given, instead calculated using total non null reviews given. We implemented using the MVC (Model View Controller) pattern. We felt it was the pattern used in expertiza , usage of same pattern would be much easier. We have run unit test using RSpec and Carpybara. The test file path is spec/models/vm_question_response_row_spec.rb. For the test, we have identified 2 scenarios. First one is regarding correctness on average score calculation, where we will create a VmQuestionResponseRow object with sample test scores inside and call its average_score_for_row method, then we match returned average to the expected average (vm_q1 object); Second one is regarding whether average score calculation includes nil values, where we will create a VmQuestionResponseRow object with one or more nil sample test scores inside and call its average_score_for_row method, then we match returned average to the expected average to check if nil is redefined and used in score calculation (vm_q2 object). In addition, we have also tested the initialization of VmQuestionResponseRow object with 5 parameters and 6 parameters to ensure the initialization process works as intended (see in code for vm_q1 and vm_q3 objects). However, due to decrease in coverage for the test (after we added it, the coverage dropped by 0.4%), we have reverted it back to original 2 test cases. The additional test cases can be found below in snapshots, and original test cases with highest coverage in on github. test file: vm_question_response_rows_spec.rb;. For the OSS project, the topic is fixing and modification on Expertize team score calculation mechanism. For this project, a meeting once every week for 2 weeks with TA was proceeded. The main focus for the first one and half week involves setting up the environment on the machine. Some of notable issues on setting up include theRubyRacer dependency problem on project, Node packages not recognized by rails (Windows), Font-Awesome-Rails path issues, etc, which were solved through file tracing, problem identifying, and debugging. For the rest of these a little over 2 weeks period, several issues were identified with the project. The main issue for program include the false score calculation mechanism by expertiza where empty scores are assumed automatically to 0 and included in calculation; this would in turn give a false score calculation result as empty scores are not supposed to be set to 0 and then included in for calculation. Through debugging and defining the problem, it was identified that the reason for such issue involves average_score_for_row method in vm_question_response_row.rb in model as shown below in red - where the row_average_score dividend was not been used correctly. Comparison of code changes can be seen in Pull request. The issue can be solved by modify the calculation for dividend using a counter to exclude nil values and modified the constructor for VmQuestionResponseRow classs that it can dynamically accept 5 or 6 parameters, as shown below (note: not_null_reviews.zero? check are used two times in order to pass the github check on coding, as combining these two lines into one (row_average_score = (row_average_score / not_null_reviews).round(2) unless not_null_reviews.zero?) would resulting in failing on github check, while the other solution which is putting both line into an unless block would not have any benefit execution efficiency wise). Code after first modification - <image> <link> Code after second modification - <image> <link> The first modification was done as it fix the issue while keep code at its most simplicity; (As shown in screen shot) The second modification was done to accommodate the scenario where an extra parameter - score row - is needed during object initialization process. It would be a more efficient constructor to use when retrieving scores from database as it allows program to initialize a VmQuestionResponseRow object now with a list of AssignmentScore objects instead of having to initialize to an empty list and putting in AssignmentScore objects one by one through a loop. (Note: the implementation for using constructor with extra parameter in project is not implemented as it is originally not part of our requirement). Afterward, several tests were performed for the model class modifications using RSpec, with some of the code as shown below: <image> <image> <image> For this project, techniques such as Unit testing, constructor overloading, and technologies such as bower, carpybara, RSpec, etc, were used.","The prose description of the changes could be more readable.
The section on tests does not describe the rationale for the tests, but just displays the code.","Dear student, 

Thank you for your submission and the effort you've put into this project. You clearly demonstrated understanding of critical software development concepts including MVC pattern, debugging, code review, and unit testing using RSpec and Carpybara.

You clearly described the particular issue you encountered with Expertiza's homework reviewing mechanism, and your proposed solution comes across as both methodical and effective. Your rationale for using the MVC pattern becomes clear when reading through your documentation and the effort you took towards keeping things consistent.

Your approach for setting up your testing scenarios seems reasonable and well thought out. Good job identifying the relevant test cases and thoroughly explaining their significance. Perhaps next time, you could provide some actual examples of the tests you ran, including any pertinent edge cases and how these were addressed.

Your explanation of the changes and enhancements you made to the code is quite detailed. However, you could further improve your documentation by providing actual code snippets to give a comprehensive picture of what was done. This would have made it easier to follow your thought process and understand the specifics of your implementation.

In terms of formatting, your submission could benefit from better organization. The information seems somewhat jumbled and a bit difficult to follow at times. Try to structure your text better and consider breaking down your paragraphs. This will help improve readability and ensure that your main points are clearly understood.

Finally, it's commendable on how meticulous you were in your work, especially when it comes to debugging and fixing bugs you encountered. Social skills such as collaborative problem-solving (as evident in your interactions with the TA) will prove valuable in your future endeavors.

Overall, well done on this project. Keep up the great work, and continue seeking out and addressing challenges just as you did here.

Best,

[Your Name]"
428,E2063,"This page provides a description of the Expertiza based OSS project. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.6. <link> 1.1.1.1. <link> 1.1.7. <link> 1.1.1.1. <link> 1.1.8. <link> 1.1.9. <link> 1.1.10. <link>. <link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. The tree-display.js and its tree_display_controller.rb files are designed to allow Expertiza users to view their Assignments, Courses and Questionnaires at one place. This is the primary control page, as well as the home page for instructors on Expertiza which allows them to create, modify, delete and view Assignments. The primary problem with this is that both the files, due to their bulky and unoptimized methods, slow the rendering of UI on screen. The methods in these files can be studied and refactored to improve the overall performance of this controller and its corresponding UI. Moreover, any obsolete or unused methods can be removed and DRY principle should be implemented. This project mostly revolves around these 2 files, and would involve refactoring JavaScript more than Ruby on Rails. Knowledge of JavaScript is a prerequisite for this project. The following tasks were accomplished in this project: 1. Removed methods that were not used 2. Modified tree display controller to better parse data prior to being accessed by the react client 3. Fixed beta branch issue with showing dropdowns for courses and questionnaires. 4. Fixed beta branch issue with showing edit option for courses and assignments. This class manages different the different tabs: courses, assignments, and questionaires. 1. Instructors can view the course, assignment and questionnaire tabs. Instructors can select rows for questionnaire's and courses to view a dropdown of more information. For course rows, they have options to edit, delete, copy, add TA, create an assignment, create teams, view grades, assign surveys, and view reviews. For assignments, they can edit, delete, copy, assign to course, create teams, assign reviewers, view submissions, view scores, view reports, and view survey responses. 1. Problem 1 : The dropdown doesn't work for assignments and questionaires. This is due to the handleExpandClick function, as it appears that the get_sub_folder_contents method is not capable of returning the data. <code> 1. Solution : Change the the JQuery route to a post because you can't give parameters to a get route and also change this in routes.rb file. <code> <code> 1. Problem 2 : Tree display controller needs to better parse the data prior to being access to the react client because currently, there are too many comparisons when checking for the type of tab. Example: <code> 1. Solution : Centralize the attributes of each tab so that the tree_display doesn't need to keep parsing between the tabs. 1. Problem 3 : The Assignments and Courses tab isn't showing the edit option for each row. It seems that what's implemented is trying to verify that there was an active user and the active user is null. <code> 1. Solution : Remove the active user implementation and replace with a check to make sure the current tab isn't Questionnaire. <code> 1. Drawback :The assignments tab did not have any data when we used the reset debugging extension (i.e. the childNodes attribute was null). Thus we assumed there was no data to display underneath each assignment. -After debugging, we found that the ""nodeType"" attribute in the :reactParams field of the post request identifies the type of childNodes to be retrieved (i.e. ""Courses"" or ""Questionnaires"") -We found that a ""FolderNode"" value for this attribute equates to a questionnaire. A lot of the efforts in pushing objects into moreContent could be consolidated into a central format. An example of how its currently implemented for courses is: <code> With a centralized implementation, we consolidated this information into const node_attribute. (See code repository for implementations for questionnaire and assignments, Course only shown for simplicity of demonstrating implementation). <code> With this new implementation to obtain these actions, we just use the getActions function. Additionally now call the is{Tab} to receive the name of the tab. <code>. Unused Methods and Functions were commented out 1. Example 1 : <code> 1. Example 2 : The assignments tab did not have any data when we used the reset debugging extension (i.e. the childNodes attribute was null). Thus we assumed there was no data to display underneath each assignment <code>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. Clean Code: A handbook of agile software craftsmanship. Author: Robert C Martin.","tree_display_controller is used to display hierarchical items, such as assignments in different courses, or different kinds of questionnaires.  For Problem 2, no solution code is shown.  I found the solution of Problem 3 to be described confusingly.  You say, ""Unused methods and functions were commented out.""  Do you mean that you commented them out, or that you removed methods that had been commented out?  Examples 1 and 2 of code improvement don't show what was improved.  The testing sections are empty.","Dear Student,

This assignment is a comprehensive analysis of a complex software project. Your work on refactoring the JavaScript files for better optimization is very commendable. You have described the primary issues well and have proposed concrete solutions to improve the overall performance of the Expertiza application. 

Moreover, your active identification and elimination of unused code are impressive. I appreciate your strategic approach to problem-solving; you did not just identify problems, but you also provided logical, clearly explained solutions - this will be exponentially valuable in your future coding endeavors.

For future projects, it does help to provide straightforward titles for the different sections of your document; this makes it easier for other individuals to understand and locate the information in your writing. Along with focusing on the technical side, the presentation of your work is also important. Your current format can be a little difficult to follow at times.

Further, the sudden mention of the class and its functions towards the end of your analysis with no prior build-up can be confusing. It might be helpful to improve the assignment's flow if you introduce each component in sequence or have a structure that builds upon each point. This way, your readers will be able to follow your logical flow effortlessly and understand your process, as well as your results. Remember, always imagine that someone without context of your work is reading your assignment - you want to make sure they can comprehend it.

I want to express my admiration for how greatly you have delved into the Expertiza source code and taken on the task of improving it. Your dedication, in-depth understanding, and execution are seen and applauded. I hope to see more of your exceptional work in future projects.

Keep up the good work!

Regards,
Your Instructor"
429,E1949,"This page is a description of Expertiza OSS project E.1949 Write Unit Tests for Importing assignment participants and import glitches. Expertiza is a web application where students can submit and peer-review learning objects (articles, code, web sites, etc). It is used in select courses at NC State and by professors at several other colleges and universities. The import feature is the most helpful feature for instructors to set up assignments. The instructors usually have a list of students, teams, etc from their learning management system. Being able to import these into expertiza saves a lot of time when setting up an assignment. 1. Importing participants redirects to a confirmation screen listing the users that are going to be imported but the users do not seem to be imported. 2. This is an intermittent issue that can be addressed through a test case. We looked into the files responsible for importing assignment participants. The imported file goes through the following process. 1. Add one line to expect that #create_new_user method in import_file_helper is NOT called in each test case that the user HAS an account, and do the opposite in case the user DOES NOT HAVE an account. <code>. 1. Thoroughly test the #import method in the sign_up_topic model. This includes the following test cases: 1. The record is empty 2. The record is not empty and the topic is not existing, including special cases 3. The record is not empty and the topic is existing, including special cases <code>. 1. Thoroughly test the #import method in the team model. This includes the following test cases: 1. Duplicates exist. Ignore the new team. 2. Duplicates exist. Replace the existing team with the new team. 3. Duplicates exist. Insert any new members to the existing team. 4. Duplicates exist. Rename the new team and import. 5. Duplicates exist. Rename the existing team and import. <code> <code>. 1. To view the testing vedio, please click the link upon. 1. This video shows the complete test process of the CSC/ECE 517-E1949 task 1, 2 and 3 using RubyMine, all tasks have been tested successfully. The modification of testing code and testing result of each task can also be found in the Test Plan section and Result section above respectively. 1. All tests passed successfully except for the part 2 of task 3. The fail of part 2 is as expected and the reason part 2 of task 3 failed is explained in Result part above. More details please see Result in Part 2: Reason for building failing in the Result Section. 1. All test passed. <image>. 1. All test passed. <image>. 1. Part1: All test passed. <image> 1. Part2: Reason for build failing: One of our tasks is to add a test for a function that does not exist yet, namely to rename the existing team when there is import conflict. Therefore, as per test-driven development practice, the test will always fail until the function is correctly implemented. <image>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.","If you used snippets from Github instead of typing the code into Mediawiki textboxes, you could more clearly show what has been changed.  That is not clear from the code you provided.
Tests could have been described more completely, e.g., Why is this test necessary? What does it test? How does it test it?
In general, most of the document is just a listing of code.  Saying more about why you made the changes you did would have been helpful.
They have uploaded a video that shows testing on their development environment and that cleary shows their contribution","Dear Student,

I appreciate your endeavor to document each and every step you took to carry out this assignment. The sequence of procedures explained in your work is clear and understandable. Your team has done an excellent job in terms of adding and testing different scenarios for importing assignment participants in the Expertiza application. You’ve also effectively explained the process when the import feature encounters certain conditions such as non-existent users, and duplicate teams.

Having said that, I would suggest organizing the project document a little better. The sectioning and numbering of the steps you have listed seem muddled in some parts. For instance, there are multiple parts labeled '1'. Proper numbering and sectioning can result in better representation of your work progression and conclusions.

Also, I am unable to view the images and testing videos you mention in the description. If they are meant to be there, please ensure they are visible or linked appropriately. If they are placeholders, remember to replace them with relevant diagrams, snapshots, or links before final submission.

About the failed test case in Task 3 Part 2, it's good that you followed test-driven development practices. This shows a thorough understanding and application of unit testing and its principles. Make sure to note this as a pending task or future improvement aspect in your report so that this function can be implemented in the subsequent development steps.

Overall, the assignment shows excellent grasp over unit test creation and the understanding of Expertiza OSS Project requirements. Good job! Keep it up!

Best,
[Your Name]"
430,E1460,"Expertiza is a web application developed using Ruby on Rails that serves as a peer-review system. The application allows students to submit and peer-review learning objects (articles, code, web sites, etc)<ref> <link> </ref><ref> <link> </ref>. It is an open source project and it's codebase is maintained in GitHub. We are contributing to Expertiza as a part of our Object-Oriented Design and Development's Open-Source Software (OSS) Project. Our goal in this project is to refactor the StudentQuiz controller . In this Wiki Page, we would be explaining the changes that we have made for the same. Contents 1.1. <link> 1.2. <link> 1.3. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.1.4. <link> 1.1.1.5. <link> 1.1.1.6. <link> 1.1.1.7. <link> 1.1.1.8. <link> 1.1.1.9. <link> 1.1.7. <link> 1.1.8. <link> 1.4. <link>. The StudentQuiz controller consists of methods involved in creating, scoring & recording responses of the quizzes taken by reviewers or students of the other teams with the same topic. The changes that are needed to be done are described as follows:<ref> <link> </ref> 1. Pluralize the class. (StudentQuizzesController) 2. Rename methods to conform to RESTful style. (e.g. :- Rename the list method to index.) 3. Reduce the number of instance variables per controller action. 4. Review Method graded? for boolean zen. 5. Perform Code cleanup by removing unused code. 6. Use good Ruby style guidelines in the code. 7. Split a method performing multiple tasks, into seperate methods. 8. Fix logical errors in the code. <references/>.",Very detailed writeup; every line that was changed is explained.,"The instructor's feedback:

Dear Student,

Well done on your assignment on Expertiza, a Ruby on Rails web application. The introductory section provides good background details about the application and the role this project plays in your ongoing learning.

Despite yielding high-order contextual information, the section potentially lacks one or two core details. Please discuss the purpose of Expertiza and how your efforts to refactor the StudentQuiz controller contribute to this goal. Your readers may gain a better understanding of the importance and implications of your project through this.

Your table of contents seems to be composed of links that don't offer much insight or context into what each section might contain. Make sure your titles are descriptive to help guide readers through your work.

The task list is concise and clear about the specific refinements you intend to make. Providing a brief reason why each change is necessary in the context of your project could offer more depth, though. For example, why is it beneficial to pluralize the class or to rename methods to conform to a RESTful style? Sharing this information can assist others in understanding the logic behind your decisions.

While you have done well in providing a clear overview of the changes that will be made, I advise you to include a brief summary of the potential challenges you anticipate experiencing in this process. This may provide you with an opportunity to propose possible solutions or ask for assistance in areas where you might need it.

You did a good job of presenting your work. However, be aware that links need to go somewhere for an assignment to be most effective and helpful. Links currently represented as ""<link>"" should be updated to actual, relevant URLs to improve your work's usefulness, credibility, and overall professionalism.

Keep pushing yourself, and I'm looking forward to seeing your final project.

Best, [Your Name]"
431,E1510,"Currently when an Instructor logs into Expertiza,there are a lot of select* from assignments queries being fired on database which would have an adverse effect on performance. We analyzed the source of this issue and made some changes, which reduced the number of select queries executed. The performance is high improved. The mission involved is tracing the source of the issue and modify the code to fix the issue. Before the improvement is achieved, each time an instructor logs into Expertiza, there would be several database queries, which are more than needed and take more time to render the view. Below is the console outputs when an instructor logs in. <image> There are 7 assignment queries after load _row_header.html.erb , 3 assignment queries after load _shared_actions.html.erb , and 3 assignment queries after load _assignments_actions . All of these queries are same. These duplicate queries have an adverse effect on the performance. To locate the files that generate the duplication of queries, we use a Gem called QueryReviewer<ref> <link> </ref> to help trace the datebase queries. QueryReviewer is an advanced SQL query analyzer<ref> <link> </ref>. It accomplishes the following goals: 1. View all EXPLAIN output for all SELECT queries to generate a page 2. Rate a page's SQL usage into one of three categories: OK, WARNING, CRITICAL 3. Attach meaningful warnings to individual queries, and collections of queries 4. Display interactive summary on page. Installing query_reviewer is simple. All you have to do to install it into your Rails 2 or 3 project is <code> Right now if you use bundler, simply add this to your Gemfile : <code> or to use the latest from github: <code> After installing and running this Gem on the Rails application, it would pop-up database query information on the webpage, as is shown below. <image> We can follow the trace and locate the source of the issue in assignment_node.rb , also the source code in _assignment_action.html.erb. We log into Expertiza as an instructor with the QueryReviewer activate and watch the output of QueryReviewer. The above figure shows the tracing result of the QueryReviewer and it tells us that we should pay more attention to the three files: assignment_node.rb, _row_header.html.erb and _entry.html.erb. In file <link> , we can find in 3 places use Assignment.find(node.node_object_id) , which is actually a database query request. <code>. In <link> : <code> we can see in this view, parent_node is a AssignmentNode object, it execute: 1. parent_node.get_name method 2. parent_node.get_directory method 3. parent_node.get_creation_date method 4. parent_node.get_modified_date method However, in <link> : <code> We find all these method called Assignment.find(self.node_object_id) method, which is actually a database query request. These 'find's are actually redundant for a specific Assignment instance. So we will figure out a way to eliminate those redundant method calls. An instance variable @assignment is used here instead of multiple times of calling .find method, thus reducing database queries. <code>. In this class, we define a new variable @assign_node , and in every get_ method, instead of using Assignment.find(self.node_object_id) to find the AssignmentNode object, we first search if @assign_node variable exist, if not, we define @assign_node = Assignment.find(self.node_object_id) , else we directly use @assign_node . Because _row_header.html.erb file uses many get_ method, after modification, the number of assignment queries decreases much. <code>. 1. Originally there are 13 queries after loading these related pages, and now there are only 5 of them. As shown below. 2. The time consumed for rendering the view is 943 sec before and 284 after the modification. We can see the performance has been highly improved. If we have a larger database, the improvement would be more significant. <image>. Before our modification, when an instructor open the expertiza website and log in, it takes much time to show the page after log in, especially when a larger database hiding behind. We saw the problem on the console windows which emerged as a duplication of unnecessary queries. After our modification, the duplication disappeared and the time consumption is reduced significantly. Now when an instructor log in expertiza, it takes shorter time to get to page after log in. Please check our new version of <link> on github. <references/>.","Describes the changes made very well.
The prose is quite readable.  Code has been added to explain what was not elaborated in the ticket.  However, to be helpful for people doing followup projects, the writeup should've explained hurdles that were encountered and how they might be able to be overcome.  There should be a summary at the end of the report.","This is very detailed and thorough work, demonstrating a clear understanding of the problem as well as good debugging and problem-solving skills. Your use of QueryReviewer to identify the source of the problem, and your successful efforts to reduce unnecessary queries with the use of instance variables, are very impressive. 

Your report is clear, well-structured and includes sufficient detail, allowing a reader to follow your diagnostic process and understand your solution. The inclusion of visual aids and code snippets further aid comprehension. 

I would suggest that next time, you pay a bit attention to the explanation of how exactly the implemented changes impact the performance. Keep in mind that not every reader may be familiar with the specifics of Ruby on Rails or SQL queries, so your explanation might need further elaboration. 

Also, consider outlining potential drawbacks or limitations of your solution, if any. Lastly, it would be great if you discuss more about potential future work or improvements that can build on this effort.

Nonetheless, this assignment shows high-quality work. Keep up the good work!"
432,E1839,"This wiki page is the description of the E1839 OSS Writeup Project - Review Requirements and Thresholds - for Fall 2018, CSC/ECE 517. <link> is an open source project based on <link> framework. The Expertiza project is a software that creates reusable learning objects through peer review. It is a web application where students can submit and peer-review learning objects (articles, code, websites, etc). It is used in some courses at NC State University and by professors at several other universities. It supports team projects, and the submission of almost any document type, including URLs and wiki pages. Expertiza enables the instructor to create new and customize existing assignments. It also enables the instructor to create a list of topics the students can sign up for as part of a project. Students can form teams in Expertiza to work on various projects and assignments. Expertiza supports submission across various document types, including the URLs and wiki pages. In Expertiza, there are two ways of assigning reviews to reviewers: 1. Instructor-selected: The instructor decides who reviews whom. 2. Auto-selected: Case reviews are not assigned until a student seeks to choose something to review. This section is mostly about auto-selected reviewing. A reviewer is ordinarily allowed to choose only among work that has received the minimum number of reviews so far. For example, if all submissions have received at least one review, the next person who tries to review is allowed to choose only a submission that has only one review so far, unless there are no more such submissions, in which case the reviewer chooses from among submissions that have 2 reviews (if there are any), or the minimum number of reviews, whatever that is. For assignments that have topics, this severely constrains a reviewer’s choice of what topic to review on. (For assignments that don’t have topics, a reviewer doesn’t have anything to choose; (s)he just gets one of the submissions that have the fewest reviews so far.) To allow reviewers a larger set of topics to choose from, the instructor can set the threshold (on the Review Strategy tab of assignment creation/editing) to some integer k > 0. Then any submission that has within k reviews of the fewest number can be chosen by a new reviewer. Let’s say that all submissions have at least 1 review. If k = 3, then the reviewer can choose any topic where there is a submission that has 4 or fewer reviews so far. There's another issue. Suppose that the minimum number of reviews for any submission is 2, but that the person has reviewed all the submissions that have only 2 reviews. Then they are not allowed to review at all (unless k > 0). That’s wrong; they should always be allowed to review the work with the least reviews that I have not already reviewed. And that should generalize to situations in which k > 0. Another issue is that there is no way for Expertiza to tell a reviewer how many reviews are required. In the case of instructor-selected reviewing, that’s not a problem, but for auto-selected reviewing, there is no way to specify how many reviews are required (or even how many are allowed, in case students are allowed to do extra reviews). Issue #402 : To allow reviewers a larger set of topics to choose from, the instructor can set the threshold (on the Review Strategy tab of assignment creation/editing) to some integer k > 0. Then any submission that has within k reviews of the fewest number can be chosen by a new reviewer. Let’s say that all submissions have at least 1 review. If k = 3, then the reviewer can choose any topic where there is a submission that has 4 or fewer reviews so far. Suppose that the minimum number of reviews for any submission is 2, but that I have reviewed all the submissions that have only 2 reviews. Then I’m not allowed to review at all (unless k > 0). 1. Solution : This issue has been fixed previously. The reviewer will get assigned a submission even if it has fulfilled the required number of reviews, to ensure that the reviewer always receives a new submission to review as long as it is not his own. Issue #228 : To Allow a reviewer who has already reviewed all submissions that have the minimum number of reviews m to review any submission that has ≤ m+k reviews. 1. Solution : This issue is similar to issue 402 and has been already fixed. If the student has already reviewed the least number of reviewed assignment, then he/she will get the next least reviewed assignment. Refer to expertiza/app/models/review_assignment.rb file A combined explanation of issue 402 and 228 has been discussed below with the help of existing code. <code> This snippet of code will do the following features: 1. Return nil if the array of choices of review is empty 2. Reject contributors that have not selected a topic, or have no submissions 3. Reject contributions of topics whose deadline has passed, or which are not reviewable in the current stage 4. Filter submissions already reviewed by a reviewer 5. Filter the contributors with the least number of reviews 6. If this assignment does not allow the reviewer to review other artifacts on the same topic, remove those teams 7. Add topics for all remaining submissions to a list of available topics for review Issue #417 : Implement a num_reviews_required (and num_reviews_allowed) field in the assignments table to say how many reviews per reviewer are required, and how many are allowed (default should be # allowed = # required.). Make it settable from the Review Strategy tab and viewable when a student clicks on “Others’ work”. Do the same for meta-reviews (“reviews of reviews”), which students can also be assigned to do for an Expertiza assignment. 1. Solution : This issue has been resolved by adding the following piece of code in the file /expertiza/app/views/student_review/list.html.erb <code>. Issue #402 and Issue # 228 : This is shown graphically with dummy topics and assignment. We create a dummy assignment with two different topics oss1 and oss2. oss1 has 2 slots and oss2 has 1 slot. So when a student who has submitted oss2 tries to review others work he will not be able to select oos2 at all because he cannot review his own submission. When a person who has oss1 as the topic goes to this page and he asks to get a new submission for review it will give another slot’s oss1. If he does it again it says there are no more submissions available to review for this topic. So if he has already reviewed all the other submissions of his topic oss1 and he requests for one more submission of oss1, he will not get any more submission to review because the only one left is his own submission. Issue #417 : We have added the reviews and meta-reviews left option. It can be demonstrated from the image below. Here is the preview of the old information. <image> In the below diagram, we can see the updated information about the number of reviews left. <image> Improved UI and Ruby Code practices 1. a. The two statements ""Set Allowed Number of Reviews per reviewer"" and ""Set Required Number of Reviews per reviewer."" are not well differentiated. It can be very confusing for an instructor to give values to them. Solution : Information buttons have been provided beside these statements in the review strategy tab to make sure that the instructor knows the difference between the two. 1. b) When the number of allowed or required reviews are not set on the Review Strategy tab, the system does not have a message to display to a reviewer about how many submissions of work they are required to and allowed to review depending on the values set by the instructor in the ""allowed number of reviewers per reviewer"" field and the ""Set Required Number of Reviews per reviewer."" field. Solution : Added a toggle hidden option to show the options only when we are setting the max reviews and meta-reviews limit. 1. c)The capitalization and punctuation of statements such as ""Set Allowed Number of Reviews per reviewer"" and ""Set Required Number of Reviews per reviewer."" in review strategy tab are incorrect. Solution : This view has been fixed by making changes in the respective files. All these modifications are made in the app/views/assignments/edit/_review_strategy.html.erb Here is the snippet of the old layout with lack of info icon. <image> The updated image has been demonstrated below. <image>. There are two versions of this project. They are: 1. <link> 2. <link>. The project is implemented in Ruby on Rails that uses MVC architecture. It separates an application’s data model, user interface, and control logic into three distinct components (model, view and controller, respectively). We are trying to reuse the existing functionalities in Expertiza, thus avoiding code duplication. Whenever possible, code modification based on the existing classes, controllers, or tables will be done instead of creating the new one. 1. <link> 2. <link> 3. <link> 4. <link> 5. Clean Code: A handbook of agile software craftsmanship. Author: Robert C Martin.",This design doc consists mostly of excerpts from the project requirements and the code.  The description of Issues 402 and 228 just collects together the comments from the code.  The text describing what was done to fix Issue 417 is at the end of the test plan!,"Thank you for your thorough and detailed assignment. Your research and explanation about the Expertiza project is impressive and informative. The examples and issues you provided create a clear understanding of how the project works.

As for your code analysis, it's great that you explained the purpose of the code snippet and how it impacts the project. However, it would have been more useful if you provided the exact code snippet alongside its explanation, instead of just mentioning ""<code>.""

Your analysis of the issues and solutions is excellent, especially with regards to how the issue was resolved and the impact it had. It would have been more helpful if you provided specific datasets or examples to illustrate these issues and solutions.

It's nice to see that you’ve taken the time to identify UI issues and propose solutions. The use of images to showcase changes is a commendable approach. It might be more effective to include these images directly in your write-up, rather than referring to them as ""<image>.""

The way you describe code practice improvements suggests a deeper understanding of not only the project, but also of how to implement better code. You demonstrate an excellent grasp of MVC architecture, which shows that you're capable of critical analysis.

The ""Clean Code: A handbook of agile software craftsmanship"" reference at the end of your work is a bit misplaced. It would be more effective if references were scattered throughout your paper where appropriate, instead of being listed at the end without clear connection to the content of your work.

Keep up the good work and continue refining your ability to articulate complex concepts clearly."
433,E1467,"Project name: <link> <ref> <link> </ref> Our project is to refactor the code in the ""Leaderboard"" functionality of the web application <link> <ref> <link> </ref>. The Expertiza project is a system to create reusable learning objects through peer review. The leaderboard functionality is to show top 3 individual scorers in each questionnaire type ( ReviewQuestionnaire , AuthorFeedbackQuestionnaire , MetareviewQuestionnaire and TeammateReviewQuestionnaire ), in each course of the logged-in user. The leaderboard also shows the current standing of the logged in user under personal achievements. <image> <table> Contents 1.1. <link> 1.2. <link> 1.3. <link> 1.4. <link> 1.5. <link> 1.6. <link> 1.7. <link> 1.8. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.9. <link> 1.10. <link>. Classes involved: leaderboard.rb and associated other model and controllers classes. 1. Come up with an efficient way to search for participants based on assignment ids. 2. Refactor score hash for personal achievements. (method: extractPersonalAchievements ). Seperate out method which will rank individual personal achievements. 3. Refactor addEntryToCSHash according to your new metric method. 4. Seperate out computation of CS entries(metric) and refactor it to be more modular and elegant. 5. Refactor getParticipantEntriesInAssignmentList method. Its very complex (Complexity=142) . 6. Refactor addEntryToCSHash according to your new metric method. Leaderboard.rb class gets all the assignments within all the courses taken by currently logged in user. It also fetches any independent assignments (not associated with any course), that the user has taken. Then, it fetches all the participants who have participated in the computed list of assignments and aggregates their scores based on the questionnaire type. Several questionnaire type is associated with a single assignment. e.g. Direwolf application has - Review Questionnaire , Author Feedback Questionnaire and Teammate Review Questionnaire . Leaderboard model has following 3 important methods: <table>. In the OSS project, we have refactored these methods along with other smaller methods in Leaderboard.rb , Leaderboard_helper.rb , Leaderboard_controller.rb and associated views files. We have also refactored ambiguous variable and method names. We have keenly focussed in reducing the database calls, loops and redundant storage and computation. We have refactored many files related to Leaderboard implementation leading to reduction in overall complexity of the feature. Also, there was a requirement in the project, that we should come up with an efficient way to search for participants based on assignment ids. However, upon investigation, we found that scores stored in table ScoreCache, gives us revieweeId which is either participantId or teamId. Therefore, we have a method getAssignmentMapping , which creates a mapping of participant and team with corresponding assignment. This is very useful while computing leaderboard. Changes made in the methods of model leaderboard.rb <table>. Changes made in methods of Helper leaderboard_helper.rb <table> There are several other changes in the views and controller which deal with renaming of the methods and variables, adding proper comments etc and minor code refactoring. Please refer to our forked github repository to view those changes. Leaderboard is a separate implementation which includes reading existing scores for the sole purpose of creating the leaders in different categories. As the task is more related to calculate and manipulate data, it was not feasible to implement any design pattern. We reduced the complexity and redundancy of database calls by reducing database calls from 625 to 111 to do the same task. On VCL session there are 2 instances running. On port 3001 the original instance is setup and on port 3000 the refactored instance is setup. Login by any user and navigate to Home > Leaderboard to test the functionality. In below images we have shown that the output after refactoring is same. We changed the order in which the output is displayed to make it more coherent. Note for testing : It is recommended that in order to test the leaderboard functionality by any user who has participated in several assignments, some of them which is associated with any course and there are other existing users who have participated in the same assignment. <link> <table>. The refactoring process included reducing the database calls, loops and redundant storage and computation in all classes associated with Lleaderboard functionality. While refactoring, the team has ensured to improve the readability of the code too by renaming ambiguous method and variable names and adding relevant comments to explain the objective of a code construct. In the project description code complexity has been highlighted for several methods. <link> <ref> <link> </ref> has been used to measure the code complexity of the current repository of Expertiza. After refactoring, we used the same tool i.e. Code Climate to measure the code complexity. Following is the snapshot of code complexity of Leaderboard.rb from Code Climate. <table> The report shows that all the 3 methods to be refactored have improved code complexity by over 50%. Following is the overall improvement report by Code Climate. <image>. We computed the number of data base ""SELECT"" call generated by the database driver by filtering the messages from the rails server's log. In the original code there were 625 database select access generated for the leaderboard view. In the new refactored code the number of select calls dropped to 111 . Shown below is the number of select calls generated per table. <table>. Google Chrome extension <link> <ref> <link> </ref> gives time to load a page. We tried this extension to measure performance change after refactoring. We noticed that the time to load page reduced by almost 15% . This table indicates time to load page in seconds <table>. Based on use case and requirement, we can implement a metric to calculate final scores based on weights of an assignment or a questionnaire type. However, it solely depends on the the requirement whether such logic should be implemented in the Leaderboard model or the Score computation model. The team recommends that such manipulation and calculation of scores should not be part of Leaderboard model. Leaderboard model should focus on determining the eligible participants and compute the final leaderboard list. <references/>.","Good writeup, though not as detailed as some","Dear Student, 

I want to commend you for your thoroughness and attention to detail in explaining your refactoring project for the Expertiza application's leaderboard functionality. 

The explanation of the current system, requirements, refactoring process, and improvements made shows deep knowledge and understanding of the codebase and refactoring principles. Your attention to reducing database calls, loops, redundant storage, and computation shows that you are aware of effective coding principles. 

Your report contains a good balance of descriptions and technical details. The use of tables to provide deeper insights into your changes is also appropriated. I also appreciate your observance of readability and maintainability of your code by renaming ambiguous method and variable names as well as providing relevant comments to the codes.

Furthermore, your assessment on the improvement on the project is valuable. The Code Climate tool was a good choice in determining the decrease in complexity of your methods. It would be interesting to see data on how much each refactoring technique contributed to the overall effect.

Your suggestions on improvements to be made based on use-case and requirement analysis indicates a good understanding of how the system can be further improved. Keep this in mind as it is important insight to take forward in your software engineering knowledge.

For future assignments, I would suggest that you think about more user-centric performance improvements. Whilst database calls and code complexity are important, optimizing for a more responsive and effective user experience is a great benefit for the end-user.

In overall, your work is praiseworthy.  The clarity, organization, and technical skills demonstrated, as well as the significant performance improvements achieved in this project are commendable.

Good work! 

Best,
[Your Name]"
434,E17A6.1,"Expertiza <link> is a project developed using Ruby on Rails <link> . It provides features like peer review, team assignments and submission of projects. This can be achieved by submitting code base, URL of hosted code on remote server and Wiki submissions. It is an open source application and the code can be cloned from GitHub <link> . This application provides an efficient way to manage assignments, grades and reviews. This makes the process easier and faster when the class strength is large. Expertiza provide the function for user to request an account, but the function is not perfect. The goal of our project is to improve this feature. It will enable Expertiza to handle the pending request for super-admin and add institution for user. 1. Currently, a new user can only choose institution from the dropdown. The new user should be able to add a new institution. 2. A place where a new user to write a brief introduction is needed in this page. 3. Also, in models/requested_user.rb, there are some validations, such as validate email address. It will be better to update the flash message on the view when validation fails. 1. Currently, you have to go to /users/list_pending_requested this url to access a list of pending requests. It will be better to add an option in “Administration > Show…” menu 2. Make “Email Address” column in /users/list_pending_requested page clickable. So that super-admin or admin could converse with requesters by clicking email addresses directly. 1. After super-admin or admin approves the request, make sure the record does not disappear on the page. And there should be an email send to email address offered by requester. 1. Modify the test of request new user method. 2. Add a new option for the drop-down bar of institution in the new user request page. 3. Add a new textarea in the new user request page, to input a new institution and introduction. 4. Add validation for new institution new institutions and introductions. 5. Add flash message for requested_user.rb. 6. Add a new button on the layout. 7. Modify the layout of /users/list_pending_requested page. 8. Enable the system will send an email after the request is processed. <image> 1. The above tables is the original table for this project, however it lacks a column for introduction. So we need to add a new column for request_user table. The new table will be shown below. <image>. <image> <image> 1. Name: Instructor or Teaching Assistant request a new account 2. Actor: Instructor or Teaching Assistant 3. Other Participants: None 4. Precondition: None 5. Primary Sequence: 1. Click on “Request account”. 2. Select a role. 3. Fill in a user name. 4. Fill in a full name. 5. Fill in an email address. 6. Select an institution. 7. Fill in the introduction field. 8. Click on “Request”. 1. Alternative Flow: 1. If the institution not in the list, click on “Others”. 2. Fill in the institution name. 1. Name: Admin or Super admin view list of new account requests 2. Actor: Admin or Super admin 3. Other Participants: None 4. Precondition: Instructor or Teaching Assistant has requested a new account 5. Primary Sequence: 1. Log in to Expertiza. 2. Click on the link “/users/list_pending_requested”. 3. View the list of new account requests. 1. Alternative Flow: None 1. Name: Admin or Super admin accept a new account request 2. Actor: Admin or Super admin 3. Other Participants: None 4. Precondition: Instructor or Teaching Assistant has requested a new account 5. Primary Sequence: 1. Log in to Expertiza. 2. Click on the link “/users/list_pending_requested”. 3. Select a request. 4. Click on “Accept”. 5. Click on “Submit”. 1. Alternative Flow: None 1. Name: Admin or Super admin reject a new account request 2. Actor: Admin or Super admin 3. Other Participants: None 4. Precondition: Instructor or Teaching Assistant has requested a new account 5. Primary Sequence: 1. Log in to Expertiza 2. Click on the link “/users/list_pending_requested”. 3. Select a request. 4. Click on “Reject”. 5. Click on “Submit”. 1. Alternative Flow: None 1. Name: Admin or Super admin send an email to applicant 2. Actor: Admin or Super admin 3. Other Participants: None 4. Precondition: Instructor or Teaching Assistant has requested a new account 5. Primary Sequence: 1. Log in to Expertiza 2. Click on the link “/users/list_pending_requested”. 3. Select a request. 4. Click on the email address. 5. Write the email. 1. Alternative Flow: None. The project is implemented in Ruby on Rails that uses MVC architecture. It separates an application’s data model, user interface, and control logic into three distinct components (model, view and controller, respectively). In this project, we follow the Test-driven development (TDD) software development process, which means that we would first write a test that fails before you write new functional code. We are trying to reuse the existing functionalities in Expertiza, thus avoiding code duplication. Whenever possible, code modification based on the existing classes, controllers, or tables will be done instead of creating the new one. <code> <code> <code> <code> <code>. <code> <code> <code> <code>. Below are the mock-up screens that explain “new account acreation” functionality in Expertiza. 1. 1.New user should click “request account” for requesting a new account, then redirect to the “request new ” page. <image> 1. 2.After redirect to “request new ” page, new users should enter their information, includes role, name, e-mail and institution. If the institution that new users want to choose is not in the list, we can choose “others” option, then a textbox will appear. We can enter our new institution in this textbox. Finally, we can click “request” button to submit our request, and wait for being approved by administrator. <image> 1. 3. If we login as administrator, we can see the screens below. <image> 1. 4. If we click “show requests”, we can see this screen. The email address is clickable. <image> 1. 5.If we click the email address, the email editor will pop out. Administrator can converse with requestor directly. <image>. Our project is a TFD project, and we got the test template from our mentor.In our test file, our test has 5 parts. In the first part, we test the request account feature. in the second part, we test the whether the email address clickable. in the third part, we test the reject function of administrator in lest_pending_requeted page. In the fourth part, we test the the accept function of administrator and test if the user will receive a confirmation email. Finally, we test if the new user can signin with new account and password. 1.Now in the new user request page, the user can add a new institution by choose 'Other' and input their own institution. <image> 2.The new institution is able to saved into institutions table as a new record. <image> 3.The newly created request is stored in requested_users table and has a correct institution_id. <image> 4.The flash message on the view when validation fails is updated. <image> 5.The administrator can access the '/users/list_pending_requested' url via “Administration > Show…>new requests” menu <image> The admin can access the '/users/list_pending_requested' url via “Administration > Manage>new requests” menu <image> 6.“Email Address” column in /users/list_pending_requested page clickable. <image> <image> 7.After super-admin or admin approves the request, the record does not disappear on the page. <image> 8.There is be an email send to email address offered by requester.And for super_admin and user. <image> <image>.","The use cases are described nicely.  It would be good to boldface the name of the use case. The text in the db table is too large, & is essentially repeated twice.  The individual sections are cohesive, but there is no transition between the sections, making it hard to read sequentially.  UI changes are described, but code changes are not.  Mockup screens are useful.  Kind of hard to find the captions between screenshots, however.","Overall, I am extremely impressed with the level of detail and consideration you've poured into this assignment, from the explanation of the existing system and the problems it currently has, to your proposed solutions and assumptions for improvements and how they can be implemented. The structure of your assignment is highly logical and coherent which makes it pleasant to read. It does, however, seem quite lengthy and certain sections seem repetitive.

The inclusion of mock screenshots and the line-by-line factored problems and your solutions allows for a vivid, understandable display of what you are aiming for in improving upon the current system. This also ensures that there is no miscommunication between you and potential clients, as they would have a clear picture of exactly what you aim to do.

I would however advise you to work on establishing criteria on how you plan to conduct the debugging phase after implementation. It's essential to know how you plan to assess the success of your improvements for future designs.

In the code sections, it would be great if you also provided a brief explanation of what the code blocks are set out to achieve. This makes it easier to follow your thought process and better appreciate the complexity and cleverness of your solutions.

Despite this being quite a technical assignment, your constant use of non-jargon language to explain the system is commendable as it enables an individual with minimal IT knowledge to grasp the essence of your work. 

Lastly, I would advise you to pay attention to your numbering format especially in bullet points. In certain sections, it seems a bit mixed up which might confuse the reader. 

Overall, this was a great assignment and you should be proud of your work. Keep up the good work, well done!"
435,E1687,"Expertiza is a Ruby on Rails based open source project. The main motive of this project is to make learning more effective through peer review. This website is a result of combined effort of both students and faculty at NC State, and is used not just by this university but also in many other universities. The website allows students to form teams and work on various projects listed by the instructor and also suggest new topics that seem interesting, though they can opt not to work on them. It also makes it easy for the instructor to add a new topic to an assignment/project, create a new project and add students to it. The time spent by TAs and instructor is greatly reduced. The key feature is peer review, where the students can review the work of others and provide feedback. This helps in improving the existing work and also provides a new way to learn. There isn’t any restriction on the format of submission as it accepts any form of submission varying from URL to wiki pages, which isn’t a common feature in other websites. In Expertiza, user and instructor accounts are currently created by existing super administrators, instructors or TAs. For new users to access the system and experiment the features offered by Expertiza, a “demo-like” feature needs to implemented. The following are the set of requirements that needs to be catered with this feature: 1. Allow people to request instructor accounts over the web. This feature should also have security features such as Captchas to help avoid account creation by bots. 2. When a user account is created over the web, the super-admin should get e-mail regarding the same and also the user should be notified upon approval/denial (if denied, then reason should be specified). 3. Currently, Expertiza consists of a lot of entities that can be made publicly visible to all other users in the system. But, accounts created this way should not be able to see existing public features, until the super-admin manually gives them permission to view public courses, assignments, and questionnaires. 4. A user who creates an account over the web should be pointed to an instruction page and/or video on how to create an assignment and register students for it, etc. The following solutions shall be addressing the problems discussed above. Once a user wants to register and try the features of Expertiza, upon opening the website, one can register by filling up the form and click the register button. There is a captcha that shall be shown below, to make sure that it isn't any bot that is accessing. It provides security to the application. Once the user requests for an account creation, the super admin receives a mail informing about the request with the name of the requested user. The super admin shall then, look for the details of the user in the Review Requested Users tab and can either approve/decline the request. Once the super admin approves the user request, the user gets a mail notifying that they now have the permission to access the features of Expertiza. A temporary password in clear text is also sent in the mail for login. If the request is rejected, then the reason should be mentioned in the reason column of the form. But there is no mail sent to the user regarding that. There shall be a flash message saying, “Login denied. Needs permission from super admin” that can be seen on the login page if an unregistered user tries to access the features of Expertiza. This helps in removing the access to few 'publicly visible features' as it denies access completely. Once the user requests for an account, upon clicking the request sign up , he/she is automatically redirected to the instructions page with the video tutorials explaining various features of Expertiza and on how to access them. The following are the list of files that were created/edited throughout the project. 1. views/auth/_login.html.erb 2. views/users/request_new.html.erb 3. views/users/review.html 4. views/instructions/home.html.erb 5. views/users/edit.html.erb 6. views/mailer/request_user_message.html.erb 7. views/users/new.html.erb 8. views/users/_password.html.erb 9. views/users/_user.html.erb 10. users_controller.rb 11. routes.rb 12. models 13. mailer_helper.rb 14. mailer.rb 15. models/requested_user.rb 16. config/initializers/recaptcha.rb Note that we have used the existing modules and developed these pages. In _login.html.erb a new button called Request Sign Up was added for the new users to register. The register page will look as above. On clicking Request , a user will be redirected to a page like below: <image> User will have to fill up all the required details and request a signup. When a super administrator logins to his account he can go to Manage/users/review requested users menu as shown below. We have put the review requested users in the menu, rather than a separate tab, making it more flexible to integrate some more features under the users option later. <image> Super Admin can either approve/reject a user. The view for this page would be as shown below. This is an entirely new page wherein, the super admin can also mention the reason for a rejection of a request and view the entire list of requested users. <image> In addition to the above files a new file in instructions, named home.html.erb is created which will have all the videos explaining how Expertiza works. In users_controller.rb we will be having two new methods. 1. Method 1 - request_user_create. This is to the new user to request for an account in Expertiza and also mail all the super admins about the new user request. Upon the request, this method uses the user parameters (fields entered in the request sign-up form) and a status of 'Under review' is assigned by default. On verifying the captcha, the super admin(s) gets a mail regarding the request with the user name and the requested user is redirected to the instructions page. 2. Method 2 - create_approved_user. This is for the super admin to either approve or reject the user request and send a mail to the requested user if his/her account is created. The mail also contains a password for the user to login. The codes for each method are: <code> <code>. We have created a new table called requested_users with table description that is similar to users . The status column, which isn't present in the users tables indicates the approval/rejection of the request of the user. Though the description of this table is similar to the users table, we thought it was better to go with a new one, keeping in view of the following advantages: 1. The users table had lot more entries which weren't needed for the requested user scenario and also vice-versa. The entries like status and reason of the requested_users table weren't necessary once the user request has been approved. This was lot more memory is saved. 2. The users table was accessed at many places in Expertiza, so any change in that would have to be reflected at all places. It was comparatively easier to manage with a new table rather than using the existing one. The description of the table is as follows: <image>. Screencast <link> to our demonstration. We did write the test cases and pushed those to the github link submitted, but since we couldn't test them we have commented them. We have written test cases for the following functionalities separately. We have written them to be tested in RSpec. 1. Test the model requested_user so that no invalid entries (blank email ID, blank name etc.) are accepted. 2. Test the mailer to verify if the body, subject, the mail id sent to/from are correctly functioning. Note that we haven't tested for controller and views because, we were unable to run them. The controller and view tests might need lots of runs to finalize on the test.","The document looks good. The ""problem description"" and ""approach"" part contains a large section of text. It will be better to split them using bullet points.","Dear Student,

Thank you for your comprehensive documentation on your assignment's project to improve Expertiza's user and instructor account creation procedures. Your detailed proposal clearly explained the enhancements you envisioned and the processes you planned to use for implementation.

Your project demonstrated a thoughtful approach to enhancing user experience by ensuring that users can only see existing public features welcome to them. Your decision to include captcha to avoid bot account creation is also commendable as it aligns with best practices for web security. 

The inclusion of the email notification feature for both the super-admin and the user depending on account approval or denial status is an excellent feature that will improve communication and feedback within the system. I find that your decision to prevent unapproved users from accessing publicly visible features until they receive permissions is thoughtful and could potentially improve system security.

You displayed good insight when you created a separate table for account requests. This not only prevents unnecessary congestion in the users table but also avoids the accidental alteration of critical user data.

However, you mentioned that you were unable to test your project, particularly the controller and views. It is critical to run tests for your project so you can accurately verify its functionality and fix any unforeseen issues. 

Next time, please ensure that you run tests for all sections of your projects to help ensure their reliability and accuracy. Double-checking your code helps you to catch potential problems early before they become more significant issues.

Also, remember that screenshots and images can bring your project documentation to life. Do ensure you include images in the project documentation section to illustrate the different sections and functions of your code. It was missing from this project.

Ultimately, this was a well-structured project with potential strengths in improving user experience in Expertiza. Good job overall! 

Kind regards,
[Your Name]"
436,E17A3,"Expertiza is an open source project developed by North Carolina State University using Ruby on Rails. It is mainly a tool used to collaborate among students and faculty on a course and act as a common repository to track students’ progress on assignments. It is a simple tool where the instructor creates multiple assignments required and teams are assigned projects. Students submit their work and review other’s work and provide feedback. Wiki link: <link> Github link: <link>. 1. The current Expertiza UI for reviewing uses a simple html text area for each criterion, which starting to look dull for the users. We would like you to improve the feel and look UI for the reviewers by applying CSS styling and arrange the layout of the questions/controls as the instructor designed in rubric designer (the rubric designer is currently being built by Michael Moran please contact him to get the specification of the data model). 2. Moreover, the current form still uses plain old HTML form that sent the text entered in several text areas to the controller only after the user clicks the submit button. The problem with this approach is that the reviewers sometimes lose their reviews when the page is accidentally refreshed, or when a session is broken because they take too much time writing the reviews. 3. Another problem is that the reviewers might enter their reviews from a browser with a different encoding than UTF-8. This prevents Expertiza to store the data since the database is only set up to store UTF-8 strings. Moreover, we found that the review text contains misspelled words and incorrect use of English grammar that makes the review hard to understand. Updates in requirements as of 11 November, 2017 4.Replace the text area with a rich text editor that allows user to customize the fonts, bold, insert link to images / videos (possibly generate a thumbnails of the links). Approach: We have replaced text area in the review form with <link> rich text editor. There are many rich text editors available like <link> , <link> , etc. but we have considered TinyMCE for following reasons: 1. Lightweight as compared to other available libraries, considering we have multiple editors on the same page. 2. Easy to serialize or deserialize content to HTML. 3. Compatible and easy to integrate with Rails applications. Usage 1. Gem used: <link> 2. Behaviour of TinyMCE can be modified by making changes in config/tinymce.yml 1.1. Plugins embedded: 1.1.1. Link : Allows a reviewer to link external resources such as website URLs 1.1.2. Media : Adds the ability for reviewers to be able to add HTML5 video and audio elements to the editable area. 1.1.3. Code Sample : Lets a reviewer insert and embed syntax color highlighted code snippets into the editable area. 3. Initializing TinyMCE: To initialize tinyMCE in the new text area add the ""tinymce"" class as mentioned in the below example and ensure it has a unique ID. <code> Then invoke the tinymce helper to initialize TinyMCE: <code>. Approach: We have replaced drop-down used for giving scores in the review form with <link> . Now reviewer has to select a number of stars for each review questions instead of selecting a value from drop down. Features 1. As reviewer hovers over stars, labels are displayed next to the stars div, which is in sync with our current interface where the instructor can define labels for the min and max scores that show up next to the first and last value in the drop down. 2. Number of stars depends on the number of options in the drop-down generated in the code. 3. No logical changes have been done to embed this feature in the form. Usage 1. bower install <link> . 2. Initializing star rating: To initialize star rating in the new select box apply the javascript as mentioned in the below example and ensure it has a unique ID. <code>. Automatically save the draft versions of all inputs and restore users draft and resume their reviewing when they accidentally close or refresh the current page. Approach: The current design of the system clears all the data in the text fields once a session for the user has been ended. We were briefed to change this design so that someone who was halfway through a review could complete it at a later time even if they ended the current browser session without saving manually. We are making an AJAX call to save user entered text from the current text box as soon as user switches to next text box. This AJAX call is made every 10 seconds to save the content, also the user gets to see the green tick showing the last time when his user entered text has been saved. Please see the snapshots below for reference. UTF-8 :To solve UTF-8 encoding problem, we can make a form accept only UTF-8 characters by using an attribute of the form tag. But most of the characters, including a lot of characters from languages other than English, are present in UTF-8 character set so the application will work perfectly fine on just allowing UTF-8 characters in the text box. Below is the code snippet on the same. <code> Spellcheck : Since we have used rich text format, spellcheck is being handled by the same and we have just enabled the spellcheck option for the browser. Below screens are for criterian based review forms. We have used DRY principle, we have made changes in the existing code and even used the same javascript functions. Manual test cases plans: 1. Field Widths – If the screen contains text boxes that allow data entry and the width of data entered does not exceed the width of the form. 2. Save and Submit Review – If the screen has the save and submit review buttons. 3. Cosmetic Inconsistencies – The screen look, feel and design should match the other screens in your application. 4. Spelling – Ensure that you have test cases that look for spelling errors. 6. Screen Font Type - Ensure that the screen font family matches from screen to screen. 7. Backlink - Ensure that backlink is present on the screen. 8. Review draft is saved - Ensure that user draft version is saved automatically in every 30 seconds. 9. Star rating- ensure that rating stars are displayed on the screen in place of the select dropdown. Automation testing: We are keeping the same test cases since as per our implementation to improve the review UI, we have not changed anything on the id and the class elements of the javascript, we have just changed the CSS elements, so basically, we have not broken the existing test cases. Also, we have thoroughly tested the new UI changes manually. 1. Embedding more plugins in TinyMCE like inserting images, special characters, tables, etc. 2. Embedding code snippets from GitHub to enable the reviewer to link authors code using 'permalink' feature of GitHub. 3. Using multi-step review form having one review question per step. This will improve the user experience while reviewing others work. Demo <link> .","The doc provides a good narrative about the changes to be made and how they affect the UI, but it does not say anything about the code that is affected, and it should.  Later programmers use the design doc to help them understand the code.  Also, the test plan is rudimentary.  It says what the tests will check for, but not how they will do the checking.  It is leaving all the work until later.","Dear student,

Thank you for your detailed work on this assignment and for your wonderful attention to every element of the Expertiza project. Your engagement with the platforms and improvements suggested display a strong understanding of the problem statement and appropriate solutions.

I specifically liked the consideration of the TinyMCE text editor and the explanation on why it was chosen over other libraries. The time you took to detail how to initialize TinyMCE and explain its features shows deep comprehension. The issues addressed, the loss of data on page refresh and the problems with UTF-8 encoding, were accurately identified and appropriately tackled.

However, there is room for improvement here. There is an inconsistency in the flow of your sentences making it difficult to follow your thought process in some places. I suggest maintaining a logical and straightforward order and practicing readability in your writing. I also feel you could provide a more comprehensive manual testing plan for the new features implemented. 

The exploration for future improvements is very promising, showing a future-oriented perspective, and indicating more ways to enrich the program.

In future tasks, also try to explain a bit more about your thought process when taking some important decisions, and also list any possible limitations of the choices made. This could would give an even deeper understanding of your complete approach to problem-solving.

Well done on your hard work - it is apparent in the thoroughness of your assignment. Keep it up!

Best,
[Your Name]"
437,E1678,"Expertiza is an online system that is used by students to view/submit assignments and review others' work. Expertiza also provides tools to visualize the scores and gauge the improvements made during the course semester. It also facilitates and monitors team projects. It is targeted at educational and non-profit organizations. The project is funded by the National Software Foundation (NSF), NCSU Learning in a Technology-Rich Environment (LITRE) program, the NCSU Faculty Center for Teaching and Learning, the NCSU STEM Initiative, and the Center for Advanced Computing and Communication. Expertiza is an open-source project with the source code available as a public repository on GitHub. It is developed using Ruby on Rails and is increasingly becoming robust thanks to the innumerable bugs being fixed by the community. The project has a micro-blog on SourceForge where the developer community report bugs and document updates. Expertiza has two kinds of review strategies, as specified in the Review Strategy tab of assignment creation: Auto-selected Reviews are not preassigned, but when a student comes to do a review, (s)he can select from the reviews that are available at that point. Instructor-selected Instructor decides in advance who reviews whom.Until now, when the strategy is auto-selected, there has been no maximum on the number of reviews a student could select. So students can review as many topics as they want. Set a maximum on the number of reviews a student can choose with auto-selected reviewing. Implement a maximum, and allow the instructor to set that maximum via a checkbox asking whether there is a maximum, and if the box is checked, a textbox to specify what the maximum number should be.If there is a maximum, and a reviewer has already selected the maximum number of reviews, the button that allows selecting an additional review should be disabled. This requirement needs changes to the instructor view and student’s review page. These are small changes to the existing code. So we didn’t find any design pattern which can be used as part of requirement. Instructor view changes While creating the assignment, instructor should be able to specify maximum on the number of reviews done by each student. Assignment related configurations are handled by edit method in the assignment_controller . This method gathers all the information and calls edit view to display results. We added checkbox for this selection under Review Strategy tab of instructor view. If the instructor selects this checkbox, he’ll be prompted to enter the value for the maximum reviews allowed for each student. This threshold value is stored in num_reviews column of Assignment table. All these codes are part of assignments/edit/review_strategy file since it displays all the elements in Review strategy tab. Controller stores these values in assignments database. There are no changes to assignments controller. Instructor view looks as shown below. <image> Requirement 1 - Instructor View Changes Student Topic Review page changes Students review topics page is displayed by list method of Student_review_controller . We added a check in the controller to see if the chosen number of topics exceeds the value set by the instructor. Topic selection will be disabled in views/student_review/_set_dynamic_review.html.erb file if the selected number of topics exceeds configured maximum value as shown below. <image> Requirement 1 - Student View Changes. Current behaviour of expertiza doesn’t allow the students to drop the reviews. If the student selects some topic and want to drop for some reason, he/she need to contact instructor to drop that review. Student Topic Review page changes Students review topics page is displayed by list method of Student_review_controller . List.html.erb file calls /views/student_review/_responses.html.erb partial to display already selected topics. Add a delete symbol to the review topics if the assignment stage is not “finished” and review is “not submitted” . <image> Requirement 2 - Allow students to drop reviews <image> Requirement 2 - Allow students to drop reviews only if Review has not been submitted. Student_review_controller changes Add destroy method to student_review controller. This method should track down the corresponding response map for the topic that needs to be dropped and then delete it. While creating the assignments instructor can allow students to see their teammate score by selecting Show teammate reviews? checkbox. But this option shows both the scores and teammate reviews on the grades/view_my_score page. There is already existing code to display and hide the teammate reviews. This requirement doesn’t need any design patterns since we need to modify small portion of the existing code. Instructor view changes General tab of assignment creation has ""show teammate reviews ?"" option. We replaced this option with two options. ""show teammate scores ?"" , ""show teammate reviews?"" . ""Show teammate reviews ?"" checkbox value is stored in show_teammate_reviews column in the Assignments table. We added one more boolean column show_teammate_score to hold the selection value of ""show teammate scores ?"" option. This is how instructor view will change after implementation. <image> Requirement 3 - Instructor View Changes Changes to students view score page Code to display teammate reviews and scores is present in the /views/grades/view_my_scores file. We added a code to selectively display scores and reviews based on the boolean variables ( show_teammate_reviews, show_teammate_score) present in the Assignments database table. If the instructor only selects show teammate scores? student will be able to see aggregate teammate score as shown below. <image> Requirement 3 - Show aggregate teammate scores Students will be able to see only reviews if the instructor selects show teammate reviews ? during assignment creation. <image> Requirement 3 -Show only teammate reviews Students will be able to see both the score and teammate reviews if the instructors checks both boxes from assignment configuration page. There is no option that lets reviewers see others’ reviews of the same work after they submit their review of that work. This option should be specified in a reasonable way on the Create Assignment page. So we didn’t find any design pattern which can be used as part of requirement 4, but we re-used code that displays reviews submitted by student for a chosen topic. Instructor view changes While creating the assignment, instructor should be able to specify if students should be allowed to see reviews done by other students for the same work. Assignment related configurations are handled by edit method in the assignment_controllers . This method gathers all the information and calls edit view to display results.We are planning to add checkbox show_other_reviews for this selection under General tab of instructor view. If the instructor selects this checkbox, this feature will be active for the assignment. The checkbox will be added in the ""assignments/edit/_general"" file since It displays all the elements in General tab. show_other_reviews will be a hidden form field that stores the value of this checkbox that is finally persisted in assignments database. <image> Requirement 4 - Instructor view to allow students to review others work Changes to student_response controller and views The View link displays the submitted/in progress reviews of the student and is handled by the list action of the StudentReviewController (student_review_controller.rb) and the associated list view is ""/views/student_review/list.html.erb"" file. We plan to add another link Other Reviews to the partial _reponses view. This link would be visible only if the show_other_reviews option has been enabled by the instructor and the review for the topic has been submitted by the student. This link would be next to each of the Review Topics submitted by the student of that assignment. Clicking this link would be handled by an action other_reviews of the reponse_controller (response_controller.rb). After fetching some necessary query parameters the action method would filter responses submitted by other students for that topic and all rounds, exclude the response of the logged in student and set some instance variables. These instance variables would be displayed in the new view other_reviews in (views/response/other_reviews.erb). <image> Requirement 4 - Student view - link to view other submitted reviews <image> Requirement 4 - Student view - Reviews submitted by other reviewers for the same work. The existing implementation of expertiza doesn’t provide a student the option to not see review scores or the text feedback. Sometimes a student might just want to see the scores and not the reviews and other times might want to see the reviews and not the scores. The ability to turn off either one is not provided by expertiza. Database Changes In the participants table, we add a new field called reviewsetting which contains details about the student's chosen review setting. If the value is set to 0 then the student can view both scores and feedback, if the value is set to 1 then the student can view only the scores and if the value is set to 2, then the student can view only the feedback. By default, the value is set to 0. Participant Controller Changes In the participants controller a new method is introduced to handle the change in the reviewsetting value. The controller is in charge of updating the value in the database based on the option selected by the student. Student View Task page changes In the student task view, the page where the student can submit work, view scores, review others, etc. we added a new option for the student to change review settings. Clicking on that link takes the student to the change_reviewsettings page where the student can choose to either view both scores and feedback or just scores or feedback. Review page changes In the partial to view the reviews _review.html.erb, conditions have been added to check the value of the reviewsetting variable. Based on the value of the variable, either both the scores and feedback or just the scores or just the feedback is displayed to the student.","Well defined problem statement, lacks information on design. workflow explained with flowcharts and UML diagrams","Dear Student,

You have presented your assignment in an extremely comprehensive manner, and I must say that your detailed understanding of Expertiza and its functionalities is commendable. 

Regarding the implementation of the “set a maximum on the number of reviews a student can choose with auto-selected reviewing”, I appreciate the clear explanation. It seems like this feature will greatly handle the traffic of students' progress in reviewing. However, I suggest that you try to explain why this new feature is crucial besides explaining how to implement it.

Moreover, you illustrated the changes in the instructor's and students' view effectively. But for the sections where images were referred to, I believe it would be more useful to have the images or diagrams included to enrich your illustration.

The inclusion of a new feature to allow students to review the other students’ work is substantial. This will encourage more engagement amongst students in their coursework. However, as a suggestion, it will be beneficial to consider scenarios where this feature might pose disadvantages, such as promoting comparison or competition, and how you plan to prevent that.

Your idea to include selection in terms of showing reviews or scores is innovative. However, have you considered the impacts this might have on the learning process of the student? While there are students who may only want to view either their scores or reviews, it might be beneficial for the overall learning experience for the student to view both. In any case, some assessment on the implementation of this feature will provide an in-depth coverage on this aspect.

Finally, please do remember to cite sources or references, especially for any background information or statistics you may use. This is very important in maintaining academic honesty.

Overall, great work on your assignment! I'm looking forward to seeing how you improve on this for your final submission.
"
438,E2014,"Expertiza uses the jquery’s date-time picker widget for setting dates and times on various views. This is absolutely required so that all users select the date and/or time in a specified and fixed format. Instructors need to use it often while setting or modifying deadlines for various assignments in a course. Over the years, different developers used different version and formats of the date-time picker due to which there are inconsistencies across the expertiza project. The main problem with the date-time picker is that the widget and the date-time formats used across the expertiza project are not consistent. Moreover, the JQuery based date-time UI widget itself is on version 0.8 which is extremely old and no longer consistent with expertiza's looks and feel. The primary task of the refactor was to find, refactor and make the date-time picker consistent at all places while exploring the possibility of updating the date-time picker to a newer version or completely replacing it by another better widget which works in conjunction with modern javascript libraries. The first step in the approach was to explore the current functionality of existing date time picker. We explored the code base to understand the how 'datetimepicker.js' library was used and its respective compatibility. Simultaneously, we also studied other libraries and gems which could provide a consistent and easy alternative. Since the existing library was no longer being maintained (inactive since mid 2015) ( <link> ), and the new gem 'bootstrap-datetimepicker' provided a relatively recent and easier implementation. So we decided to pick the latter one and replace the older one. According to our solution, the existing library needed to be replaced by the new gem. The initial exploration phase helped us to extract the files where datetimepicker has been used in the codebase. The gem was included in the GemFile to make it available throughout the project. Further, necessary syntactical changes were made respective to the new gem. Another key point was to realise the use of a specific format at a specific place. For instance, a shorter format was used in pages to make efficient use of space. The following section includes specific files and the changes made in each of them. This section discusses the changes implemented as a part of this refactor. Following gems and its dependencies have been added to the GemFile for bundled installation: 1. <link> This gem packages the <link> for the Rails 3.1+ asset pipeline. It is based on bootstrap3 and requires momentjs as a dependency. 1. <link> Moment.js is a lightweight javascript date library for parsing, manipulating, and formatting dates. This gems adds the required javascript files to the project which are used by the new Bootstrap3-datetimepicker gem. Next, the CSS and javascript file provided by the gems need to be included the asset pipeline by including the following in application.js and application.scss file. The screenshots below depict the additions to the respective files: <image> <image>. The existing date-time picker widget was replaced by the new date-time picker in the following views: 1. Edit and create assignments - app/views/assignments/edit/_due_dates.html.erb This contains fields to set the submission and review deadlines for different rounds. The existing JQuery call to the date time picker was replaced by the call to the new widget. Following changes were made to the file: Before: <code> After: <code> 2. Topic sign up sheet - app/views/sign_up_sheet/_due_dates.html.erb This page is used by the instructor to set up the topic sign up page for projects. The form includes a selection of start date and end date for signup. Following changes were made to the file: Before: <code> After: <code> 3. New survey creation - app/views/survey_deployment/new.html.erb The page contains the form to allow the creation of new surveys. The survey start and end dates can be set using the form. The old code used two separate inline onClick event to call the same DateTime picker. Both the calls were replaced by a single jquery call. Before: <code> After: <code> 4. Version logs - app/views/sign_up_sheet/_due_dates.html.erb The version logs file which is only accessible to the admins uses the date tie picker to filter the search results using the start and the end date. Following changes were made to the file: Before: <code> After: <code>. The old jquery based date-time picker was replaced by a new modern bootstrap based date-time picker as shown in the pictures below. The new bootstrap date-time picker widget also has different styles which can be implemented by changing the code as per the documentation <link> . Old Date-Time Picker <image> New Date-Time Picker <image>. This refactor was mainly concerned with the date-time picker widget UI. Thus most of the testing was done manually as automated testing cannot be used to test the widget. After refactoring each of the pages using the date-time widget, rigorous testing was done to check if the date-time picker selected the right date in appropriate formats. Automated testing was performed to test the models and controllers which relied on the date-time picker for its correct functioning. Code climate was used to maintain the code quality and Travis CI build checks were properly monitored for each commit. The new date-time picker widget was manually tested for correctness using the following manual steps: 1. Create and edit assignments Login into instructor account -> Select Manage Assignments -> Click on the plus sign to the right -> Fill in the relevant details -> In the 'due dates' enter the submission and review deadline using the new date time picker widget -> Save -> Check if assignment with proper deadline is being created. 2. New survey creation Login into instructor account -> Select Manage assignments -> From the list of assignments select an assignment and select the 'assign survey' action-> Fill in the relevant details -> Enter the survey start and end date using the new date time picker widget -> Save -> Check if the survey is created with proper deadline. 3. Version logs Login to the Admin/Super admin account -> Open the version logs page -> Select the proper date range to filter the results -> Click 'search' -> Check if results are getting filtered according to the dates selected. To the test the datetimepicker.js functionality, Rspec testing on an untested controller using this gem was performed. In versions controller, search functionality uses the new datetimepicker.js gem. This controller is being given access to only admins and super-admins. The tests check if the datetimepicker.js is correctly used and on the button click the relevant data is returned from database. Also the datetimepicker feature with start date and end date detection should work for both admins and super-admins. <image> <image> <image>. Travis-CI Build Test of the beta branch after a refactored function is merged in the beta branch. <image>. 1. GemFile. ( <link> ) 2. GemFile.lock ( <link> ) 3. application.js ( <link> ) 4. application.scss ( <link> ) 5. assignments/edit/_due_dates.html.erb ( <link> ) 6. sign_up_sheet/_due_dates.html.erb ( <link> ) 7. survey_deployments ( <link> ) 8. _row_header.html.erb ( <link> ) 9. search.html.erb ( <link> ) 10. factories.rb ( <link> ) 11. versions_search_spec.rb ( <link> ) 12. list.html.erb ( <link> ). Github Repo: <link> Pull Request: <link>.","The team has a put together an informative wiki page with all the sections, changes and steps described in detail. The highlight of the team is addition of their specs for the frontend.","Dear Student,

Excellent work! I appreciate the depth and detail of your analysis and solution. It's clear you've done your research thoroughly on the project as well as the other libraries that could be potential replacements. Specifics about different file changes help to understand the scope of your work in a detailed manner. Moreover, stating reasons behind your choices, and explaining how they better serve the project's needs helps in understanding your decision-making process. 

I also admire your foresight in testing all the functionalities connected to the date-time picker. It's imperative to ensure that any change you make doesn't disrupt the overall functioning of the system, and your meticulous tests reflect this approach. 

Your piece includes crystal clear analysis of the problem, extensive exploration of different solutions, and a step-by-step walkthrough of your approach. It's a commendable effort of creating comprehensive documentation that is easy to follow.

However, please double-check your work next time for any typing errors or broken links that could hinder understanding. For instance, the links to the GemFile, GemFile.lock, application.js, application.scss, and the other files and the Github repo are missing. I also missed the actual source code in the ""Before"" and ""After"" sections. 

Nevertheless, this is a fine piece of work. Your efforts to identify the problem in the system and your diligence in finding the right solution does not go unnoticed. Keep up the good work!

Best Regards,
[Your name]"
439,E1680,"The Expertiza project is software to create reusable learning objects through peer review. It also supports team projects, and the submission of almost any document type, including URLs and wiki pages. Expertiza is an open source project and is based on “Ruby on Rails” framework. Expertiza facilitates easy creation of assignments and a list of topics for the same. Expertiza, in other words, gives a very simple web interface for assignment management for both the students as well as instructors. Expertiza should be able to distribute surveys to the users. The survey can be one of the following: 1. Course survey (all the participants of the course can take it). 2. Global survey (all the users in Expertiza can take it). The survey can also be targeted (the admin can specify a group of people who will receive this survey). The three kinds of surveys in this project are: 1. 1. Assignment Survey questionnaire 2. 2. Global survey questionnaire 3. 3. Course evaluation questionnaire. 1. Survey questionnaire should be a subclass of questionnaire. 2. The creation, editing, filling in, and checking that all the questions have been answered survey should be similar to the procedure used for other types of questionnaires (e.g. peer-review questionnaires). 3. There should be a page to see the distribution of results for any question. 4. We should use the same controller method to take the survey as to fill in the peer-review, namely, response_controller. 5. We should use the same code to display the existing survey responses as to display the responses in peer reviews. 6. For each course or assignment, the admin/instructor should be able to create a survey and have some (or all) of the participants receive the survey. Assignment Survey questionnaire, Global Survey questionnaire and Course Evaluation Questionnaire are the existing models which are subclasses of questionnaire. Their display types are survey, global survey and course evaluation respectively. The controller file present currently is survey_controller.rb. In the design we have three kinds of survey- 1. assignment_survey_questionnaire 2. global_survey_questionnaire 3. course_evaluation_questionnaire These models should be made as subclasses of the class questionnaire. Complete refactoring is needed as the existing code is inefficient. <image>. 1. There is a constraint that the survey has to be filled in using the same controller method as used for filling in peer review, namely response_controller. Also, the same code has to be used to display the existing survey responses as to display the responses in peer review. 2. The response_controller can be used to make sure that the survey can be taken only once by each user, depending upon the survey type and the users who are allowed to access (can be listed using 'action_allowed?'). The answers can be saved using the 'saving' method. Also, the responses can be viewed once, the survey is submitted. 1. Instructor or admin both can add survey for any course or assignment 1. The creator would be able to select the participants based on the scope of the survey, that is, all the students or all the Expertiza users or specific group of people. 1. There would be a generic set of questions which will be included in global_survey_questionnaire. 2. These questions will be by default added to every survey the user creates. 3. But, creator will be able to omit them with one ‘checkbox’ button (Or, we can have specific selections for each of the questions to be included). 4. Or, there can be option of separating the global survey and course survey. The quiz taker will take the global survey first and then the course survey. 1. app/controllers/survey_deployment_controller.rb 2. app/controllers/statistics_controller.rb 3. app/controllers/course_evaluation_controller.rb 4. app/controllers/survey_controller.rb. 1. app/models/global_survey_questionnaire.rb 2. app/models/survey_questionnaire.rb 3. app/models/survey_deployment.rb 4. app/models/metasurvey.rb 5. app/helpers/survey_helper.rb 6. app/models/survey_participant.rb 7. app/models/survey_response.rb 8. app/helpers/survey_response_helper.rb. 1. app/views/survey_deployment/ 2. app/views/statistics/ 3. app/views/survey_response/ 4. app/views/survey. 1. Changing name of the model 'survey_questionnaire' to 'assignment_survey_questionnaire' 2. Changing all the entries in the database. That involves, migration of all questionnaire entries where type=""survey_questionnaire"" to ""assignment_survey_questionnaire"". 3. In our part of project implementation, there is no need to incorporate any changes to the Assignment Questionnaire. 4. Changing the name of 'Course Evaluation' tab in page header to 'Surveys'. 1. Deleting all traces of 'survey_deployments','survey_participants', and 'survey_responses.'. 1. Adding columns to the 'Assignments' table: survey_id and global_survey_id. 2. Adding columns to the 'Course' table: survey_id and global_survey_id. 1. We update 'survey_id' and 'global_survey_id' in the 'assignments' table. 2. This requires checking if any entry for 'survey_id' is already present: Case TRUE: Warning to user 'Update to an existing survey'. Case FALSE: Allow update. 1. The survey is mapped to participants through 'participants' table. 2. In 'participants' table: <code> 1. Using the 'type' we can get the type of object i.e. assignment or course, and then using parent_id the particular instance of that object can be mapped to the survey and listed for the user/participant. 1. There is no explicit assigning of surveys to participants. Updating the new columns in 'assignments' and and 'courses' table is sufficient for assigning the surveys. 1. In place of 'Course Evaluation' tab, the 'Surveys' tab, will use the list method to enable student/user/participant to see all the surveys assigned to them particularly. 2. Depending upon the status of the response i.e. submitted or not submitted, the user/participant can view or update, respectively, the surveys. 1. Checking the 'assignments' or 'courses' the participant has enrolled in. 2. Checking if the 'assignments' or 'courses'have active surveys (survey_id != NULL). 3. If participant has already responded to the survey, only 'View' option is available. 4. If there is no previous response, 'Submit Response' option is available. 1. There is a global table for all the responses in Expertiza-'response_map'. All the responses in expertiza are saved in this table. 2. When participant responds to the survey, based on the survey type, the entry in the response_map is: <code> 1. The other entries are: <code> <image>. Login as instructor: 1. Use credentials username: instructor6, password:password. 2. Click on Manage -> Questionnaires-> Survey / Global Survey/ Course evaluation. 3. Create a new Survey/ Global Survey/ Course evaluation filling in the parameters asked for. <image> Login as student: 1. The course survey is for all the students, whereas the global survey is for a few random students using Expertiza. 2. Take the survey visible through your account.",Very good job.  Improvements evidently made since last peer review.  Description for Problems 2 and 3 could have included brief code snippets as in Problem 1; that's all I see as room for improvement.,"Thank you for the thorough job you did in completing this assignment. You clearly have a solid understanding of the Expertiza project, particularly its features for survey distribution and management. I am impressed by the level of detail you provided, especially in the aspects regarding the handling of response data and survey assignment mechanisms. You also did a good job of identifying necessary changes and improvements to leverage the questionnaires’ full functional specifications.

However, it would be helpful if you could organize your ideas more clearly. The assignment sometimes jumps from one topic to another without much explanation or transition, which could make it hard for your audience to follow your line of thought. For example, when presenting your design for the three types of survey, you suddenly discuss code refactoring without fully explaining its relevance.

Another note for improvement would be to clarify each point being made. Be cognizant in avoiding redundancy or repetition, and ensure that the numeration of the points you make is correct; there were several instances where the numbering was repeated or out of sync in your assignment.

Moreover, I noticed you included very technical details (pages of codes, table names, etc.). While these are necessary for understanding the system’s architecture and the specific improvements you proposed, they might be too detailed for an assignment like this. I would recommend focusing more on explaining the logic behind these technical decisions on higher level conceptual terms.

Finally, your assignment lacks a concluding section that can serve to tie together all your points and provide an overview of the implications of the improvements you propose. Overall, good work on the assignment. Refining your writing organization and focus can help convey your well-grounded understanding to your readers more effectively."
441,E2013,"Expertiza is an online web application for educational purpose, and is developed using Ruby on Rails. Instructors are able to create, modify, delete and view assignments and students are able to form teams, submit assignments and make reviews using this application. The tree-display.js and its tree_display_controller.rb files are designed to allow Expertiza users to view their Assignments, Courses and Questionnaires at one place. This is the primary control page, as well as the home page for instructors on Expertiza which allows them to create, modify, delete and view Assignments. The primary problem with this is that both the files, due to their bulky and unoptimized methods, slow the rendering of UI on screen. The methods in these files can be studied and refactored to improve the overall performance of this controller and its corresponding UI. Moreover, any obsolete or unused methods can be removed and DRY principle should be implemented. This project mostly revolves around these 2 files, and would involve refactoring JavaScript more than Ruby on Rails. There may be unused methods in the controller or java script file due to previous development, maintenance and refactoring. Loading speed of the web page is slowed down by repeated interface with database regarding to same variables but by different methods. To find out unused methods in dynamically typed language like Ruby is difficult, thus our team is focusing on the suspicious methods which have neither comments nor references showing in github. All suspicious methods are tested and following shows the confirmed used methods as well as their functionality. goto_... Methods are called when the instructor clicks on the corresponding node under the ""Manage"" menu (e.g. ""goto_quetionnaires"" is called when clicking on ""Questionnaire"" node.) and the user will get redirected to corresponding pages. confirm method is called when the instructor tries to delete a course/assignment/review and chooses ""yes"" at the confirmation page. folder_node_ng_getter functions to render json of the node. (e.g. Returning all the courses data when clicking on ""Course"" node.). 1. We found one unused method bridge_to_is_available and delete it. <image>. 1. We simplified the month string representation in file app/assets/javascripts/tree_display.jsx <image> 2. We found the goto_* functions in file app/controllers/tree_display_controller.rb are not necessary and can be replaced with the goto_controller(name_parameter). However, they are called outside of the files in our scope and we did not modify them for now. <image> 3. We found a confusing variable name ""res2"" in file app/controllers/tree_display_controller.rb and changed. <image> 4. We found two confusing method names ""update_is_available"" and ""update_is_available_2"" and that ""update_is_available"" is used for checking the accessibility of users who are tas/owners while ""update_is_available_2"" is used for checking the accessibility of user who are instructors. <code> is changed to <code> and <code> is changed to <code> 5. We found three confusing method names ""initialize_fnode_2"" and ""children_node_2_ng"" and that ""res_node_for_child_2"" for corresponding nested chidren nodes (the subfolders in the tree display). <code> is changed to <code> , <code> is changed to <code> and <code> is changed to <code> 6. We renamed a few variable and method names related to update_tmp_obj <code> is changed to <code> and <code> is changed to <code>. The tree_display.js and tree_display_controller.rb are mainly related to the ""Manage"" tab and its child nodes. Thus, the following steps are needed to test the functionality from UI: 1. Log in as an instructor. 2. Click on the ""Manage"" tab as well as its child node on the tool bar and to test if they are redirected to the correct page. (Child node means ""Users"", ""Questionnaires"", ""Courses"", etc. under ""Manage"" menu or ""Review Rubrics"", ""Metareview Rubrics"", etc. under ""Questionnaires"" menu. And the reason calling it ""child node"" is because it is the variable name used in code.) 3. Click on the displayed contents to test if the details can be displayed properly. We passed all Travis CI build and Codeclimate checks.","The document talks about a set of changes to the class.  The changes are shown clearly, but there is little description of the rationale behind the changes, why these specific issues were chosen.  There is very little information on testing.  Saying ""see if they are redirected to the correct page"" does not mean much unless one knows what page they should be directed to.  Ditto for ""details can be displayed properly."" 
","Thank you for submitting your detailed assignment. You have showcased thorough understanding and knowledge about refactoring and optimizing code, especially with Ruby on Rails and JavaScript. Your effort in identifying and providing solutions to the issues found in the given web application is commendable. However, I recommend the following:

1) Elaborate more on the specifics of the changes you made. For instance, you mention 'confusing variable' and 'confusing method names' but don't explain what made them confusing and why the new names are better.
   
2) Ensure to explain why certain methods were considered unnecessary and could be replaced.
   
3) In instances where you didn't modify certain elements due to scope restrictions, propose how these might be modified in the future or why they should be considered for modification.

However, overall, this is a comprehensive assignment demonstrating a strong understanding of the main concepts. Your explanations are clear and your identification and resolution of potential issues within the web application are generally well thought out and executed. Well done!"
443,E1505,"Expertiza is a web application developed using Ruby on Rails that serves as a peer-review system. The application allows students to submit and peer-review learning objects (articles, code, web sites, etc)<ref> <link> </ref><ref> <link> </ref>. It is an open source project and it's codebase is maintained in GitHub. We are contributing to Expertiza as a part of our Object-Oriented Design and Development's Open-Source Software (OSS) Project. Our goal in this project is to refactor the assignment_participant model . In this Wiki Page, we will explain the changes that we have made for the same. Contents 1.1. <link> 1.2. <link> 1.3. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.1.4. <link> 1.4. <link>. The assignment_participant model is subclass of Participant model and is used to maintain the list of students/users participating in a given assignment. The changes that are needed to be done are described as follows:<ref> <link> </ref> 1. Rename methods prefixed with “get”. 2. Move methods to appropriate file helper classes. 3. Move methods to appropriate models. 4. Remove unused methods 5. Use good Ruby style guidelines in the code. <references/>.","Well written, but does not mention design patterns or principles
Gemfiles should be downgraded. Schema changes should be shown as migrations and not direct changes in schema file.","Dear Student,

Thanks for your submission. I see that you have a clear understanding of Expertiza and your role in refining its components, specifically the assignment_participant model. You've communicated your goals effectively and have outlined the steps you're planning to take to optimize the model. 

However, I think your work would benefit from some additional considerations in the future. 

Consider providing more elaboration on the specific tasks you're taking on. For instance, when you mention “Rename methods prefixed with 'get'”, it will be helpful to explain why this is necessary, and perhaps provide examples for clarity. 

The same applies to your points about moving methods to appropriate file helper classes and models. Be sure to offer rationale and examples for these actions as they will help not only your own understanding, but will also be beneficial for anyone else looking at your work. 

Keep in mind to use references efficiently for the complete understanding of your project's specific parts rather your article's structure. 

In terms of your summaries at the end of each task, it's crucial that you be specific about the changes that were made to the codebase and the impact those changes had on the functionality of the system.

Looking forward to seeing your progress in implementing and further explaining these changes.

Best,
[Your Name]"
444,E1550,"response.rb is the class that manages the response to all rubrics in Expertiza. if someone fills out a review form, the instance of the review form is a Response. If someone gives feedback (a “rejoinder”) to an author, that is a Response too. Or if someone evaluates a teammate contribution, fills out a survey, or takes a quiz, they are creating a Response. Note: Method display_as_html writes the HTML for displaying a rubric. This would ordinarily be view code, but it is used by so many different views that it is done here. Questions are written out in the order of their sequence number (anyone who creates a rubric can specify sequence numbers for questions). After all questions are displayed, there is a blank for an additional comment. <image> Auto selected Reviewing <image> Auto selected Reviewing <image> Auto selected Reviewing <image> Auto selected Reviewing <image> Auto selected Reviewing <image> Auto selected Reviewing. When the get_maximum_score() function is called it takes care of the weight of the question. It multiplies the weight to the score and adds it to the final score. <code>. All the email code has been shifted to the mailers. Comments have been removed. <image> Auto selected Reviewing. response_helper.rb contains helper methods that display the questionnaires and rearrange questions so that the most frequently answered questions are at the bottom while the less frequently answered questions are at the top. Method is no longer being used in Expertiza and has been removed. Method is no longer being used in Expertiza and has been removed. <image> Auto selected Reviewing.","The changes have not really been explained.  Rather, code snippets have been concatenated together (except in the description of grade weighting).","Hello, 

Overall, you have a good foundation in your understanding of the concepts but your assignment seems somewhat disjointed, which makes it harder to fully comprehend the key principles behind the 'response' concept. 

When describing the role and purpose of 'response.rb', try to provide more structure in your explanation. You could begin with the overall purpose of 'response.rb', then go detailed into the different scenarios where a 'Response' instance is created. Also, ensure to define unfamiliar terminology like 'rejoinder' for better understanding.

While discussing the display_as_html method, provide more details about its functionality and why this method is a part of response.rb, instead of being a part of view code. Your explanation here is unclear.

Your reference to the get_maximum_score() function is abrupt and lacked the context. So, include a detailed explanation of why this function is significant and the role it plays.

Your sentences about comments being removed, email code shifting to mailers, and a method not being used need more context to understand their places in your assignment. Considering the difference of base knowledge between you and your readers can be beneficial in formulating more comprehensive explanations.

Your mentioning of response_helper.rb appears to be out of place and can be confusing, as it is a separate file that should not be included in a discussion about 'response.rb'. Try to stick to the task at hand and discuss only 'response.rb'. 

You’ve made good progress but there’s still some more work to be done to bring clarity and coherence. Make these modifications and your assignment can improve a lot. Keep going!"
446,E1909,"Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link>. <link> is an open source project based on the <link> framework. Expertiza provides a platform for instructors to create assignments and for students to set up teams to facilitate early communication and teamwork in these assignments. Expertiza also provides an environment where students can peer review other students, allowing these users to view feedback on their assignments in a timely manner. Expertiza supports submission across various document types, including the URLs and wiki pages. The following items were improved in the refactoring of the given file: 1. Long blocks of code converted into separate methods 2. Ambiguous variable names changed to meaningful variable names 3. Macros added to replace hard-coded values 4. Code clarity 5. Test Coverage. The Review Mapping Controller handles mapping a given group's assignment submission to students working in other groups for peer review. The controller handles items associated with routing submissions to reviewers, handling permissions for instructor review calibration, and controlling drafts or uncompleted reviews. Included in this controller is the ability for the instructor to specify the number of required reviews per student or the number of reviewers per team in order to have group submission automatically sent to all students' review queues. in automatic_review_mapping method, the following bits of code were added to separate methods: <code> The above was moved into the team_assignment method that assigns users to a new team. <code> Again, the above is a unnecessarily large 'if' block that could be moved to another method, one that was named validate_review_selection The following is the final block of code moved to another method from automatic_review_mapping: <code> This block was moved to the maps_strategies_for_artifacts method. Next, the assign_reviewers_for_team method was evaluated for refactor. The following blocks of code were found that seemed to go past simply what the name of the method entailed, so they were moved to other methods: <code> The above performs its own standalone operation, it's not needed in an already long method that has its own priorities. As such, it was moved to generate_insufficient_review_collection. <code> The above creates a new hash table and performs standalone operations on it, and it is used nowhere else in the assign_reviewers_for_team method. It was moved to generate_teams_hash. <code> Although the above could stay as-is in assign_reviewers_for_team, there already seems to be too much functionality in this method, which is why it was moved to insufficient_assign_reviewers. There are existing RSpec tests (spec\controllers\review_mapping_controller_spec.rb) for the given file; we were tasked with ensuring that our changes did not break any of the existing tests, thus retaining the previous code's functionality. For the commit associated with our final submission, all existing tests pass according to travis-ci. 1. <link> 2. <link> 3. <link>.","Your examples say that code was added, but don't describe the code or what it is used for.  The reader needs to figure that out by reading the code.  For someone following on, it would be much more useful to have a description of how the code works. ","Dear Student,

Thank you for your commitment and meticulous approach to this assignment.

Your documentation of the entire refactoring process is excellent and gives ample clarity as to what you have done. You have made meticulous changes to the original code, such as the conversion of long blocks of code into separate methods, changing ambiguous variable names, and adding macros to replace hard-coded values. These are all great practices in improving the readability and maintainability of the code. Furthermore, the improved test coverage provides more confidence in how the refactored code will perform.

The explanation of the functionalities within the Review Mapping Controller is clear and concise, making it easy for other developers to understand the purpose of the controller and the associated features. Your decision to choose specific methods to focus on for refactoring was logical and well-reasoned. I especially appreciate how you've highlighted the need to break down the code into more manageable and logical chunks. 

However, while there is an adequate description of your work, including some rationale, it would be beneficial for you to further elaborate on the solutions you generated and why you believe these to be effective. The <code> sections seem to be placeholders. Perhaps these are intended to stand for the code you refactored? In future, make sure you include these parts, so it's clearer for the reader. 

Given your impressive ability to decipher and understand complex code, I encourage you to continue working on these skills as they will serve you well in your software development future. 

Also, it's great to see that you verified your changes with the existing tests and made sure that functionality wasn't broken. This is very important in real-world projects, where regression issues can often lead to more problems than the original ones you were trying to fix.

Keep up the great work!

Best,
[Your Name]"
447,E1502,"The Expertiza project is system for using peer review to create reusable learning objects. Students do different assignments; then peer review selects the best work in each category, and assembles it to create a single unit.<ref> <link> </ref>. Used on the admin side of Expertiza for creating/ editing questionnaires (rubrics, surveys and quizzes). It helps in add/removing questions, options, etc for a questionnaire. Very big controller that handles a lot more than the name suggests. Functionalities need to be moved to appropriate controllers. Quiz methods are should be treated the same as any other type of questionnaire; differences between quiz questionnaires and other questionnaires should be implemented in the model class, quiz_questionnaire Turn the questionnaire into a “form object.” The ..._questions methods: save_new_questions, delete_questions, save_questions should be in a separate class. Other classes involved: questionnaire.rb quiz_questionnaire.rb questions_controller.rb What needs to be done: Move quiz related functions to quiz_questionnaire.rb . copy, update_quiz, valid_quiz methods, clone_questionnaire_details is too long. Debug output (print statements) should be removed. Understand the functions in the controller and comment them. Ensure that the code is understandable to the next programmer who works on it. What We Have Done Method Refactoring <table> Format Refactoring Case 1: Loop Condition Change all the looping conditions into one format Before <code> After <code> Case 2: If Condition Change all the if conditions into ruby format Before <code> After <code> Case 3: Name Change all the name from ""JAVA name"" to ""Ruby name"" Before <code> After <code> Refactoring Example In models/questionnaires.rb , we add copy_questionnaires method, as shown below: <code> References <references/>. <table>. Change all the looping conditions into one format Before <code> After <code>. Change all the if conditions into ruby format Before <code> After <code>. Change all the name from ""JAVA name"" to ""Ruby name"" Before <code> After <code>. In models/questionnaires.rb , we add copy_questionnaires method, as shown below: <code>. <references/>.","They did not say too much in their wiki
Wiki has little prose in it.  It is generally clear, but does not explain why changes were made.","Dear student,

Your overview of the Expertiza project is clear, and your understanding of its utilization for peer review and creating reusable learning objects is commendable. Your identification of the need to restructure the controllers to improve the system's functionality is appropriate and displays good technical insight.

However, your assignment is missing the actual code examples. ""Before <code> After <code>"" are placeholders where actual code should be. Similarly, it appears you meant to include a table but have only indicated where it should be ""<table>"". Please include the real code examples and table data to demonstrate your understanding of the topic.

Additionally, please ensure to properly format your references. The ""<references/ >"" tag you used seems inappropriate and indistinct. It is important to properly cite each reference according to the recommended citation format to give credit to the original contributors and maintain academic integrity. 

Lastly, there appears to be repetition of information towards the end of the assignment. Please revise the repeated segments to enhance the clarity and organization of the write-up.

Please, address these points and resubmit the assignment. Keep up with the good work. 

Best,
[Your Name]"
448,E1557,"In this project, we have unit tested various methods in SignUpSheetController.rb and SignUpSheet.rb as well as refactoring these methods. We first wrote unit tests to ensure we had adequate coverage for our methods. Then, we refactored our methods with confidence found from our unit tests. We found that directly testing the functions that we refactored provided better assurances that our refactorings were correct rather than manual testing the user interface. For our unit testing, we used the RSpec framework. We choose this framework since legacy tests of our methods were implemented with RSpec<ref> <link> </ref> . We also utilized the RSpec-Mocks<ref> <link> </ref> to test functions related to the database without having to use fixtures. We wrote multiple controller tests and model tests for corresponding functions so as to test various scenarios and get 100% test coverage. We sought to obtain this high level of coverage to make refactoring more precise. We believe that highly tested code is resilient errors that could occur when refactoring. Before we started working on Expertiza<ref> <link> </ref>, running RSpec on the codebase resulted in 992 / 4184 lines of code (23.71%) covered. After our work, running RSpec on the codebase resulted in 1144 / 4278 lines of code (26.74%) covered. E.g. If you run the test in spec/controllers/sign_up_sheet_spec.rb by command ""rspec spec/controllers/sign_up_sheet_spec.rb"", then you can see the 100% line coverage for controller method save_topic_deadlines() in sign_up_sheet_controller.rb. For checking the coverage, open the index.html page coverage folder and go to respective controller. Similar, run the tests in Model and Controllers folder to see 100% test coverage for following functions. 1. Create() in SignUpSheetController 2. self.add_signup_topic() in SignUpSheet 3. save_topic_deadlines() in SignUpSheetController 4. self.confirmTopic() in SignUpSheet. We performed various refactorings on our code to increase the codes readability and remove redundancy. We extracted variable from complicated statements to increase the readability of the code. In the code base we were working with, there were a variety of lines of code that were more than 80 characters long. These lines of code were hard to read. So, we split them up into multiple lines of code by extracting statements found in function calls into their own variable. Example: <code> Became: <code>. We attempted to enforce good Ruby conventions while refactoring the code<ref> <link> </ref>. This entails doing things like correcting the formatting of the code to make it more readable. In addition to this, we converted a variety of iterators to follow good ruby conventions. For example, sign_up_sheet.rb had the function self.add_sign_up_topic(assignment_id) which contained an iteration through a set of topics while manually maintaining an index variable. Manually maintaining the index variable can be problematic for future maintenance. <code> We replaced these with the Ruby each_with_index iterator. This allows us to pass the responsibility of maintaining the count of the index to the iterator. <code> We replaced ""=>"" while passing parameter by colon (:) So that <code> became <code>. We have refactored the methods which were doing a lot of things into two or more methods so as to segregate the functionality and following the basic principal that one method should do only one thing. Also, this helped in making the methods more readable and easy to understand. E.g. In sign_up_sheet.rb Model, ""def sign_up_wailisted()"" is the new method extracted from original method self.confirmTopic(). There are many more such examples which are done as part of refactoring. 1. Clone the repo <code> 2. Change current directory to cloned repository 3. Run Command: <code> <code> 4. Check coverage: Open overage/index.html in browser and check line coverage for following methods 1.1. Create() in sign_up_sheet_controller.rb in Controllers 1.2. self.add_signup_topic() in sign_up_sheet.rb Models 1.3. save_topic_deadlines() in sign_up_sheet_controller.rb in Controllers 1.4. self.confirmTopic() in sign_up_sheet.rb in Models. We were not able to recreate the problem found in issue 580. After multiple attempts of trying to recreate the bug we began to examine the source code. We believe that someone else has already fixed the bug before we started working on the project. <references></references>.","Good writeup as far as it goes, but it does not explain the tests in much detail.","Feedback: 

Looking at your report, it's clear that you've applied yourself diligently to both the testing and refactoring tasks. Your articulation of the project flow and the methods you covered is descriptive. It is impressive to note that you were able to increase code coverage by a reasonable amount. 

You have used RSpec for testing which is a good choice. I appreciate how you've incorporated RSpec-Mocks as well to simulate database interactions, and also how you've aimed for a 100% testing coverage. 

The code refactoring techniques you've applied like reducing line length, enforcing Ruby conventions, replacing long statements with variables and refactoring methods for single responsibilities, indicates your understanding of the importance of code clarity and readability. It would have been even more insightful if the before and after code refactor examples were included in this report. That could demonstrate the changes and improvements more vividly. 

Also remember to remove placeholders such as <code>, <references></references>, <ref> <link> </ref> unless you are providing actual code snippets and references. You might want to review and edit those sections. 

Finally, it's great that you provided instructions for replication. The approach you followed to find that the issue 580 was already fixed is appreciable, as is your honesty in stating the same. 

Overall, good work! Keep seeking high standards for your code and continuing to apply these best practices in your future projects."
449,E1748,"This page provides a description of the Expertiza based OSS project for Fall 2017. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.4. <link> 1.1.5. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.6. <link> 1.1.7. <link>. <link> is an open source project. It is based on <link> framework. The expertiza project is supported by National Science Foundation. Expertiza is a web application which allows instructors to create new assignments, list of topics which students can sign up for. It allows students to submit and peer-review learning object like articles, code, web sites etc. Students can also form teams for various assignments and projects. It is used in select courses by professors at NC State and various other universities. The following tasks were required to be completed in this project: 1. Issue #80: Add past-due assignments to task list. 2. Highlight with specific colors current and next due dates. 1. Past Due assignments are not present in the task list. If a student is a participant of an assignment and has not submitted the assignment before the assignment due date/deadline, then the assignment is considered as a past due/overdue assignment for that student. These past due assignments are not present in the task list and we have added this functionality to the existing system. 1. Highlighting next due dates. Different To do tasks in the task list with different due dates are highlighted with different shades of red color. An assignment that has to be submitted earlier has a redder color than assignments that have later due dates. 1. The function overdue_tasks? is added in the model student_task.rb file to fetch those tasks with current stage set as finished and which were not started by the student. <code> 1. In the list.html.erb file we used the tasks not started section as a template to construct the past due assignments section. <code> 1. The past due assignments variable from the controller contains the list of past due assignments as its contents which are looped through with a do each loop. The participant, stage and topic_id are used to obtain the due date of the assignment. Then the assignment name and its deadline are displayed. <code> 1. To highlight with specific colors current and next due dates we made several changes to the currently existing list.html.erb file. <code> The rgb() style color attribute is used to set the color of a html tag. A variable r is used to set the red color parameter in rgb function. Initially it is set to 255 which is the Darkest shade of red that is possible. Then a variable step is used to determine by what value the r variable must decrease to lessen the intensity of the red color. The size of the task list is used to initialize the step value. An if condition is used to make sure that step is initialized only when there are tasks to be completed. The task list before and after the changes are shown below. <image>. <image> The student in the example above is a participant in 6 current assignments that are displayed in the task not yet started section of the task list. Each of those is highlighted with colours as described. The student has failed to submit 6 other assignments before their respective due dates and they appear in the past-due assignments section of the task list. TODO: Get proper steps with username and password. (Example Logins (username/password) : student5000/password and instructor6/password). The testing has to be done manually. Following are a few test cases with respect to our code changes that can be tried from UI: 1. Login as student and check if past due assignments section is present on the task list. 2. If no such section is present, the student does not have any past due assignments. 3. Log in as an instructor and create a new assignment. 4. Set the deadline for the assignment to a date and time few minutes from the current date and time. 5. Assign the student being tested as a participant to the created assignment. 6. Login as the student and check the task list after the due date for the assignment has passed. 7. The new assignment will be in the Past Due assignment section. To check if the Tasks not yet started section has assignments highlighted with colours: 1. Login as a student and check if there are any assignments in tasks not started section. 2. If no assignments are present, the student is not involved with any current assignments. 3. Log in as an instructor and add the student as a participant to few assignments. 4. Log in as the student and now see that the assignments in tasks not yet started section are highlighted with colours as described in the wiki. Edge Cases The edge case for when there are no past due assignments for a student has been handled. In this case, no past due assignments are displayed. The edge case for when there is only one assignment in the tasks not yet started section has been handled. In this case, the assignment is highlighted with a dark red colour. 1. <link> 2. <link>.",Organized wiki writeup. Concise and to the point. Manual testing has been mentioned but with addition of testing (missing) it can be further varified. Overall the code snippets are all clear and great for next time in given to further enhance. Next team will have a clear idea reading the wiki as well as the future work section of the wiki. ,"Dear Student,

Firstly, I want to commend your effort on this project as it's evident that you have put in a good amount of work. However, there are a few areas that need to be addressed.

1. Please rearrange the order of contents. You have started well by providing an overview of Expertiza and the functionality added during the project but the content seems to be jumping around as we proceed. Try working on the structure to make it more fluid and informative.

2. The implementation part of your assignment is well-described and detailed. I particularly liked how you included the code along with the explanations. However, the readability can be further improved through the use of code formatting or blocks, especially for the reader who needs to understand and follow the code.

3. The paragraphs that explain your testing cases are greatly detailed which is commendable. However, the TODO item makes it appear incomplete. Make sure to separate completed sections from the parts of the project that require further work.

4. While you have mentioned various links, the actual links to the resources or additional information are missing. This remains a crucial part to your project, so please ensure to add functioning links that your readers can follow.

5. Make sure to double check your work for typographical errors and grammatical mistakes as it reduces the level of professionalism in your work.

6. In addition, do remember to append a conclusion at the end of your project. This gives the reader a quick summary of what the project was about, what was achieved and any pertinent future work that needs to be done.

I look forward to reviewing your revised work.
Best,
[Your Name]"
451,E2001,"This page provides a description of the Expertiza based OSS project Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.1.4. <link> 1.1.1.5. <link> 1.1.1.6. <link> 1.1.1.7. <link> 1.1.1.8. <link> 1.1.1.9. <link> 1.1.1.10. <link> 1.1.7. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.8. <link>. Expertiza is an open source software project created using Ruby on Rails. Expertiza allows instructors to craft new assignments and edit existing ones. This flexibility ensures that each round of students gets an experience that is appropriate to the given situation. It also allows the instructor to create a list of project options and have the students bid for their favorite project. While their are a plethora of benefits for instructors, students also gain some benefits when using Expertiza. They are able to form teams and keep track of the past peers they have worked with, and are also able to manage the progress and submission of their assignments. Questionnaire controller is the controller for the Questionnaire object. A Questionnaire can be of several types including the following: 1. Review 2. Metareview 3. Author feedback 4. Teammate Review 5. Survey 6. Assignment 7. Global Survey 8. Course Survey 9. Quiz Of these several different types of questionnaire's the questions, that can be added, have a different formats including: 1. Criterion 2. Drop down (multiple choice) 3. Text box (short question) 4. Text area (long question) Within the controller itself the object can be copied (clone the given questionnaire), created, viewed, edited, updated, deleted, questions can be added, saved, or removed, and creating a questionnaire node for assignming questionnaire attributes. The next section explores the database relationships with questionnaires_controller.rb. The following diagram visualizes connections in our database. The relationships between relevant tables that are touching questionnaire.rb are shown. <image>. Background: In Expertiza, Questionnaire is a super-class utilized by all questionnaires, including rubrics, quizzes, and surveys. Rubrics are used to assess things such as project submissions and project teammates. All of the above-mentioned questionnaires are sub-classes of the Questionnaire super-class. Since this super-class is used in a multitude of locations ensuring that there are no issues in the code is very important since an error can cause malfunctions throughout Expertiza. Problem: Questionnaires controller has been refactored repeatedly over the past few years, yet some improvements can still be made through refactoring to increase the quality and dryness of the code. These problems are as follows: 1. Unsafe reflection method const_get called with parameter value 2. Hardwired variables in add_new_questions and save_new_questions 3. Unnecessary checks for QuizQuestionnaire, checks can be removed 4. Use guard clause to enclose methods instead of conditional 5. Removed unnecessary method 'create_questionnaire' 6. Break up create method into new 'create_questionnaire' 7. Use each_key instead of keys.each 8. Split lines of code to fit within recommended 160 character length 9. Removed useless assignment of variable in save method 10. Resolved issues involving use of unsafe reflection. 1. app/controllers/questionnaires_controller.rb 2. spec/controllers/questionnaires_controller_spec.rb. Problem Method(s) save_new_questions, delete, and save_questions used conditional to wrap code instead of guard clause. Using guard clause can reduce complexity and number of lines in code. Solution For example, we go from: <code> To: <code>. Problem Method(s) create and save_new_questions have unnecessary checks for if question type is QuizQuestionnaire. Solution We removed the check in both methods. We go from: <code> To: <code>. Problem Method(s) save_new_questions and add_new_questions used hardwired variables. When applicable all values used should be stored as variables so the user knows the purpose of the variable, if that value is used in multiple areas it can be changed with a single change, and it's just messy. For instance both add_new_questions and save_new_questions used the same scalar value 1 for a similar task. We go from: <code> To our code which incorporates constants. <code> With our constants at the top of the code for easy accessibility: <code>. Problem Unsafe reflection method const_get called with parameter value Solution Remove the unsafe reflection through using a variable that checks for null values. We go from: <code> To: <code>. Problem Method create_questionnaire, had no apparent calls to it. Aside from assigning a creator ID, it is similar in functionality to create, so we assume that the method was at some point created as a duplicate. We remove the method to make the code dry. Solution For example, we remove: <code>. Problem The create method itself was 49 lines long. This is too long to be viewable at a glance. Breaking it up into a second private method 'create_questionnaire' to handle attribute assigning and node creation. Solution For example, we go from: <code> To: <code>. Problem The existing code uses keys.each to iterate through the hash. Keys.each is useful for modifying a hash, but in this implementation this is not necessary. So, each_key is used to improve performance timing. Solution For example, we go from: <code> To: <code>. Problem Some of the lines of code exceed the recommended 160 characters per line. To remediate, we simply split code across multiple lines and indent accordingly to maintain readability. Solution For example, we go from: <code> To: <code>. Problem The existing code included assignments of variables that were not used throughout the file. We assume that these variables were created to implement functionality that has since been removed through previous refactor attempts. In any case, we remove the variable keep the code dry. Solution For example, in the following method: <code> We remove the unnecessary variables and comments, resulting in the following method: <code>. Problem The same do loop for hash iteration to update questions for a questionnaire existed in both the public methods 'update' and 'save_all_questions' methods. In order to remove repetition and make the code dry, this do loop was refactored into its own method 'save_question_hash'. Solution For example, in the following method: <code> We refactor the do loop into its own method: <code>. In order to evaluate the changes to Expertiza throughout the OSS project two different methods were used. The first being automatic testing using RSpec and the second being manual testing through accessing the Expertiza project on one's local machine. More in depth discussion of these tests can be found below. In many cases the issues were resolved by editing a few lines of code within various methods without the need for additional methods. Thus, adding more test was not needed in these cases. However, in order to ensure the code edits didn't cause any previously crafted test to fail an RSpec test was ran before each commit. If and only if all test passed could the commit be pushed. The command utilized to test the questionnaires controller is as follows: <code> However, if a VCL was utilized for development this following command was used instead. <code> In one case the create_questionnaire method was removed, thus in order to keep the set of tests clean the following test block was removed from the testing file: <code>. Test Log in Website url: <link> Log in: instructor6 Password: password Test Create questionnaire 1. After logging in click the Questionnaires tab. 2. Select the plus sign for Review 3. Enter ""test1"" for name (or something similiar), 0 for min, 10 for max, and no for review private. 4. Select Create Test edit/add questions: 5. Change dropbox of question type to TextArea, select Add ""1"" more. Press the add button. 6. Change dropbox of question type to Criterion, select Add ""2"" more. Press the add button. 7. Edit question content: ""Test question Textarea"", ""Test question Criterion1"", and ""Test question Criterion2"" in that order. 8. Press Save review questionnaire. 9. Refresh page. All entries should still be available. 10. Select edit or view advice. 11. From descending order fill the boxes with the associated number. i.e. the first box has a 5 above it. Insert 5 in the box. Do this for both criterion. 12. Select save and redisplay advice, then press Back to Questionnaire 13. Going back to Edit/view advice shows the same numbers inputted earlier. Test View Questionnaire 14. Select back 15. Click on the name Review: This should show a drop down showing different reviews made. 16. Find the review that was created. 17. Select the view icon to the right. The information should match what was created earlier. Test Delete Questionnaire 18. Select Back. 19. Repeat steps 15-16 20. Select the big red X for delete. When prompted, select YES 21. Click on the name Review. The Questionnaire created previously will not be present anymore These manual tests demonstrate some of the functionality of the questionnaire controller. Feel free to try your own test cases. 1. Code Refactoring Best Practices <link> 2. Expertiza on Github <link> 3. Expertiza Project Fork <link> 4. Expertiza Website <link> 5. RSpec Documentation <link>.","In the early sections, the page lists several types of questionnaires, and several types of questions, without explaining what they are used for.  And then in database relationships, relationships are shown without explaining what they have to do with the project.  It is the authors' job to explain this, not the reader's job to figure it out.
When QuizQuestionnaire checks are explained, it just says that the checks were removed!  But they are needed.  It seems that their change would make the weight for every item 1 in every questionnaire!  Maybe the code is not this naive, but the changes certainly should have been explained better!
For the changes to the create method, no comments are added ... though old comments are preserved.","Dear Student,

Well done on your assignment. Your deliverable demonstrates a comprehensive understanding of Expertiza software project and its functionalities. You've done an exemplary job of detailing the problem, its impact, potential solutions, and the effects of the solutions. 

I appreciate the in-depth analysis you've provided on the software's source code, highlighting the areas that require refactoring due to existing problems. Your solutions are practical and demonstrate a good understanding of fundamental principles of software engineering, particularly with regard to improving code readability and maintainability.

It's great to see how you've integrated multiple solutions like the use of guard clauses, removing redundant checks, making constants more accessible, removing unused reflection, and breaking large methods into smaller ones. Your documentation is also very well-done with each problem and its solution detailed clearly.

I have to commend you for the comprehensive testing, both automated and manual, performed to validate the code's functionality. This attention to detail further strengthens your submission. 

However, do remember that in a professional setting, you likely wouldn't need to include all your code samples in the report itself. It's generally preferred to provide a high level overview in the report and then make the actual revised code available in a repository or as an attachment. 

Keep up the great work, and aim to continue implementing best practices in your future coding endeavors. You're doing an excellent job connecting theory and practice.

Best regards,
[Your Name]"
452,E2054,"Expertiza is an open source project based on Ruby on Rails framework, created and maintained by the joint efforts of students and faculty at North Carolina State University. It allows the instructors to create new assignments and customize new or existing assignments. Expertiza also allows an instructor to create a list of topics the students can sign up for. Students can form teams on the web application to work on various projects and assignments together. Additionally, students can peer review each other's submissions allowing them to improve upon their work. Expertiza supports submission across various document types, including the URLs and wiki pages. Each assignment should have its own unique auto-generated submission directory, which is named based on the assignment name entered by the teacher. In the current implementation of Expertiza, there are following issues need to be addressed: Issue #1: The directory name should be auto-generated from the assignment name. Issue #2: It should be done by changing spaces in the names to underscores. E.g., the directory for Program 1 is by default ""Program_1"". Issue #3: A check should be added to prevent two assignments in the same course from having the same name. Issue #4: Verify or add if not present - a check to stop two assignments from sharing the same directory. Issue #5: On changing name of an assignment while creating it, the code shouldn't throw a NoMethodError. Fix #1: Submission directory is successfully being generated after the assignment name is typed in. If needed, the submission directory can be changed, however any modifications to the assignment name will just auto-generate it to match. Fix #2: A check was added to ensure that assignments in the same course do not share the same name. When creating a course, if the assignment name is a duplicate, it will reset the entire form. Fix #3: A check was added to ensure that assignments in the same course do not share the same submission directory. When creating a course, if the submission directory is a duplicate, it will reset the entire form. Fix #4: These checks were also put in place when modifying an existent assignment. 1. <link> 2. <link>. The controller, helper and spec were modified for this project: 1. Assignments Controller - assignments_controller.rb 2. Assignments View - _general.html.erb 3. Assignemnts Controller Spec - assignments_controller_spec.rb 4. Assignments Model - assignment.rb. This is a controller that helps instructors create, modify, copy new assignments. Each assignment can be associated with specific Rubrics, Review Strategy and Due dates. This the view for creating the new assignments and editing the existing assignments. This view also handles specifications of Rubrics, Review Strategy and Dates. Tests and bug fixes pertaining to assignments controller. The ruby code which defines how the assignment model functions. The project primarily deals with the AssignmentsController and AssignmentsView, and changes made are as follows: The directory name is auto-generated from the assignment name typed in by the instructor. This is achieved by replacing all spaces in the names with underscores, and removing all special characters like '/','\','$', etc from the auto-generated submission directory name. If any two assignments of the same name under the same course are attempted to be created, it is prevented and an error message is displayed to the user stating the the submission directory name already exists. The odd case of a teacher editing the name of an already existing assignment to one that already exists is also handled. Expertiza will display a similar error message stating that the assignment couldn't be saved. Most changes were made in the assignments_controller.rb file. Checks were added to ensure that an existing assignment name or submission directory did not exist when creating a new assignment. If the assignment was not created due to an error, the code would render new which would cause the assignment to be created even though it did not pass all of the checks. Instead of using render new , redirect_to ""/assignments/new?private=1"" was used to ensure the form would be reset upon any errors. The following function was added to app/views/assignments/edit/_general.html.erb , to generate submission directory names with underscores replacing spaces: <code> Changes were made to the create function in assignments_controller.rb , such that it only creates the assignment directory if the one with the same name doesn't already exist: Before <code> After <code> Changes were made to the update_feedback_assignment_form_attributes function in the same file to flash an error if an edited file has the same name: Before <code> After <code> The following validations were added to app/models/assignment.rb , without these validations the user was allowed to change the assignment name or submission directory to one that already exists. <code>. The following steps must be performed to test the project UI: Step 1: Log in as an Instructor, with Username - instructor6, Password - password <image> Step 2: Create a new assignment. In this case our assignment is called ""E2054 Test Assignment"", under course CSC 216 Fall 2009 <image> Step 3: To save the assignment, the Review and Author Feedback rubrics need to be filled in <image> Step 4: On completion, the assignment will be saved <image> Step 5: If another assignment of the same name under the same course is created, the following error is displayed <image> Step 6: On editing an already made assignment to match the same details as ""E2054 Test Assignment"" <image> We get the following error: <image>. The following RSpec tests were added to the assignments_contoller_spec.rb file <code> <link>.","At the start, it would have been helpful to explain WHY auto-generated submission directories are necessary.

The statement, ""When creating a course, if the assignment name is a duplicate, it will reset the entire form"" is not clear; why would an assignment reset the course-creation form, and anyway, completly resetting the whole form because the instructor types the wrong value into a single field seems like a harsh penalty.  Also, the statement is repeated, as fixes #2 and #3.

There are quite a few misspellings, e.g., ""Assignemnts""

The ""Before"" and ""After"" code snippets are harder to read than if you took a screenshot from the Github diff view, which would show clearly what lines have been changed.

Manual testing should say to type in the instructor name.  ""instructor6"" is only the instructor name if someone is working with the de-identified db, which wouldn't be the case if someone is testing a production system.

OTOH, there are good prose descriptions of changes, and copious screenshots.","Dear Student,

Good work on the assignment. Your exploration and detailed format of Expertiza’s issues and proposed fixations are commendable. It is clear that you have a good understanding of the Ruby on Rails framework and how it is vectoring in the context of Expertiza. 

You've covered the problem and your solution exhaustively and are able to explain your process in a way that is easy to understand. Your code appears to be well-organized and you've clearly explained the changes you've made and why you've made them. I appreciate the level of detail you put into documenting your changes and clearly explaining the thought process behind them.

The observations and detections of different related scenarios and edge cases to consider are evident of your problem-solving skills. Your approach to handling errors and prevention strategies is especially impressive. These are high-demand skills in software engineering!

It seems like you have taken a boilerplate-driven development approach, which is always a good way to debug and build robust and error-free systems. Particularly, your modifications to the assignments_controller.rb file seem quite thoughtful and it appears they would certainly improve the application's resilience.

Your test strategy also shows a good understanding of Test Driven Development. I would like you to focus on unit testing in more detail in your next assignment. This will greatly help you develop better software systems and is an important topic to better master for future software development.

Lastly, do remember to remove placeholders such as <link> and <image> while submitting. Make sure to replace it with the correct visuals or links as it strengthens your explanation.

Great work overall - looking forward to your next assignment!

Best,
[Your Name]"
453,E17A1.1,"Expertiza is an open source project based on Ruby on Rails framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. We have tried two different ways of setting up the Expertiza Environment, first approach used the Ubuntu-Expertiza image while the second approach involved setting up on NCSU's VCL Infrastructure. The process involving both of these approaches are detailed below. We referred the following <link> . Ubuntu-Expertiza image (.OVA) [Recommended] This is the link for the image. ( <link> ) And you can install VirtualBox (free) and import this image into VirtualBox. Some machine may require you to enable virtualization and then run the following commands. <code> VCL Setup The process of getting expertiza up and running on VCL is well detailed in the following <link> . After completing the steps mentioned in the video, Additionally, we had to install Redis and NodeJS separately to get the expertiza site running. The process is detailed below: 1. Steps to install Redis: <code> Run the redis-server using: <code> 1. Steps to install NodeJS on CentOS: <code> 1. Run the expertiza Rails server <code> 1. For logging in as an instructor:- Username: instructor6 Password: password 1. For logging in as an student:- Username: student17 Password: password. At present the calibration functionality is limited, the following points present the scenarios where the current implementation is lacking: 1. No support for varying rubric by round feature. 2. From the perspective of the student, lack of differentiation of review - whether its from an expert or otherwise. 3. A student is not notified once an expert submits a review. 4. Additionally, a student should be able to see how an expert rated his/her assignment - similar to how it's done in calibration results for calibrated assignments( As seen when Show Calibration Results is clicked. ). Tasks are broken down into sub-tasks as follows: 1. Refactoring: 1.1. a checkbox in the ""General"" Tab from “Calibrated peer-review for training?” to “Add expert peer review?” 1.2. a tab name for instructor from “Calibration” to “Expert review” on the assignment setting page 1.3. partial file from “_calibration.html.erb” to “_expert_review.html.erb” 1.4. the link title on student side from “show calibration results” to “show expert peer-review results” 1.5. the file “response/show_calibration_results_for_student.html.erb” to “response/show_expert_review_results_for_student.html.erb” 1.6. title in “response/show_calibration_results_for_student.html.erb” to start with “Expert review comparison report for” 2. Functionality changes 1.1. Vary-rubric-by-round - Currently, the functionality of calibration is limited. It does not support varying-rubric-by-round feature. We need to add support for having different rubrics for different rounds. 1.2. Both TAs and instructors could do expert reviews - need to modify “response/show_calibration_results_for_student.html.erb” to make it support multiple expert reviews. A new migration file needs to be written to make the following changes in the DB Schema ( And across all files using these fields ): 1. “is_calibrated” field in assignment table to “has_expert_review” 2. “calibrate_to” field in response_map table to “expert_review_to”. The following files need to be modified and/or refactored based on their respective tasks: 1. student_review/_responses.html.erb 2. student_review/list.html.erb 3. assignments/edit.html.erb 4. assignments/edit/_calibration.html.erb 5. response/show_calibration_results_for_student.html.erb. For the purpose of this project, experts in the expertiza domain are Teaching Assistants(TAs) and Instructors. The following two patterns are implemented in the project - 1.MVC Pattern – The project is implemented in Ruby on Rails that uses MVC architecture. It separates an application’s data model, user interface, and control logic into three distinct components (model, view, and controller, respectively). 2.DRY Principle – We are trying to reuse the existing functionalities in Expertiza, thus avoiding code duplication. Whenever possible, code modification based on the existing classes, controllers, or tables will be done instead of creating the new one. The following diagram shows the User Interface changes that are to be made as part of the project. This diagram shows the Assignment Setting page in the General tab. <image> This diagram shows the Assignment Setting page in the Calibration tab. <image> The following diagram shows the flow of control in case of peer reviews. <image>. The following is the use case diagram for the feature that we are going to implement. <image>. The expertiza project uses RSpec and Capybara to test the various functionality associated with the back-end and front-end components. Hence, we will also be writing test cases for the new functionality - added as a result of this project. We would also need to add additional fixtures in spec/feature to be used in the testcases. There are three main actors that interact with the new functionality, these are: 1. Instructors 2. Teaching Assistants 3. Students Hence, we would have to write tests for each of these types of users and test the expert review functionality. The tests for the aforementioned changes will be incorpoirated in a new test file called 'expert_review_spec.rb' located in <link> folder. Some of the tests that we have in mind as of now, are as follows: 1. Instructor 1.1. Login as instructor using pre-configured credential. 1.2. Go to ""General"" tab 1.1.1. Verify ""Add expert peer review?"" present instead of ""Calibrated peer-review for training?"" 1.3. Verify whether the instructor can see ""Expert Review"" on the assignment setting page. 1.4. Perform Expert Review, based on values declared in Fixtures available to Instructor. 1. Teaching Assistant 1.1. Login as TA using pre-configured credential. 1.2. Go to ""General"" tab 1.1.1. Verify ""Add expert peer review?"" present instead of ""Calibrated peer-review for training?"" 1.3. Verify whether the TA can see ""Expert Review"" on the assignment setting page. 1.4. Perform Expert Review, based on values declared in Fixtures available to TA. 1. Student 1.1. Log in as Student using pre-configured credential. 1.2. Verify if student can see ""Show expert peer-review results"" 1.1.1. When a new expert-review is available. 1.1.2. Show nothing when nothing is available. 1.3. Testing to check if the reviews show up. 1.1.1. If added by TA. 1.1.2. If added by instructor. 1.1.3. If multiple reviews from either TA or instructor show up as a list. 1.4. Testing varying-rubric-by-round feature.","Environment setup really shouldn't be a part of the design doc.  The main issue, in my opinion, hurting readability is that there are lists of tasks involved and descriptions of changes, but they are separate.  It's difficult to see how they relate to each other.  That makes the document harder to understand than it should be.","Overall, your assignment is informative, detailed, and demonstrates your impressive grasp of various technical concepts. However, there are some areas that would benefit from improvements.

Structure: The paper is a bit unstructured and could improve with more logical organization. A clear structure can help your reader better understand your content. Consider incorporating subheadings for different topics to make the text more digestible.

Content: There is extensive detail in your explanation of Expertiza. It's great you've illustrated the functionalities and limitations of the existing system elaborately. Your meticulous explanation of refactoring, functionality changes, and UI patterns really shows your understanding of the topic. However, sometimes the level of detail makes the text overly complicated, especially for readers who might not be familiar with Expertiza. Try simplifying and summarizing where you can.

Code Placement: There are places where you referred to <code> without including specific code examples after it. Make sure you include specific code examples or remove the reference to avoid confusion.

Numbering: The numbering format seems incorrect in some places. Consider revising and properly formatting your assignment. For instance, numbering should follow a logical sequence like 1., 2., 3., rather than 1., 1., 1.

Testing: Your testing section is exhaustive and well covered; it shows a comprehensive understanding of testing scenarios for different types of users. 

Figures and Diagrams: You made reference to diagrams and images in your content, but they were not seen, which could create confusion for your reader. Try to embed the images directly in the document.

References: It will be beneficial to add your source references at the end of your assignment, to give credit to the original authors of the work from which you've drawn your information.

In conclusion, this is a solid assignment with great depth. By improving its readability, ensuring correct and appropriate use of examples, and properly laying out your explanations, you will only enhance the quality of your work. Keep up the good effort."
455,E1561,"<link> is an <link> <link> application which is used by instructors and students for creating assignments and submitting peer reviews. Expertiza allows the instructor to create and customize assignments, create a list of topics the students can sign up for, have students work on teams and then review each other's assignments at the end. The Source code of the application can be cloned from <link> . Files involved: popUpController.rb participantsController.rb What they do PopUpController displays a review when a user (instructor or student) clicks on a list of reviews. ParticipantsController handles participants in an assignment. What's wrong with them: PopUpController contains only two prominent methods, but they are very big. ParticipantsController contains redundant code. What needs to be done: 1 popUpController.rb 1.1 Action_allowed method always returns true. It needs to be fixed. 1.2 Team_user_popup method needs refactoring. @teamId is assigned but never used. Add comments to make code more readable. Rename variables based on their usage 1.3 Refactor Participants_popup and team_users_popup methods into smaller private methods. 2 participantsController.rb 2.1 In add and update_authorization methods, permissions collection object can be used to reference its elements without assigning each element to individual private variables. 2.2 Inherit and bequeath_all methods are similar. Common statements can be migrated to private method. Add comments in code to make it easy to understand. 2.3 Cluster all the flash messages under one private method to make the code more manageable 2.4 Fix email_sent method. It contains a dummy email address. Modified Action_allowed method to return true only if... <table>. Local variables like can_submit, can_review, etc removed and permissions object referenced directly <table>. Moved common functionality of Inherit and bequeath_all to private method populate_copied_participants <table>. <table>. <table>. Login as a instructor ""instructor6/password"". Click on Assignments -> review report -> and on a team. <references/>.",Some code sequences in writeup are a bit long.  But it does explain what has been done & why.,"Dear Student,

Thank you for your detailed explanation of the problems in the Expertiza application and your proposed improvements. I appreciate your thorough analysis and thoughtful recommendations for refactoring the code. 

For popUpController.rb, I agree with your assessment that the action_allowed method should be reviewed and the team_user_popup method simplified. Your suggestion to use smaller, private methods to improve the readability and maintainability of the code is very apt.

With regards to participantsController.rb, using the permissions collection object directly does seem like a clean solution. Also, your intention to refactor similar methods, consolidate flash messages and improve the email_sent method for better maintainability is commendable. 

However, it would be great if you could provide examples with the suggested changes applied, to give a more concrete idea. Moreover, I see some placeholders like '<table>' in your discussion, which seem to stand for some details that are missing. Also some details about testing the modified code will make your report more comprehensive. 

Please also remember to properly cite your references, which you have mentioned but not listed.

It is good to see that you approach the task critically and I am looking forward to your further findings and improvements.

Best regards,
[Your Name]"
456,E1853.1,"<link> is an Open Source project based on the <link> framework, supported by National Science Foundation. It is the software to create reusable learning objects through peer review. It is a project where students can submit and peer review learning objects(articles, code, websites, etc). The users of this software include students and professors. Expertiza is used by select professors and students in North Carolina State University, for example. It supports team projects, reviews of projects/teammates, submission URLs, Wiki pages and certain document types. Instructors can create projects and the students can bid for the projects. The students can be assigned teams for a particular project or they may form their own team with fellow classmates. <link> is a software development process that relies on the repetition of a very short development cycle, requirements are turned into very specific <link> , then the software is improved to pass the new test cases only. This is opposed to software development that allows software to be added that is not proven to meet requirements. Test-driven development is related to the test-first programming concepts of extreme programming, begun in 1999,but more recently has created more general interest in its own right. The TDD sequence can be can be summarized in following steps: 1. Add a Test 2. Run all tests and see if the new test fails 3. Write the code 4. Run tests 5. Refactor code 6. Repeat Advantages of using TDD: 1. Narrowing Problem Focus 2. Tidier Code 3. Not worrying about dependencies 4. Easier refactoring 5. Better Test coverage and fewer bugs. <link> is a software testing method by which individual units of source code are tested to catch errors early in the development process. For a model it involves testing the interface and on how it responds to commands and queries from outside. Model testing is bounded to the functionality of only the model under test and doesn't test how its collaborating models get affected based on this query. Unit Testing provides several benefits which can be summarized in the below points. 1. Finds problems early: Unit testing finds problems early in the development cycle. This includes both bugs in the programmer's implementation and flaws or missing parts of the specification for the unit. In test-driven development (TDD), which is frequently used in both extreme programming and scrum, unit tests are created before the code itself is written. When the tests pass, that code is considered complete. 2. Facilitates change: Unit testing allows the programmer to refactor code or upgrade system libraries at a later date, and make sure the module still works correctly (e.g., in regression testing). The procedure is to write test cases for all functions and methods so that whenever a change causes a fault, it can be quickly identified. Unit tests detect changes which may break a design contract. 3. Simplifies Integration: Unit testing may reduce uncertainty in the units themselves and can be used in a bottom-up testing style approach. By testing the parts of a program first and then testing the sum of its parts, integration testing becomes much easier. 4. Documentation: Developers looking to learn what functionality is provided by a unit, and how to use it, can look at the unit tests to gain a basic understanding of the unit's interface's API. 5. Design: When software is developed using a test-driven approach, the combination of writing the unit test to specify the interface plus the refactoring activities performed after the test is passing, may take the place of formal design. Each unit test can be seen as a design element specifying classes, methods, and observable behavior. The goal of the project is to test the Menu.rb, i.e. the Menu model by writing unit tests, which are written using <link> . The unit tests are to be written such that the path coverage of menu.rb is greater than 90% and achieve the highest possible branch coverage. The following files were involved: 1. app/models/menu.rb (already existing) 2. spec/models/menu_spec.rb(created as part of this project). The goal is to test the menu model file. For this, we create a corresponding menu_spec.rb file where we write the tests. For this purposes different sub-tasks involved: 1. Setting up the Expertiza environment 2. Understand the functionality of model file in menu.rb 3. Understand the linked data attributes being used, like menu_items, controller_actions, content_page, permissions_id, etc. 4. Creating dummy entries for testing different functionalities. 5. Writing testing conditions for different functions and cross-checking with the expected outputs. The steps that we followed to set up the Expertiza environment are as follows: 1. Install Virtual Box software from Oracle in the local machine. 2. Download the Ubuntu image and import the image file into the Virtualbox environment. 3. Execute the following set up commands in the terminal to set up the application in the local machine. Setup commands: 1. sudo su 2. gem install bundler 3. exit 4. git clone [Forked Expertiza repository url] 5. cd expertiza 6. bash setup.sh (change config/database.yml, there is no MySQL password by default) 1. bundle install 2. rails server After successfully setting up the environment, LogIn to the Expertiza application using necessary credentials. To navigate to the menu.rb file: 1. Open terminal inside the virtual environment. 2. Navigate to the model folder of the application by typing the following command in the terminal: cd/expertiza/spec/models. Menu is a model which gives the functionality to the top menu bar in the Expertiza website. It controls the display of the tabs based pn the user. It links the menu items associated with each tab in the menu using a tree. It directs how these tabs are displayed with regards to different users which have different permission attributes. A super admin has the permission to edit the menu bar, by adding or deleting menu item blocks from it. Upon adding each item, he gets to position it either in the main menu bar or into different subcategories. The following Menu is displayed for the Student role : <image>. Mock/dummy objects are needed to be created for any unit testing criteria. These objects are loaded newly and deleted after every testing condition. Several methods exist for creating such objects, whose parameters need to be designed to satisfy the conditions under test. Using factories command pattern is one such method where few of the attributes are filled in with predefined values when created. We have used factories and created the mock objects that we need to execute the tests. Menu model require several other mock objects to be created namely Node(this is a subclass in the menu class), menu_item, site_controller, controller_action,etc. A total of 21 testing conditions were required to be performed for testing all the functions in menu model file. The conditions that needed to be tested are as below: Node class 1. initialize <code> 2. setup <code> <code> <code> 3. site_controller <code> 4. controller_action <code> <code> 5. content_page <code> 6. add_child <code> Menu class 1. initialize <code> <code> <code> 2. select <code> <code> 3. get_item <code> 4. get_menu <code> 5. selected <code> 6. selected? <code> <code> 7. crumbs <code>. A screenshot of the tests passing is shown here: <image>. <image> <link>. After writing the test cases we used SimpleCov to measure the C0 coverage of our rails application. SimpleCov was already installed earlier. After running rake spec to run the test cases, SimpleCov creates a directory called coverage in our rails application folder. This folder called coverage contains an index.html file which when opened in a browser renders an HTML page which gives the C0 coverage of each of the files in the Controllers, Models, Helpers in the app directory. These are the learning outcomes after performing this project: 1. Writing tests using the Test Driven Development approach. 2. Writing unit tests for models and controllers in RSpec. 3. Understanding the functionality of an already developed application. In our case, before writing the test cases for the menu.rb we had the understand how different models interacted with each other and how each action by different users would make changes in the database schema. 4. An understanding of how different tables are structures in the schema in large applications. 1. <link> 2. <link> 3. <link> 4. <link>.","Using a fixed-width font forces the columns to be pretty wide to read them, which hampers readability, and you never listed or grouped the tests that you wrote.  But other than that, this an excellent and reable explanation of the work you performed.","Overall, this is a very comprehensive assignment. It is evident that you have a good understanding of Expertiza, Test-driven Development (TDD), and unit testing. You explained these concepts clearly and systematically.

The assignment's aims are clear, and you provided a well-detailed approach of how you achieved your goals, such as how you set up the Expertiza environment and ran tests. Your explanation of the functionality of the menu model and how it is used on the Expertiza website was particularly well done.

I also appreciate the time and detail you gave to explaining the importance and benefits of Unit Testing. You explained very well what unit tests are and why they are vital to the coding process. 

The testing conditions and steps mentioned are very comprehensive, which shows your understanding and application of TDD. It would have been even more beneficial if there were actual code snippets attached for each of the testing conditions mentioned, but I understand the limitations in terms of space and formatting.

The presentation and organization of content are very good; the use of sequential points makes it easy for anyone to understand the processes you followed. The screenshots you provided will likely be beneficial for visual learners.

In the future, I would recommend that you include any challenges that you faced during the project and how you overcame them. These would provide valuable insights for anyone trying to follow in your footsteps.

For the section where you write about Menu and Node Class, you may want to consider a more detailed explanation of the code and what each function does functionally. This increased level of detail will further aid understanding.

Nonetheless, you have demonstrated a strong knowledge and application of Expertiza, TDD, and unit testing. Well done! Keep up the excellent work."
459,E1566,"For users intending to view the deployed Expertiza associated with this assignment, the credentials are below: 1. Instructor login: username -> instructor6, password -> password 2. Student login: username -> student4340, password -> password 3. Student login: username -> student4405, password -> password. Expertiza is an educational web application created and maintained by the joint efforts of the students and the faculty at NCSU. It’s an open source project developed on Ruby on Rails platform and it’s code is available on Github. It allows students to review each other’s work and improve their work upon this feedback. The following is an Expertiza based OSS project which deals primarily with the GradesController and GradesHelper. It focusses on refactoring some of the more complex methods, modifying some of the language to make it more Ruby friendly, removing some redundant code. The goal of this project is to attempt to make this part of the application easier to read and maintain. A controller and a helper file were modified for this project namely: 1. GradesController 2. GradesHelper. This is a controller that helps students and instructors view grades and reviews, update scores, check for grading conflicts and calculate penalties. A couple of long and complex methods were refactored from this controller along with removal of some non-functional code and a few language changes to make it Ruby style. Three methods in particular, namely conflict_notification ,calculate_all_penalties and edit were found to be too long and were in need of refactoring into smaller, easier to manage methods. Few more compact methods were created for this purpose. There were no existing test cases for the controller. We have added a spec file named 'grades_spec.rb' under the spec folder. As no changes were done for the model, no tests for the model were included. This is a helper class which contains methods for constructing a table(construct_table) and to check whether an assignment has a team and metareveiw(has_team_and_metareview). We worked on the following work items(WIs) WI1 : Refactor calculate_all_penalties method into smaller methods WI2 : Move the repeated code in conflict_notification & edit methods to a separate method list_questions. WI3 : Refactor the code as per the Ruby style guidelines and incorporate the good practices WI4 : Test the conflict_notification method to test the changes made. WI5 : Move the repeated code in view and view_my_scores methods to a separate method retrieve_questions. 1. Refactoring calculate_all_penalties method This is used to calculate various penalty values for each assignment if penalty is applicable. The following changes were made: 1. This method was very complex, performing too many functions within a single method and had to be broken into 3 smaller methods each having a more well defined function. 2. The following 3 methods were created after splitting the first method <code> 3. Changes were also made to make the code follow ruby style.The language was made more ruby friendly. 4. Finally some redundant code was commented out as it was non-functional. Refactoring into smaller more specific methods: <image> Removal of non-functional code : <image> Change of language to make it more Ruby friendly: <image> 1. Move the redundant piece of code from conflict_notification & edit methods to a new method list_questions The conflict_notification method is used to help the instructors decide if one of the reviews are unfair or inaccurate. This was again split into 2 methods with some part of the code which is repeated in another method refactored into a new method. <image> Refactored #Created a method which was a duplicate in conflict_notification and edit methods <image> edit method: This method is used to edit the questionnaires. This method again has code which is repeated in the conflict_notification method and thus the repeated section was split into a new method. <image> New method: Refactored #Created a method which was a duplicate in conflict_notification and edit methods <image> Similar refactoring was performed to obtain the retrieve_questions method: <image> This is the new method created after the above refactoring: <image>. There were no existing test cases for the GradesController. We have added a new spec file 'grades_spec.rb' which covers testing scenario for the newly added method. The specs were run on the previous and current files and they return the same results implying that the refactored code does not break anything. As the model was not changed, no test cases were added for the model. Following steps needs to be performed to test this code from UI: 1. Login as instructor. Create a course and an assignment under that course. 2. Keep the has team checkbox checked while creating the assignment. Add a grading rubric to it. Add at least two students as participants to the assignment. 3. Create topics for the assignment. 4. Sign in as one of the students who were added to the assignment. 5. Go to the assignment and sign up for a topic. 6. Submit student's work by clicking 'Your work' under that assignment. 7. Sign in as a different student which is participant of the assignment. 8. Go to Assignments--><assignment name>-->Others' work (If the link is disabled, login as instructor and change the due date of the assignment to current time). 9. Give reviews on first student's work. 10. Login as instructor or first student to look at the review grades. 1. The construct_table method in GradesHelper is not used anywhere. It has no reference in the project. So we feel it can be safely removed. 2. The has_team_and_metareview? method in GradesHelper can be broken down into separate methods, one each for team and metareview. This will provide improved flexibility. It needs some analysis though, as both the entities(team & metareview) are currently checked in conjuction from all the views they are referenced from.","Good description of the changes made, well laid out an readable.","Dear Student,

Congratulations on a very comprehensive and well-structured report on your Expertiza project. You provided a clear overview of the assignment with a thorough description of Expertiza's system. It's fantastic to see such detailed information about the processes you worked through.

The level of detail you provided regarding Expertiza's GradesController and GradesHelper was beneficial in understanding the specifics of your work.

The detailing of the refactoring process for the calculate_all_penalties, conflict_notification, and edit methods showed a deep understanding of what needed to be adjusted to make the methods more manageable. Including specific examples and visuals to explain your process (even though the images couldn't be seen) indicates a strong grasp of the content. 

Your explicit outlining of the work items and the changes made for each enhancement made your report easy to read and understand. You have clearly described the purpose of every change, plus shown evidence of forward planning with considerations made for testing.

Lastly, giving suggestions about the construct_table method in GradesHelper and breaking down the has_team_and_metareview? method is commendable as you are thinking about improving the existing system.

One piece of advice for future assignments: you could try providing a brief description of what is happening in the code snippets or the refactored methods for those unfamiliar with programming. This would allow for better communication of your work progress to non-technical people.

Overall, your work indicates a high level of understanding of both the Expertiza system and Ruby on Rails platform. Well done on maintaining such a high standard of work!

Endeavor to keep refining your coding and technical writing skills. Great job!

Best Regards,
[Your Name]"
460,E2062,"The ReviewMappingHelper is a helper class that is responsible for mapping reviews and feedback to reviewers and assignment teams. Additionally, this helper class reports of the status of project reviews. The goal of this project was to add RSpec tests for the functionality added for project <link> . The changes submitted by project E1948 can be found <link> . See the Test Outline section to see the specifics of our testing work. review_mapping_helper.rb review_mapping_helper_spec.rb. <code>. For this project, our plan was to write new RSpec tests for new methods added in project E1948 for ReviewMappingHelper. In total, our team wrote 34 tests to cover the 8 new methods created or altered methods. These 8 methods are listed below. See the Test Outline for more details on the RSpec tests written these methods. 1. get_review_volume 2. get_team_color 3. obtain_team_color 4. link_updated_since_last? 5. get_each_review_and_feedback_response_map 6. get_awarded_review_score 7. check_submission_state 8. feedback_response_map_record 9. get_team_color. This section shows the RSpec test we created for each of the methods defined in Relevant Methods above. The full test file can be found <link> . This method gets review and feedback responses for all rounds for the feedback report. Before testing this method, RSpec sets up an assignment, a review, and a reviewee. Then it creates 2 responses from the reviewer (one for each of the initial 2 rounds). During testing, these RSpec tests assures this method returns the correct amount of responses for each round. In this scenario created, each round should return 1. There is an additional two tests in this RSpec feature, testing to see if a 3rd round returns nothing if there was no response created (which there is not a 3rd response pre-setup. Likewise, there is an additional test where it creates a third response and assures that this method returns 1 for round 3. Setup <image> Tests <image>. This method gets the review score awarded based on each round of the review. Before testing this method, RSpec sets up an assignment, a reviewer, and a reviewee. Then it assignments 3 scores (one for each round) given by the reviewer. During testing, these RSpec tests check to see if this method returns the correct awarded score for each round requested. Setup <image> Tests <image>. This method checks the submission state within each round and assigns team color accordingly. The check_submission_state method calls the submitted_within_round? method to check if the submission was made in the current round and if yes then the purple color will be assigned to the team. One of the test cases tests this feature that purple color is being set or not. If no link was included by the team in the submission or the link is not a wiki link or the assignment was not submitted within the round, then the team will be assigned green color. These conditions are also being covered in the tests below. Setup <image> Tests <image> <image>. This method is a helper method for get_each_review_and_feedback_response_map. It sets the instance variables @review_responses_round_ and @feedback_response_maps_round_ after calculating the number of responses received by the team after each round. This method should return the corresponding response map associated with each round of review. The initial setup to test this method includes creating a reviewer, creating responses and review_response_map_ids. The tests check if the correct response map is returned or not for each round. Setup <image> Tests <image>. This method is a helper method for _team_score.html.erb view. It sets the metrics, namely min, max and avg score value for all reviews for a particular round and team. It uses the pre-populated instance variable @avg_and_ranges and makes new instance variables @min, @max, @avg and sets the latter values to the corresponding value from the former. In the setup for the Rspec test, we create assignment, due dates for 3 rounds, student, reviewee, reviewer and user. Since the method requires @avg_and_ranges for lookup, we hardcode values as explained previosly. In each of the test cases, we assert for the @min, @max, @avg instance variables with our hardcoded values initially setup in @avg_and_ranges. If the assertions pass, it means that the method successfully looked up @avg_and_ranges and set the corresponding values to @min, @max, @avg. We have 3 test cases each for round 1, round 2 and round 3. Setup <image> <image> Tests <image>. This methods checks if the link submitted for evaluation has been updated or not since the last round. The method takes in parameters round, due date and link updated time and compares the dates to check whether the latter for before the former time. The method returns false if it's not updated and true otherwise. The setup for this rspec test included creating an assignment and creating 2 rounds with corresponding due dates along with a reviewer and reviewee for the same. The first test case asserts that the method returns false when link is not updated. The second test case asserts that the method returns true when the link is updated within the due date. Setup <image> Tests <image>. 34 out of 34 tests in the review_mapping_helper_spec.rb test file. Our code changes can be viewed <link> . URL link of video of review_mapping_helper_spec.rb tests running and passing:- <link>. Main Expertiza Repository can be found <link> . Our forked Repository can be found <link> . In addition to adding new test cases to ReviewMappingHelper, we implemented two other changes to the Expertiza code. 1. We refactored get_review_metrics to get_review_volume, as per request from the professor <image> 1. We refactored get_team_colour & obtain_team_colour to read get_team_color & obtain_team_color, as per request from the professor <image> 1. We refactored calcutate_average_author_feedback_score to calculate_average_author_feedback_score, as per request from the professor <image>. 1. The use of the ""dig"" method in Expertiza was causing failures in the Travis build because the ""dig"" method is supported after ruby version 2.3 and expertiza uses ruby version 2.2.7. We fixed this by replacing ""dig"" with an equivalent dictionary accessing code in the methods get_awarded_review_score and get_review_volume. <image> <image>.","It is good that the tests have been divided into tested methods.  However, some methods have so many tests that they need more specific comments on particular tests.  This is especially true of get_team_color, and check_submitted_status.  The text at the top of the method is not detailed enough to describe what is going on in all these tests.","Firstly, I'd like to commend you and your team on the exhaustive testing work you've done for the ReviewMappingHelper. It's evident that thorough thought went into planning and executing the RSpec tests for the new functions added in Project E1948.

Your explanation and illustration of the setup and tests for each method were well outlined and easy to follow. This crucial step betters both the understanding and credibility of your tests, so well done on that. Ensuring such a high level of transparency is essential in software testing and you've done well to achieve this. 

I appreciate how you took notice of the need for refactoring some of the method names to improve code clarity and conciseness, in accordance with the professor's request. It shows that you understand the importance of readability and maintainability in code. 

Your decision to replace ""dig"" with an equivalent dictionary accessing code to mitigate the Travis build failure issue is also commendable. This again shows your team's adaptability to work around compatibility issues, which is a very valuable quality in software development. 

However, there seems to be a numbering issue with the bullet points under ""Other changes to the Expertiza code"". All points are marked as '1.', please rectify this for clarity.

On the whole, your work on this assignment is impressive. You have accurately followed the principles of writing RSpec tests, demonstrated good debugging practices, and documented your work effectively.

Please keep up the good work and continue striving to improve your skills. Well done!"
461,E1786,"Expertiza Background Expertiza is an open-source educational web application developed on Ruby on Rails platform. Students and Instructors (including TA's) use this application though their credentials. Instructors can add new projects, assignments etc as well edit the previous ones and at a later stage can see the student submission and grade them. They can even put a time limit (deadline) for submitting the assignment. Students can form teams for the projects, submit their work through handles (Wiki page, link to a video etc). Students can even review their teammates and other peers, as well give them any suggestions if required. GitHub hooks to Expertiza to encourage contributors. Expertiza project is supported by National Science Foundation. Description of the current project This project is intended to make Bookmarks more user-friendly, credible and valid. Bookmarks in expertiza are created by reviewers and can be used by authors for their work on any project. On each line of the signup sheet are two icons, one for adding a bookmark to the topic, and another for viewing bookmarks on the topic. If the instructor allows the participants to create bookmarks, then only a participant has access to create and view them. He should be able to create a new Bookmark only if he enters a valid one. Problem 1 : When a user after logging into expertiza wants to add a new bookmark or view existing bookmarks for the available projects, he will click on the buttons against the specific title. Once he goes to either 'Create New Bookmark page"" or ""View existing bookmarks page"", he's not able to go back to Sign-up sheet using ""back"" button. <image> Enhancements to this problem : We can go back to Sign-up sheet after clicking on ""back"" button. <image> Problem 2 : If a user clicks ""Add Bookmarks"" button, he will be navigated to a ""Add a new bookmark page"" where he can give details of new bookmark (like URL, description etc ). A messgae "" You've successfully created a new bookmark"" is displayed on the console even if we give null values (i.e if we do not fill up those fields at all). <image> After creating an empty bookmark, we are displayed this message as below in the figure. <image> Enhancements to this problem: Now, it shows an error message asking us to fill the fields. <image> Problem 3: When the instructor doesn't give access for participants to add/view bookmarks, the participants are still able to access them. He un-checks ""Allow participants to add bookmarks"" button and participants are still able to access them. <image> Enhancements to this problem : Now,if the instructor un-checks the button ""Allow participants to create bookmarks?"", the actions View and Add Bookmarks are no longer visible/accessible. <image>. 1. app/views/bookmarks/list.html.erb : This file is a view for listing the existing bookmarks of a particular Title of the project. 2. app/views/bookmarks/new.html.erb : This file is a view for creating a new bookmark - (A valid one). 3. app/views/sign_up_sheet/_actions.html.erb : This file is a view for showing the actions against the title of the bookmark. 4. app/controllers/bookmarks_controller.rb : This file has the code regarding the access that instructor gives to students regarding Bookmarks. a) Back button for the page ""View Bookmark"" and ""Create Bookmark"" was resolved. 1. Login with the credentials to expertiza. 2. Go to 'My assignments' and select OSS Project/writeup. 3. Select 'Signup sheet'. 4. Many titles for projects are shown. Select a title and choose either 'View Bookmark' or 'Add Bookmark' button 5. If you choose 'View Bookmark', after viewing, press the back button to go back to Signup sheet. 6. You will land up in Sign-up sheet page. 7. If you choose 'Add Bookmark', you can add by giving Bookmark details and save it. 8. Now press back button. 9. You will land in Sign-up sheet page. b) Creating Blank(Empty) Bookmarks problem was resolved. 1. Login into the expertiza with the credentials. 2. Go to 'My Assignments' 3. Select OSS Project/writeup 4. Now choose the ""Sign-up sheet"". 5. You will be displayed with titles to all available OSS projects. 6. Choose the one for which you want to create/add a bookmark. 7. Try giving empty fields and press ""ENTER"". 8. You should be given a warning saying ""Error occurred while creating bookmark. Make sure you entered all fields"". 9. You will still remain in the same page unless you press 'Back' button. c) Issue of having the access to create the bookmarks even though instructor denied the access was resolved 1.Login to expertiza as instructor. 2. Select 'Manage' tab and choose 'Assignments' from it. 3. Select OSS Project and to edit. 4. Click on 'Topic' button and see if the 'Allow participants to create bookmarks' is checked or not. 5. If it's checked, un-check it. 6. Now login into expertiza as student and select 'My assignments' 7. Click on OSS project/writeup. 8. Select 'Sign-up sheet' and you see all titles available for OSS projects. 9. Against each title, you can't see any buttons to either add/view bookmarks. 10. You can now repeat the process by checking in the button and see if the add and view button against the titles are accessible/not. 1. A questionnaire can be built to grade a bookmark. Questions maybe like "" How helpful was this bookmark? "", "" Did you use this bookmark for your work? "". 2. A reviewer should be recognized or credited if he added useful bookmarks i.e if the author has made use of the bookmark. 3. A function to add extra credits automatically if a participant had submitted more than threshold number of useful bookmarks. 1. Expertiza on Github : <link> 2. Video on youtube : <link> 2. Pull Request : <link>.","The writeup is essentially a design doc.  While there are screenshots of new functionality, there is no description of the changes made to implement it.","Thank you for your comprehensive analysis of the Expertiza application and the identification of improvements for the Bookmark feature! Here is some feedback on your work:

1. Your presentation is quite detailed, and you have done well to explore different aspects of the functionality of the bookmarks. Your problem identification appears thorough.

2. The workflow walk-throughs for each issue and the proposed enhancements are very helpful for understanding the real-world application and effectiveness of your improvements. You have outlined clear step-by-step processes for replicating the issues and their solutions that will prove invaluable for future testing and development.

3. The exposure of files of code related to the bookmarks is beneficial. Next time, also consider describing any significant code modifications you made in these files to rectify the identified issues.

4. Feedback for Problem 1: Your approach of ensuring the 'back' button works correctly to enhance user navigation is fundamentally important. Good job in identifying and rectifying this.

5. Feedback for Problem 2: Your solution to preventing empty bookmarks creation is spot-on. It’s vital to keep the application data valid and meaningful to maintain its continuous usefulness.

6. Feedback for Problem 3: Your solution to restrict students from adding/viewing bookmarks when the instructor didn't permit it is crucial to make the application more secure and reliable.

7. Your suggestions on possible enhancements, such as grading bookmarks, recognizing useful bookmark contributors, and giving extra credits, are interesting. I would encourage you to further explore these ideas in the future. 

8. I appreciate the inclusion of links to further resources at the end. For clarity, you could also add a brief description of what each link contains.

In summary, excellent work identifying and rectifying potential issues in the application! Keep up the solid analysis.
"
462,E1779,"In Expertiza, there are teammate advertisement, invitation and join team request features which facilitate students to form teams. Teammate advertisement works only for assignments with topics. The topic holders can create advertisement and a trumpet icon will show on the signup sheet page. If one respond to the advertisement, a join team request will be created and the topic holder can see it on “Your team” page. After a student gets a team and the team is not full, (s)he should also be able to send invitations to others. Issues as described by the problem statement: Fix Issue #311: When one responds to an advertisement, (s)he should only be able to respond once. When a team advertises for new members, someone who responds to an ad should only be allowed to respond once. Currently, after someone responds to an ad, they can respond again an unlimited number of times. Fix Issue #227 : If user 'A' got a topic and user 'B' got no topic, then if A join B’s team, A’s topic is dropped and A and B end up with a new team with no topic. This issue should be handle carefully because we cannot simply add B to A’s team (imagine, if A has teammate X and B has teammate Y...). One of a potential fix is that, for assignment w/ topics, one cannot not post an ad unless (s)he holds a topic, similarly, one cannot sent invitations unless (s)he holds a topic. 1) app/models/sign_up_sheet.rb 2) app/helpers/student_teams_helper.rb 3) app/views/sign_up_sheet/_table_line.html.erb 4) app/views/student_teams/view.html.erb. A user who is enrolled in an assignment and has a topic, can advertise for more team members. When another user goes on the 'your team' link, who is enrolled in the same assignment but doesn't have a team and topic yet, he will be able to see the team advertisements by other teams. He can respond to any of the available advertisements. As soon as he responds to an advertisement, an entry is created in the ""join_team_requests"" table and the ""status"" attribute of the corresponding tuple holds ""P"" value signifying pending status. This request goes to the team who had posted that advertisement. The request can be approved or denied by the team members. In either of the case, the ""status"" changes to ""A"" or ""D"" respectively for that entry. If there is an entry in the ""join_team_requests"" table for a user, then (s)he can only see advertisements if the corresponding ""status"" is ""D"", which implies that this user is not yet part of a team. This can be checked by querying for participant_id, which is unique for each combination of (user_id, assignment_id), and then checking the ""status"" corresponding to that participant_id. Pseudocode representing the logic we have used to modify sign_up_sheet.rb: <code> Pseudocode representing the logic we have used to modify view.html.erb: <code>. If a user has an assignment and a topic only then (s)he will be able to advertise for team members to join their team. If a user doesn't have a topic (s)he won't be able to advertise. The scenario in which A, B were two users, A with a topic, B without a topic, A joins B's team but A's topic gets dropped; A,B become a team but with no topic. Such cases are now avoided as we have ensured that without first selecting a topic a user cannot advertise for team members nor can he send invitations to other users to join his team. This is done by quering in the database using inner join between tables-SignUpTopic, signed_up_teams, team_users; and checking if the user has a topic for a particular assignment. If (s)he has a topic then he'll be able to see the option for advertising for teammates. If the assignment doesn't have a topic then the user will be able to send out team invitations. Pseudocode representing the logic we have used to modify student_teams_helper.rb: <code> <code> Pseudocode representing the logic we have used to modify view.html.erb: <code>. Automated tests cannot be written for this project. Automated tests will only be able to test the functionality of Rails and not the functionality of the amended files. 1)Login as Admin, create an assignment with all the necessary details like maximum no of users per team, add topics for the assignment, enroll users(students) in the assignment. 2)Login as user(Student) or impersonate a student, say student A, whom you have enrolled in the assignment. You should be able to see the assignment now in the Assignment section. 3)Since A doesn't have a topic yet, so you won't be able to see the advertise link. 4)Go to the sign-up sheet for the assignment, select a topic. A now has a topic, so now A can advertise for team-members. 5)Post an advertisement-""Need team-members who know Ruby."" 6)Login as another user(Student) or impersonate another student, say student B, whom you have enrolled in the assignment. 7)Since B doesn't have a topic yet, so you won't be able to see the advertise link. 8)Go to the sign-up sheet for the assignment, you'll be able to see a trumpet icon next to the topic that has an ad posted. 9)Click on the icon, you'll see the ad posted by A. Click on request to join A's team. 10)On doing so an entry is created on the table """" and status holds value ""P"" signifying a pending request. 11)Now if you go on the sign-up sheet again, you will no longer see the trumpet icon through which you can access the ads since you have already responded to an ad and the request is in pending state. 12)Login as user A or impersonate A, now you'll be able to see the team join request sent by user B. 13) Now, you can either approve it or decline it. Suppose you approve it, B will become a part of your team, and the status will change to ""A"". And now if you login as B or impersonate B, you will no longer be able to access the trumpet icon which is a link to all ads pertaining to topics the concerned assignment. 14)Had user A declined User Bs join request, the status in the table """" would change to ""D"", that means user B still doesn't have a team. So, now if you login as B or impersonate, you'll be able to see the ads again. 1)Login as user(Student) or impersonate a student, say student A, whom you have enrolled in the assignment. 2)You should be able to see the assignment now in the Assignment section. Since A doesn't have a topic yet, so you won't be able to see the advertise link. 3)Go to the sign-up sheet for the assignment, select a topic. A now has a topic, so now A can advertise for team-members. Post an advertisement-""Need team-members who know Ruby."" 4)This ensures that for an assignment with topics, a user can send out advertisements only if (s)he has a topic. 5)Login as Admin, create an assignment with all the necessary details like maximum no of users per team, do not add topics for the assignment, enroll users(students) in the assignment. 6)Login as user(Student) or impersonate a student, say student A, whom you have enrolled in the assignment. You should be able to see the assignment now in the Assignment section. 7)Since the assignment doesn't have any topics, therefore, you will be able to see the advertise link. You won't see a sign-up sheet since the assignment has no topics. You can advertise for teammates. 1) On clicking on 'Manage Content' the following screen is rendered which lists the existing assignments.","Generally a pretty reasonable description; however, the description of the tests is a long list of actions with no overall description.","Hello,

First off, thank you for providing a detailed response. It clearly shows your understanding of the Expertiza system and your skill in identifying problems within the system. You've thoroughly explained the issues and potential ways to resolve them, highlighting changes in code and associated logic.

However, there are areas that need improvement:

1. **Incomplete Codes and Tests:** You've mentioned modifying certain files and indicated placeholders for pseudocode but haven't provided the actual pseudocode. Be sure to include this next time. Testing is also crucial in software development and it seems you've stated ""Automated tests cannot be written for this project."" While certain parts may be hard to test automatically, it is usually possible to write tests for most parts of a project. It would be good to discuss this further.

2. **Clarity and Structure:** While your assignment is comprehensive, it's a little hard to follow due to its length and structure. Do consider breaking it down into more clear and manageable chunks using headers for different sections. 

3. **Modeling your thought process:** Consider explaining your thought process in choosing one solution over another. What are the trade-offs of your selected approach? Are there other potential solutions? How does your solution handle edge cases?

4. **Writing and Grammar:** Be mindful of your writing. There are some grammatically incorrect sentences and incorrect use of parentheses. Make sure to proofread your work before submission.

Overall, you've done a good job, and with these improvements, your next assignment will be even better. Keep up the good work!"
463,E2115,"<link>. Currently, Expertiza has no way to associate mentors with teams. For assignments with topics, like the OSS project, mentors are associated with topics, and then whichever team is assigned to the topic inherits the mentor for that topic However, for assignments without topics (like Program 2), there is no good way to “automatically” assign mentors to projects. The instructor needs to watch teams being formed, and every time a new team is formed, a new mentor needs to be assigned, outside of Expertiza. This leads to a lot of work for the instructor, as well as sometimes long delays before a team is assigned a mentor. For assignments without topics, mentors should be assigned to teams. Assume that things happen in the following order: 1. An assignment without topics is created that requires teams of size of up to k. 2. Students sign up for teams. 3. When a team reaches a target size of greater than 50% of the maximum teammate capacity, then: 1.1. A mentor will be assigned to this team and notified via email. 1.2. Participants in an assignment will be identified as mentors via their participant permissions ( <link> ). This adds a fourth, “mentor” permission to the existing three permissions (“submit”, “review”, and “take quiz”). Anyone with “mentor” permission for an assignment is eligible to be automatically assigned to mentor a team when a new team is formed. Develop a trigger that: 1. Is activated when any team has been formed that has k members, where k is greater than 50% of the maximum team capacity 1.1. ex: max members = 4, trigger activated when the team size reaches 3 2. Assign a mentor to the team 1.1. Mentors should be evenly assigned to teams, so a good strategy is to assign the mentor who has the fewest teams to mentor so far. 3. Notify the mentor via email that they are now assigned to a specific team, and provide the email addresses of the team members. 4. Possibly notify the team members that they have been assigned the mentor with contact information (further discussion here). The mentor assignment feature has a few preconditions and assumptions which have been outlined below. 1. An instructor has already added an assignment without topics. 2. “mentor” permission exist 3. There are users in said assignment with mentor permissions. 4. A mentor has yet to be assigned to said assignment. 5. Mentor assignment is done only once, does not take into consideration drop offs. The main workflow of the mentor management for assignments without topics is outline below. <image> <link>. The following main logic components are described below. Each block of logic is to be independent from one another, in order to avoid DRY and de-couple code responsibility. A simplistic UI design approach is to be implemented. Below is a mock rendering of the new information that will appear on the student_teams/view?student_id= expertiza page. The value will be only present if the mentor has been automatically assigned. <image> <link> The instructor view will also need to have visibility of what mentors the teams have. Below is a mock rendering of the new information that will appear on the /teams/list?type=Course&id= expertiza page. The role column will be added. <image> <link>. 1. <link>. <image> <link>. This code will Kick off the Mentor Management workflow from the perspective of the instructor when adding members. This is not supported for CourseTeams which is why the other half of this if block does not include the same code. This code can be further enhanced by consolidating where members get added to a single place. 1. <link> <image> <link> 2. <link> <image> <link> <image> <link> 3. <link> <image> <link> 4. <link> <image> <link>. A string constant called DUTY_MENTOR was added to the Participant model, since the duty column of the participants table was used to hold this title. The constant name is prefixed with DUTY_ in the event that other duty titles are added in the future. The assignment form needed a new :auto_assign_mentor flag added to its model. This will allow for the auto assign mentor feature to be disabled if the instructor does not want the work flow executed for the assignment. One trigger had to be added to invitation.rb so when users accept invitations to join a team the mentor management logic can execute. 1. <link> <image> <link> 2. <link> <image> <link> 3. <link> <image> <link>. Two views were updated in the Expertiza application to allow the user to see who the mentor is on their team. The Expertiza application makes use of plenty of view partials to compose the UI. We tried to find the least intrusive place among the pile of view partials where we could add a new column for displaying the duty title for mentors. This also had to be done in two places, since the instructor view of a team is different than the student's view of the same team. For the former, teams_user.rb was updated to append (Mentor) to a user's name in the view. 1. <link> 2. <link>. <image> <link>. Our team tried to avoid any database changes, but in order to add a flag for disabling the mentor management functionality we added a new boolean column to the assignments table called auto_assign_mentor. 1. <link> Update the assignment factory to include a default value for the new auto_assign_mentor flag for testing. 1. <link> Update invitation_spec.rb to resolve failing tests after the addition of code to trigger mentor management in invitation.rb. 1. <link> Implement tests for the MentorManagement class. 1. Login as instructor6, using 'password' as password and find the Rock on Assignment 2. Check the paticipants for this assignment, make sure there are some students attempting this assignment. 1.1. You can add your own students to the assignment if you want. 3. Impersonate the student account you found.If there is no team, create one by inviting other student to your team, or create a team using the admin control. 4. By toggling the Auto assign mentors when team hits > 50% capacity? in the assignment configuration page you will be able to: 1.1. Enable the functionarities and logics that our team implemented. 1.2. Disable the functionarities and logics that our team implemented to allow an admin to assign mentor manully. 1. Add team members to any team under the Rock on Assignment using any following way: 1.1. Invitate/Accept the team invitation using impersonated student accounts. 1.2. Add student to team by using the admin control. 2. Observe that when the member size passing the capacity (3 for this Rock on assignment), a mentor called Student6801 will be added to the assignment team. 3. Remove the mentor and the added students of the assignment team using the admin control. 4. Observe that when the member size below the capacity (e.g. the second team member added), a mentor will not be added to the assignment team. 5. You should also be able to see that mentor is showing on the team list. 1. By doing similar step as we mentioned above, you should not see any of the following: 1.1. A mentor is added to the team after the team size changed. 1.2. A mentor is displaying on the team list unless this mentor account: Student6801 is manually added or invited. Based on the the workflow diagram we propose, we should be including a minimum of 5 tests: 1 for addMentor , 1 for removeMentor , 1 for selectMentor , and 2 more to exercise the paths through our workflow diagram. 1. A team will have a mentor after addMentor is called. 2. A team will have a mentor removed after removeMentor is called. 3. The mentor with lowest number of team assigned will be return after selectMentor is called. 4. The selectMentor except not to receive any message if a team already has a mentor. 5. The selectMentor except not to receive any message if a team has size < 50% of the maximum size.","The problem description is reasonable, but the code is not described.  This will make it hard for later teams to understand the code.","This assignment demonstrates a unique and well-thought out approach to the problem of assigning mentors within Expertiza. 

The assignment does a good job of introducing the problem and detailing the proposed solution. The fact that you take note of, and account for, various preconditions is commendable. The diagram is very helpful in understanding the flow of mentor assignment, and it is evident a lot of effort was put into creating this system. 

However, the assignment could have used clearer organization in its parts; there was a great deal of content to address and absorb in one piece. It would also be useful to have more detailed instructions for how to test the system you've implemented. For example, the last section jumps between different actions and expected results without clear delineation, which can be confusing to follow.

This system would benefit from more in-depth testing, particularly when considering edge cases. For example - what happens if there are not enough mentors to cover all teams? Thus, the assignment could be significantly improved with additional detail about what specific tests will be run, how they will be implemented, and what constitutes a pass or fail for each test.

Lastly, while the system seems to function as intended for the most part, the assumption that mentor assignment is done only once and does not account for drop-offs is something that could potentially be revised to enhance the system’s robustness.

Overall, this is an ambitious and well-developed piece of work. With a little bit more attention to detail in terms of organization, instructive guidance and comprehensive testing, it has a high potential to be an excellent piece of work."
464,E2065,"The student_task/list page is the page displayed to a student after logging in into expertiza. It has mainly two div(s), one to show the upcoming tasks including 2 parts: 1. Information about tasks. It shows the projects that need to be completed and how long they are close to the deadline, and marks specific revisions prompts. 1. Show the record of each group collaborator(s) for each course. Another div is to display all the assignments and their information, include Assignment, Course, Topic, Current Stage, Review Grade, Badges, Stage Deadline, Copyright Grants and Make Public. Original page before modifying showing below, all the courses and all the assignments are displaying in the same table, and badges have own column. <image> <image>. 1. app/helpers/student_task_helper.rb 1. app/views/student_task/list.html.erb 1. spec/features/airbrake_expection_errors_feature_tests_spec.rb 1. spec/features/student_task_spec.rb 1. spec/features/assignment_submission_spec.rb. Here are some existing problems and unclear parts of the page： 1. Problem1 : Consider the cases where a student might be enrolled in assignments from more than one course. In this case, assignments should be grouped by course, with the course name given before the listing of the first assignment. 1. Problem2 : Remove the column for Review Grade because it makes no sense, change Review Grade to Submission Grade. Show the actual score and show the blue button. If you hover over your mouse at the blue button, should also show the commands about grades. 1. Problem3 : Delete the badges column, and if the Assignment has a badge, mark it directly next to the assignment name under the assignment column. 1. Problem4 : There is an unnecessary gap between the two div. It needs to be rearranged to be more beautiful. Fixing app/views/student_task/list.html.erb original code of how to display course are showing below <code> In order to group the courses, we added a group_by method to find out which courses does this assignment belongs to, and group the assignments that has the same courses name at one table. The modified code is showing below. <code> We will print out the course name as each table head, group the assignments, and we take down Course coloum from table content since the course name is already showing as table head. Also, for the assignments that have not assigned to a course, we will print out No Course Assigned Yet . 1. Fixing app/views/student_task/list.html.erb 1. app/helpers/student_task_helper.rb For this problem, first, we change Review Grade to Submission grade, which only need to modify <code> to <code> on list.html.erb. Second, we change how we display the score. Instead of showing a blue button, we added how much scores they got (e.g. 32/40), which make users easier to see what scores they got. We modified get_review_grade_info(participant) function inside of student_task_helper.rb. Original code is showing below <code> In the original code, each grade is assigned to /100, which is not correct because not every assignment has 10 reviews (one review count for 10 point). Instead of using /100, we use num_reviews_allowed, it will give us the maximum reviews that each assignments are allowed. Since we need to display the current score on the page, we need an array to carry the current score and display it on the result. The modified code showing below. <code>. Fixing app/views/student_task/list.html.erb Since not too many assignments are able to get badges, that make badges column barely have contents. Therefore, we display it after the assignment name and delete Badges coloum. If one student gets a badge, it will display a small picture after the badged assignment. Hover over your mouse on it, and it will display the information about this badge. <code>. Fixing app/views/student_task/list.html.erb Our main purpose of this project is to make the student_task/list page looks better. For problem 4, we fixed unnecessary white space between two divs. We changed two div's style to style = width:18 and style = width:80 , so two div will display on the same lines. <code> <code>. Page showing right now <image> <image>. 1. Fixing spec/features/airbrake_expection_errors_feature_tests_spec.rb 1. Fixing spec/features/assignment_submission_spec.rb 1. Fixing spec/features/student_task_spec.rb According to the modification of each problem, we write test separately to test whether its function is realized or not. 1. First, we modified spec/features/airbrake_expection_errors_feature_tests_spec.rb . Since when no assignment was assigned to the student, it should not show the table content on the page. Change from <code> to <code> 1. Second, we modified spec/features/assignment_submission_spec.rb . In order to use the content inside of the original test file, we added a def function. The function is able to set up the database for testing needed, and test the necessary function from the student_task/list page. - The def function we added is showing below. <code> - Later on, we will use this list_page function on our test cases. It will show if the student_task/list page has the assignment name( Assignment1684 ) that we putted on the database. Also, since there are an assignment assigned to the student, we will expect page to have course table information ( eg. Assignment, Submission Grade, Topic, Current Stage, Stage Deadline, Publishing Rights ). Since the assignment was not being graded yet, on the submission Grade column it will show a N/A . We are using student student2064 as our user. Therefore, the page should show student2064 . We also assigned the student to team up with CSC517, test ( student_id, user type. user type will be test #random number ), and on the page it should show Students who have teamed with you CSC517, test#{n} . Next, the page should not contain other course name. Testing code is showing below. <code> 1. Next, we added a new file spec/features/student_task_spec.rb . We included spec/features/helpers/instructor_interface_helper.rb on the test file. instructor_interface_helper set up the instructor6 log in page for us already. However, instructor_interface_helper did not help us to sign up an assignment to the user. Therefore, we will testing if the user have not been signed up for an assignment, and the student_task/list page will only show the first div part. The course information table will not appear on the page. <code>. Our Rspec test is able to pass Travis CI testing. <image>. We deploy this part of the program on VCL to test UI and other functions. The link to the website is as follows: <link> Using the following account to log in for testing： Username: instructor6 Password: password And then click <link> to the fixed page. 1. <link> 2. <link> 3. <link> 4. <link>.","It is difficult to follow the changes for Problem 1.  The problem description is separated from the code snippet.  The new code is evidently inserted in the code shown above, but it's not clear where the new code resides.  A Github diff view would have been much clearer.  This is also true for Problem 2. The first change to tests needs to be described more fully.  The description of the second test is quite confusing and should be reworded.","Dear Student,

You have shown meticulous attention to detail and have provided a comprehensive description of the problems identified and the changes you made to solve them. Your outline of code changes, as well as the reasoning behind those changes, demonstrate your deep understanding of the subject matter.

However, there are some areas that need improvement in your assignment:

1. Formatting: In your solution, numbering was irregular. Please be sure to properly format your document to improve readability and coherences. Proper formatting makes it easier for your readers to understand your thought process and follow along with what you're doing.

2. Subject: You have discussed many things in your solution, but it can be difficult to follow your discussion due to the fact that you jump from one area to another. While your content is detailed and comprehensive, it would be helpful to organize your thoughts and ideas in a systematic and coherent manner.

3. Visual Aids: You have mentioned images at several times in your submission. However, they cannot be viewed. If you have tried to add images to your document, please try again and make sure that they have been included correctly. Images can be very helpful for explaining complex processes and ideas.

4. Code Snippets: Some parts of your code are missing in your assignment. Wherever you've mentioned <code>, presumably to refer to code snippets, the actual code isn't provided. Be sure to embed the actual code in your document so that it can be properly reviewed.

In your future assignments, do try to focus on maintaining a systematic approach to problem solving, and take care to properly format your document to improve readability. Keep up with the good work, and keep improving

Best Regards,
[Your Name]"
465,E1781,"For testing the changes made, the following credentials are recommended: 1. Instructor Login: username: instructor6 password: password This project does compile. Reviewers can refer <link> and the YouTube link <link> for navigation help. Expertiza is a web portal which can be used to manage assignments related to a course. It provides a platform to view assignments, manage teams, select topics and work on improvement through anonymous peer reviews. Expertiza allows the instructor to define different topics that students or teams could choose from as their assignment. Each topic can have 0 or more slots that indicate the number of students or teams that can be signed up for that topic. To improve the user experience when managing topics, the following tasks were identified: 1. Issue #971: Change create topic UI into AJAX 2. Issue #926: We need a way to sort topics by topic number in assignment#edit page 3. Issue #718: We should allow instructors to give feedback when accepting or rejecting topic suggestions. The following files were modified for this project: 1. app/assets/javascripts/application.js 2. app/assets/javascripts/signup.js 3. app/assets/stylesheets/application.scss 4. app/controllers/sign_up_sheet_controller.rb 5. app/models/sign_up_topic.rb 6. app/views/assignments/edit.html.erb 7. app/views/layouts/application.html.erb 8. app/views/sign_up_sheet/_add_signup_topics.html.erb 9. app/views/sign_up_sheet/_add_signup_topics_staggered.html.erb 10. bower.json 11. config/routes.rb 12. Gemfile - changed json from version 1.8.3 to 1.8.5. The following files were added to this project: 1. app/assets/images/icons-2x.png 2. app/assets/images/icons.png. Currently, when instructors manually enter topics, they have to go back and forth between the list of the topic page (views>sign_up_sheet>_add_signup_topics.html.erb) and the create topic page(views>sign_up_sheet>new.html.erb). Adding a new topic can be done through an editable grid (see js-grid) without leaving the list of topic page, by making use of AJAX. The list should be automatically updated when a new topic is entered. To enable AJAX the sign_up_sheet_controller.rb is modified so that it renders JSON to handle the javascript table/form. In addition, when adding a topic, the default slot is set as 1 instead of 0. The current warning message that shows up when the slot is 0, has been fixed to close properly. On the controller app/controllers/sign_up_sheet_controller.rb we edited the Load_add_signup_topics, which was converted from a function into a Rest endpoint(Json). <code> <code> An Example output of the Json rendered for Assignment Id : 843 by the load_add_signup_topics Action is as follows: { ""id"": ""843"", ""sign_up_topics"": [ { ""id"": 3958, ""topic_name"": ""Power consumption issue"", ""assignment_id"": 843, ""max_choosers"": 3, ""category"": """", ""topic_identifier"": ""1.1.1"", ""micropayment"": 0, ""private_to"": null, ""description"": null, ""link"": null, ""slots_filled_value"": 0, ""slots_waitlisted"": 0, ""slots_available"": 3, ""partipants"": [] }, { ""id"": 3959, ""topic_name"": ""Perspectives on parallel computers (1.4 in old edition)"", ""assignment_id"": 843, ""max_choosers"": 2, ""category"": """", ... (And so on.) Similarly, all the actions/methods (destroy|setup_new_topic|update_existing_topic|update|set_values_for_new_topic ) were changed to render Json rather than rendering a view, in order to satisty the Ajax requirements in the front end. On the model app/models/sign_up_topic.rb an attribute accessor was created for variables to set properties that are required for the JSON. <code> On the View ' app/views/sign_up_sheet/_add_signup_topics.html.erb' the following was added: <code> The content of the above tag is completely rendered via Javascript, where we use JSGrid for dynamically allowing users to Add, Delete and Update Topics on the same page. In ' app/assets/javascripts/signup.js ' file, the following was added: The following content shows how AJAX calls are handled/made to our signup controller so that the CRUD operations on the topics page is dealt with <code> The Preview View for Topics Management : <image> After Our Implementation using JS Grids : <image>. This task is to do with sorting the Topics according to the topic number. This functionality is taken care by Js-Grid by itself, where clicking the topic# will toggle the topics in the ascending/descending order. Sorting in Ascending Order: <image> Sorting in Descending Order : <image>. Instructors should be allowed to give feedback when accepting or rejecting topic suggestions. Earlier, feedback on topics suggested by students can be given only when the instructor wants the topic to be revised, not when (s)he is approving or rejecting it. Feedback should be possible in any of these cases. In app/controllers/suggestion_controller.rb Including the text provided in the comment field, while approving the topic. This ensures that comments are saved when an instructor accepts a topic suggestion in the backend. <code> Including the text provided in the comment field, while rejecting the topic.This ensures that comments are saved when an instructor rejects a topic suggestion in the backend. <code> In app/views/suggestion/show.html.erb The following piece of code is to handle scenarios in frontend to list the comments even for approval and deniel of suggestions. <code> Only an instructor should be able to approve or reject a submission. Therefore, only for instructor role, approve and reject submission options will be provided. <code> Comments can be added even during topic approval or rejection. <image> Comments during approval or rejection get reflected in the feedback list. <image>. Screencast of the demo: <link> The majority of the changes can be tested via the UI. Follow the instructions below to check the tasks. 1. Issue #971: Change create topic UI into AJAX 1. Login as an instructor. It will automatically go to the manage courses page 2. Click Assignments tab next to Courses 3. Select the assignment for which a new topic has to be added 4. Click the edit icon for the assignment and go to Topics tab 5. You will be able to see the topics list in a grid format. Click on add icon on the right side corner of the grid 6. You can also edit an existing entry by just clicking on that row in the grid without being redirected to a new page 1. Issue #926: Sort topics by topic number in assignment#edit page. 1. Log in as any user or instructor. 2. Go to the assignments list. Note: this is not the manage assignments for instructors. 3. Click into a finished assignment. You will notice the actions column is gone. 4. Click into a current assignment. You will notice the actions column appears. 1. Issue #718: 1. Login as an instructor. It will automatically go to the manage courses page. 2. Click on the ""Manage Notifications"" link above the ""Courses"" and ""Assignments"" links. Note: The link was placed here because the system has numerous issues when adding menu items. It would require us to do more work that the entirety of this project to correct the menu additions in the superuser menu. 3. You will be directed to a creation page for notifications. Note: in order for a notification to display the expiration date must be the current date or later, and the active checkbox must be selected. 4. Log out once the notification is created. 5. Log in using any account. The notification will display on the first page the user is shown. It will disappear when they change or reload the page. Note: instructors on the management page will retain the notification if they switch between Assignments, Courses, and Questionnaires. This is because the JavaScript does not actually reload the page. Rspec tests for the new load_add_signup_topics_method implemented in the signup sheet controller, is implemented in spec/controllers/sign_up_sheet_controller_spec.rb file. In the load_add_signup_topics method, the existing data is converted to json and rendered in the form of a jsgrid. So the test method creates a mock assignment object and invokes the load_add_signup_topics method on that assignment. If the assignment is found, it loads all the topics and checks if the rendered format is json along with a http status 'OK'. If the assignment is not found, an empty json is rendered. So a http status of 'not found' is verified. In spec/controllers/sign_up_sheet_controller_spec.rb <code>.","The writeup exhibits the same issues as the code, namely that there are long sequences of text without any comments, and the prose is not formatted for readability.","Thank you for your detailed and comprehensive assignment submission. You demonstrated not only your understanding of the coursework but also your persistence in solving complex programming challenges.

Here are my comments:
1. Project compilation: You ensured the project compiled without errors, which is very important in software development. Good job!
2. Changes in the project: You identified and explained the enhancements you made, and provided your thought process for these changes. Your new functionalities are practical and helpful for instructors and students in managing the program.
3. File modification: You detailed the files you modified and the purpose of each modification. This allows for a quicker and easier tracking of changes. Great work! 
4. AJAX Implementation: Your understanding of AJAX is clearly shown in how you implemented it to enhance the Instructor's user experience. The explanations provided for your way of handling AJAX requirements are good and enrich the reader's understanding of your approach.
5. Frontend and Backend changes: Permission handling for different user roles was well implemented. You didn't just change the User Interface, but also added to the user experience by allowing the instructors to manage assignments efficiently.
6. Visual representation: The use of images was a good touch. It allowed for a visual representation of the changes made.
7. Functional testing: I appreciate the screencast demo and the steps you provided to test the app. This is very important for QA and debugging.

You do have room for improvement in a few areas:
1. Conciseness and Organization: Although detail is good, try to be a bit more precise and concise with your explanations to make it easier for the reader to understand.
2. Isolate your changes: It might be helpful to group your changes based on the individual issues identified and also provide a conclusion for each issue tackled.
3. Code snippets: Including code is very helpful. However, remember to properly format it for readability.

Overall, excellent work on this assignment. You've shown clear understanding of AJAX in rails applications. Keep on improving!"
466,E2112,"Peer-review systems like Expertiza utilize a lot of students’ input to determine each other’s performance. At the same time, we hope students learn from the reviews they receive to improve their own performance. In order to make this happen, we would like to have everyone give quality reviews instead of generic ones. Currently we have a few classifiers that can detect useful features of review comments, such as whether they contain suggestions. The suggestion-detection algorithm has been coded as a web service, and other detection algorithms, such as problem detection and sentiment analysis, also exist as newer web services..but they need to be integrated properly using API calls in expertiza code. Initially, we had planned to work on the work already done by the previous students <link> . But later on we faced many issues such as: 1) The API call links were outdated 2) The new link that we found were incompatible with the previous work 3) The planned task of adding new API calls as per Carl Colglaizer's Framework turned out to be irrelevant or not required for this project, so we dropped it. So we decided to start with integrating these API Calls from scratch. Features we added in this project 1. Setting up a config file 'review_metric.yml' where instructor can select what review metric to display for the current assignments 2. Based on the selection made by professor, API calls (sentiment, problem, sugegstion) are made and a colorful table is displayed below the review form for student to review 3. The total time taken for making these API calls will be displayed below the table. Files that are modified or added in this project 1. review_metrics.yml 2. response.html.erb 3. _response_analysis.html.erb 4. response_controller.rb 5. load_config.rb 6. response_controller_spec.rb Design Pattern In order to achieve the primary tasks of integrating the API along with making the application more extensible, the team implemented a more extensive application of the Facade design pattern to decouple the details of the calling the APIs from the caller method (here - makeArequest method). This design pattern helped us achieve the decoupling and abstraction of implementation code base (makeARequest Function) of API call from the calling function (getReviewFeedback function). Later, refactoring of _response_analysis.html.erb partial further decoupled the implementation. Thus, in a nutshell, application of facade pattern along with some refactoring lead to a decoupled implementation of integration of all 3 API calls. 1. Frontend: This image shows the flow of control for a reviewer . <image>. <image> To inspect implementation in detail, check out the 'Javascript Functionality'. In the partial view file _response_analysis.html.erb file, we added new javascript functions to make, process and display output of API calls. 1. review_metric.yml config file <code> <image> 1. response_controller.rb <code> <image> 1. response.html.rb <code> <image> 1. _response_analysis.html.erb - fetch_response_comments() function <code> <image> 1. _response_analysis.html.erb - getReviewFeedback() function <code> <image> 1. _response_analysis.html.erb - makeARequest() function <code> <image> 1. _response_analysis.html.erb - combine_api_output() function <code> <image> 1. _response_analysis.html.erb - generateTable() function <code> <image>. Here are the various endpoints for the deployment of Suggestion Detection Algorithm. (We can't make the API links unclickable for this design doc, but clicking on them won't lead you anywhere. They are just endpoints and are mentioned here for reference only.) 1. <link> for problem metrics only 2. <link> for sentiment metrics only 3. <link> for suggestions metrics only. In order to make the API call, the partial view ""_response_analysis.html.erb"" is rendered in ""response.html.erb"" view file which will be responsible for sending a JSON input to the web service. The input will contain the review comment written by the user and when the student hits the ""Get review feedback button"" the comments will be sent to these api calls in the following json format: Below is a sample input <code> Once the request is sent, we expect the output to be in the following format: Sample Output: (for sentiment analysis API call) <code> Sample Output: (for problem detection API call) <code> Sample Output: (for suggestion detection API call) <code> These outputs (which is a JSON) will be parsed and the concerned metrics such as the sentiment, problem and suggestion will be extracted so the user will be able to view a summarized result of how well their review comments are. In addition, the result will be presented in a colorful tabular format to the user after they hit the ""Get Review Feedback"" button. Also, the total time taken for making these API calls will be displayed below the table. We aim to perform automatic and manual testing for this project in order to achieve better reliability for this implementation. As for this project, very few lines of code have been written in ruby (fetch_review_metric method in response_controller.rb) we will be testing that method in response controller using rspec tests. Rspec tests for the same have been written in response_controller_spec.rb <image>. 1. The functionality was written on the client side in javascript solely in _response_analysis.html.erb 2. To test this view, any type of review must be accessible as a student. 3. There is a button at the bottom of the review called 'Get Review Feedback'. 4. When pressing button, API calls are issued and the metrics will show up within the table (a sample of which is displayed below). 5. API calls are slow and will take time to process until the 'Loading...' text disappears. 6. You can modify the comments and click the 'Get Review Feedback' button again to get new feedback, that too can be achieved without the need of saving the review, but still saving the review first is a better option to approach this. 7. All the review feedback for the comments will be displayed in a colorful table. <image>. 1. <link> 2. <link> (the link is mentioned here for records. It redirects to this same page.) 3. <link> 4. <link> (make sure you change branch to 'beta' branch if the page doesn't load by default to beta branch) 5. <link>.","Very nice visuals, and nice display of the changes made.  The document clearly presents the work that was done.  My only sugestion would be to have a bit more detail for the files changed (not only, What does the class do? but also, What do the changes do?), and the tests could be described in prose too.","Dear Student,

Thank you for your thorough and comprehensive assignment. I'm glad to note your detailed approach to problem-solving, the issues you faced, and the solutions you implemented. Your solid groundwork on integrating API calls from scratch and describing how you put the Facade design pattern to use is commendable. 

However, improvements may be made in certain areas of your assignment for better clarity and presentation. 

1. Enumerated Lists: There are multiple instances where you start enumerating points, but all your points seem to be labelled as point 1. This makes it hard to follow and understand the hierarchy of your information. 

2. Requirement References: Mention of certain specific requirements like ""Carl Colglaizer's Framework"", for example, are unclear without any context or reference. It would be helpful if you provided some background or linked to external sources for such specific mentions.

3. Graphics and Visuals: While you mention images and code samples, they are not visible. Including them in the future would be valuable, as they can provide direct visual references and better understanding for readers.

4. Links: You have included numerous links in your work but it's not clear what these are for. Providing context as to what these links lead to would be useful.

5. Objective Clarity: While your assignment is detailed, I recommend putting more emphasis on structuring and dividing content under different sections such as Executive Summary, Workflow, Challenges Faced, Solutions Provided, etc. This will help maintain clarity of thought and guide the reader through the assignment more efficiently.

It’s beneficial to proofread your work for coherence and flow. Apart from these areas, your assignment demonstrates solid work and an excellent grasp of the topic. Good job!

Kind regards,
[Instructor's Name]"
467,E1978,"1. Renaming done on the UI as well as on the backend 2. Varible names refactored appropritely 3. Flash messages changed accordingly. The error which is raised is due to the following validation present in the model late_policy.rb. 1. After discussing with professor we have decided to increase the max penalty limit to 100 2. Added a flash error message in the create function of late_policies_controller.rb <code>. 1. Added a back link in which redirects the user to edit assignment page. 2. Saved the assignment object in a session variable when the user clicks on the the edit asignment icon 3. We also added a back button on index page since there was no direct way of going back to edit assignment page once a late policy was created. 4. We also added padding between the edit and delete links on index page <code>. While testing this issue we noticed that the functionality was working perfectly fine, however, it was not user friendly. 1. We decided to add a tooltip icon explaining how this functionality works 2. We also inproved its UI by adding the alignment and padding. 1. Added test file late_policies_controller_spec.rb with appropriate test cases 2. Added test file late_policies_spec.rb with appropriate test cases. 1. <link> 2. <link> 3. <link> 4. <link>. 1. <link> 2. <link>.","This design doc has good screenshots, but I agree with some of the reviewers in saying that there should have been more desciption of your changes to the code.  Though thre isn't a lot of coding associated with the project, you could have at least described the changes for Issue 5, for example, instead of just saying that coverage would increase.  Also, collecting all the ""before"" screenshots together, follwoed by all the ""after"" screenshots is harder to follow than if ""after"" directly followed 'before"" for each issue.","Dear Student,

Great job on this assignment! You have clearly made substantial efforts to refine the user interface, improve the functionality, and ensure the backend code is well-refactored with appropriate variable names. These adjustments you made on the flash messages, the variable renaming, and refactorings are a great step toward ensuring overall code health. Your attention to updating the model validation with the new maximum penalty limit, renovating the UX for a more user-friendly navigation, and addition of relevant tooltips does enhances the project's ease of use.

Your discussion with the professor about increasing the maximum penalty limit shows your commitment to ensuring that the project meets users' needs- a quality that is very commendable.

While reviewing your assignment, I noted that you saved the assignment object in a session variable - a smart move that should enhance the user experience significantly.

However, I noticed that the code fragments were not provided. Given this, it was somewhat challenging to understand the precise dimensions of your work. When writing reports like these, it would be helpful to provide small code snippets for each point you mention. That way, it becomes easier for anyone reviewing your work to connect your descriptions to tangible programming contexts. 

The incorporation of test files indicates a good understanding of the need for implementing rigorous testing - an important aspect of any coding work, and the links you shared are helpful.

Your assignment indicates several compelling as well as effective choices with respect to the design and functionality of your program. Keep up the good work!

Best Regards,
[Instructor's Name]"
468,E1526,"<link> is a large project developed as a combined effort of students and faculty using the <link> framework. The main advantage of using Expertiza, in an educational environment, is for the instructor to introduce peer reviewing among the students. Expertiza allows the instructor to create and customize assignments, create a list of topics the students can sign up for, have students work on teams and then review each other's assignments at the end. Expertiza supports submission of almost any document type, including the URLs and wiki pages. Expertiza is supported by National Science Foundation under Grant No. 0536558. Additional funding from the <link> <link> (LITRE) program, the NCSU <link> , the NCSU <link> Initiative, and the Center for Advanced Computing and Communication. Contents 1.1. <link> 1.2. <link> 1.3. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.4. <link> 1.1.1. <link> 1.1.2. <link> 1.5. <link> 1.1.1. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.2. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.1.2. <link>. Despite an amazing set of functionality Expertiza offers, there are numerous parts of it that could use a more stylish look and an improved user experience. The goal of this project is to use both Bootstrap and AngularJS to improve the look of the entire Expertiza including the representations of buttons, tables, and other elements. Certain changes in design will also improve the efficiency of the web app when it comes to the amount of time it takes for a page to be loaded. Below are detailed explanations to the tasks listed in the description documentation. Expertiza, being an extensive web application with numerous features, heavily relies on buttons when it comes to interacting with the user. We plan to improve the user experience by replacing the plain html buttons with stylish bootstrap buttons. However, numerous elements in the current version of Expertiza, like 'Back' element, are hyperlinks rather than buttons. To make the design of Expertiza consistent, our goal is to replace this plain-styled text with color coded Bootstrap buttons. One of the entities responsible for the primitive look of Expertiza, as of now, is the lack of fixed navbar. The new design of Expertiza will include the fixed menu bar on the top of the page. Please refer to the screenshot shown below for an example from Virgin American website. As it can be seen on the screenshot, the user has scrolled down the page, but the menu bar is still visible on the top of the page, making it convenient for the user to navigate throughout the website. <image>. Please refer to the later part of this article: <link> for viewing the current design Now, when trying to open manage-courses, all records are loaded before rendering them onto the page, which takes too long time to load and is not responsive at all. Better practice is on Virgin American’s website: <link> When the website is representing the calendar, the price for each day is not actually loaded. But the skeleton of the page, which is the calendar in this case, can be displayed first. <image> So in Expertiza, we can create several buttons for course semesters in the page. After clicking on Fall 2014, the courses for Fall 2014 will come out. And if the list is still too long and takes a long time load, we can use a ‘show more’ button ,or automatically load more data when the scroll bar reaching the end of the page, to minimize the content we need to load after one single mouse click. <image>. We will need to reduce the number of buttons. For example, the first row are actions for assignments and the second row is for participant. So we can replace them to 5 buttons with responsive design, that is, no redirecting happens after clicking on the buttons. <image>. Please refer to the later part of this article: <link>. Similar to the previous tasks, we will need to make it responsive. After clicking on ‘Your scores’, all reviews are loaded before rendering the page now. That takes a long time to load and the length of review list is too long. <image>. As an assignment with a goal of improving the graphic design and responsiveness of Expertiza web application, this project mainly follows design patterns from two design pattern groups: structural and behavioral. Flyweight, a design pattern aiming to minimize the memory usage by sharing as much data as possible, is heavily implemented on the css and bootstrap side. Our team leans towards creating classes for styling that can be efficiently reused in a variety of Expertiza sections, rather than separately refining the design of each little section. This will both save us time and keep the code concise, while optimizing the memory needed to store the code. Another structural design pattern that will be seen in this project is Front Controller pattern. While this pattern suggests that there is a single controller that takes all the requests, when we have both Rails and AngularJS coexisting, we can think of Rails framework as being the ""single bridge"" to the database from AngularJS's stand point. AngularJS, being an outstanding front-end framework, will interact with the user and pass all the request to Rails framework. Rails framework then queries/updates the database and provides AngularJS with the data. Finally, the third structural design pattern that this project follows is Module pattern. Modules are one of the essential constructs in the skeleton of AngularJS framework and, hence, this project is bound to follow module pattern. <image>. Since the large part of this project is to iterate through the database query and show the data to the user with a reduced delay, this project follows the well known Iterator pattern. Along the similar lines, Observer pattern is followed to efficiently handle query requests to a large database (the main culprit behind the unpleasantly long delay). Our project intends to tackle this challenge by fetching only a screen-full of results and showing it to the user right away (fast response). While the user is looking at this first chunk of data displayed on the screen, further queries are made to the database in the background and the rest of the matching results are being returned, efficiently populating the page further. This approach greatly improves the user experience since it does not leave the user waiting empty-handed until Rails framework completes the full query of the database. <image>. For this project, it is difficult to re-design all webpages and make them responsive. After discussing with the contact person, we will be focusing only on these 3 pages: <image>. 1. Now it takes more than 15 seconds to even login to the admin's home page with the sample development database. This is definitely not good enough for a daily used web application. The cause for the long rendering time is that it will be redirected to 'tree_display/list', which needs to fetch all questionnaires, courses and assignments before page rendering. 2. The webpage looks primitive. 1. Actually it is unnecessary to fetch all data at the very beginning; if there is too much data to present, the list will be extremely long and it is quite hard for users to locate a specific course. So, we will use AngularJS and jQuery to make a asynchronous webpage that delays the database query until all the basic html elements are correctly rendered, or until the user explicitly asks for that part of data. 2. Bootstrap will be applied for better user interfaces. <image>. As illustrated above, now the displaying list is too long and it takes too long to scroll to the end, which makes locating a specific course quite difficult. Also, loading time can be reduced. 1. Create several buttons for different time intervals, for example, after clicking on the button '2013-2014', only courses for 2013 to 2014 are presenting, and there is no redirection during this process. 2. The database should not be executed before the user clicks on the button. Only parts of databased is fetched when each button is clicked. 3. Bootstrap will be applied for better user interfaces. <image>. 1. The list is too long: if there are 20k users in the database, there will be 20k rows in this table in a one page! 2. When clicking on the letter A-Z, redirections happen and the whole page is reloaded. 1. Load only a given number of records to the view, such as 100 records, when accessing into this page for the first time. 2. Using AngularJS to eliminate the redirections and page reloading for better UI performance.",Very good description of the patterns to be used. Did a good job of limiting scope of the project. Still shows the Virgin America web page; a mockup of what they are going to do would be better.,"Your project offers a well-detailed examination and plan on how to rapidly enhance the design and user experience of Expertiza using Bootstrap and AngularJS. The implications of your design choices are explained well within the project report, and the focus on improving user experience is commendable.

There are, however, areas that you need to refine for an optimum presentation:

1. The explanation about the project's reliance on buttons for user interactions could be clarified. It would be helpful if you provided more specific instances to better illustrate this point.

2. While the use of images is excellent for illustrating your points, it's essential to ensure that these images are integrated seamlessly within your text. Remember to summarize what each image represents briefly too.

3. Try to organize your thought process in a more logical manner. For instance, you could begin by discussing the current limitations of Expertiza, then outlining your proposed solutions and finally delve into the specific tasks. It would help the reader follow your argument more effortlessly.

4. The project report might benefit from more detailed descriptions of how design patterns like Flyweight and Front Controller are being used within the project. An elaboration of practical examples would add depth to your discussion.

5. The use of technical language is commendable but ensure it's followed with layman explanations to cater to the varying levels of your readers' technical know-how.

6. Your initiative on redesigning only the most crucial pages is wise considering the project's scope. However, it would be more interesting if you included some discussion on future work for the remaining pages.

Overall, a great effort with your project! The above points are merely suggestions to polish your work. Well done!"
470,E1404,"The scores for different users, participants and teams for several assignments belong to different courses are calculated for multiple views. This code is very slow because: 1. Separate db queries are used for each rubric that has been filled out by anyone associated with the assignment; these queries are made sequentially while the HTML page is being written 2. HTML for the whole page is generated, largely by controller methods, before anything is displayed. This code needs to be made faster. Requirement: Participant.find(participant id).scores # should return a Hash or new object, with a single database query. This method should return the scores of a participant from all the assignments in which the participant has submitted. 1. Participant already has its own participant id. Each user has a different participant for each assignment so we do not need to take participant id as the parameter. 2. This also means it should return a hash that will contain the scores of all the assignments in which this user is a participant since participant id changes each time. 3. Thus, the above requirements need to be changed. Instead of having a Participant.find(participant id).scores, we wrote an all_scores method in the grades_controller (since grades controller does score calculation and display for other similar features such as view_my_scores). A new view was required since this view did not exist previously. A new link has been added to the user's homepage: <image> On clicking on this link, the user will be able see his scores for all the assignments he/she has participated in. This is a new view and will look as below: <image>. We needed to write a method and add a view that computed and displayed the scores of a user across all the assignments user has participated in. We added a new method all_scores in the grades_controller.rb. This method executes the following steps: 1. :Executes the below sql query: <code> The user_id is of the current user is passed as a parameter to this query. 1. From the result obtained from the above query, we create a hash of the format: assignment name => questionnaire type questionnaire type is again a hash that is of the form: questionnaire type => score_type The score type is a hash that takes any of the three values [avg, max and min] as key the value will be the actual score. Once the hash is created and populated accordingly, this hash is used by the view to display to the user. Requirement: assignment.scores # should return a Hash or new object, with a single database query. This method should return scores of all the participants in an assignment. This can be done by using following methods: 1. Use joins on database tables participants and response_maps 2. Create a join on above mentioned tables to retrieve grade for participants in an assignment. We observed the following issues in the previous code and took the following design decisions: 1. The previous code looped through the questionnaires of the assignment and collected the related questions in an array. This array is used to compute the score for each question. Instead, we get the scores in the query itself thereby reducing the complexity of the code. 2. The previous code was calling several methods that computed the different parts of the score in a loop. These methods seemed similar in their naming and looked to be a candidate of yo-yo effect. We tried to reduce this by having the database query (wherever possible) do most of the work for the method and the method just populate the hash. 3. Even though the single query approach works faster, for assignments that have a lot of responses, we noticed that the code still took some time to complete. The query in itself runs fast (when executed directly on the SQL server). However, this seems to be bottleneck for the rails interface to the database itself. The scores are computed in the get_scores method of the assignment.rb. Previously this code worked as follows: 1. For each participant the participant.get_scores is called for each question. For all quiz questionnaires taken by the participant, get all the quiz responses. Create a hash and store the score computed by calling Score.compute_quiz_scores. The total score is then calculated and stored in the hash by calling compute_total_score for each participant. 2. For all teams that participated in this assignment, get the scores into the hash by calling Score.compute_scores for each assessment and questions. This method is specifically slow because the first step consists of several substeps, performed inside a big loop. Each of them might query the database adding to the time taken. We refactored this code to have the following steps: 1. Created an empty hash before hand. 2. Run a single SQL query that will return all the data required by the hash. 3. Loop through the result set to populate the hash. This speeds up the code since there is only a single SQL query that will get executed. The loop runs only for the number of rows in the returned result set. This means that the loop runs only for the assignment submissions that got scored. The query is outside the loop and hence reduces the time required. The old code and the new code were tested against the same database, on the same machine and network and it was observed that there was a significant reduction in time taken to get the scores. Snapshot of the time taken for the previous method: <image> Snapshot of the time taken for the method after the above changes: <image> As can be observed, the improvement is significant. Requirements: Add a method course.scores which should return a Hash. This method should return scores of all the participants enrolled in a course. 1. We needed to get the scores of all users for all assignments for a given course. A new view was required since this view did not exist previously. This view will be displayed on clicking on the View Scores option in the Actions panel of the courses as highlighted below: <image> On selecting the highlighted option above, the following page will be displayed: <image>. We needed to write a method and add a view that computed and displayed the scores of all users that have enrolled in a course. We added a method named view_course_scores in the grades_controller.rb. This method does the following steps: 1. Creates an empty hash. 2. Runs a single SQL query as below: <code> The course id is passed as a parameter to this query. 1. The result returned from the query is used to populate the hash. This hash is then used to display the different parts of the view. The following guidelines were followed wherever possible to achieve the above objectives, especially keeping in mind that they must make the implementation fast: 1. Single query instead of multiple queries. 2. Queries extracted outside loops. 3. Avoided method calls where values could be obtained in the same SQL query itself. 1. The SQL queries could possibly be made to work faster if we could come up with a better query plan or use indexing. 2. The SQL queries could be compiled into database views. We did not do it right now since we wanted to adhere to the existing hashes that were created and keep the code change as simple and minimal as possible. However, if such is required, the query can be made into a database view. 3. The view_my_scores method in the grades_controller can also be made similarly fast by replacing multiple database queries and loops with a single query.","Covers the topic, but not particularly easy to read (motivation is skimpy).","Dear Student,

Thank you for your detailed and insightful assignment response. You clearly exhibited an in-depth understanding of the technical aspects of the assignment, and provided a thorough examination of an optimized solution for speeding up the existing code.

Your comprehensive approach to the reiteration of the requirements, converting them into a more rational model through method formulation, is commendable. The strategic idea of adding the ""all_scores"" method to ""grades_controller"", to accomplish the task of score calculation across all assignments, came across quite practically.

Equally impressive is the thoughtful approach you took by optimizing the database queries and subsequent hash population for scores retrieval. The thoughtful approach you took towards SQL queries, leveraging consistent execution speed regardless of the data size, was particularly notable.

Your code refactoring techniques and proposed measures to reduce the time complexity reflect a high level of understanding of the principles of software engineering. The comparative discussion regarding the performance of the old and new codes demonstrates your excellent evaluative skills.

You have also shown great attention to possible enhancements in the future, suggesting improvements for query planning and indexing, and proposing the idea of compiling SQL queries into database views.

Though your document is elaborate and detailed, incorporating images demonstrating your changes and results would have been more helpful for comprehensive understanding. Also, including the actual code used for the queries can give a much clearer picture.

There were quite a few grammar and punctuation oversights, which could potentially hinder fluent reading and require additional time for understanding. In the future, please take more time to proofread your submissions.

Overall, your approach to problem-solving and applying optimization strategies is impressive. Continue researching and learning new ways to add value to your software engineering skills. Keep up the great work!

Best,
[Instructor's Name]"
471,E1451,"<table>. <link> is an <link> <link> application designed to support team/individual student projects which involves team creation, project sign up, project submissions, document upload (almost any format), and carry out multiple peer review processes for learning and educational purpose. The rationale behind Expertiza is that the students should not only be consumers but also creator of educational resources. Based on this philosophy, the tool is extensively managed and consumed by students of class CSC517 Object Oriented Programming Languages and Systems course at NC State University as their main project management tool. This Open Source application can be cloned from <link> , the latest active branch is <link> . <link> supports email functionality within a Rails application, which involves sending and receiving emails from and to an application. The scope of the Action Mailer within Expertiza is limited to sending emails only which we have proposed to extend to 'Receiving' under the heading ‘Future Work’. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.4. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.5. <link> 1.1.1.1. <link> 1.1.6. <link> 1.1.7. <link> 1.1.8. <link>. Design strategy has been one of the major issue for erratic behavior of Mailer within Expertiza. From past few years the Expertiza has been combined with various enhancements and the code has been changed by different teams, the difference in the implementation practices has introduced major design flaws within some components (including Mailer) of the application. Another major issue is the migration issue from <link> to <link> as a result of which many of the unsupported features for Rails 4 have stopped working. The aim of this Mailer project is to bring consistency in the design implementation and restore the e-mailer and e-mail messages capability from Projects E701 and E729, and bring back the new features created by Project E916. High-level requirements are listed below: 1. Restore features and functions in Expertiza that trigger email messages 2. Create mailers for all email messages for both asynchronous events and synchronous events 3. All emails should be sent via ActionMailer 4. Emails should have different class Significant amount of time has been spent on correcting bugs and errors in the program before the email features can be restored, and therefore this wiki also documents the changes our team has made and provides a guideline for future development and enhancement. Expertiza has two different Mailer implementations based on type of <link> : Synchronous events and Asynchronous events.<ref> <link> </ref> The synchronous events refer to events that should be immediately notified. For example, email should be sent immediately after a review; or after a feedback of the review has been posted; or a user/team is assigned a project, or a social bookmark have been added, etc. Asynchronous Events are a series of timed events which gets triggered at some fixed times, such as weekly quiz reminders, deadline approaching reminders or in fact Sign Up topic availability reminder is a very explanatory example of Asynchronous Events. Below mentioned are the changes made in each of the Mailer implementation and in related files. All synchronous events are triggered by <link> and the call is made to app/mailers/mailer.rb (formally as model in /app/models/) via the sync_message() method call. Here mailer.rb extends <link> class. Because part of the email implementation was done on Rails 3 platform, to make it compatible for Rails 4, revision has been made. The required email template has been added for both generic_message and sync_message method calls. Here is an example of synchronous event email that simulates an event when the work you reviewed before has been revised. 1. app/models/mailer.rb has been moved to app/mailers/mailer.rb 2. Two view templates have been added to app/views/mailer directory. They are sync_message.html.erb and sync_message.text.erb <code> 3. Correct <link> and <link> codes have been added to app/views/mailer/generic_message.html.erb 4. The following line in the sync_message(defn) method has been commented out from app/mailers/mailer.rb in order to encode email correctly.<ref> <link> </ref> <code> 5. The following method calls in the following files have been changed. a) app/controllers/grades_controller.rb b) app/models/courses_users.rb c) app/models/participant.rb Original: <code> Changed: <code>. The asynchronous events are registered to <link> object and a <link> server must be activated to carry out the task. All events are called to DelayedMailer class in /app/emailers/delayed_mailer.rb via one of the following methods: email_reminder(), mail_assignment_participants(), mail_reviewers(), mail_metareivewers(), getTeamMembersMail(), and mail_signed_up_users(). The DelayedMailer class acts as a wrapper class (i.e., adapter pattern <ref> <link> </ref>) to the Mailer class in the /app/mailers/mailer.rb via the delayed_message() method call. These events are added to the <link> by Delayed::Job.enqueue() command. Each event as record is stored in the delayed_job table, which can be browsed on <link> . Because all of the asynchronous events are controlled by the assignment controller, events are triggered by the add_to_delayed_queue() method. Each time when an assignment is updated or saved, all of the event queues associated with such assignment are refreshed. We found this is not very efficient but it has worked as expected. The database migration issue occurs when carrying out ""rake db:migrate"" command. We found the mirrored image from the existing database still has incorrect table fields. The problem may not appear until later during feature testing. Therefore, our team decided to fix the data migration issues from ground up. In total, more than 36 files have been fixed. Most of them are database migration files. To eliminate future table creation issues with <link> gem, we have also changed the integer byte length of <link> tables from 10 to 8 and have revised the <link> methods inside the migration files to improve efficiency. The methods missing from the app/models directory related to site_controller have been restored for controller_action, menu_item, permission, role, and site_controller models. <code> Changes to data migration files are illustrated as follows: Original: <code> Changed: <code> Detailed code changed can be found at <link> . Each due date for submission, review, meta review, sign up, and drop topic were missing under the Assignment edit page due to the bugs in its views and partials files. The <link> implementation was done via <link> gem <ref> <link> </ref> but it has not been parsed correctly. After the issue has been fixed, now the correct due dates are displayed correctly. The following changes have been made: 1. All *.rhtml files in app/views/bookmarks have been renamed to *.html.erb for compatibly reason. 2. The following lines have been added to Gemfile <code> 3. The following parsing errors in app/controllers/assignment_controller.rb have been corrected. Original: <code> Changed: <code> 4. The following code in ap/views/assignments/edit/_rubrics.html.erb has been changed. Original: <code> Changed: <code>. <link> is a <link> framework for <link> programming language. Inspired by <link> , it resembles a <link> specification. To test the emailer features, we have restored <link> test cases for both delayed_mailer.rb (asynchronous maier) and mailer.rb (synchronous mailer). Because the existing RSpec files were developed in RSpec 2.x, upgrade is required. Ideally, the files in /test/fixtures should be used to populate the test data for RSpec, and therefore we did not restore all the files in /spec/fixtures/ directory. Currently, the fixture<ref> <link> </ref> files are not completed and loading them into the test database may cause failure for the test, so we recommend to comment out the following line in the /spec/rails_helper.rb <code> Future developers must take extreme care to make sure all fixture files work before enable this option. 1. The two test files listed below have been added spec/ directory: a) spec/integration/delayed_mailer_spec.rb b) spec/models/mailer_spec.rb The following code has been added to each test case: <code> 2. The following code has been added to spec/rails_helper.rb in order for the RSpec to pass the test. <code>. Because asynchronous events require a daemon running in the background and the new Delayed::Job class for Rails 4 has additional fields, the following steps are recommended. 1. Install Expertiza and execute 'bundle install' 2. Create database and perform data migration using 'rake db:migrate' 3. Execute 'rails generate delayed_job:active_record' at the prompt. This will create a delalyed_job file in /bin directory. 4. Execute 'rails generate delayed:upgrade' if delayed_job has been created before. 5. Enter your <link> server account settings in config/environments/production.rb file. You may find an example in config/environments/developments.rb file. 6. Start the rails server by entering <code> 5. Start the delayed_job server by executing <code>. 1. The due date for signup activity may not display correctly. To refresh, users must click the ""review round"" button or the ""save"" button again. 2. Each time an assignment is saved all delayed_job tasks will be deleted and refreshed even if the dates have not been changed. This may not be very efficiency and may cause problems in the future. Checking mechanism should be built in to verify if any date has been changed. 3. DateTimePicker field could be accidentally changed by mouse click. 4. Prioritization in the Delayed Job function in case of multiple email load 5. Extending functionality to include Weekly/Monthly digest that can consist of users WebAssign summary. 6. In-built messaging (Inbox, Sent, Draft etc.) functionality in addition to email for easy tracking of outgoing and incoming messages. 7. Extending Expertiza's scope to include 'Receive' email functionality. <references/>.","Good writeup, till we get to ""Known issues"". Most of them are not clear at all.","Good effort on the assignment. First, you clearly understand the tasks required in using Expertiza. You have given comprehensive account of the challenges you've encountered, how you overcame them, and how you have proposed to make adjustments to make the system better. Your command of object-oriented programming languages is good, as is made clear by your analysis.

However, there are a few areas where improvements can be made:

1) Organization: Your assignment would benefit from more clearly labeled sections and subheadings to indicate the distinct parts of your assignment. Headers such as ""Background,"" ""Programming Challenges,"" ""Proposed Changes"" would guide reader's understanding better.

2) Incomplete Links: It seems like your assignment included links but they are not working correctly. Please revise and replace the dummy <link> placeholders with the actual links. 

3) Grammar and syntax: There are several instances of grammatical errors in your essay which disrupts the flow and readability of your content. For instance, ""Another major issue is the migration issue from <link> to <link>..."", try replacing the second instance of ""issue"" with ""challenge"" or ""difficulty.""

4) Code Samples: Where you've given code, ensure that they are correctly formatted for easier reading and understanding. 

5) References: Ensure all references are correctly labeled and linked at the end.

All these suggestions will make your work more clear, accessible, and easy to understand. Keep practicing your programming skills, and your written communication skills will improve with practice as well. Good job so far!"
473,E1980,"1. In Expertiza, peer reviews are used as a metric to evaluate someone’s project. Once someone has peer reviewed a project, the authors of the project can also provide feedback for this review, called “author feedback.” While grading peer reviews, it would be nice for the instructors to include the author feedback, since it shows how helpful the peer review actually was to the author of the project. Expertiza allows instructors to view kinds of reports of assignments in their courses such as submissions, scores, and review reports. To improve the report views, some table columns such as team name, score, the average should be made sortable by using the same existing sort library. Workflow <image>. We have to sort “Review done”, “Team reviewed”, “Score awarded/Avg score”. in the “view review report” table. The sort button should work on all browsers, not only chrome. <image>. We will be using tablesorter function of jQuery to sort the table.To sort the columns that have constraints, custom scripts will be created. Tablesorter supports custom sorting. According to the problem type, we are supposed to perform three kinds of sorting. We need to make changes in the table head tag. By default the sorting is disabled on the columns, we must enable sorting on those columns in order to make it sortable. Three types of scenarios may arise: 1. Sorting by columns alphabetically - To sort the columns alphabetically, the table-head attribute must include sorter-true class with it. 2. Sorting by date - Sorting by date includes creating a generic format for all dates(mmddyyyy). This generic format will be used to parse dates and sorting will be done based on this format. 3. Sorting by the first number followed by the second number - It will require splitting up of the data into two parts separated by '/' and then sorting the first part, followed by the second part. For “Author feedback report” table, we have to change the header name “Review response rejoined” to “Review responded to” and “Last rejoined at” to “Last responded at”. Then, sort “Rejoinder” and “Review “Review responded to” as string (alphabetically), sort “# author feedbacks done” by the first number then the second number (same as “Review done” in the “View review report” table) and sort “Last responded at” as date. We will use tablesorter function of jQuery to sort the table. To sort the columns that have constraints, custom parser will be created and used on top of tablesorter. The approach is similar to the first issue. <image>. When the user clicks on the “View reports” icon, a page appears with a dropdown. However, that page does not say what assignment’s reports are being viewed. Add a header, “Reports for [name of assignment]” at the top. We will add header on top of Dropdown menu. For this we already have assignment name in the _searchbox.html.erb partial. We will use that above the search box to display the name of assignment. <image>. For Author feedback reports, when no feedback has been submitted by any student, the names of the participants appear in a strange horizontal format. Fix this so that the formatting is correct, regardless of how many participants have done author feedback. <image>. In file _feedback_report.html.erb The main issue behind the unusual horizontal format of all rows (student ID) is due to the value of rowspan=0 when there are no reviews. This causes all new potential rows being viewed on same single row. So to solve this issue, we will change @rspan variable value in review_mapping_helper.rb. We will add a condition to check the value of @rspan. If @rspan is 0, we will change it to 1. This will make one entry of student per row in the table. <image>. 1. app/assets/stylesheets/table_sorter.scss (issue 1) 2. app/controllers/tree_display_controller.rb (issue 1) 3. app/helpers/review_mapping_helper.rb (issue 5) 4. app/views/reports/_feedback_report.html.erb (issue 2) 5. app/views/reports/_review_report.html.erb (issue 1) 6. app/views/reports/_searchbox.html.erb (issue 4) 7. app/views/reports/_teammate_review_report.html.erb (issue 3) 8. spec/features/review_mapping_helper_spec.rb (issue 5). We have modified the app/views/reports/_review_report.html.erb file. We added jquery tablesorter in the script section to sort the columns. We had to enable the sorting on various columns so we added ""sorter-true"" in class of all the table headers. To make the UI consistent, we used the glyphicon that is used uniformly across expertiza and placed it behind table header data. Added the following script to the file. <image> <image> <image> <image>. We used jQuery tablesoter to sort the data in app/views/reports/_feedback_report.html.erb. We created custom parser to sort the dates in the last column and placed it tablesorter script. The custom date parser parses the date in the form of mmddyyyy. In rejoinder column, the student is displayed only once for entire feedback as shown in figure below. This led to blank data entries in the <td>. Due to blank columns the tablesorter threw an error. To rectify this, we created a CSS style tag and Javascript function to dynamically change the visibility of data in <td> tags. When the sorting is done based on rejoinder column, student data in rejoinder column will be hidden. While sorting on other columns, data in rejoinder column will be made visible. <image> <image> <image> <image> <image> <image> <image>. We added a header on top of Dropdown menu. For this we already had assignment name in the _searchbox.html.erb partial. We used that above the search box to display the name of assignment. <image> <image>. We changed in app/helpers/review_mapping_helper.rb for this issue firstly we found out the cases for which rspan was coming to be 0 and then changed the rspan value to 1. <image> <image>. For Sorting Review Report Table 1. Login to expertiza using the above credentials. 2. Under Manage Notifications tab click on Assignments. 3. Under Assignments click view report. 4. Select Review Report from Drop-down menu. 5. Sort the columns by Clicking on it. For Sorting Author Feedback Report Table 1. Login to expertiza using the above credentials. 2. Under Manage Notifications tab click on Assignments. 3. Under Assignments click view report. 4. Select Author Feedback report from Drop-down menu. 5. Sort the columns by Clicking on it. For Sorting Teammate Review Report Table 1. Login to expertiza using the above credentials. 2. Under Manage Notifications tab click on Assignments. 3. Under Assignments click view report. 4. Select teammate review report from Drop-down menu. 5. Sort the columns by Clicking on it. For Missing Header on View Reports 1. Login to expertiza using the above credentials. 2. Under Manage Notifications tab click on Assignments. 3. Under Assignments click view report. 4. Name of assignment should be displayed above the drop-down menu. For Rendering Proper Format in Author Feedback Report 1. Login to expertiza using the above credentials. 2. Under Manage Notifications tab click on Assignments. 3. Under Assignments click view report. 4. From drop-down menu select Author Feedback Report. 5. Students will be displayed in proper format. References 1)Expertiza Github <link> 2)Github Pull Request <link> 3)TableSorter Documentation <link> 4)Live Expertiza <link> 5)Youtube Video <link>.",Quite a good description of the changes to be made and how they were implemented.  There is no mention of automated tests.,"This assignment is generally well-done and thoughtful but there are concerns to be addressed. 

1. Clarification: The explanations and steps are comprehensive, but certain sections need further refining for better clarity. Ensure each step and process is transparent and adequately detailed.
 
2. Use of Media: It would've been more effective if you could include actual images or diagrams in places where you mentioned ""<image>"". Specific illustrations would help to grasp the concept better.

3. References: Always remember to provide the actual links for references where you mentioned ""<link>"". Actual links will aid in cross-verification of the sources referenced.

4. Language: At times, the language used is ambiguous and could lead to misinterpretation. Be sure to opt for clear and straightforward expression.

5. Proofreading: There are some areas where grammatical errors are evident, disrupting the smooth flow of reading. It is advised to proofread your work before submission to avoid such grammatical mishaps.

6. Code Formatting: Ensure that when you include code in your assignment, it is formatted correctly. Use punctuation as required and break lines where necessary for better readability.

7. Consistency: Ensure consistency in your writing. For example, there are instances where you refer to the same thing in different ways, which could confuse the reader. 

8. Conclusion: A summary or conclusion at the end of your assignment would have been beneficial. It serves to round off your work and emphasizes the key points that you discussed. 

Overall, your assignment features a good deal of thorough analysis and practical examination. However, it will be significantly enhanced by focusing on and addressing the aforementioned points."
474,E1808,"<link> is a platform through which students are able to view and manage their assignments, form teams for a group project and review other team's work for improvement. It uses <link> Framework. 1. Refactor automatic_review_mapping method 1.1. Write failing tests first 1.2. Split into several simpler methods and assign reasonable names 1.3. Extract duplicated code into separate methods 2. Refactor response_report method 1.1. Write failing tests first 1.2. Use factory pattern to create a corresponding report according to the switch condition 1.3. Create corresponding helper classes for different report types. 1. app/views/review_mapping/ 1.1. _answer_tagging_report.html.erb 1.2. _calibration_report.html.erb 1.3. _feedback_report.html.erb 1.4. _plagiarism_checker_report.html.erb 1.5. _review_report.html.erb 1.6. _self_review_report.html.erb 1.7. _summary_report.html.haml 1.8. _summary_reviewee_report.html.haml 1.9. _team_score.html.erb 1.10. _teammate_review_report.html.erb 2. app/views/user_pastebins/ 1.1. _save_text_macros.html.erb 3. app/controllers/ 1.1. review_mapping_controller.rb 4. app/helpers/ 1.1. response_report_helper.rb 1.2. review_mapping_helper.rb 1.3. automatic_review_mapping_helper.rb 5. spec/controllers 1.1. review_mapping_controller_spec.rb 6. spec/helpers 1.1. automatic_review_mapping_helper_spec.rb. Review mapping controller handles the review responses that are done on every assignment. It assigns reviews to different teams or individual student depending on the type of assignment(team project or individual project). It keeps track that all the teams are reviewed and assigned teams to review too. Refactoring is used to improve a design code by changing the structure of the code such that the functionality remains the same. The changes made are quite small, but the overall effect becomes significant. As this method was long and complex it needed to be broken down into smaller methods with specific functionality. Original: <code> After Refactoring: <code>. This method automatic_review_mapping was very long and complex. A few methods in the controller were acting as private methods for this method and were being called only in this method. So this automatic_review_mapping method was split into smaller methods. All these small methods and the private methods were shifted to a helper class: AutomaticReviewMappingHelper. Methods 1. initialize(created) 2. automatic_review_mapping_strategy(updated) 3. execute_peer_review_strategy(updated) 4. peer_review_strategy(updated) 5. assign_reviewers_for_team(updated) The common parameters that are used in the automatic review mapping method are defined here so that they can be used as instance variables throughout for better flow of the code. <code> <code> <code> <code> <code>. This method consisted of long case statements making it a long and complex to understand. So this method was refactored using Factory Design Pattern. Original <code> After Refactoring <code>. As seen, the controller method originally was sharing a lot of instance variables with the corresponding views, and it has the long switch statements. Each switch condition is corresponding to a different type of report. Thus, different report helper classes are created for different types of report. These helper classes are grouped in the helper module: ResponseReportHelper. <code> <code> <code> <code> <code> <code> <code> <code> <code> The <link> is used to create a corresponding type of report, according to the switch condition. <code>. 1. Tests for these methods already existed. We altered them according to the refactoring that needed to be done. 2. Additional tests were added for the corner cases that weren't being tested. 3. The part which is not tested, contains local variables and hence was not tested in rspec. 4. After Refactoring the tests pass for all the test cases. 5. Test cases for automatic_review_mapping for which tests are run: 1.1. all the parameters are 0 1.2. all parameters except student_review_num are 0 1.3. calibrated parameters are 0 review_num are non-zero 1.4. Team is empty, max team size is 1 and when review_num parameters are not zero 1.5. Create Teams when team is empty 1.6. when artifacts num are non zero it should set the instance variables and call methods. 1. Test cases for response_report for which tests are run: 1.1. when type is SummaryByRevieweeAndCriteria 1.2. when type is SummaryByCriteria 1.3. when type is ReviewResponseMap 1.4. when type is FeedbackResponseMap 1.5. when assignment does not have varying_rubrics_by_round feature 1.6. when type is TeammateReviewResponseMap 1.7. when type is Calibration and participant variable is nil 1.8. when type is PlagiarismCheckerReport Tests for automatic_review_mapping: <code> Test for response report: <code> Additional Tests in the Controller: <code> Additional Tests in helper_spec: <code>. Tests passed for Revised Code: 1. Test for helper <image> 1. Test for Controller <image>. 1. Download <link> (Download an Ubuntu-Expertiza image (.OVA) including latest DB.) 1. Install VirtualBox and import this image to the VirtualBox. 2. clone the repo (steps 2 to 5 are executed from the terminal in the image.) git clone <link> 1. go to expertiza folder cd expertiza 1. run bash setup.sh bash setup.sh 1. run bundle install bundle install 1. run rails server rails server 1. Use firefox in the image and test response_report method 1.1. Type in <link> 1.2. If you need to log in, use account name “instructor6”, and password “password”. 1.3. In order to view different reports, select different types of report and click “Submit” button. <image> 1. Use firefox browser in the image and test automatic_review_mapping method 1.1. Type in <link> 1.2. If you need to log in, use account name “instructor6”, and password “password”. 1.3. select Insturctor-Selected from Review Strategy dropdown <image> 1. 1.1. Here are three different strategies to assign reviewers. In order to assign reviewers, enter a number in the text field and click “Assign reviewers” or “Assign both calibrated and uncalibrated artifacts” button. <image> <image> <image>. 1. <link> 2. <link> 3. <link>.","There is a good explanation of the code changes before the code is presented, but later on there are places where several methods are juxtaposed without any explanation about what they do.

It is good that you described how the Factory Method pattern was used.","Dear Student,

The thorough work presented in this assignment is commendable. Your understanding of the assignment requirements and goals is clear, and your approach towards solving the problem is well planned and methodically executed.

Your analysis of the situation was logically sound, and the process you used to refactor the code exhibits a firm grounding in the principles of software development best practices. In particular, the segmentation and reconstruction of the methods along with the modular approach toward utilizing helper classes for different types of reports, shows an ability to understand and apply principles such as the single responsibility principle, encapsulation and modularity. 

Your detailed explanation of the changes in code structure suggests a high level of understanding with regards to the complexities involved in maintaining and enhancing existing codebase. This is an essential skill for software developers. The use of the Factory Design pattern displays your grasp on adopting design patterns to improve code structure and maintainability. 

Your tests seem well thought out and it's great to see that you are aware of the importance of testing in software development. Also, incorporating edge cases in your tests ensures the robustness of your solution.

However, the assignment can be improved upon in the following ways:
1. Include comments in your code. It enhances readability and understanding of the code.
2. The explanation of your code and the functionality could be more brief.
3. Your explanation regarding how the original code was refactored could be clearer.

On the whole, this is an excellent work which shows that you are making commendable progress in understanding complex software development concepts and applying them judiciously. Keep up the good work!

Best,
[Your Name]"
475,E1456,"Contents 1.1. <link> 1.2. <link> 1.3. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.4. <link> 1.5. <link> 1.6. <link> 1.7. <link> 1.8. <link> 1.9. <link> 1.10. <link> <link> <link>. Questionnaire Controller interacts with the user to create and edit questionnaires such as review rubrics, teammate-feedback rubrics, quizzes, and surveys. This page provides a detailed description of Open Source Project on Expertiza for refactoring the questionnaire controller. Why is Refactoring Required 1. It helps in making the code more understandable 2. It makes the code more maintainable 3. To remove repetition of code. The scope of the project is to refactor Questionnaire Controller which is very huge, in order to follow the standard principle of Fat Models and slim controllers. 1. questionnaire_controller.rb 2. questionnaire_helper.rb 3. advice_controller.rb. 1. Functionality moved to quiz_questionnaire.rb. 2. edit_advice method was not being used, so it was removed. 3. save_advice moved to the advice_controller. 4. copy, update_quiz, valid_quiz methods were long and have been broken up. clone_questionnaire_details was also broken up and renamed. 5. Added comments to select_questionnaire_type 6. Debug output (print statements) have been removed. 7. Changed code to follow the global rules. 8. save_new_questions, delete_questions, save_questions have been moved to a separate class. <link> <link> <link>. A Subset of the UML class diagram including only the related classes for this project can be drawn as shown below. <image> Questionnaire Controller is the superclass of QuizQuestionnaire and all the other classes - User class, Advice class and Questionnaire classes are related model Classes to the controllers that we have modified. Several methods in Questionnaire Controller class required refactoring to ensure that the change is reflected in the entire project. The names were changed to follow method naming conventions in Ruby. Deprecated code was removed and re-coded to ensure that the code worked in future version of Rails as well. Duplicate codes were commented out. Methods that are more general in the sub classes were moved to the parent class. Some methods that calculate that were colliding with other files were moved to a helper method questionnaire_helper.rb . <table>. 1. The quiz questionnaire related methods such as view_quiz, update_quiz, new_quiz and validate_quiz are moved to questionnaire_helper.rb to make the questionnaires_controller thin and follow global rule of thin controllers and fat models . <image> 2. Non Restful method names changed accordingly to make them Restful. Before <code> After <image> 3. edit_advice method is evidently not used, and removed. This edit function is already implemented in advice_controller.rb. 4. save_advice has been moved to the advice_controller. 5. Global rule changes for using Hash - value key pair implemented [Use key: ‘value’, not :key => ‘value’] accordingly. <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> 6. "".eql? nil"" used instead of "" == nil"". <code> 7. Removed duplicate and redundant code making the code DRY. <code> 8. Removed unnecessary debug prints present in the code. <code> 9. Used `&&` and `||` rather than `and` and `or` to keep boolean precedence as per global rules. <code> 10. More global rule changes. <code>. The following object oriented design principles were followed during refactoring: 1. Single Responsibility Principle : The single responsibility principle states that every context (class, function, variable, etc.) should have a single responsibility. It was maintained that each method should be involved with a single responsibility and the code that was not related to that particular functionality was moved to other method. This was also taken care of in terms of classes. 2. DRY Principle : Don't Repeat Yourself! The repetitive and redundant code was removed from the associated classes and methods. We tested the functionality of the questionnaires controller before and after refactoring by manually creating and listing the questionnaires, there is no change in behavior observed. Please find the snapshots below for reference. After Refactoring, the questionnaire controller is working as before. <image> <image> <image>. 1. Refactoring was performed as per requirements in the files questionnaire_controller.rb, and advice_controller.rb. 2. The code from models cannot be moved directly to controllers, so the code was moved to the helper class questionnaire_helper.rb. 3. Some methods with confusing method names have also been renamed. <link> <link> <link> <link> <link>.",Very clear.,"Dear Student,

This is a very thorough and detailed work on refactoring the questionnaire controller. You have clearly demonstrated an understanding of the task and the key principles of object-oriented software, including Single Responsibility Principle and DRY Principle. 

Also, your reasonings for the need to refactor and the benefits it brings, as well as your explanation of the entire process, were articulate and concise. The use of code snippets and visual aids added value by making your descriptions clearer and more tangible. 

However, here are a few areas you could enhance:

1. In the initial part of your assignment, you've listed a number of links but without any explanation of what they're for or where they take the reader. It'd be helpful to provide context and captions for each link.

2. Consider explaining a bit more about what specific functions the Questionnaire Controller had before the refactoring and how these functions have been improved subsequent to your work.

3. It would also be helpful to include some explanation about the changes you made regarding the QuizQuestionnaire and why these specific changes were necessary.

4. The use of UML diagrams is commendable, but make sure you provide full interpretation and analysis of these diagrams. Describing each component of the diagram (like class, object, etc.) would make your explanations more beneficial.

5. Finally, although you've mentioned that no changes in behaviour were observed post refactoring, it would be beneficial to document how you tested the functionality both before and after refactoring. Adding more screenshots to back up your testing may be helpful.

The assignment was done to a high standard, and the feedback is for refining your future work. Great job overall!

Best,
[Your Name]"
476,E2107,"Expertiza has a functionality that allows students and instructors to receive and give grades, respectively. This functionality is implemented in the grades_controller.rb file. This controller currently violates some essential Rails design principles including having too much calculation and having methods' names that violate Ruby naming convention. Here are the refactoring steps needed to be taken in order to fix the grades_controller.rb . 1. Create a new private method to encapsulate the population of the view model for all the necessary data (lines 102-107). 2. Simplify the logic surrounding the error flashing. The nested logic seems unnecessary (lines 190-192). 3. In line 300: 1.1. Increase readability by fixing whitespace according to the common Ruby Programming guidelines. 1.2. Return is not needed here. 1.3. Remove space between ‘!’ and its argument. 1.4. Use meaningful variable names and break up the expression. 4. Move these functions into grades_helper.rb and change their names to be more Ruby-like: 1.1. calculate_all_penalties 1.2. calculate_penalty_attributes 1.3. mean (also cease the usage of the assignment) 1.4. calculate_average_vector 1.5. build_score_vector 1.6. Remove_negative_scores_and_build_charts 5. The previous programmer used update_attribute, which is concerning, as validations are ignored (Line 153 and 219). 1. Comment changed that was wrong (""head"" into ""heat"") <image> 1. Line 102-107 (New Private Method made to encapsulate this) <image> <code> <image> <code> <image> 1. Line 190-192 <image> <code> <image> 1. Line 300 <image> <code> <image> 1. Lines 153/219 <code> <image> <image> <code> <image> <image> <code> <image> <image> <code> <image> <image> <code> <image> <image> <code> <image> <image> <code> <image> <image> <code> <image> <image>. To test this controller, run the following command to verify the changes do not break any core functions. <code> <image> <image> When you run the program and get to login page. Use credentials below for instructor. <code> <image> A good student to impersonate for testing is <code> <image> <code> <image> <code> <image> <code> <image> <code> <image> 1. To Do: Add Rspec tests to grades_helper.rb Important views for using refactored functions <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code>.","The page is pretty well organized in what changes they made. Their pictures were not taken with a screenshot, instead were just taken with their phone camera. They didn't provide a manual test plan, which is problematic as we have no good way of verifying their changes without significant work involved.","Dear Student,

Thank you for submitting your assignment on refactoring the grades_controller.rb in Expertiza. You've provided a comprehensive set of actions necessary to improve the controller, observing both Ruby and Rails best practices.

One comment I have is related to the changes you have suggested for line 300. You mentioned how meaningful variable names can increase readability — this is an excellent point. However, being specific about the current variable names that you'd suggest switching out would be helpful in your critique. 

Your plan to move multiple functions into grades_helper.rb is well-justified. It's clear that having these calculations separate from the controller will simplify the controller and make the codebase more maintainable. Please, in the final implementation ensure that the new function names strongly adhere to Ruby standard naming convention.

You also correctly identified the misuse of update_attribute, as it skips validation. In such cases, it would be more appropriate to use update or update! in the place of update_attribute.

Unfortunately, I cannot provide specific feedback on the lines of code and images included in your assignment, as they have not been displayed here. Make sure to properly attach or embed images and code snippets in your future assignments, for a more thorough review. 

Lastly, I appreciate your intent of testing the refactored controller by impersonating a student. However, remember that manual testing should complement, not replace, automated tests. Your idea to add Rspec tests to grades_helper.rb is an excellent one, don't forget to implement that.

Overall, well-done on identifying key areas of improvement in the code. Apply this keen sense of detail to your future work as it will serve you well! 

Best,

[Your Name]"
477,E1649,"Expertiza is an Open Source Software project developed by NCSU. It allows the instructor to create assignments as well as modify existing assignments. Students can signup for topics in an assignment and can submit articles, codes, web-sites etc. It is a web application built on Ruby on Rails framework. It also allows students to review the submissions that have been made other students. In the current implementation only the students can sign up for topics. Because of this, no higher authority (e.g instructor) can control the signups in a straightforward manner. If the instructor wishes to assign a particular topic to a team or remove a team from a particular topic then the instructor has to impersonate that student and sign up for the topic. Due, to the current implementation, you can neither handle the mistakes in signups , nor make modifications to the existing signups without impersonation. The new implementation allows an instructor to assign a particular topic to a team as well as remove a team from a topic.This functionality has been added in views/sign_up_sheet/_all_actions.html.erb which now has a '+' sign to assign a topic to a particular user. If the instructor clicks on this, then a view will appear which takes in the username of a student to be added. When the box is filled out and the “add” button clicked, then the indicated user’s team is signed up for the topic. If there are no slots available for that topic then the team will be put on the waiting list. There is also a 'X' sign that will help the instructor to remove a team from a topic. Some of the scenarios where the instructor might wish to add a team would be if the sign up deadline has passed, or if the instructor has decided to update the maximum number of teams allowed to choose a particular topic. The instructor might want to drop a team from the topic if the team doesn't want to proceed with the same topic for the assignment. With the new implementation, Instructors/Teaching Assistants do not need to go through the trouble of impersonating a student in order to add or drop their team from topics. We have chosen the nested if-else approach because there were many scenarios , all of which required us to take different actions. Changes were made in the following files - 1. controllers/sign_up_sheet_controller.rb 2. views/sign_up_sheet/_all_actions.html.erb 3. views/sign_up_sheet/assign_topic.html.erb 4. views/sign_up_sheet/remove_topic.html.erb Functions added to implement functionality :- 1. update_team 2. assign_topic 3. remove_team 4. remove_topic In the sign_up_sheet controller, two major methods were added: <image> <image> Two additional icons have been added in the Actions column. The ‘green plus’ icon allows you to add a team to the current topic. Clicking on the icon redirects you to a form, where the admin is required to enter the username of the person whose team he wishes to add. <image> Clicking submit then redirects back to the original page, with a flash message containing the status of the operation. <image> In case the topic has already been assigned the maximum number of teams, the new team is added to the waitlist. <image> The 'red cross' icon is used to remove a team from the given topic. Clicking on it takes the admin to a form, where he is required to enter the username of one of the team members belonging to the team that is to be removed. Submitting the form redirects the user back to the original page, with a flash message indicating the status of the remove operation. <image>. The system can take in individual users who don't have a team or topic and can add him/her to the existing teams that are enrolled for the topic. 1. <link> 2. <link> 3. <link>.","Very good job of describing the requirements and the ultimate functionality.  Screenshots well integrated into description.  Unfortunately, does not show the new code or describe its functionality.","The assignment is well-written and includes a comprehensive overview of the modified Expertiza program. You have done a commendable job detailing the existing issues with the software, along with the proposed solutions for those issues. It's evident that you have a clear understanding of the project and have properly invested time and efforts to come up with potential enhancements. 

However, there are a few details overlooked in your work. You provided an explanation of the changes made to the files but haven't given any justification as to why you chose those specific files to modify. Adding a specific reason for this would enhance your explanation, making it easier to understand your process better.

The reference to the images and links in your assignment is not clear. Please ensure you adequately integrate the images and links into your text so that their relevance in the context can be understood. 

I appreciate your detail about how the system can accommodate users who do not currently have a team, but there's a need for more clarity in this section. Does the system automatically add the user to existing teams, or does the user choose a team? 

Lastly, you briefly mentioned using a nested if-else approach but didn't explain why it was the most suitable given the context. It would also be useful to include some test cases demonstrating the scenarios where the new implementation works and whether there could be potential pitfalls or not.

In essence, you did a solid job on the assignment, exhibiting a strong comprehension of the project and sharing thorough analysis. Your work would benefit from just a few adjustments, mainly around the clarity of some patches, as stated above. Keep up the good work!"
479,E2070,"A response is the object that is created when someone fills out a review rubric, such as when one writes a review, gives feedback to a reviewer, or fills out a survey. Responses to the individual rubric items are kept in Answer objects; each Answer object has a response_id to say what Response it is part of. Since response_controller needs to work with many kinds of responses, its code is pretty general. It is not the worst controller in the system, but it would be much clearer if its method names were more descriptive of what they do. This project tries to modify and refactor the response_controller.rb in a more clear way. response_controller.rb response.rb. 1. def assign_instance_vars 2. def scores 3. def new 4. def set_questionnaire 5. def set_questionnaire_for_new_response 6. def show_calibration_results_for_students. Since most of the method involved in our project is private methods and all of the public methods in response controller were already tested. Thus, we will focus on testing methods we created in the model class: response.rb spec/models/response_spec.rb will be edit in order to test our methods. We did the following refactor to make this method more clear: 1. the instance variables are actually action handles to the views from controller including ""new"" and ""edit"", thus refactoring method name to assign_action_parameters would be better to understand what this method is trying to do. 2. This method is a private helper method and is used in new and edit methods to set the action parameters for the new and edit actions <image> 1. After renaming, the method became more clear of what it's doing <image>. 1. This method was already defined in other classes and is useless in the current class, thus remove it would be a reasonable choice. <image>. 1. In the method set_content in response_controller.rb, there is one line of code that ""new_response ? set_questionnaire_for_new_response : set_questionnaire"". Thus, we can tell the method set_qustionnaire will called when new_response is false, which means that the object was triggered by an existing response. In the method set_questionnaire, the line of code that “@questionnaire = @response.questionnaire_by_answer(answer)”, which is looking up the questionnaire answered by this existing response. Therefore, refactoring the method name to find_quesetionnaire would be better to understand. <image>. 1. In the method set_content in response_controller.rb, there is one line of code that ""new_response ? set_questionnaire_for_new_response : set_questionnaire"". Thus, we can tell the method set_qustionnaire will called when new_response is true, which means that the object was triggered by a new response. In the set_questionnaire_for_new_response method, the ""cast"" statement informs us that the new questionnaire are created based on the types or Reviewers, such as Review, Metareview, Teammate Review and so on. Therefore, refactoring the set_questionnaire_for_new_response method to create_new_questionnaire would be better to understand. <image>. 1. This method shows the result of expert review for reviewer after teacher or TA submit the calibration by editing the assignment. 2. The method makes about five database accesses and the code is quite messy and thus break it into 2 methods with the business logic moved to response.rb would be a good way to make the code in controller cleaner. <image> 1. The method get_questions_from_assignment is the part that's inside the model class and contains logic of mapping reviews with assignments in the questionnaire and return questions in the joined table <image>. <image>. <image>. <image>. 1. This method contains a complicated condition that determines whether the submission has been updated since the last time it was reviewed. If it has not, then the reviewer can edit his/her previous review. If there has been an update, then the reviewer gets a new review form to “update” the review. 2. So we break the new method into two methods: new and get_most_recent_response and put the logic into the response controller class. 3. The method get_most_recent_response in the model class tests whether there has been a review since the last file or link was submitted and in the controller this method was called to get the newest response. <image> 1. The new method after refactoring, now the code is quite clear and with only one appearance of variable ""@response"" <image>. <image>. <image>. <code>. Most of the method involved in our project is private methods and all of the public methods in response controller were already tested. Thus, we will focus on testing methods we created in the model class: response.rb spec/models/response_spec.rb will be edit in order to test our refactored methods <image>.","There are good descriptions of the code changes, but some of the Github diffs have very small type and are thus hard to read.  Screenshots for show_calibration_page are just dropped into the narrative without any structure or explanation.  That is also true of the new method.  The description of the Rspec tests should be more detailed.","Thank you for your well-detailed approach to refactoring response_controller.rb and the thoughtful justification provided for renaming and restructuring several methods. Your group has demonstrated a good understanding of the principle of making code more readable and maintainable.

Here's a few pointers to make your assignment submission even better:

1. For each of the changes you proposed, it would be beneficial to include snippets of the original code and the refactored code side by side for easier comparison. Your description was clear, but having a visual comparison would provide an immediate understanding of the changes you made.

2. You have done a great job of explaining the reasoning behind your changes. However, try to make sure these explanations are concise and straightforward. In some sections, the explanations were extensive which could make it a bit difficult for others to follow.

3. You mentioned that you refactored several methods and moved some logic from the controllers to the models. Break down how this increases the modularity of the code, which is a crucial part of software design.

4. While you mentioned that you tested the new methods in the model class, details of the test cases and the results would be helpful to understand if the refactoring is done correctly and does not introduce new bugs.

5. Before diving into the refactor process, provide a brief overview of the purpose of response_controller.rb and its role within the broader system. This would help set context for your work.

Keep up the good work! Your commitment to refactoring for enhanced clarity is commendable and an important aspect of software engineering."
482,E2022,"<link> provides a feature to peer review other teams assignments/projects after the submission deadline. Peer reviewing is usually done immediately (within one or two days) after the submission deadline, so that the students get a feedback on their work as soon as they complete it. Then the students are allowed to re-submit the project based on the reviews they get. A constructive review will help students to improve their project in a better way. Even though advice is given by instructors on how to make a good review, students sometimes find difficulty in providing a helpful review. The quality of the reviews can be improved if students are shown some example reviews while they peer review. These example reviews can either be taken from the assignment of current semester or from the same/related project of previous semesters. The objective of the project is to add a feature to show some good sample reviews while the students peer review other teams work. To enable this, students while submitting their peer review give a consent on whether their reviews can be shown as an example to others. Instructors then select a subset of these reviews to be posted as an example reviews. These example reviews are shown in the peer review page (Other's work link) to the entire class. Additionally, 1. Students should be able to see an entire review, both text and ratings, not just a single comment. 2. The student view should not show the name of the reviewer or the reviewee. The views of power users such as TA, instructor, admin should show these names. 3. The student can remove their consent anytime, and the sample review should no longer be visible to other students. This project was implemented twice before and it was last done in Fall 2019. Though their implementation worked from the UI perspective, there were problems in the code so it was not merged. Some of the problems of the previous work are 1. There were many unexplained code blocks. These code blocks where acquired from previous implementation and the last team seem to have retained it so that the build passes. 2. Project included many irrelevant files and included classes the team didn't understand. 3. Testing was not thorough. We almost follow the same design as previous work, but we will do our own implementation so that the above problems are addressed. In the order of flow, 1. Student's Consent: In each review assignment, there will be a checkbox that says ""I agree to share my review as a sample for others"" then students can decide to check this box or not just before they submit reviews. Similarly, the student can revert it back to 'private' anytime. This could be implemented by the simple addition of a checkbox in response/view.html.erb and set a ""visibility"" field to “public”of the Response object via a controller method, ""toggle_permission"". Sequence Diagram: <image> 2. Instructor's Selection: The instructor can select from among the ""public"" reviews and decides which to make visible to other students doing a particular assignment, i.e. all participants in that assignment. And this will set the “visibility” field to “publish”. Specifically, the instructor first goes to “View review report” and clicks on one team name (in the “Team reviewed” column). Then in the popup/team_users_popup page we need to add a button (better put it at top right) named “make this review an example”. If this review has already been shown as an example, the button should be “remove this review from examples” instead. Sequence Diagram: <image> 3. List of Sample Reviews: A participant can see these ""exemplary"" reviews by going to ""Others' work"" for the assignment in question, and clicking on one or more links that say, e.g., ""Sample review"". And it should be shown just below the title “Review for ...”. It could be implemented on the student_reviews/list.html.erb . Sequence Diagram: <image>. 1. Use Cases - <image> Power Users: Instructors, TAs, Admins and Super Admins. To identify the reviews to be shown as an example, we append a column to the responses table representing their respective status. The following table explains the significance of each value: <table> 1. Schema: Update the schema with the following column changes via migrations. 1) Add 'visibility' column to responses 2) Add new Table 'sample_reviews' 2. Mapping of Reviews and Assignment: The example reviews can either be taken from an assignment of the current course or it could be from an assignment from a previous course. This would enable students working on OSS Project to see OSS Project reviews from a previous semester. One idea is that when clicking to “make this review an example”, it will link to a page where you can select an assignment to which you have access (the same as the list of “Assignment” in the tree_display), then the example review will be shown to all participants of that specific assignment. We also need to do the same thing for “remove this review from examples”. Since we are adding the visibility field in responses table, we maintained the mapping of each response and assignment in another table i.e. sample_reviews . 3. MVC Setup: We would need to create new partials in various views, and possibly a helper for response_controller.rb. We could achieve that by creating a MVC setup for the entire flow. 1. Database changes: Added a column visibility in responses table. 2. Added a checkbox to select whether reviews could be shown as an example in the response views - /app/views/response/response.html.erb 3. On selecting the checkbox, update the visibility field in responses table in response controller - /app/controllers/response_controller.rb 4. The reviews which are marked as public by the students are marked with a tick mark in the review report views for the instructors. For this changes were made in the file _review_report.html.erb. A tick mark is shown if the visibility status of a response is public or published. To check for the visibility status a method visibility_public? is added in review_mapping_helper. 5. To allow instructor to select among the public reviews to shown as examples to all students a button 'Mark as an example' in the popup views. Changes corresponding to this is made in /app/views/popup/team_users_popup.html.haml 5. To enable students to see the example reviews, a link Sample reviews is added in the Other's work page. Made changes in the views of student_review - /app/views/student_review/list.html.erb. The previous approach for DB design added two new database tables to store the status and association of sample reviews, namely, samplereviewmaps and similar_assignments . The samplereviewmaps table simple stored two foreign key associations to review_map id and to the assignment_id. In our approach, we are extending the existing responses table to contain an additional field, 'visibility', that stores the status of the response(review), as suggested in the above approach. This approach would prune the need to add an extra DB table, which would store redundant information. Additionally, the similar_assignments table would store the association for a response to all the assignments, the instructor/TA decide to publish for. <image>. Our test plan includes testing through rspec tests and through GUI. As a Student (Scenario 1): Student giving consent to make their review public 1. Log in. 2. Click on Assignments 3. List of assignments is displayed. 4. Click on any assignment for which the review has to be submitted. 5. Assignment task page is displayed. 6. Click on ""Other's work"" to open the reviews summary page (at /student_review). 7. Chose to review any of the teams' assignments that are displayed. 8. Select a team for review and fill in the review. 9. Before submitting the review, select the checkbox that says ""I agree to share this review anonymously as an example to the entire class"". 10. After clicking on the submit button, the review submitted has been made public. As a Student (Scenario 2): Showing all the available sample reviews for respective assignment 1. Log in. 2. Click on Assignments 3. List of assignments is displayed. 4. Click on any assignment for which the review has to be submitted. 5. Assignment task page is displayed. 6. Click on ""Other's work"" to open the reviews summary page (at /student_review). 7. Below the heading ""Reviews for ..."", click on the ""Sample reviews"" link. 8. This opens a page where the student can view all example reviews for that assignment. As a Power User (TA/Instructor/Admin/Super Admin): Mark the review an example 1. Log in 2. Click on Manage->Assignments 3. Displays a list of Assignments 4. Click View Report/Review for a particular assignment. 5. Displays a list of reviews submitted by students. 6. Click on any review with a tick mark in ""team reviewed"" column for a particular student. 7. Displays the summary of reviews submitted by that student, with a ""Make as an example"" button on the right of every review. 8. Click on ""Make as an example"" for the intended reviews, which opens a popup that displays a list of all assignments that are a part of the instructor's courses. 9. From this list select all assignments for which the review has to be shown as a sample. 10. Click on 'Publish Sample Reviews' after selection (this closes the popup). 11. Navigate to view reviews of that particular assignment and click on ""Sample Reviews"". 12. A new page is opened that lists out all the sample reviews of the assignment. The following acceptance tests using the RSpec/Capybara tests are written. The first set of tests are for testing scenario of i) a student making his review public/private and i) student viewing the sample reviews. The second set of tests are for testing i) instructor marking a review as an example and ii) selecting the assignments to which the reviews has to be shown. <code> <code>. Pull request: <link> Repository link: <link> Previous Team's Work: <link>.","The prose is quite readable.  The sequence diagrams are decreasing in size from the first to the last, not clear why.  The code changes are not described in any detail, and they should be.  For the automated tests, a narrative could have described what they were testing, instead of leaving the reader to look at the code.","Thank you for your submission. The detailed understanding of the previous work and the issues encountered, along with the elaboration of your methods to overcome them in this project, is much appreciated. You've also outlined your project's objective well, which displays a good grasp of the task at hand.

The design flow with focus on the user experience, ensuring the privacy and consent of the students, and offering the instructors the ability to select and publish reviews as examples, is very thoughtful and displays good planning. The clear definition of the roles and the rights of the various users is also commendable.

While reading, I have noted a few points of improvement:
1. There should have been more emphasis on the testing strategy. Including unit, integration, and regression tests will ensure your project is of the highest quality.
2. A detailed risk assessment and a potential mitigation plan must be included in the initial project report. Assessing the possible issues during and after implementation helps in preparing preventive measures beforehand.
3. It would have been helpful if you had included some detail about any libraries, frameworks, or languages you intend to use for the implementation.

Please ensure to include these in your final report and good luck with your project. Also, please share the design diagrams and any other relevant visuals for a more in-depth review."
483,E2077,"Currently, Expertiza has no way to associate mentors with teams. For assignments with topics, like the OSS project, mentors are associated with topics, and then whichever team is assigned to the topic inherits the mentor for that topic, However, for assignments without topics (like Program 2), there is no good way to “automatically” assign mentors to projects. Keeping this in mind our code is set to work under the following conditions: 1. Assignment teams created for an assignment without topics 2. Mentors ( Instructors and TAs ) are only assigned to assignment teams if they have been added to an assignment as participants We've created the following <link> to demonstrate the added functionality. As well as the following <link> which demonstrates what happens when teams are created when no mentors have been added as participants to an assignment. 1. Assign a TA or instructor as a mentor for a team created for an assignment without topics. We learned from previous implementations and looked to avoid the following pitfalls when implementing our solution: 1. Code was merged from the previous team, but not refactored, so a lot of unused code remained. 2. Should have followed a better naming convention for methods 3. Some redundant codes in the views could be DRYed out. 4. Commented code should be removed. 5. Some complex logic is added but not explained in the comments. 6. Code should be placed in most relevant classes. (E.g. Do not put email code in the Team class). 7. Documentation doesn't accurately represent implementation. 8. Lacked sufficient detail for Test section. <link>. Our implementation begins when an assignment team is created. If the assignment is associated with a topic, the created team will not be assigned a mentor. If the assignment does not have a topic, a hash of potential mentors is retrieved. This hash is created from the TAs and instructors added to the assignment as participants. The keys of the hash correspond to the mentor's participant id while their values are the number of times the mentor has been assigned to mentor teams. The mentor with the lowest number of assigned teams will be the next mentor assigned to a newly created team. Once the team is assigned a mentor, an email is sent out to the mentor and students in the team to notify them of their mentor assignment. First Design: <image> Ultimately we were able to implement the following design: Final Design: <image> We created the following assignment_teams_mentors table with the following connections to existing tables. The new table created is responsible for storing all the mentors assigned to the various teams created. In order to do so, the assignment_team_mentors table will reference the participants and teams tables. <image> We will also modify the participants table to add an additional Boolean column, can_mentor . This column will help determine what TAs and instructors can mentor for a specified assignment. Currently instructors see the corresponding view when looking at teams associated with an assignment: <image> Our team proposed adding an additional ""Mentors"" column in the instructor view: <image> Currently students see the corresponding view when looking at their team for an assignment: <image> Our team originally proposed to add an additional ""Mentors"" section in the student view: <image>. These are the files we have modified/created throughout our project and a brief excerpt about what was done: Database 1. Schema.rb 1.1. Created assignment_team_mentors table which references the participants table and teams tables thru foreign keys created with the assignment_team_mentors_id column and assignment_team_id column. The assignment_team_mentors table is responsible for storing all the mentors assigned to the various assignment teams created. 1.2. Created a can_mentor column for the participants table in order to be able to know who was a mentor and who was a student. <image> Models 1. assignment_team_mentor.rb 1.1. Responsible for ensuring mentor with the least number of teams mentored, gets assigned to the next team created. 1.2. Started to add mailer functionality for notifying the mentor assigned. <image> 1. assignment_team.rb 1.1. Established a has_one: active record relation with AssignmentTeamMentor model. This ensures a team only has one team mentor. <image> 1. participant.rb 1.1. Established a has_many: active record relation with AssignmentTeamMentor model. This provides the flexibility of a potential mentor added as a participant to an assignment, to mentor multiple teams created for an assignment. <image> 1. 1.1. Added a function to set the new can_mentor column for a participant. 1.2. Added a function to get a list of all participants who can be mentors for a specified assignment based on the can_mentor column. <image> Controllers 1. teams_controller.rb 1.1. The following code was added within the create method. 1.2. Calls on AssignmentTeamMentor to assign mentor for instructor created teams. Will generate notice if unable to assign mentor to recently created team. <image> 1. 1.1. The following code was added within the list method. 1.2. A hash is generated with the assigned mentor of each team. <image> 1. student_teams_controllers.rb 1.1. The following code was added within the create method. 1.2. Calls on AssignmentTeamMentor to assign mentor for student created teams. Will generate notice if unable to assign mentor to recently created team. <image> 1. 1.1. The following code was added within the view method. <image> 1. teams_user_controller.rb 1.1. added code to send the email when a user is added to a team to the mentor. 2. participants_controller.rb 1.1. updates the can_mentor column of a participant when they are added to an assignment Views 1. views/tree_display/_page_footer.html.erb 1.1. displays mentor column header. <image> 1. views/tree_display/_row_header.html.erb 1.1. displays either mentor assigned or ""No mentor assigned"" for team level. For team participant level, blank cell is displayed. <image> 1. views/student_teams/view.html.erb 1.1. responsible for displaying to a student the mentor assigned to their team for an assignment. <image> 1. views/mailer/notify_member.html.erb 1.1. responsible for managing the template of the mail sent to the mentor Mailers 1. app/mailers/mailer.rb 1.1. responsible for managing the mailer functionally for notifying the member Rspec 1. assignment_team_mentor_spec.rb <image> 1. participant_spec.rb 1.1. The following tests were added to validate our changes made to the Participant model. <image>. The following are scenarios our team has thought about: Edge Case 1: How will we handle the ""Has topic?"" check box being changed when editing the assignment in the instructor view. This button is how we decide if we need to assign mentors to a team. <code> <image> Edge Case 2: No mentors exist <code>. RSpec test to check: 1. Validation of the model created (AssignmentTeamMentor) and the model modified (Participant). As an instructor we were able to confirm the following UI changes after mentors were assigned to teams: <image> As a student we were able to confirm the following UI changes when a mentor has been assigned to their team: <image> The following <link> further expands on this UI testing. As an instructor we were able to confirm the following UI changes after teams were created when no mentors had been added participants: <image> As a student we were able to confirm the following UI changes when a team was created without mentor participants for the assignment: <image> The following <link> further expands on this UI testing. 1. Providing ability to manually select the mentor for a team created. Such as providing a drop down list of available mentors to choose from in the following view. <image> 1. Refactor email functionality code and continue to develop to allow for the assignment team members to be notified of new assigned mentor or any other added members. <image>. <link> <link> <link> <link> <link>.","The changes are comprehensively described.  However, the are described in the microcosm; there really isn't any prose explaining how the different modified files work together.  Some of the code snippets are pretty long and should be broken up so that prose descriptions can be given of the various methods implemented by the project.  In particular, the RSpec tests need more description.  In the description of manual testing, ""after"" screenshots are shown; ""before"" screenshots would have been helpful too.","Your assignment showcases an excellent understanding of the functionality you're trying to implement. You have done an extremely thorough job outlining each part of your implementation and explaining the code structure. It is particularly commendable how you addressed potential issues by identifying pitfalls to avoid and considering various edge-case scenarios. 

The different modifications to the database and models are logically explained, and the aim to maintain distinct responsibilities of each model is evident from your design. Creating a new column in the participants table to identify potential mentors is a good approach to manage mentors assignments. This shows thoughtful planning and an understanding of industry standards. 

The reasoning for editing the controllers is clear and the functionality added is purposeful. You also have a good grasp of view handling and the need to display appropriate information to users. 

The effort put into testing, including UI and model testing, is also commendable. Validating changes, especially to fundamental elements like the Participant model, is an essential step that not all teams remember to include.

However, the assignment would benefit from more clarity in some parts.
1. Links and images referenced in the text were not included in the submission. These would provide crucial visual aid for an understanding of the workflow and design.
2. Code samples would help to understand the working and integration of the various parts discussed.
3. The section on pitfalls can be improved by explicitly tying each challenge to its solution in your implementation.
4. It might also be helpful to include user feedback or user testing results, if any, to validate your design choices and user interface.
5. You did not mention handling situations where there are more teams than available mentors which might lead to an imbalance. How would your implementation address this scenario?
6. Consider adding performance considerations especially in scenarios where there are a large number of assignments, teams or mentors.

Regardless, you have shown diligence, understanding, planning and quality work in this assignment. The work you have put into documenting the process thoroughly and thinking about possible edge cases is very praiseworthy. Excellent work!"
